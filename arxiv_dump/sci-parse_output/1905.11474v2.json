{
  "abstractText": "Although \u201dblack box\u201d models such as Artificial Neural Networks, Support Vector Machines, and Ensemble Approaches continue to show superior performance in many disciplines, their adoption in the sensitive disciplines (e.g., finance, healthcare) is questionable due to the lack of interpretability and explainability of the model. In fact, future adoption of \u201dblack box\u201d models is difficult because of the recent rule of \u201dright of explanation\u201d by the European Union where a user can ask for an explanation behind an algorithmic decision, and the newly proposed bill by the US government, the \u201dAlgorithmic Accountability Act\u201d, which would require companies to assess their machine learning systems for bias and discrimination and take corrective measures. Top Bankruptcy Prediction Models are A.I.-Based and are in need of better explainability\u2013the extent to which the internal working mechanisms of an AI system can be explained in human terms. Although explainable artificial intelligence is an emerging field of research, infusing domain knowledge for better explainability might be a possible solution. In this work, we demonstrate a way to collect and infuse domain knowledge into a \"black box\" model for bankruptcy prediction. Our understanding from the experiments reveals that infused domain knowledge makes the output from the black box model more interpretable and explainable.",
  "authors": [
    {
      "affiliations": [],
      "name": "Sheikh Rabiul Islam"
    },
    {
      "affiliations": [],
      "name": "William Eberle"
    },
    {
      "affiliations": [],
      "name": "Sid Bundy"
    },
    {
      "affiliations": [],
      "name": "Sheikh Khaled Ghafoor"
    }
  ],
  "id": "SP:4fb33a5319caa7df5664a66e3159998a90c0f3f5",
  "references": [
    {
      "authors": [
        "n. d"
      ],
      "title": "Algorithmic Accountability",
      "venue": "Retrieved April 20,",
      "year": 2019
    },
    {
      "authors": [
        "n. d"
      ],
      "title": "Explainable Artificial Intelligence",
      "venue": "Retrieved April 20,",
      "year": 2019
    },
    {
      "authors": [
        "n. d"
      ],
      "title": "Scikit-learn: Machine Learning in Python",
      "venue": "Retrieved May",
      "year": 2019
    },
    {
      "authors": [
        "n. d"
      ],
      "title": "SHAP vs LIME",
      "venue": "RetrievedMay",
      "year": 2019
    },
    {
      "authors": [
        "n. d"
      ],
      "title": "Single Family Loan Level Dataset - Freddie Mac",
      "venue": "Retrieved May",
      "year": 2019
    },
    {
      "authors": [
        "Rakesh Agrawal",
        "Ramakrishnan Srikant"
      ],
      "title": "Fast algorithms for mining association rules",
      "venue": "In Proc. 20th int. conf. very large data bases, VLDB,",
      "year": 1994
    },
    {
      "authors": [
        "Hafiz A Alaka",
        "Lukumon O Oyedele",
        "Hakeem A Owolabi",
        "Vikas Kumar",
        "Saheed O Ajayi",
        "Olugbenga O Akinade",
        "Muhammad Bilal"
      ],
      "title": "Systematic review of bankruptcy prediction models: Towards a framework for tool selection",
      "venue": "Expert Systems with Applications",
      "year": 2018
    },
    {
      "authors": [
        "Rodrigo Alfaro",
        "Natalia Gallardo"
      ],
      "title": "The determinants of household debt default",
      "year": 2012
    },
    {
      "authors": [
        "Scott Anderson",
        "Janet Jozwik"
      ],
      "title": "Building a Credit Model Using GSE Loan-Level Data",
      "venue": "Journal of Structured Finance 20,",
      "year": 2014
    },
    {
      "authors": [
        "Saabas Ando"
      ],
      "title": "n. d.]. Interpreting random forests",
      "venue": "Retrieved April",
      "year": 2019
    },
    {
      "authors": [
        "Eliana Angelini",
        "Giacomo di Tollo",
        "Andrea Roli"
      ],
      "title": "A neural network approach for credit risk evaluation",
      "venue": "The quarterly review of economics and finance 48,",
      "year": 2008
    },
    {
      "authors": [
        "Gaetano Antinolfi",
        "Celso Brunetti",
        "Jay Im"
      ],
      "title": "Mortgage rates and credit risk: Evidence from mortgage pools",
      "venue": "Available at SSRN",
      "year": 2016
    },
    {
      "authors": [
        "Sebastian Bach",
        "Alexander Binder",
        "Gr\u00e9goire Montavon",
        "Frederick Klauschen",
        "Klaus-Robert M\u00fcller",
        "Wojciech Samek"
      ],
      "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
      "venue": "PloS one 10,",
      "year": 2015
    },
    {
      "authors": [
        "Jodi L Bellovary",
        "Don E Giacomino",
        "Michael D Akers"
      ],
      "title": "A review of bankruptcy prediction studies: 1930 to present",
      "venue": "Journal of Financial education",
      "year": 2007
    },
    {
      "authors": [
        "P Berka"
      ],
      "title": "Using the LISp-Miner System for Credit Risk Assessment",
      "venue": "Neural Network World 26,",
      "year": 2016
    },
    {
      "authors": [
        "Arnab Bhattacharya",
        "Simon PWilson",
        "Refik Soyer"
      ],
      "title": "A Bayesian approach to modeling mortgage default and prepayment",
      "venue": "European Journal of Operational Research 274,",
      "year": 2019
    },
    {
      "authors": [
        "Bernhard E Boser",
        "Isabelle M Guyon",
        "Vladimir N Vapnik"
      ],
      "title": "A training algorithm for optimal margin classifiers",
      "venue": "In Proceedings of the fifth annual workshop on Computational learning theory",
      "year": 1992
    },
    {
      "authors": [
        "Michael G Bradley",
        "Amy Crews Cutts",
        "Wei Liu"
      ],
      "title": "Strategic mortgage default: The effect of neighborhood factors",
      "venue": "Real Estate Economics 43,",
      "year": 2015
    },
    {
      "authors": [
        "Sewin Chan",
        "Andrew Haughwout",
        "Andrew Hayashi",
        "andWilbert Van der Klaauw"
      ],
      "title": "Determinants of mortgage default and consumer credit use: the effects of foreclosure laws and foreclosure delays",
      "venue": "Journal of Money, Credit and Banking",
      "year": 2016
    },
    {
      "authors": [
        "B Chandrasekaran",
        "Michael C Tanner",
        "John R Josephson"
      ],
      "title": "Explaining control strategies in problem solving",
      "venue": "IEEE Intelligent Systems",
      "year": 1989
    },
    {
      "authors": [
        "Anupam Datta",
        "Shayak Sen",
        "Yair Zick"
      ],
      "title": "Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems",
      "venue": "IEEE symposium on security and privacy (SP)",
      "year": 2016
    },
    {
      "authors": [
        "Cem Demiroglu",
        "Evan Dudley",
        "Christopher M James"
      ],
      "title": "State foreclosure laws and the incidence of mortgage default",
      "venue": "The Journal of Law and Economics 57,",
      "year": 2014
    },
    {
      "authors": [
        "Ronel Elul",
        "Nicholas S Souleles",
        "Souphala Chomsisengphet",
        "Dennis Glennon",
        "Robert Hunt"
      ],
      "title": "What\" triggers\" mortgage default",
      "venue": "American Economic Review 100,",
      "year": 2010
    },
    {
      "authors": [
        "Hanming Fang",
        "You Kim",
        "Wenli Li"
      ],
      "title": "The dynamics of subprime adjustable-rate mortgage default: a structural estimation",
      "year": 2016
    },
    {
      "authors": [
        "Trevor Fitzpatrick",
        "Christophe Mues"
      ],
      "title": "An empirical comparison of classification algorithms for mortgage default prediction: evidence from a distressed mortgage market",
      "venue": "European Journal of Operational Research 249,",
      "year": 2016
    },
    {
      "authors": [
        "Christopher L Foote",
        "Paul S Willen"
      ],
      "title": "Mortgage-default research and the recent foreclosure crisis",
      "venue": "Annual Review of Financial Economics",
      "year": 2018
    },
    {
      "authors": [
        "Hamilton Fout",
        "Grace Li",
        "Mark Palim",
        "Ying Pan"
      ],
      "title": "Credit risk of low income mortgages",
      "venue": "Regional Science and Urban Economics",
      "year": 2018
    },
    {
      "authors": [
        "Jerome H Friedman"
      ],
      "title": "Greedy function approximation: a gradient boosting machine",
      "venue": "Annals of statistics",
      "year": 2001
    },
    {
      "authors": [
        "Pierre Geurts",
        "Damien Ernst",
        "Louis Wehenkel"
      ],
      "title": "Extremely randomized trees",
      "venue": "Machine learning 63,",
      "year": 2006
    },
    {
      "authors": [
        "Andra C Ghent",
        "Marianna Kudlyak"
      ],
      "title": "Recourse and residential mortgage default: evidence from US states",
      "venue": "The Review of Financial Studies 24,",
      "year": 2011
    },
    {
      "authors": [
        "Bryce Goodman",
        "Seth Flaxman"
      ],
      "title": "European Union regulations on algorithmic decision-making and a \u00e2\u0102IJright to explanation\u00e2\u0102\u0130",
      "venue": "AI Magazine 38,",
      "year": 2017
    },
    {
      "authors": [
        "Laurie S Goodman",
        "Brian Landy",
        "Roger Ashworth",
        "Lidan Yang"
      ],
      "title": "A Look at Freddie Mac\u2019s Loan-Level Credit Performance Data",
      "venue": "Journal of Structured Finance 19,",
      "year": 2014
    },
    {
      "authors": [
        "Daniel Greenwald"
      ],
      "title": "The mortgage credit channel of macroeconomic transmission",
      "year": 2018
    },
    {
      "authors": [
        "Joseph Gyourko",
        "Joseph Tracy"
      ],
      "title": "Reconciling theory and empirics on the role of unemployment in mortgage default",
      "venue": "Journal of Urban Economics",
      "year": 2014
    },
    {
      "authors": [
        "Alireza Hooman",
        "Govindan Marthandan",
        "Wan Fadzilah Wan Yusoff",
        "Mohana Omid",
        "Sasan Karamizadeh"
      ],
      "title": "Statistical and data mining methods in credit scoring",
      "venue": "The Journal of Developing Areas 50,",
      "year": 2016
    },
    {
      "authors": [
        "Sheikh Rabiul Islam"
      ],
      "title": "An efficient technique for mining bad credit accounts from both olap and oltp",
      "year": 2018
    },
    {
      "authors": [
        "Sheikh Rabiul Islam",
        "William Eberle",
        "Sheikh Khaled Ghafoor"
      ],
      "title": "Credit default mining using combined machine learning and heuristic approach",
      "year": 2018
    },
    {
      "authors": [
        "Sheikh Rabiul Islam",
        "Sheikh Khaled Ghafoor",
        "William Eberle"
      ],
      "title": "Mining Illegal Insider Trading of Stocks: A Proactive Approach",
      "venue": "IEEE International Conference on Big Data (Big Data)",
      "year": 2018
    },
    {
      "authors": [
        "Kadiri Karamon",
        "Douglas McManus",
        "Jun Zhu"
      ],
      "title": "Refinance and Mortgage Default: A Regression Discontinuity Analysis of HARP\u00e2\u0102\u0179s Impact on Default Rates",
      "venue": "The Journal of Real Estate Finance and Economics 55,",
      "year": 2017
    },
    {
      "authors": [
        "Amir E Khandani",
        "Adlar J Kim",
        "Andrew W Lo"
      ],
      "title": "Consumer credit-risk models via machine-learning algorithms",
      "venue": "Journal of Banking & Finance 34,",
      "year": 2010
    },
    {
      "authors": [
        "You Suk Kim",
        "Steven M Laufer",
        "Richard Stanton",
        "NancyWallace",
        "Karen Pence"
      ],
      "title": "Liquidity crises in the mortgage market",
      "venue": "Brookings Papers on Economic Activity 2018,",
      "year": 2018
    },
    {
      "authors": [
        "H\u00e5vard Kvamme",
        "Nikolai Sellereite",
        "Kjersti Aas",
        "Steffen Sjursen"
      ],
      "title": "Predicting mortgage default using convolutional neural networks",
      "venue": "Expert Systems with Applications",
      "year": 2018
    },
    {
      "authors": [
        "Tao Lei",
        "Regina Barzilay",
        "Tommi Jaakkola"
      ],
      "title": "Rationalizing neural predictions",
      "venue": "arXiv preprint arXiv:1606.04155",
      "year": 2016
    },
    {
      "authors": [
        "Stan Lipovetsky",
        "Michael Conklin"
      ],
      "title": "Analysis of regression in game theory approach",
      "venue": "Applied Stochastic Models in Business and Industry 17,",
      "year": 2001
    },
    {
      "authors": [
        "Zachary C Lipton"
      ],
      "title": "The mythos of model interpretability",
      "venue": "arXiv preprint arXiv:1606.03490",
      "year": 2016
    },
    {
      "authors": [
        "Bo Liu",
        "Tien Foo Sing"
      ],
      "title": "\u00e2\u0102IJCure\u00e2\u0102\u0130 Effects and Mortgage Default: A Split Population Survival Time Model",
      "venue": "The Journal of Real Estate Finance and Economics 56,",
      "year": 2018
    },
    {
      "authors": [
        "David Low"
      ],
      "title": "Mortgage default with positive equity",
      "venue": "Job Market Paper,",
      "year": 2015
    },
    {
      "authors": [
        "Scott M Lundberg",
        "Su-In Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "In Advances in Neural Information Processing Systems",
      "year": 2017
    },
    {
      "authors": [
        "Tim Miller"
      ],
      "title": "Explanation in artificial intelligence: Insights from the social sciences",
      "venue": "Artificial Intelligence",
      "year": 2018
    },
    {
      "authors": [
        "Stephanie Moulton",
        "Donald Haurin",
        "Wei Shi"
      ],
      "title": "Reducing default rates of reverse mortgages",
      "venue": "Issue in Brief 16",
      "year": 2016
    },
    {
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "title": "Why should i trust you?: Explaining the predictions of any classifier",
      "venue": "In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",
      "year": 2016
    },
    {
      "authors": [
        "Avanti Shrikumar",
        "Peyton Greenside",
        "Anshul Kundaje"
      ],
      "title": "Learning important features through propagating activation differences",
      "venue": "In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org,",
      "year": 2017
    },
    {
      "authors": [
        "Justin Sirignano",
        "Kay Giesecke"
      ],
      "title": "Risk analysis for large pools of loans",
      "venue": "Management Science 65,",
      "year": 2018
    },
    {
      "authors": [
        "Justin Sirignano",
        "Apaar Sadhwani",
        "Kay Giesecke"
      ],
      "title": "Deep learning for mortgage risk",
      "venue": "arXiv preprint arXiv:1607.02470",
      "year": 2016
    },
    {
      "authors": [
        "David J Sorenson"
      ],
      "title": "Loan Characteristics, Borrower Traits, and Home Mortgage Foreclosures: The Case of Sioux Falls, South Dakota",
      "venue": "Journal of Regional Analysis and Policy",
      "year": 2015
    },
    {
      "authors": [
        "MR SOUSA",
        "J GAMA",
        "E BRAND\u00c3O"
      ],
      "title": "Stress-testing the return on lending under real extreme adverse circumstances",
      "venue": "In European Financial Management Association annual conference. Amsterdam: EFMA",
      "year": 2015
    },
    {
      "authors": [
        "Maria Rocha Sousa",
        "Jo\u00e3o Gama",
        "El\u00edsio Brand\u00e3o"
      ],
      "title": "Links between Scores, Real Default and Pricing: Evidence from the Freddie Mac\u00e2\u0102\u0179s Loan-level Dataset",
      "venue": "Journal of Economics, Business and Management 3,",
      "year": 2015
    },
    {
      "authors": [
        "Maria Rocha Sousa",
        "Jo\u00e3o Gama",
        "El\u00edsio Brand\u00e3o"
      ],
      "title": "A new dynamic modeling framework for credit risk assessment",
      "venue": "Expert Systems with Applications",
      "year": 2016
    },
    {
      "authors": [
        "Erik \u0160trumbelj",
        "Igor Kononenko"
      ],
      "title": "Explaining prediction models and individual predictions with feature contributions",
      "venue": "Knowledge and information systems 41,",
      "year": 2014
    },
    {
      "authors": [
        "William R Swartout"
      ],
      "title": "Rule-based expert systems: The mycin experiments of the stanford heuristic programming project: BG",
      "year": 1985
    },
    {
      "authors": [
        "William R Swartout",
        "Johanna D Moore"
      ],
      "title": "Explanation in second generation expert systems",
      "venue": "In Second generation expert systems",
      "year": 1993
    },
    {
      "authors": [
        "Chao Yue Tian",
        "Roberto G Quercia",
        "Sarah Riley"
      ],
      "title": "Unemployment as an adverse trigger event for mortgage default",
      "venue": "The Journal of Real Estate Finance and Economics 52,",
      "year": 2016
    },
    {
      "authors": [
        "Rick L Wilson",
        "Ramesh Sharda"
      ],
      "title": "Bankruptcy prediction using neural networks",
      "venue": "Decision support systems 11,",
      "year": 1994
    },
    {
      "authors": [
        "Yifei Wu",
        "Jeffrey H Dorfman"
      ],
      "title": "Reducing residential mortgage default: Should policy act before or after home purchases",
      "venue": "PloS one 13,",
      "year": 2018
    },
    {
      "authors": [
        "Scott Cheng-Hsin Yang",
        "Patrick Shafto"
      ],
      "title": "Explainable Artificial Intelligence via Bayesian Teaching",
      "venue": "In NIPS 2017 workshop on Teaching Machines,",
      "year": 2017
    }
  ],
  "sections": [
    {
      "text": "CCS CONCEPTS \u2022 Computing methodologies\u2192 Inductive logic learning.\nKEYWORDS Artificial Intelligence, explainability, interpretability, bankruptcy prediction model, domain knowledge\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Submitted to KDD \u201919, August, 2019, USA \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-9999-9/18/06. . . $15.00 https://doi.org/preprint\nACM Reference Format: Sheikh Rabiul Islam, William Eberle, Sid Bundy, and Sheikh Khaled Ghafoor. 2019. Infusing domain knowledge in AI-based \"black box\" models for better explainability with application in bankruptcy prediction. In KDD \u201919: 2nd KDD Workshop on Anomaly Detection in Finance,August 04\u201308, 2019, Anchorage, Alaska - USA. ACM, New York, NY, USA, 9 pages. https://doi.org/ preprint"
    },
    {
      "heading": "1 INTRODUCTION",
      "text": "Over the past few years, the field of Artificial Intelligence (AI) has gained enormous interest for its practical success in many application areas. Recent advances in machine learning and artificial intelligence have given rise to many complex and powerful models which are being adopted in many sophisticated areas such as medical, finance, and cyber-security. Some of the more notable models are Artificial Neural Networks (ANN), Genetic Algorithms (GA), Support Vector Machines (SVM), and Ensemble Approaches. Sometimes these models are called \u201dblack box\u201d models. Although the high complexity of the models\u2019 non-linear functions come with good predictive power for black box models, they are limited by their explanation and interpretation capabilities. Which is followed by a lack of trust in the model and the decisions it makes.\nIn response to that issue, as a precaution to fight the unethical use of AI and biases in decision making, governments are trying to introduce and enforce new laws and regulations. For instance, the European Union implemented the rule of \u201dright of explanation\u201d, where a user can ask for an explanation of an algorithmic decision [40]. In addition, more recently, the US government has introduced a new bill called the \u201dAlgorithmic Accountability Act\u201d [1] which would require companies to assess their machine learning systems for bias and discrimination and take corrective measures. Should the bill pass, it will be enforced by the US Federal Trade Commission which is in charge of consumer protection and antitrust regulation.\nBlack box models are frequently used in the financial area, particularly towards bankruptcy prediction. In particular, the main focus of bankruptcy prediction is to predict the probability that the customer will be in default or bankrupt in the near future. The high rate of bankruptcy affects heavily the firm\u2019s owners, partners, society, and the overall economic condition of the country in general [15]. According to literature reviews by Alaka et al. [15] and Bellovary et al. [22], six out of the top eight Bankruptcy Prediction Model (BPM) are Artificial Intelligence (AI) based. They\nar X\niv :1\n90 5.\n11 47\n4v 2\n[ cs\n.A I]\n3 0\nM ay\n2 01\nalso suggest that BPMs based on \u201dblack box\u201d models such as ANN, GA, and SVM outperform all other models due to their capability of learning any non-linear function. Recently another black box model, ensemble approaches, where multiple models are combined for better results by correcting each other\u2019s error, shows promising performances. However, these \u201dblack box\u201d models lack explainability (i.e., explaining the internal working mechanism to humans) and interpretability (i.e., a sense of what\u2019s happening), which raises ethical issues for domains like finance. A decision in the financial domain (e.g., credit approval, default prediction) needs to be more than a number\u2014 it needs to explain the reason behind the decision that makes sense to a human. Furthermore, when there are many explanatory variables, and some explanatory variables are complex, this further complicates the explainability.\nResearch in Explainable Artificial Intelligence is an emerging field, seeing a resurgence after three decades of slowed progress since the work of Chandrasekaran et al. [29], Swartout et al. [70], and Buchanan et al. [69]. In their work on Explainable Artificial Intelligence(XAI), Miller et al. [58] argue that most of the work on XAI focuses on the researcher\u2019s intuition of what constitutes a good explanation. However, there exists a vast area of research in philosophy, psychology, and cognitive science on how people generate, select, evaluate, and represent explanations and associated cognitive biases and social expectations towards the explanation process. Therefore, the author emphasizes that, the research on explainable AI should incorporate study from these different domains.\nAccording to Lipton et al. [54] and [8], interpretability has three different notions:\n(1) interpretability in pre-modeling: finding and using simple, summarized, and relevant set of features from the domain; (2) interpretability in modeling: generating explanation along with the prediction to improve transparency;and (3) interpretability in post modeling (a.k.a. post-hoc): understanding the dynamics between input and predicted output for an already trained/tested model.\nUnfortunately, the post-hoc notion of interpretability is not purely transparent and can be misleading, as it provides an explanation after the decision has been made. The algorithm can be optimized to placate subjective demand, and the explanation from it also can be misleading though it seems plausible (Lipton et al. 2016) [54], [8]. Furthermore, from the literature review, we find that interpretability in pre-modeling is under-focused. Therefore, we particularly focus on the explainability of black box models using domain knowledge which falls into interpretability in the pre-modeling stage. In this work, we take bankruptcy prediction as the context for our experiments.\nIn our proposed approach, we replace hard to interpret features of a model with easily interpretable features (induced from domain knowledge) which allows the decision to be expressed in terms of an interpretable and concise set of features. We use a frequent pattern mining algorithm to find frequent feature sets used in different bankruptcy literature. Later, we relate the frequent feature set with the popular financial concept of credit to come up with a generalized feature set for the experiments, which ultimately allows us to infuse domain knowledge to increase the explainability and interpretability of \"black box\" models. To asses credit risk by\nhuman experts, the 5C\u2019s of credit is commonly used to analyze key factors: character (reputation of the borrower/firm), capital (leverage), capacity (volatility of the borrower\u2019s earnings), collateral (pledged asset) and cycle (macroeconomic) conditions [9, 19]. The domain knowledge infused feature set gives us a generalized frequent feature set which is used for our experiments for better explainability.\nIn summary, our contributions in this work are as follows: (1) we demonstrate a way to collect and use domain knowledge from the literature; (2) we introduce a way to bring popular concepts (e.g., the 5 C\u2019s of credit) from literature to aid in interpretability and explainability; and (3) our experimental results show \"black box\" models can be better explainable with little or no compromise in performance when domain knowledge is infused.\nWe start with a background of related work (Section 2) followed by a description of our proposed approach and an overview of the dataset (Section 3) used in this work. In Section 4, we describe our experiments, followed by section 5 which contains results and a discussion of the experiments. We conclude with limitations and future work in section 6."
    },
    {
      "heading": "2 BACKGROUND",
      "text": "Early research in explainable AI started with the preliminary work of Chandrasekaran et al. [29], Swartout et al. [70], and Buchanan et al. [69]. Recent advancements in AI, successful adoption in different applications, and awareness of ethical and bias issues necessitates have fueled recent research in Explainable Artificial Intelligence (XAI). For instance, the DARPA division of the Department of Defense (DoD) is spending $2 billion on its XAI program. They are developing a toolkit library consisting of machine learning and human-computer interface software for developing explainable AI systems that will be available for military and commercial use [7].\nYang et al. [74], propose a method based on \u201dBayesian Teaching\u201d, where a subset of an example in used to train the model instead of the whole dataset. The subset of the example is chosen by domain experts that are most relevant to the problem. However, for this purpose, choosing the right subset of examples in the real world is challenging.\nIn sentiment analysis, the rationale for a prediction is important for understanding decisions. Lei et al. [52] propose an approach that generates the rationale for a prediction. They demonstrate the approach with sentiment analysis from the text where a subset of text is selected as the rationale for the prediction. In addition, the selected text is concise and sufficient enough to act as a substitute for the original text, still capable of the correct prediction. Although their approach outperforms available attention-based models, it is limited to only text analysis.\nMaking a prediction that can be trusted is another challenge. Ribeiro et al. [60] propose a novel explanation technique capable of explaining the prediction of any classifier in an interpretable and faithful manner by learning an interpretable model locally around the prediction. Their concern is on two issues: (1) whether the user should trust the prediction of the model and act on that, and (2) whether the user should trust a model to behave reasonably well when deployed. In addition, they involve human judgment in their experiment to decide whether to trust the model or not.\nLundberg et al. [57] propose a unified approach called \u201dSHAP\u201d which unifies seven previous approaches: LIME [60], DeepLIFT [61], Tree Interpreter [18], QII [30], Shapley sampling values [68], Shapley regression values [53], and Layer-wise relevance propagation [21] to make the explanation of prediction for any machine learning model. Both LIME [60] and SHAP [57] use a simplified input mapping, mapping the original input to a simplified set of input. However, none of the models incorporate domain knowledge. The following approach infuses domain knowledge into the experiment and works as a substitute for original complex features in order to generate a prediction which is explainable by itself."
    },
    {
      "heading": "3 METHODOLOGY",
      "text": "The proposed approach consists of two components: a feature generalizer, which gives a generalized frequent feature set with the help of domain knowledge, and an evaluator, that produces and compares the results using the generalized feature set from the original feature set."
    },
    {
      "heading": "3.1 Feature Generalizer",
      "text": "First, the frequent feature miner takes multiple different sets of features used in different bankruptcy prediction literature (see section 3.4) to discover the most frequent set of features (i.e., a frequent combination of features used in different literature) using a popular and classic frequent pattern mining algorithm called Apriori (Agrawal et al. [14]). In Figure 1, the input to the algorithm is: X1, X2,.... Xn \u2208 X where X is the universal set of features used in mortgage bankruptcy prediction literature. The output is some frequent set of features with a specified support and maximum count of features in the set: X f1, X f2,.....Xm \u2208 X where X is the universal set of features as before, but herem is much smaller than n. Finally, the frequent set of features is fed into the domain knowledge mapper. In the domain knowledge mapper, a popular, easy to understand and interpret domain concept is introduced and mapped with the frequent feature set. For our case, we introduce the 5C\u015b of credit which refers to capital, character, cash flow, conditions, and collateral. Based on the mapping, the domain knowledge mapper outputs a generalized frequent feature set infused with domain knowledge."
    },
    {
      "heading": "3.2 Evaluator",
      "text": "The task of the evaluator (Figure 2) is to execute and compare the performance of two experiments: one using original features (X ) of the dataset and the other one using the generalized frequent feature sets (X \u2019). If the difference is within an allowable threshold, then the output from the latter experiment is deemed as final output, and the output is explained using the contribution from each of generalized, and more explainable and interpretable, frequent features."
    },
    {
      "heading": "3.3 Algorithms",
      "text": "We use six different algorithms: one is for frequent pattern mining, and the remaining five are supervised \u201dblack box\u201d models for predicting bankruptcy/default.\n3.3.1 Apriori. TheApriori algorithmwhichwas proposed byAgrawal et al. [14], a classical algorithm in data mining for finding frequent patterns. For our case, when a set of features or explanatory variables found in a paper meets a user-specified support threshold, then that set of features can be treated as frequent feature sets. The support for a set of features X in a paper pi is defined as follows: Support (X) = (number of paper in which all features of X appear) / (total number of paper). For example, if the support threshold is set to .5 (i.e., 50%), then the feature set LTV, creditScore, interestRate, delinquencyStatus is called a frequent feature set if and only if this set of features is found together at least 50% of times among all the papers. Here is an intuition of the working mechanism of the Apriori algorithm. The Apriori algorithm iteratively finds frequent feature sets of a length starting from 1 to k, where k is the maximum number of features in any frequent feature set. The frequent feature sets must meet the minimum support threshold of the algorithm. In addition, a subset of features from the frequent feature set must also be a frequent feature. For example, if LTV, creditScore, interestRate, delinquencyStatus is a frequent feature set, then any of the features or any combination of features (e.g., LTV , LTV, creditScore) within this feature set is also a frequent feature set. In section 4, we will clarify this more.\n3.3.2 Artificial Neural Network (ANN). An Artificial Neural Network is a non-linear model, capable of mimicking human brain functions. It consists of an input layer, multiple hidden layers, and the output layer. Each layer consists of multiple neurons that help to learn the complex pattern, each subsequent layer learns more abstract concepts before it finally merges into the output layer. ANN was first used in 1994 by Wilson and Sharda [72] for bankruptcy prediction. In terms of different performance metrics, given enough data, ANN performs best for many problems due to its capability of learning any non-linear function.\n3.3.3 Support Vector Machine (SVM). The Support Vector Machine (SVM) was first introduced by Boser, Guyon, and Vapnik [25] and\nhas been used for many supervised classification tasks. The model learns an optimal hyperplane that separates instances of different classes using a highly non-linear mapping of input vectors in high dimensional feature space [Hooman, 2016]. SVM is listed as one of the top nonlinear algorithms for bankruptcy prediction in different literature surveys [15, 22]. When the number of samples is too high (i.e., millions) then it is very costly in terms of computation time. In that case, a non-linear algorithm like ANN can be a better choice as an ANN usually works well with large datasets.\n3.3.4 Random Forest (RF). A Random Forest is a tree-based ensemble technique developed by Breiman et al. [27] for the supervised classification task. In RF, many trees are generated from the bootstrapped subsamples (i.e., random sample drawn with replacement) of the training data. In each tree, the splitting attribute is chosen from a smaller random subset of attributes of that tree (i.e., the chosen split attribute that is the best among that random subset). This randomness helps to make trees less correlated as correlated trees makes the same kinds of prediction errors and can overfit the model. This results in a forest of trees being generated, and the output from all the trees are averaged for the final prediction. This averaging helps to reduce the variance from the model. Furthermore, RF can work in a parallel computing environment as trees can be grown independently. According to [34], RF has been used in different credit scoring and customer attrition applications.\n3.3.5 Extra Trees (ET). Extremely Randomized Trees or Extra Trees (ET) is also a tree-based ensemble technique like RF and share a similar concept with RF. The only difference is in the process of splitting attribute selection and determining the threshold (cutoff) value, both are chosen in extremely random fashion [47]. As in RF, a random subset of features are taken into consideration for the split selection but instead of choosing the most discriminative cut off threshold, ET cut off thresholds are set to random values. Thus, the best of these randomly chosen values is set as the threshold for the splitting rule [6]. As a result of multiple trees, the variance is reduced, compared to Decision Trees, however bias is introduced, as a subset of the whole feature set is chosen for each tree. The ET which was proposed by Geurts et al.[38], has continued its success by achieving the state of the art performance in some anomaly/intrusion detection research [45\u201347].\n3.3.6 Gradient Boosting (GB). Friedman et al. [37], generalized Adaboost to a Gradient Boosting algorithm that allows a variety of loss function. Here the shortcoming of weak learners is identified using the gradient, while in AdaBoost it is done through highly weighted data points. Gradient Boosting (GB) is a classifier/regression model in the form of an ensemble of weak prediction models, such as Decision Trees which are fitted with data initially. It also works sequentially like the AdaBoost algorithm, in that each subsequent model tries to minimize the loss function (i.e., Mean Squared Error) by paying special focus on instances that were hard to get right in previous steps."
    },
    {
      "heading": "3.4 Data",
      "text": "We use two sources of data in this work:\n(1) Explanatory variables dataset: We went through the following 33 research papers related to mortgage bankruptcy prediction: [16, 17, 20, 23, 24, 26, 28, 31\u201336, 39, 41\u201344, 48\u201351, 55, 56, 59, 62\u201367, 71, 73] . We collected the explanatory variables used in each of these papers. We made the dataset available to the research community at here [3]. Table 1 lists the features that appear four or more times in the literature. (2) Freddie Mac single-family loan-level dataset: The Freddie Mac dataset [12] is the most frequently used dataset in the 33 previously mentioned research papers. It is also a publicly available dataset. For ensuring transparency, supporting the risk-sharing initiative, and building more accurate credit performance models, Freddie Mac, a government-sponsored enterprise, is making available loan-level credit performance data on fixed-rate mortgages that the company purchased or guaranteed. This is the source of data for the supervised algorithms used in this work. We took a stratified sample of the data to make sure the ratio of default vs non-default sample is same in both the original and the sample dataset. As the original dataset is an imbalanced dataset, the sampled data contains 113,130 records, out of which only 198 of the records are defaults, giving us a highly imbalanced dataset with only .18% (<1%) of target samples. In the anomaly detection problem, the class imbalance is not uncommon. In total there are 54 features in the dataset. We removed 24 unimportant features using feature ranking of the Random Forest algorithm, which gives us 30 features that we use for the experiments. Furthermore, we use 70% of the data for training the models and kept 30% of the data as a holdout set to test the model. We make sure the target class has the same ratio in both the training and test sets."
    },
    {
      "heading": "4 EXPERIMENTS",
      "text": "First, in the feature generalizer (see section 3.1), for frequent feature mining, we use the Python-based library Mlxtend [2], which is actually an implementation of the Apriori algorithm. Second, in the evaluator (see section 3.2), all supervised algorithms are implemented using the Python-based Scikit-learn [10] library. In addition, we use Tensorflow [13] for the Artificial Neural Network. We run all experiments on a laptop with 12GB of RAM and a core i7 processor.\nIn other currently ongoing work, we investigated 33 research papers [16, 17, 20, 23, 24, 26, 28, 31\u201336, 39, 41\u201344, 48\u201351, 55, 56, 59, 62\u2013 67, 71, 73] related to mortgage default/bankruptcy prediction and collected all explanatory variables (i.e., features) [3]. These collected features are the input data for the frequent featuremining algorithm. The output is the frequent feature sets. The hyper-parameters for the frequent pattern mining algorithm (i.e., Apriori) are a minimum support threshold .05 and a maximum length 8. Here, support for a set of feature(s) is the ratio of the number of research paper containing that feature(s) and the total number of the research paper. Furthermore, maximum length refers to the maximum number of features that we want to see in any frequent feature set. We brought 5 C\u2019s of credit as a concept from the domain and mapped the frequent features with the individual C\u2019s. We only keep the frequent feature sets that have at least one matching feature from each of the\nC\u2019s in the 5 C\u2019s of credit. Table 3 shows how we did the mapping and 4 shows the mapped generalized frequent feature set. We wrote a python script [4] to do this mapping.\nIn the evaluator part, we use the Freddie Mac dataset for experimenting with the supervised algorithms ANN, SVM, RF, GB, and ET used in this work. We took a stratified sample of the data which contains 113,130 records, out of which 198 of the records are default giving us a highly imbalanced dataset with only .18% (<1%) of target samples. Furthermore, we use 70% of the data for training the models and kept 30% of the data as a holdout set to test the model. We make sure the target class has the same ratio in both sets. We run the supervised algorithms in two different ways:\n(1) using original features: we use all 30 selected features given by the feature selection algorithm; (2) using generalize frequent features set: we use each of the 25 generalized features sets separately for each algorithm. Each of the generalized feature sets consists of eight generalized feature based on the mapping from the domain knowledge (see 3 and 4). Out of the 25 runs for each algorithm with a different generalized feature set, we observe the performance and report the best performance with a corresponding generalized feature set in Section 5."
    },
    {
      "heading": "5 RESULTS AND DISCUSSION",
      "text": "The frequent pattern mining algorithm gives us a total of 4691 different combinations of feature sets. We discard feature sets that consist of less than eight features because frequent feature sets need to be big enough to cover at least one feature from each of the 5 C\u2019s.In addition, a few of the 5 C\u2019s are related to two or more features. By keeping combinations that consist of only eight features, we\nget 231 combinations of frequent feature sets. Table 2 exhibits few randomly chosen frequent feature sets of length 8.\nTable 3 shows amapping of the 5 C\u2019s to relevant features based on the information from [9, 19]. So far, we have 231 frequent feature sets irrespective of those containing at least one representative feature (based on mapping in 3) from each C of the 5 C\u2019s of credit . We filter these frequent feature sets of length 8 by matching with the features mapping in Table 3 \u2014all feature sets that don\u2019t contain at least one of the features from each category (each of the 5 C\u2019s) is discarded. This gives us 25 feature sets where each of the feature sets contains at least one of the features under each C of the 5 C\u2019s of credit. We call these 25 feature sets the generalized frequent feature sets. Table 4 shows some random generalized features sets.\nTable 5 exhibits the performance comparison of different algorithms with or without using the generalized frequent feature set in terms of different performance metrics. An appended -G after the algorithm name refers to when the algorithm is run using the generalized frequent feature set. In addition, Figure 3 complements Table 5 by providing the dispersion in performance metrics when using the generalized frequent feature set. Surprisingly, for all algorithms, there is no difference in accuracy in either of the cases when we use the generalized frequent features set or the original feature set. However, accuracy is not a good fit for our dataset to measure the performance due to a high imbalance in the data. The model can achieve a very high accuracy by classifying most of the samples as the majority class, which is misleading. Instead, recall, precision, fscore, and ROC-AUC are better measurements as it takes into account the misclassification errors (Type I error or false positives, Type II error or false negatives) that the model makes. In terms of precision, for all algorithms, performance drops slightly\n(in between 2 to 5%) when using the generalized frequent feature set. In terms of recall and fscore, GB-G is the best and SVM-G is the worst. In terms of ROC-AUC, ANN-G is the worst and ET-G is the best. Overall, in terms of recall, precision, and fscore, the algorithm using the generalized frequent feature set performs better than when the same algorithms uses the original features of the dataset.\nFurthermore, from Figure 4, we can also see that, for the most important performance metric recall, we are getting better performance (ranging from 2-10%) for ANN-G, RF-G, and GB-G. In terms\nof any performance metrics, there is at least one algorithm that performs better or equal using the generalized frequent feature. We need to choose the right algorithm based on the class distribution in the data as performance metric response differs based upon the distribution of the class in the data. Furthermore, when we use the generalized feature sets, we run the algorithm on all 25 generalized feature sets to discover the best feature sets. We found that using frequent feature set # 5 (see Table 4), out of the 25 generalized feature sets, for algorithms RF-G, ET-G, and GB-G we are able to achieve the best result based on performance metric recall. For ANN-G and SVM-G, pattern 3 and 6 worked better accordingly. Therefore, this helps to choose the best generalized frequent feature set for a particular algorithm among many generalized frequent feature sets.\nWe only tested with the Freddie Mac dataset and there is a chance that the original features (even after excluding unnecessary features using the feature selection technique) still overfit the model, which leads to a better or equal result for all performance metrics in our case. Validating the result with multiple datasets is part of the future direction of this work. Furthermore, overall, all algorithms using a generalized frequent feature set takes less execution time compared to their counterparts due to the much fewer number of features. For a few algorithms (e.g., ANN), a fewer number of features decreases the computation time.\nOverall, even though infusing domain knowledge might lead to some compromise in performance, clearly it ensures better explainability and interpretability as the output is made from a concise and familiar set of features from the domain. Our success so far is in the generation of the output using an intuitive set of features. Our further concern is to show the result in an interpretable way. One way is by expressing the output as a percentage of the total risk, and the segregation of the output value is the percentage that each of the generalized frequent features is liable. We can express the total risk probability with the following formula:\nP(D) = G\u2211 \u0434=0 contribution(\u0434) (1)\nwhere g is the generalized frequent feature. Instead of using contributions from generalized frequent features, we can also express the output in terms of the contribution from each element of the\ndomain concept. This might improve the interpretability a little bit at the expense of losing some details.\nThe correct way to come up with the breakdown of contribution from each feature for a particular prediction contribution is challenging. The naive way to formulate this can be by using the importance or permutation importance of the features. However, the importance of the feature is usually calculated based on a set of data (e.g., training set) and can be achieved directly from feature importance methods in most supervised algorithms. However, in case of sample wise feature importance this is not for straight forward. Moreover, the test sample might not be a good representative of the training set. Other work such as LIME [60], Tree Interpreter [18], SHAP [57], and ELI5 [5], can discover the contributions of features in the prediction. However, each of the available techniques/tools come with some limitations: some are applicable to only text or images individually, and some are applicable to only a class of algorithms (e.g., tree based approaches, neural networks). Most of these\napproaches try to find out how the prediction deviates from the base/average scenario. Lime [60] tries to generate an explanation by locally (i.e., using local behavior) approximating the model with an interpretable model (e.g., decision trees, linear model). However, it is limited by the use of a linear model to approximate local behavior.Furthermore, SHAP unifies previous approaches including LIME by borrowing features from those. While SHAP comes with theoretical guarantees about consistency and local accuracy from game theory, in the case of black box kernel SHAP, it needs to run many evaluations of the original model to estimate a single vector of feature importance [11]. ELI5 also uses the LIME algorithm internally for explanations, however, the model is not truly agnostic, mostly limited to tree-based and other parametric or linear models. Tree Interpreter is limited to only tree-based approaches (e.g., Random Forest, Decision Trees). Our future work includes finding an optimal solution for sample-wise feature contribution in the prediction and express the sample-wise output according to the formula 1."
    },
    {
      "heading": "6 CONCLUSIONS AND FUTUREWORK",
      "text": "Future adoption of \"black box\" models is in an inauspicious position due to the lack of explainability. Governments of different countries have started to introduce laws to ensure accountability, right of explanation, and eliminating bias/discrimination in decisions. Sophisticated areas such as finance, security, and healthcare are in need of better explanations of their \"black box\" models. In this work, we demonstrated a way to collect and use domain knowledge from the literature. We also introduced a way to bring and infuse popular concepts (e.g., 5 C\u2019s of credit) from the literature that aide in better interpretability and explainability. Our experimental results show that \"black box\" models can be better explainable without much compromise in performance when domain knowledge is infused.\nExperimenting with our proposed approach on multiple data sets will help us validate its versatility. Moreover, finding an optimal solution to segregate the contribution of each participating feature (sample wise) will aide in better explainability of sample wise output and better run-time of the model. In addition, incorporating other concepts as domain knowledge will verify its generality, making this approach transferable to other domains like cyber-security\nand healthcare. For instance, in cyber-security, better explanation would aide in the understanding of different attack scenarios and safeguarding the model from adversarial attacks."
    },
    {
      "heading": "ACKNOWLEDGMENTS",
      "text": "Thanks to Tennessee Tech Cyber-security Education, Research and Outreach Center (CEROC) for funding this research."
    }
  ],
  "title": "Infusing domain knowledge in AI-based \"black box\" models for better explainability with application in bankruptcy prediction",
  "year": 2019
}
