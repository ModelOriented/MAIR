{"abstractText": "There is an increasing interest in estimating heterogeneity in causal effects in randomized and observational studies. However, little research has been conducted to understand heterogeneity in an instrumental variables study. In this work, we present a method to estimate heterogeneous causal effects using an instrumental variable approach. The method has two parts. The first part uses subject-matter knowledge and interpretable machine learning techniques, such as classification and regression trees, to discover potential effect modifiers. The second part uses closed testing to test for the statistical significance of the effect modifiers while strongly controlling familywise error rate. We conducted this method on the Oregon Health Insurance Experiment, estimating the effect of Medicaid on the number of days an individual\u2019s health does not impede their usual activities, and found evidence of heterogeneity in older men who prefer English and don\u2019t self-identify as Asian and younger individuals who have at most a high school diploma or GED and prefer English.", "authors": [{"affiliations": [], "name": "Michael Johnson"}, {"affiliations": [], "name": "Jiongyi Cao"}, {"affiliations": [], "name": "Hyunseung Kang"}], "id": "SP:21aca2f7d033cb9dfc8fb1ad0db088391587a5af", "references": [{"authors": ["A. Abadie"], "title": "Semiparametric instrumental variable estimation of treatment response models", "venue": "Journal of Econometrics, 113(2):231\u2013263.", "year": 2003}, {"authors": ["J.D. Angrist", "G.W. Imbens", "D.B. Rubin"], "title": "Identification of causal effects using instrumental variables", "venue": "Journal of the American Statistical Association, 91(434):444\u2013455.", "year": 1996}, {"authors": ["S. Athey", "G. Imbens"], "title": "Recursive partitioning for heterogeneous causal effects", "venue": "Proceedings of the National Academy of Sciences, 113(27):7353\u20137360.", "year": 2016}, {"authors": ["S. Athey", "G.W. Imbens"], "title": "Machine learning methods for estimating heterogeneous causal effects", "venue": "stat, 1050(5):1\u201326.", "year": 2015}, {"authors": ["S. Athey", "J. Tibshirani", "S Wager"], "title": "Generalized random forests", "venue": "The Annals of Statistics,", "year": 2019}, {"authors": ["M. Baiocchi", "J. Cheng", "D.S. Small"], "title": "Instrumental variable methods for causal inference", "venue": "Statistics in Medicine, 33(13):2297\u20132340.", "year": 2014}, {"authors": ["M. Baiocchi", "D.S. Small", "S. Lorch", "P.R. Rosenbaum"], "title": "Building a stronger instrument in an observational study of perinatal care for premature infants", "venue": "Journal of the American Statistical Association, 105(492):1285\u20131296.", "year": 2010}, {"authors": ["F.J. Bargagli-Stoffi", "K. De-Witte", "G. Gnecco"], "title": "Heterogeneous causal effects with imperfect compliance: a novel bayesian machine learning approach", "venue": "arXiv preprint arXiv:1905.12707.", "year": 2019}, {"authors": ["F.J. Bargagli-Stoffi", "G. Gnecco"], "title": "Estimating heterogeneous causal effects in the presence of irregular assignment mechanisms", "venue": "2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA), pages 1\u201310. IEEE.", "year": 2018}, {"authors": ["R. Blundell", "J.L. Powell"], "title": "Endogeneity in nonparametric and semiparametric regression models", "venue": "Econometric Society Monographs, 36:312\u2013357.", "year": 2003}, {"authors": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "title": "Classification and Regression Trees", "venue": "New York: Chapman and Hall/CRC.", "year": 1984}, {"authors": ["S. Darolles", "Y. Fan", "Florens", "J.-P.", "E. Renault"], "title": "Nonparametric instrumental regression", "venue": "Econometrica, 79(5):1541\u20131565.", "year": 2011}, {"authors": ["A. Finkelstein", "S. Taubman", "B. Wright", "M. Bernstein", "J. Gruber", "J.P. Newhouse", "H. Allen", "K. Baicker", "O.H.S. Group"], "title": "The oregon health insurance experiment: evidence from the first year", "venue": "The Quarterly Journal of Economics, 127(3):1057\u20131106.", "year": 2012}, {"authors": ["R.A. Fisher"], "title": "The design of experiments", "venue": "edinburgh: Oliver and boyd,", "year": 1935}, {"authors": ["P.R. Hahn", "J. Murray", "C.M. Carvalho"], "title": "Bayesian regression tree models for causal inference: regularization, confounding, and heterogeneous effects", "venue": "Confounding, and Heterogeneous Effects (October 5, 2017).", "year": 2017}, {"authors": ["P. Hall", "Horowitz", "J. L"], "title": "Nonparametric methods for inference in the presence of instrumental variables", "year": 2005}, {"authors": ["M.A. Hern\u00e1n", "J.M. Robins"], "title": "Instruments for causal inference: an epidemiologist\u2019s dream? Epidemiology, pages 360\u2013372", "year": 2006}, {"authors": ["J.L. Hill"], "title": "Bayesian nonparametric modeling for causal inference", "venue": "Journal of Computational and Graphical Statistics, 20(1):217\u2013240.", "year": 2011}, {"authors": ["J.L. Hodges Jr", "E.L. Lehmann"], "title": "Estimates of location based on rank tests", "venue": "The Annals of Mathematical Statistics, pages 598\u2013611.", "year": 1963}, {"authors": ["J.Y. Hsu", "D.S. Small", "P.R. Rosenbaum"], "title": "Effect modification and design sensitivity in observational studies", "venue": "Journal of the American Statistical Association, 108(501):135\u2013148.", "year": 2013}, {"authors": ["J.Y. Hsu", "J.R. Zubizarreta", "D.S. Small", "P.R. Rosenbaum"], "title": "Strong control of the familywise error rate in observational studies that discover effect modification by exploratory methods", "venue": "Biometrika, 102(4):767\u2013782.", "year": 2015}, {"authors": ["G.W. Imbens"], "title": "Better late than nothing: Some comments on deaton (2009) and heckman and urzua (2009)", "venue": "Journal of Economic Literature, 48(2):399\u2013423.", "year": 2010}, {"authors": ["H. Kang", "B. Kreuels", "O. Adjei", "R. Krumkamp", "J. May", "D.S. Small"], "title": "The causal effect of malaria on stunting: a mendelian randomization and matching approach", "venue": "International journal of epidemiology, 42(5):1390\u20131398.", "year": 2013}, {"authors": ["H. Kang", "B. Kreuels", "J. May", "Small", "D. S"], "title": "Full matching approach to instrumental variables estimation with application to the effect of malaria on stunting", "venue": "The Annals of Applied Statistics,", "year": 2016}, {"authors": ["H. Kang", "L. Peck", "L. Keele"], "title": "Inference for instrumental variables: a randomization inference approach", "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society), 181(4):1231\u20131254.", "year": 2018}, {"authors": ["K. Lee", "D.S. Small", "F. Dominici"], "title": "Discovering effect modification and randomization inference in air pollution studies", "venue": "arXiv preprint arXiv:1802.06710.", "year": 2018}, {"authors": ["K. Lee", "D.S. Small", "J.Y. Hsu", "J.H. Silber", "P.R. Rosenbaum"], "title": "Discovering effect modification in an observational study of surgical mortality at hospitals with superior nursing", "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society),", "year": 2018}, {"authors": ["R. Marcus", "P. Eric", "K.R. Gabriel"], "title": "On closed testing procedures with special reference to ordered analysis of variance", "venue": "Biometrika, 63(3):655\u2013660.", "year": 1976}, {"authors": ["W.K. Newey", "J.L. Powell"], "title": "Instrumental variable estimation of nonparametric models", "venue": "Econometrica, 71(5):1565\u20131578.", "year": 2003}, {"authors": ["P.R. Rosenbaum"], "title": "Overt bias in observational studies", "venue": "Observational Studies, pages 71\u2013104. Springer.", "year": 2002}, {"authors": ["P.R. Rosenbaum"], "title": "Design of Observational Studies, volume 10", "venue": "Springer.", "year": 2010}, {"authors": ["D.B. Rubin"], "title": "Randomization analysis of experimental data: The fisher randomization test comment", "venue": "Journal of the American Statistical Association, 75(371):591\u2013593.", "year": 1980}, {"authors": ["D.B. Rubin"], "title": "Using propensity scores to help design observational studies: application to the tobacco litigation", "venue": "Health Services and Outcomes Research Methodology, 2(3-4):169\u2013188.", "year": 2001}, {"authors": ["D.O. Staiger", "J.H. Stock"], "title": "Instrumental variables regression with weak instruments", "year": 1997}, {"authors": ["J.H. Stock", "J.H. Wright", "M. Yogo"], "title": "A survey of weak instruments and weak identification in generalized method of moments", "venue": "Journal of Business & Economic Statistics, 20(4):518\u2013529.", "year": 2002}, {"authors": ["E.A. Stuart"], "title": "Matching methods for causal inference: A review and a look forward", "venue": "Statistical Science: A Review Journal of the Institute of Mathematical Statistics, 25(1):1.", "year": 2010}, {"authors": ["L. Su", "I. Murtazashvili", "A. Ullah"], "title": "Local linear gmm estimation of functional coefficient iv models with an application to estimating the rate of return to schooling", "venue": "Journal of Business & Economic Statistics, 31(2):184\u2013207.", "year": 2013}, {"authors": ["X. Su", "Tsai", "C.-L.", "H. Wang", "D.M. Nickerson", "B. Li"], "title": "Subgroup analysis via recursive partitioning", "venue": "Journal of Machine Learning Research, 10(Feb):141\u2013158.", "year": 2009}, {"authors": ["S.A. Swanson", "M.A. Hern\u00e1n"], "title": "Commentary: how to report instrumental variable analyses (suggestions welcome)", "venue": "Epidemiology, 24(3):370\u2013374.", "year": 2013}, {"authors": ["S.A. Swanson", "M.A. Hern\u00e1n"], "title": "Think globally, act globally: an epidemiologist\u2019s perspective on instrumental variable estimation", "venue": "Statistical Science: A Review Journal of the Institute of Mathematical Statistics, 29(3):371.", "year": 2014}, {"authors": ["T. Therneau", "B. Atkinson", "B. Ripley", "M.B. Ripley"], "title": "Package \u2018rpart", "venue": "Available online: cran. ma. ic. ac. uk/web/packages/rpart/rpart. pdf (accessed on 20 April 2016).", "year": 2015}, {"authors": ["S. Wager", "S. Athey"], "title": "Estimation and inference of heterogeneous treatment effects using random", "year": 2018}], "sections": [{"text": "tional studies. However, little research has been conducted to understand heterogeneity in an instrumental variables study. In this work, we present a method to estimate heterogeneous causal effects using an instrumental variable approach. The method has two parts. The first part uses subject-matter knowledge and interpretable machine learning techniques, such as classification and regression trees, to discover potential effect modifiers. The second part uses closed testing to test for the statistical significance of the effect modifiers while strongly controlling familywise error rate. We conducted this method on the Oregon Health Insurance Experiment, estimating the effect of Medicaid on the number of days an individual\u2019s health does not impede their usual activities, and found evidence of heterogeneity in older men who prefer English and don\u2019t self-identify as Asian and younger individuals who have at most a high school diploma or GED and prefer English."}, {"heading": "1 Introduction", "text": ""}, {"heading": "1.1 Motivation: Utilization of Medicaid in Oregon and the Complier Average", "text": "Treatment Effect\nIn January of 2008, Oregon reopened its Medicaid-based health insurance plan for its eligible residents and, for a brief period, allowed a limited number of individuals to enroll in the program. Specifically, a household in Oregon was randomly selected by a lottery system run by the state and any eligible individual in the household can choose to enroll in the new health insurance plan; households that weren\u2019t selected by the lottery could not enroll whatsoever.\nFor policymakers, Oregon\u2019s randomized lottery system was a unique opportunity, specifically a natural experiment, to study Medicaid\u2019s causal effect on a variety of health and economic outcomes, as directly randomizing Medicaid (or withholding it) to individuals would be infeasible and unethical. Finkelstein et al. (2012) used the randomized lottery as an instrumental variable (see Section 2.2 for details) to study the complier average treatment effect (CATE), or the effect of Medicaid among individuals who enrolled in Medicaid after winning\nar X\niv :1\n90 8.\n03 65\n2v 1\n[ st\nat .M\nE ]\n9 A\nug 2\n01 9\nthe lottery (Angrist et al., 1996). CATE reflects Medicaid\u2019s impact among a subgroup of individuals, say the average effect of Medicaid in reducing medical debt among those who comply with their lottery result and enroll in Medicaid, and differs from the average treatment effect for the entire population (ATE) or the intent-to-treat (ITT) effect of the lottery itself on the outcome. In this paper, we focus on studying the CATE; see Imbens (2010) and Swanson and Herna\u0301n (2013, 2014) for discussions on CATE.\nOften in studying CATE, the population of compliers is assumed to be homogeneous whereby two compliers are alike and have the same treatment effect. But, no two individuals are the same and it is plausible that some compliers may better benefit from the treatment than other compliers. For example, sick individuals who enroll in Medicaid after winning the lottery may benefit more from Medicaid than healthy individuals. Also, the perceived benefit of enrolling in Medicaid among sick versus healthy individuals creates heterogeneity in the compliance rate, i.e. the number of people who sign up when they win the lottery, with sick people presumably signing up more than healthy people. Alternatively, if people are equally likely to enroll in Medicaid if they win the lottery, those who are unemployed may benefit more from Medicaid in terms of reducing healthcare spending and medical debt than those who are employed. The theme of this paper is to explore these issues, specifically the heterogeneity of CATE and how to discover them in an honest manner."}, {"heading": "1.2 Prior Work and Our Contributions", "text": "There are many recent works in causal inference using tree-based methods to estimate heterogeneity in the average treatment effect, with majority of them utilizing sample splitting or sub-sampling to obtain honest pointwise inference; see Su et al. (2009), Hill (2011), Athey and Imbens (2016), Hahn et al. (2017), Wager and Athey (2018), Athey et al. (2019) and references therein. Hsu et al. (2013) uses pair matching, classification and regression trees (CART) [Breiman et al. (1984)], and the absolute value of the treatment difference between pairs to discover treatment heterogeneity and to conduct honest inference, all without sample splitting. A follow-up work by Hsu et al. (2015) formally showed that the proposal strongly controls the family wise error rate for testing heterogeneous treatment effects and subsequent works by Lee et al. (2018a,b) extended this idea of using absolute value of the treatment-control difference to study effect heterogeneity.\nThere is also work on nonparametrically estimating treatment effects using instruments, mostly using likelihood, series, or moment-based approaches [Abadie (2003), Blundell and Powell (2003), Newey and Powell (2003), Hall et al. (2005), Darolles et al. (2011), Su et al. (2013), Athey et al. (2019)]. Recently, Bargagli-Stoffi and Gnecco (2018) and Bargagli-Stoffi et al. (2019) explore effect heterogeneity within IV context by using causal trees [Athey and Imbens (2015)] and Bayesian causal forests [Hahn et al. (2017)] to estimate heterogeneity in the ITT effect and dividing it by the compliance rate. However, to the best of our knowledge, none of the methods use matching, a popular, intuitive, and easy-to-understand method, as a device to nonparametrically estimate treatment heterogeneity in the context of IVs and guarantee strong familywise Type I error control, to ensure that only \u201dtruly\u201d significant heterogeneity is detected. Works on using matching in IV context by\nBaiocchi et al. (2010) and Kang et al. (2013, 2016) only focus on the population complier average treatment effect; they do not explore heterogeneous treatment effect with an IV. Also, aforementioned work by Hsu et al. (2013, 2015) using matching and CART to explore treatment heterogeneity were in non-IV contexts.\nThe goal of this paper is to propose a matching-based method to study treatment effect heterogeneity in IV settings. Specifically, the target estimand of interest is what we call the heterogeneous complier average treatment effect (H-CATE). A heterogeneous complier average treatment effect (H-CATE) is the usual complier average treatment effect, but for a subgroup of individuals defined by their pre-instrument covariates. At a high level, H-CATE explores treatment heterogeneity in the complier population, where we suspect that not all compliers in the data react to the treatment in the same way. Some subgroup of compliers may respond to the treatment differently than another subgroup of compliers, who may not respond to the treatment at all; some may even be more likely to be compliers if they believe the treatment would benefit them and they may actually benefit from the treatment. The usual complier average treatment effect (CATE) estimand obscures the underlying complier heterogeneity by averaging across these two types of compliers whereas H-CATE attempts to expose it. Also, in the case where the four compliance types in Angrist et al. (1996), compliers, never-takers, always-takers, and defiers, have identical effects, H-CATE can identify the heterogeneous treatment effect for the entire population by using an instrument. Section 2.3 formalizes H-CATE and provides additional discussions.\nMethodologically, to study H-CATE, we combine the ideas of heterogeneous treatment effect estimation in non-IV matching contexts by Hsu et al. (2015) and matching with IVs by Kang et al. (2016). Specifically, we first follow Kang et al. (2016) and conduct pair matching on a set of pre-instrument covariates and test the CATE for each pair. Second, we follow Hsu et al. (2015) where we obscure treatment-control difference using absolute differences and CART to discover subgroups and novel H-CATEs without contaminating downstream inference. Third, we follow Hsu et al. (2015) and use closed testing to test H-CATE in different subgroups to find statistically significant subgroups, while strongly controlling for familywise error rate. Simulation studies are conducted to evaluate the performance of our proposed method under varying levels of compliance and effect heterogeneity. We illustrate its honest simultaneous discovery and inference while strongly controlling familywise error rate. We then analyze heterogeneity in the effect of Medicaid on increasing the number of days a complying individual\u2019s health does not hamper their usual activities."}, {"heading": "2 Method", "text": ""}, {"heading": "2.1 Notation", "text": "Let i = 1, . . . , I index the I matched pairs for individuals j = 1, 2, and Zij denote a binary instrument for individual j in matched pair i, so that one individual of the pair receives the instrument value Zij = 1 and the other receives the value Zij = 0. In the OHIE data, Zij = 1 and Zij = 0 denotes an individual winning or losing the lottery respectively to enroll in Medicaid. Let Z be the vector of instruments, Z = (Z11, Z12, . . . , ZI1, ZI2)\nand Z denote an event of instrument assignments for all individuals.\nFor individual j in matched pair i, let d1ij and d0ij denote the binary potential exposure, or treatment, values given the instrument value of Zij = 1 and Zij = 0 respectively. Further, define the potential response r (d1ij) 1ij for individual j in matched set i with exposure d1ij receiving instrument Zij = 1 and r (d0ij) 0ij similarly but with instrument Zij = 0. For the OHIE data, d1ij denotes whether an individual enrolled in Medicaid and r (d1ij) 1ij denotes the outcome, say the number of days not affected by one\u2019s physical or mental health when they win the lottery Zij = 1. The observed response is defined as Rij = r (d1ij) 1ij Zij + r (d0ij) 0ij (1\u2212Zij), and the observed exposure, or treatment, is defined as Dij = d1ijZij + d0ij(1 \u2212 Zij) for individual j in matched set i. Define F = {(r(d1ij)1ij , r (d0ij) 0ij , d1ij , d0ij ,Xij , uij), i = 1, . . . , I, j = 1, 2} to be the set of potential outcomes, treatment levels, and covariates, both observed, Xij , and unobserved, uij .\nWhen partitioning the matched sets into subgroups for discovering treatment heterogeneity, the following notation is included. We define a \u201dset of sets\u201d, or grouping, G which contains mutually exclusive and exhaustive subsets of the pairs sg \u2286 {1, . . . , I}, so that G = {s1, . . . , sG}. An appended subscript sg is used to denote an individual partitioned into the gth subset sg. To avoid overloading the notation, the subscripts s and sg will be used interchangeably when it isn\u2019t necessary to specify a subgroup g. The set of potential outcomes, exposures, and covariates for subset sg are thus defined as Fs = {(r (d1sij) 1sij , r (d0sij) 0sij , d1sij , d0sij ,Xsij , usij) : sg \u2286 {1, . . . , I}, i \u2208\nsg, j = 1, 2}, where F = \u22c3 s Fs. For example, consider a grouping of two groups, G = {s1, s2} for I = 10 matched pairs. Then it may be that the first few pairs and last pair make up the first group and the rest are in the second group, s1 = {1, 2, 3, 10} and s2 = {4, 5, 6, 7, 8, 9}. The set of potential responses, exposures, and observed and unobserved covariates for the first group is then Fs1 = {(r (d1s1ij) 1s1ij , r (d0s1ij) 0s1ij , d1s1ij , d0s1ij ,Xs1ij , us1ij) : s1 = {1, 2, 3, 10}, i \u2208 s1, j = 1, 2}. The observed response, binary instrument, and exposure for a given individual in subset sg is then denoted Zsij , Rsij , and Dsij respectively. The notation assumes that the Stable Unit Treatment Value Assumption (SUTVA) holds [Rubin (1980)]."}, {"heading": "2.2 Review: Matching, Instrumental Variables, and the Complier Average Treat-", "text": "ment Effect (CATE)\nMatching is a popular non-parametric technique in observational studies to balance the distribution of the observed covariates between treated and control individuals by grouping individuals based on the similarity between their covariates; see Stuart (2010) and Chapters 3 and 8 of Rosenbaum (2010) for overviews of matching. Pair matching is a specific type of matching where each treated individual is only matched to one control individual. In the context of instruments and pair matching, the IV serves as the treatment/control variable and the matching algorithm creates I matched pairs indexed by i = 1, . . . , I where individuals j = 1, 2 in each matched pair i are similar in their observed covariates xij but one receives the instrument value Zij = 1 and the other receives the instrument value Zij = 0. Covariate similarity between individuals is typically measured by a rank-based Mahalanobis distance matrix with propensity score calipers to threshold distances exceeding a\ncertain value to infinity [Rosenbaum (2010)] and the optimal pair matching using optimal calipers can be found using the bigmatch R package [Yu (2019)] available on CRAN.\nInstrumental variables (IV) is a popular approach to analyze causal effects when unmeasured confounding is present [Angrist et al. (1996); Angrist and Krueger (2001); Herna\u0301n and Robins (2006); Baiocchi et al. (2014)]. In an IV analysis, an instrument is utilized to extract variation free of unmeasured confounding in the treatment assignment and use this variation to identify causal treatment effects. To make claims of causality, the instrument must satisfy three core assumptions: (A1) the instrument is related to the exposure or treatment,\u2211I i=1 \u22112 j=1(d1ij \u2212 d0ij) 6= 0; (A2) the instrument is not related to the outcome in any way except through the treatment, r (k) 0ij = r (k) 1ij \u2261 r (k) ij for a fixed exposure k; (A3) the instrument is not related to any unmeasured confounders that affect the treatment and the outcome, P (Zij = 1|F ,Z) = 12 within each pair i (see Figure 1). If these core assumptions are satisfied, it is possible to obtain bounds on the average treatment effect. To further point identify a treatment effect, one needs to be willing to make an additional assumption. Here, we assume the (A4) monotonicity assumption to identify CATE, d0ij \u2264 d1ij , so that no individuals act against the direction in which the instrument values pushes toward treatment, i.e. no defiers exist. See Herna\u0301n and Robins (2006) and Baiocchi et al. (2014) for discussion on other assumptions needed for point identification in an IV context.\nIn the Oregon Health Insurance Experiment, the lottery for individuals to have access to Medicaid is a plausible instrument. The lottery is randomized which ensures that the instrument is unrelated to unmeasured confounders satisfying (A3). Winning the lottery, on average, increased enrollment of Medicaid by 30% (Finkelstein et al., 2012) satisfying (A1). Assumption (A4) in the context of the OHIE states that there are no individuals who defy the lottery assignment to take or not take Medicaid if they lost or won the lottery respectively. This is guaranteed by the enforcement of the lottery, since an individual who loses cannot have access to Medicaid. However, we remark that Finkelstein et al. (2012) measure the exposure as whether or not an individual has ever had Medicaid during the study and a few individuals were already enrolled in Medicaid before the lottery winners were announced. Finally, assumption (A2), also referred to as the exclusion restriction assumption, is the only assumption potentially violated since individuals are not blinded to their lottery results, thereby allowing for lottery losers to seek other health insurance or lottery winners to make less healthy\ndecisions since they\u2019re now able to be insured. These changes in an individual\u2019s behavior could affect their outcome regardless of their treatment and so may violate the exclusion restriction assumption.\nLet NCO be the total number of compliers in the population. Under the IV assumptions (A1)-(A4), the\ncomplier average treatment effect, defined as\n\u03bb =\n\u2211I i=1(r (1) 1ij \u2212 r\n(0) 0ij)I(d1ij = 1, d0ij = 0)\u2211I\ni=1 \u22112 j=1 d1ij \u2212 d0ij\n= 1\nNCO I\u2211 i=1 (r (1) 1ij \u2212 r (0) 0ij)I(ij is a complier) (1)\ncan be identified from data by taking the ratio of the ITT effect estimate, which is the difference in means of R between instrument values 1 and 0, over the compliance rate, which is the difference in means of D between instrument values 1 and 0 [Angrist et al. (1996)]. Statistical inference of CATE is usually via the delta method [Wooldridge (2010)]. Alternatively, in the context of matching and IV, Rosenbaum (2002), Baiocchi et al. (2010) and Kang et al. (2016) proposed a test statistic for CATE by using the adjusted differences in outcomes\nT (\u03bb0) = 2\nI I\u2211 i=1 2\u2211 j=1 Zij(Rij \u2212 \u03bb0Dij)\u2212 (1\u2212 Zij)(Rij \u2212 \u03bb0Dij) (2)\nalong with an estimator for the variance of T (\u03bb0),\nS2(\u03bb0) = 1\nI(I \u2212 1) I\u2211 i=1 2\u2211 j=1 (Zij(Rij \u2212 \u03bb0Dij)\u2212 (1\u2212 Zij)(Rij \u2212 \u03bb0Dij)\u2212 T (\u03bb0))2 (3)\nto test the null H0 : \u03bb = \u03bb0. Specifically, Baiocchi et al. (2010) and Kang et al. (2016) showed that T (\u03bb) S(\u03bb) asymptotically follows the standard Normal distribution. Additionally, the same set of authors used the test statistic to propose a Hodges-Lehmann type estimator [Hodges Jr and Lehmann (1963)] for the effect ratio\n\u03bb\u0302 =\n\u2211I i=1 \u22112 j=1(Zij \u2212 Z\u0304i.)(Rij \u2212 R\u0304i.)\u2211I\ni=1 \u22112 j=1(Zij \u2212 Z\u0304i.)(Dij \u2212 D\u0304i.)\nwhere Z\u0304i., R\u0304i., and D\u0304i. are the averages of the pairs for the observed instrument, response, and exposure respectively. For a (1\u2212\u03b1)% confidence interval for the effect ratio, the equation T 2(\u03bb)/S2(\u03bb) \u2264 z1\u2212\u03b1/2 is solved for \u03bb, where z1\u2212\u03b1/2 is the (1\u2212\u03b1/2) quantile of the standard Normal distribution. This turns out be equivalent to solving the roots of a quadratic equation; see Kang et al. (2016) and Kang et al. (2018) for details."}, {"heading": "2.3 Heterogeneous Complier Average Treatment Effect (H-CATE)", "text": "We formally define the target estimand of interest in the paper, the heterogeneous treatment effect among the population of compliers, or H-CATE. Formally, H-CATE is defined as CATE for a subgroup of compliers with\na specific value of covariates\n\u03bb(x) =\n\u2211I i=1 \u22112 j=1(r (1) 1sij \u2212 r\n(0) 0sij)I(d1ij = 1, d0ij = 0, Xij = x)\u2211I\ni=1 \u22112 j=1(d1sij \u2212 d0sij)I(Xij = x)\n(4)\nBecause within each matched pair, two individuals are assumed to have identical covariate values, \u03bb(x) can be rewritten as taking a subset of I matched pairs with identical covariates x, say s \u2286 {1, . . . , I}\n\u03bbs =\n\u2211 i\u2208s \u22112 j=1 r (d1sij) 1sij \u2212 r\n(d0sij) 0sij\u2211 i\u2208s \u22112 j=1 d1sij \u2212 d0sij\n(5)\nSince each H-CATE, \u03bbs, has the same form as the original CATE, we can apply the test statistic in Kang et al. (2016). Formally, consider the subset-specific hypothesis denoted H0s : \u03bbs = \u03bb0 against H1s : \u03bbs 6= \u03bb0. Then, we can use the test statistic (2) with variance (3) as described in Section 2.2 using the pairs specific to the subset in question.\nWe conclude this section by showing that the original CATE is equal to a weighted version of H-CATE:\nLemma 1. Suppose assumptions (A1)-(A4) hold. For a given mutually exclusive and exhaustive grouping G = {s1, . . . , sG} of sets of pairs sg \u2286 {1, . . . , I}, where there is at least one complier within each group sg, CATE is equivalent to a weighted average of H-CATEs where the weights are the proportion of compliers within subgroup sg, g = 1, . . . , G divided by the total number of compliers in the data.\n\u03bb = G\u2211 g=1 wsg\u03bbsg , wsg =\n\u2211 i\u2208sg \u22112 j=1 d1sij \u2212 d0sij NCO\nAn implication of Lemma 1 is that the typical analysis of CATE hides the underlying heterogeneity of CATE. For example, suppose there are two subgroups defined by a binary covariate, say male or female, and consider two scenarios. In the first scenario, among compliers, 80% are male and 20% are female, and the H-CATE of male is 1.25 and H-CATE of female is 0. In the second scenario, the male/female complier proportions remain the same, but H-CATE of male is now 1.5 and H-CATE of female is -1. In both cases, by Lemma 1, CATE is 1. But, in the second scenario, females have a negative treatment effect. By studying CATE only, as is typical in practice, the differential effects defined by H-CATE would have been masked. The next section presents a way to expose CATE and discover novel H-CATEs."}, {"heading": "2.4 Discovering Novel H-CATE", "text": "A naive approach to finding novel H-CATE would be to exhaustively test every H-CATE for every subset of matched individuals and gradually aggregate matched pairs depending on their covariate similarities. However, the above procedure will not only lead to false discoveries of null treatment effects, but it will also be grossly underpowered.\nInstead, based on the work by Hsu et al. (2015), we propose to use exploratory machine learning methods, such as CART, where the response going into the machine learning method is the absolute value of the difference in adjusted outcomes and the predictors for the machine learning method are the Xi from each matched pair. CART will group matched pairs into subgroups with similar treatment effects, formulating groupings G and use closed testing (Marcus et al., 1976) to not only test the effect heterogeneity in these groups, but also do so in a manner that strongly control for familywise error rate; see Algorithm 1 for details.\nGiven : Observed outcome R, binary instrument Z, exposure D, covariates X, null value \u03bb0 for testing, and desired familywise error rate \u03b1\n1 Pair match on observed covariates 2 Calculate absolute value of pairwise differences for each pair\u2223\u2223Yi\u2223\u2223 = \u2223\u2223(Zi1 \u2212 Zi2)(Ri1 \u2212 \u03bbDi1 \u2212 (Ri2 \u2212 \u03bbDi2))\u2223\u2223 3 Construct mutually exclusive and exhaustive grouping using CART. Here, CART takes |Yi| as the\noutcome and Xi from each matched pair as the predictors and outputs a partition of covariates, which we use to define G and consequently, H-CATEs.\n4 Run closed testing to test statistical significance of detected H-CATEs Output: Estimated and inferential quantities for H-CATEs (e.g. effect size, confidence interval,\np-value) and novel H-CATEs from closed testing.\nAlgorithm 1: Proposed method to discover and test effect heterogeneity in IV with matching\nWe explain in some detail the key steps in the Algorithm. Similar to Fisher\u2019s sharp null that there is no treatment effect for every individual [Fisher (1935)], we assume there is no instrument effect for every individual, H0 : r (d1ij) 1ij \u2212 \u03bbd1ij = r (d0ij) 0ij \u2212 \u03bbd0ij . This is equivalent to assuming that each individual has a treatment effect proportional to their treatment value, H0 : r (d1ij) 1ij \u2212 r (d0ij) 0ij = \u03bb(d1ij\u2212d0ij). Under this assumption, the absolute\nvalue of the difference in adjusted outcomes, \u2223\u2223Yi\u2223\u2223 = \u2223\u2223(Zi1 \u2212 Zi2)(Ri1 \u2212 \u03bbDi1 \u2212 (Ri2 \u2212 \u03bbDi2))\u2223\u2223, between pairs\nobscures the instrument assignment of the pairs making \u2223\u2223Yi\u2223\u2223 = \u2223\u2223r(d0i1)0i1 \u2212\u03bbd0i1\u2212 (r(d0i2)0i2 \u2212\u03bbd0i2)\u2223\u2223 a function of F only, a fixed (and unknown) quantity. This is not the case if the adjusted outcomes, Yi, were used without the absolute values, as Yi is a function of both F and Z, which is not a fixed quantity. Consequently, conditional on F , building a CART tree based on |Yi| does not affect the distribution of Z; the distribution of Z remains 1/2 as stated in assumption (A3); see Section 3.1 for more details.\nThe algorithm also applies closed testing by conducting nested hypotheses tests constructed from CART\u2019s grouping G. Specifically, for a subset of the mutually exclusive and exhaustive G groups L \u2286 {1, . . . , G} and the hypothesis of the intersection of these groups H0L, closed testing rejects H0L at level \u03b1 if all of the valid p-values pL\u2032 (i.e. p-values from test statistics that control Type I error for that specific hypothesis), of the supersets L\u2032 of L are less than \u03b1. That is, closed testing rejects H0L if pL\u2032 \u2264 \u03b1 for all L\u2032 \u2287 L. Marcus et al. (1976) show that this closed testing procedure rejects at least one true hypothesis at level \u03b1 if and only if the intersection of all true hypotheses is rejected, and therefore the familywise error rate is controlled to be at most \u03b1. Proposition 1 shows this principle holds for Algorithm 1 using CART with absolute valued differences.\nProposition 1 (Familywise Error Rate Control of Algorithm 1). Under the assumption H0 : r (d1ij) 1ij \u2212 r (d0ij) 0ij = \u03bb(d1ij \u2212 d0ij), the conditional probability given (F ,Z,G) that Algorithm 1 makes at least one false rejection of\nthe set of hypotheses is at most \u03b1.\nThrough the use of closed testing, our algorithm allows for strong control of the familywise error rate. It however does not describe the algorithm\u2019s statistical power to detect effect heterogeneity. As a means of exploring the power of our method, we conduct simulation studies measuring the true discovery rate of H-CATE."}, {"heading": "3 Simulations", "text": "The following three simulation settings are designed to (1) analyze the honesty of the simultaneous discovery and inference of the presented method, (2) analyze the proposed method\u2019s performance as a function of constant compliance rate, and (3) again analyze the proposed method\u2019s performance but with varying compliance rate between groups. We hope to see that our method, through CART, not only discovers that H-CATE only depends on certain covariates, but also tests the corresponding hypotheses generated from CART without inflating Type I error.\nEach of the simulation settings use data generated in the form of a \u201cGod\u2019s table\u201d, which is a table of all the\npotential outcomes r (d0ij) 0ij and r (d1ij) 1ij , potential treatments d0ij and d1ij , and covariates Xij of each individual j within each pair i (see Table 1). The observed treatment and outcome values are then taken from the table based on the value of the instrument (i.e. the lottery win), which is determined by a fair coin toss.\nFollowing Hsu et al. (2015), there are six pre-instrument covariates, each generated from independent Bernoulli trials with 0.5 probability of success. At most two covariates, x1 and x2, modify the treatment effect. That is, H-CATEs defined by \u03bb(x1, . . . , x6) in equation 4 are dependent on at most x1 and x2. Also, because both x1 and x2 are binary, there are at most four different H-CATEs \u03bbx1x2 , defined by the different combination of binary variables \u03bb00, \u03bb01, \u03bb10, and \u03bb11. Similar to the design of the OHIE, the data is generated under the assumption of one-sided compliance. This means that, for every individual, the potential treatment having not received the instrument is 0, d0ij = 0. The potential treatment having received the instrument, d1ij , is then a Bernoulli trial with success rate \u03c0x1x2 . The notation implies the success rate, or compliance rate, may depend on the covariates capable of modifying the treatment effect, x1 and x2. Finally, the potential outcomes having not received the instrument r (d0ij) 0ij are from a standard normal distribution r (d0ij) 0ij \u223c N(0, 1), and the potential outcomes having received the instrument r (d1ij) 1ij are a function of the H-CATE and treatment value r (d1ij) 1ij = r (d0ij) 0ij + d1ij\u03bbx1x2 .\nEach simulations consists of I = 2000 pairs for a total of 4000 individuals. And, the regression trees are created in R using the package rpart [Therneau et al. (2015)]. Unless specified otherwise, we use a complexity parameter of 0.005 (half of the default setting) and maintain the default settings for the rest of rpart \u2019s parameters."}, {"heading": "3.1 Honest Simultaneous Discovery and Inference", "text": "One advantage of our method is being able to use the entire data for discovering and testing effect modifiers. In order to simultaneously discover and draw inference on the sample, we use the absolute value of the pairwise differences |Y | as the outcome of CART to obscure the sign of the difference in adjusted outcomes and preserve the original distribution of the instrumental variables (i.e. distribution based on assumption (A3)). We can then use this distribution to draw inference on our discovered potential effect modifiers. We study this phenomenon in two cases: (1) testing a single effect modifier (i.e. one hypothesis) and (2) testing multiple effect modifiers (i.e. multiple hypothesis).\nIn the first case, we are concerned about testing a single hypothesis and controlling the Type I error rate after discovering the hypothesis via CART. To investigate the effect of simultaneously discovering and drawing inference, we generate a \u201cGod\u2019s table\u201d with no treatment effect, \u03bbx1x2 = 0 for all x1, x2, and form potential effect modifiers for two different cases, (i) using |Y | and (ii) Y as the outcome for CART. The first leaf of each tree (or tree\u2019s root if no leaves are formed) is then used to test the null hypothesis of no treatment effect. As a result of conducting CART to form a hypothesis 2000 times, Figure 2 shows the histogram of p-values when we use |Y | as the outcome for CART versus Y as the outcome for CART. Under |Y |, the p-values resemble a uniform distribution and hence, Type I error is controlled. However, under Y , the p-values are right-skewed implying that Type I error is inflated. In other words, the null hypothesis is rejected more frequently when using Y as the outcome of CART, demonstrating the \u201cwinner\u2019s curse\u201d phenomena. Therefore, as predicted by Proposition 1, using |Y | as the outcome in CART prevents the contamination of the \u03b1 level of the hypothesis test and allow for simultaneous discovery and inference.\nIn the second case, with multiple hypotheses, we are concerned with the average Type I error rate and strong control of the familywise error rate rate when testing multiple hypotheses. To evaluate strong control of the familywise error rate, we generate the data where there is an effect in some groups and no effect in others, \u03bb00 = 2, \u03bb01 = \u03bb10 = 0 = \u03bb11 = 0. Furthermore, for rpart, we reduce the complexity parameter to 0.0001 to encourage more liberal splitting and set the max depth of the regression tree to be 4 to save on computational time. After data generation we randomly assign instrument values within pairs and split the data using |Y |\nand Y 2000 times. Each hypothesis is tested for whether or not there is a treatment effect H0 : \u03bb = 0, so true hypotheses are hypotheses of groups of pairs generated with \u03bb01 = \u03bb10 = \u03bb11 = 0. The average Type I error rate is computed by taking the average of the proportion of false rejections from each of the 2000 simulated trees and the familywise error rate is computed by taking the average of any false rejections amongst the 2000 simulated trees.\nThe results of this simulation show that the average type I error rate and familywise error rate are below the \u03b1 level of the hypothesis tests in both simulation settings |Y | and Y . The average Type I error rate for |Y | and Y is 0.0008 and 0.0003, respectively. The familywise error rate for both |Y | and Y is 0.028 (See Table 2). This is surprising considering that closed testing requires that each hypothesis test be level \u03b1 to strongly control the familywise error rate and using Y as the outcome contaminates the test\u2019s level, as seen in Section 3.1. Despite the theoretical underpinnings for this data generation process, closed testing seems to strongly control the familywise error rate regardless of whether or not the test\u2019s size is preserved by a technique such as taking the absolute value. Upon closer investigation, it seems that the trees formed in both Y and |Y | cases are the same at the upper levels of the tree, as there is a particularly strong signal for a certain group \u03bb00 = 2. This then leads to the same hypotheses in both settings resulting in similar Type I error rates and familywise error rates. Overall, the simulation suggests that in the case where there is one very strong signal, the difference between using |Y | and Y is minor. But, we do stress familywise error control is only guaranteed for the |Y | case."}, {"heading": "3.2 Weak Instrument with Constant Compliance", "text": "Instrument strength is a description of how large of a push the instrument gives towards or against treatment. If the probability of complying with the instrument\u2019s nudge is high then the instrument is considered strong. Under noncompliance, the performance of statistical tests and estimation depends strongly on the strength of the instrument, particularly when the instrument is weak; see Staiger and Stock (1997) and Stock et al. (2002) and references therein for more details. It is our intention to understand how instrument strength affects estimating and inferring H-CATE.\nWe chose four heterogeneous treatment settings for consideration. The four settings are referred to as (a) no heterogeneity, (b) similar heterogeneity, (c) strong heterogeneity, and (d) complex heterogeneity, and each of the four settings have an overall complier average treatment effect of \u03bb = 0.5. The settings are defined as (a) there are no effect modifiers resulting in one subgroup with equal treatment effects, \u03bb00 = \u03bb01 = \u03bb10 = \u03bb11 = 0.5; (b) there is one effect modifier resulting in two subgroups with similar but different treatment effects, \u03bb00 = \u03bb01 = 0.7 and \u03bb10 = \u03bb11 = 0.3; (c) there is one effect modifier resulting in two subgroups with dissimilar treatment effects, \u03bb00 = \u03bb01 = 0.9 and \u03bb10 = \u03bb11 = 0.1; and (d) there are two effect modifiers resulting in three subgroups, one with a strong effect, two with no effect, and the last group with the average effect, \u03bb00 = 1.5, \u03bb01 = \u03bb10 = 0 and \u03bb11 = 0.5. These definitions are concisely provided in Table 3. We note that each group has the same compliance rate.\nTo further measure and understand the performance of the proposed method, we measure the ability of CART to correctly partition the pairs into groups defined in Table 3. For each pair i, we know their treatment effect \u03bbi, which depends on the pairs of covariates x1 and x2, so we\u2019re able to define a perfect partition based\non the treatment effects in the leaves of CART. Let \u03bb\u0304g = |sg|\u22121 \u2211 i\u2208sg \u03bbi denote the average treatment effect of the gth subgroup sg, or leaf, in G. A perfect tree is then defined as the case when \u03bbi = \u03bb\u0304g for all i \u2208 sg for every g, which is the case that CART partitions the subgroups to having the same identifying treatment effects. The metric used to measure how close a given tree is to a perfect tree is\n\u03c6G =\n\u2211G g=1 \u2211 i\u2208sg (\u03bbi \u2212 \u03bb\u0304g)\n2 + \u03c32i\u2211G g=1 \u2211 i\u2208sg \u03c3 2 i\nwhich is the fractional increase in mean squared error from grouping G compared with a perfect grouping, used by Hsu et al. (2015). Here, \u03c32i = 1 for all individuals as r (d0ij) 0ij \u223c N(0, 1) in the \u201cGod\u2019s table\u201d. A perfect tree has \u03c6G = 1. From hereon, \u03c6G is referred to as tree accuracy.\nThe simulations are conducted within each treatment heterogeneity setting. We first generate the data in the form of a \u201cGod\u2019s table\u201d for a given compliance rate, as described above. Then, we (i) randomly assign the instrument within each pair i, (ii) calculate |Yi|, (iii) form grouping G using CART, and (iv) finally conduct hypothesis tests using closed testing. We repeat (i)-(iv) 2000 times and measure two quantities, the average true discovery rate and the average Type I error. The true discovery rates are computed as the number of true rejections of false null hypotheses divided by the total number of false null hypotheses per simulation and the average is taken across the 2000 simulations. Similarly, the Type I error rate is calculated as the total number of false rejections of true null hypotheses divided by the total number of true null hypotheses and the average taken across the 2000 simulations. We remark that the null hypothesis is that of no treatment effect and, since all treatment heterogeneity settings have an overall effect of \u03bb = 0.5, only hypotheses consisting of pairs generated with \u03bbx1x2 = 0 are true null hypotheses.\nFigures 3 and 4 show the true discovery rate under the four treatment heterogeneity settings as a function of instrument strength, as measured by the overall compliance rate. We see that as compliance with treatment grows, the true discovery rate of our method grows for all of the treatment heterogeneity settings. This aligns with our expectations, since as more individuals comply with their treatment there is a stronger signal of treatment effect. We further see that the tree becomes more accurate as the compliance rate increases, since the size of the dots denote the average tree accuracy for the regression trees formed. Recall that a values closer to 1 denotes greater accuracy. The size ranges from smallest, a tree accuracy of \u03c6G = 1 to largest, \u03c6G \u2248 1.4. In Figure 3, which presents the no heterogeneity and the slight heterogeneity setting, there is a minor difference in the true discovery rate and tree complexity. The size of the dots in this figure represent \u03c6G = 1 for the no heterogeneity setting and range from \u03c6G \u2248 1.02 to \u03c6G \u2248 1.04 in the slight heterogeneity setting.\nIn Figure 4, we observe a counter-intuitive dip in true discovery rate as compliance rate grows. To investigate\nthis drop, we also plot in shades of gray the true discovery rate of single subgroups formed by CART, and the darker shade of gray denotes leaves containing pairs with a stronger treatment effect. For example, in the strong heterogeneity setting, the darker gray represents pairs formed by \u03bb00 = \u03bb01 = 0.9, and the lighter gray represents pairs formed by \u03bb10 = \u03bb11 = 0.1. For the complex heterogeneity setting, the darker gray denotes pairs generated by \u03bb00 = 1.5, and a lighter gray isn\u2019t shown because CART fails to form a group consisting of only pairs generated by \u03bb11 = 0.5. By comparing the curves, we see that the drop in the true discovery rate is due to the formation of leaves with smaller treatment effects as the compliance rate grows. This can be seen from the size of the dots decreasing at the start of the dip, indicating that the tree is getting more accurate. Specifically, tree accuracy ranges from \u03c6G = 1 to \u03c6G = 1.15 for the strong heterogeneity setting and \u03c6G = 1.03 to \u03c6G = 1.36 for the complex heterogeneity setting. Because the compliance rate is large enough, these small effects are beginning to be detected by CART. But, the power to detect these effects are much smaller than the large effects represented by the darker grey curves and the overall true discovery rate, which is roughly the average of these two curves, dips at the lower end of the compliance rate. However, As the compliance rate grows, we see the true discovery rate of our method begin to climb again, as more signal for the smaller H-CATE groups is gained."}, {"heading": "3.3 Weak Instruments with Varying Compliance", "text": "Up until now, the simulation setting has assumed constant compliance rates across the groups, but it is possible that the compliance rates vary between groups. Therefore, we further consider four varying compliance rate settings as an extension of understanding the method\u2019s performance. These four different compliance settings are referred to as (a) same, (b) similar, (c) different (1), and (d) different (2) and are functions of the overall\ncompliance rate \u03c0. Each are categorized based on the distance from the overall compliance rate. If the overall compliance is less than a half, \u03c0 \u2264 0.5, a group\u2019s compliance rate is \u03c0x1x2 = \u03c0 + cx1x2\u03c0, and if \u03c0 > 0.5, a group\u2019s compliance rate is \u03c0x1x2 = \u03c0 + cx1x2(1 \u2212 \u03c0) for some constant cx1x2 \u2208 [0, 1]. The four settings are then defined by the constants cx1x2 ; (a) same compliance c00 = c01 = c10 = c11 = 0; (b) similar compliance c00 = c01 = \u22120.1 and c10 = c11 = +0.1; (c) different (1) compliance c00 = c01 = \u22120.5 and c10 = c11 = +0.5; and different (2) compliance c00 = \u22120.3, c01 = \u22120.5, c10 = +0.1, and c11 = +0.7. The compliance settings for when \u03c0 \u2264 0.5 are concisely shown in Table 4. When combined with Table 3, we have a total of 16 possible settings of heterogeneity in H-CATE. We also remark that subgroups experiencing a larger H-CATE have a reduced compliance rate.\nFigure 5 shows the true discovery rate of the four compliance types for each treatment heterogeneity setting. The gray lines now denote the different compliance types, where the darker shade of gray represents a more dissimilar compliance rate between groups. So, the lightest shade of gray represents the same compliance setting and the darkest shade represents the different (2) compliance setting. As the compliance rates get more different, reducing the signal of the stronger H-CATE group, we observe a reduction in the true discovery rate. This is most noticeable in the strong heterogeneity setting, where we see pronounced differences in the true discovery rate amongst the different compliance settings. In this setting, we also see a change in true discovery rate between the more different and more similar compliance groups; the more different compliance groups have an increased true discovery rate after an overall compliance rate of \u03c0 \u2248 0.45. At this point, the dot sizes of the lighter gray lines are smaller, implying the trees are becoming more accurate at lower overall compliance rates. This is due to the lower compliance rate in the groups with stronger H-CATE obscuring the signal for which CART uses to split on. As the overall compliance rate grows, so too does the subgroup-specific compliance rates, and so the true discovery rates of the compliance settings converge. This is evidence that our method\u2019s true discovery rate relies on both the subgroup-specific size of H-CATEs and subgroup-specific compliance rates.\nOur simulation studies show that our method strongly controls for familywise error rate while remaining able to detect a variety of treatment heterogeneity. The use of |Y | as the outcome of CART prevents an increase in Type I error, preserving the level \u03b1 of our hypothesis tests. However, we did note that in the presence of strong signal, closed testing with |Y | and Y had little differences in Type I error rate. Our analysis of our method\u2019s power showed that the true discovery rate is a function of both the size of subgroup\u2019s H-CATE and subgroup\u2019s compliance rate."}, {"heading": "4 Oregon Health Insurance Experiment Example", "text": ""}, {"heading": "4.1 Data Description", "text": "We use our method to analyze the differential effects of Medicaid on the number of days an individual\u2019s physical or mental health prevent their usual activities from the OHIE study. In brief, the OHIE collected administrative data on hospital discharges, credit reports, and mortality, survey data on health care utilization, financial strain, and overall health, and prerandomization demographic data. A total of 74,922 individuals were included in the study. Of these individuals, there were 11,808 lottery winners and 11,933 controls with publicly available survey data for a total sample size of 23,741 individuals for our analysis; see Finkelstein et al. (2012) for details.\nWe matched on demographic, prerandomization variables recorded by Finkelstein et al. (2012): sex, age, whether they preferred English materials when signing up for the lottery, whether they lived in a metropolitan statistical area (MSA), their education level (less than high school, high school diploma or GED, vocational or 2-year degree, 4-year college degree or more), and self-identified race (as the individual reported in the survey). Since some of the covariates had missing data, namely self-identifying as Hispanic or Black and their level of education, we also match on indicators of these covariates; see Section 9.4 of Rosenbaum (2010) for details. We used R package bigmatch [Yu (2019)] to generate our optimal pair matched set using optimal calipers, where the caliper is optimal in the sense that it is the smallest caliper such that an optimal match exists. The covariate similarity between lottery winners and losers is calculated using a robust rank-based Mahalanobis distance as in Yu (2019). The performance of the matched set is assessed by checking covariate balance in Figure 6.\nFor the majority of covariates, the matching algorithm did little to change the absolute standard differences\nbetween lottery winners and controls, which is not surprising given that the lottery was randomized. However, the indicator for missingness in education, self-identified American Indian, and Black were made to be more similar after matching. An absolute standardized difference of 0.25 is deemed trustworthy [Rubin (2001), Stuart (2010)], which our covariates satisfy after matching."}, {"heading": "4.2 Analysis and Results", "text": "In this paper, we examine the effect of enrolling in Medicaid on the number of days an individual\u2019s physical or mental health did not prevent them from their usual activities, in the past 30 days of their survey response. The absolute value of the difference in adjusted outcomes are calculated and used by CART to form a tree partitioning of the groups. Our formed tree, shown in Figure 7, was created using the R package rpart [Therneau et al. (2015)] with a complexity parameter of 0 and maximum depth of 4. The depth of the tree was chosen by forming trees of larger depth and then pruning back until a more intepretable tree was obtained.\nFor each node of the CART, we test for whether or not there is an effect of enrolling in Medicaid H0s : \u03bbs = 0. In Figure 7, a solid lined box denotes a hypothesis that was rejected and a dashed lined box denotes a hypothesis that was failed to be rejected, both by the closed testing procedure. Each node contains its corresponding estimated H-CATE \u03bb\u0302s, its 95% confidence interval, the number of pairs Is, and compliance rate \u03c0s. Here, a positive H-CATE implies a decrease in the number of days where the individual\u2019s physical and mental health prevented them from their usual activities, and a negative value implies an increase. Note, some nodes imply a significant effect of Medicaid at the alpha level of 0.05, but are enclosed in a dashed lined box. This is due to the closed testing procedure; an intersection of hypotheses containing the node in question was failed to be rejected, and so any hypotheses in this intersection cannot be rejected.\nFrom the CART results, we can see evidence of heterogeneous treatment effects amongst the complier population. Complying men, over the age of 36, who do not identify as Asian, and prefer English have a\nstronger effect of Medicaid on the number of days an individual\u2019s physical or mental health did not prevent them from their usual activities. Furthermore, complying individuals younger than 36, who prefer English, and with no more than a high school diploma or GED have a stronger effect of Medicaid on increasing the number of days not impeded upon by their physical and mental health. Lastly, it\u2019s possible that CART overfits the data and suggests heterogeneity where it doesn\u2019t exist, but our method controls for this by conducting honest familywise statistical inference and retaining the null if there is truly no treatment effect.\nWe also note that there is some variation in the compliance rates amongst groups, although most of them are minor. The minor variation suggests that while some groups are more likely to be compliers than others, most of the effect heterogeneity is likely driven by the variation in how the treatment responds to these subgroups; a bit more formally, most of the effect heterogeneity in the data is likely arising from the numerator of H-CATE rather than the denominator of H-CATE."}, {"heading": "5 Summary", "text": "We propose a method to detect treatment effect heterogeneity using an IV. Under the usual IV assumptions, our method discovers and tests heterogeneity in H-CATEs by using matching, CART, and closed testing, all without the need to do sample splitting. The latter is achieved by taking the absolute value of the adjusted pairwise differences to conceal the instrument assignment. Our method was shown to strongly control the familywise error rate. We conducted a simulation study to examine the power of our method under varying degrees of\ncompliance and effect heterogeneity and showed that our method can detect wide variety of heterogeneity. Our method was used to study the effect of Medicaid on the number of days an individual\u2019s physical or mental health did not prevent their usual activities where we used the lottery selection as an instrument. It was found that Medicaid has a larger impact on improving the number of days not impeded upon by their health for complying, older, non-Asian men who selected English materials at lottery sign-up and for complying, younger, less educated individuals who selected English materials at lottery sign-up."}], "title": "Detecting Heterogeneous Treatment Effect with Instrumental Variables", "year": 2019}