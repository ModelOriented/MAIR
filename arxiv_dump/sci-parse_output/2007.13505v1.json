{"abstractText": "A central mechanism in machine learning is to identify, store, and recognize patterns. How to learn, access, and retrieve such patterns is crucial in Hopfield networks and the more recent transformer architectures. We show that the attention mechanism of transformer architectures is actually the update rule of modern Hopfield networks that can store exponentially many patterns. We exploit this high storage capacity of modern Hopfield networks to solve a challenging multiple instance learning (MIL) problem in computational biology: immune repertoire classification. Accurate and interpretable machine learning methods solving this problem could pave the way towards new vaccines and therapies, which is currently a very relevant research topic intensified by the COVID-19 crisis. Immune repertoire classification based on the vast number of immunosequences of an individual is a MIL problem with an unprecedentedly massive number of instances, two orders of magnitude larger than currently considered problems, and with an extremely low witness rate. In this work, we present our novel method DeepRC that integrates transformer-like attention, or equivalently modern Hopfield networks, into deep learning architectures for massive MIL such as immune repertoire classification. We demonstrate that DeepRC outperforms all other methods with respect to predictive performance on large-scale experiments, including simulated and real-world virus infection data, and enables the extraction of sequence motifs that are connected to a given disease class. Source code and datasets: https://github.com/ml-jku/DeepRC", "authors": [{"affiliations": [], "name": "Michael Widrich"}, {"affiliations": [], "name": "Bernhard Sch\u00e4fl"}, {"affiliations": [], "name": "Milena Pavlovi\u0107"}, {"affiliations": [], "name": "Hubert Ramsauer"}, {"affiliations": [], "name": "Lukas Gruber"}, {"affiliations": [], "name": "Markus Holzleitner"}, {"affiliations": [], "name": "Johannes Brandstetter"}, {"affiliations": [], "name": "Geir Kjetil Sandve"}, {"affiliations": [], "name": "Victor Greiff"}, {"affiliations": [], "name": "Sepp Hochreiter"}, {"affiliations": [], "name": "G\u00fcnter Klambauer"}], "id": "SP:ca4209e614b726f89210d0073cf96b9257f2f15f", "references": [{"authors": ["R. Akbar", "P.A. Robert", "M. Pavlovi\u0107", "J.R. Jeliazkov", "I. Snapkov", "A. Slabodkin", "C.R. Weber", "L. Scheffer", "E. Miho", "Haff", "I. H"], "title": "A compact vocabulary of paratope-epitope interactions enables predictability of antibody-antigen binding", "venue": "bioRxiv,", "year": 2019}, {"authors": ["B. Alipanahi", "A. Delong", "M.T. Weirauch", "B.J. Frey"], "title": "Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning", "venue": "Nature Biotechnology,", "year": 2015}, {"authors": ["L. Arras", "J. Arjona-Medina", "M. Widrich", "G. Montavon", "M. Gillhofer", "M\u00fcller", "K.-R", "S. Hochreiter", "W. Samek"], "title": "Explaining and interpreting LSTMs", "venue": "In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning,", "year": 2019}, {"authors": ["W.R. Atchley", "J. Zhao", "A.D. Fernandes", "T. Dr\u00fcke"], "title": "Solving the protein sequence metric problem", "venue": "Proceedings of the National Academy of Sciences,", "year": 2005}, {"authors": ["F. Briggs", "X.Z. Fern", "R. Raich"], "title": "Rank-loss support instance machines for miml instance annotation", "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "year": 2012}, {"authors": ["A.J. Brown", "I. Snapkov", "R. Akbar", "M. Pavlovi\u0107", "E. Miho", "G.K. Sandve", "V. Greiff"], "title": "Augmenting adaptive immunity: progress and challenges in the quantitative engineering and analysis of adaptive immune receptor repertoires", "venue": "Molecular Systems Design & Engineering,", "year": 2019}, {"authors": ["Carbonneau", "M.-A", "V. Cheplygina", "E. Granger", "G. Gagnon"], "title": "Multiple instance learning: a survey of problem characteristics and applications", "venue": "Pattern Recognition,", "year": 2018}, {"authors": ["S. Christley", "W. Scarborough", "E. Salinas", "W.H. Rounds", "I.T. Toby", "J.M. Fonner", "M.K. Levin", "M. Kim", "S.A. Mock", "C Jordan"], "title": "VDJServer: a cloud-based analysis portal and data commons for immune repertoire sequences and rearrangements", "venue": "Frontiers in Immunology,", "year": 2018}, {"authors": ["A. Christophersen", "M. R\u00e1ki", "E. Bergseng", "K.E. Lundin", "J. Jahnsen", "L.M. Sollid", "Qiao", "S.-W"], "title": "Tetramer-visualized gluten-specific CD4+ T cells in blood as a potential diagnostic marker for coeliac disease without oral gluten challenge", "venue": "United European Gastroenterology Journal,", "year": 2014}, {"authors": ["B.D. Corrie", "N. Marthandan", "B. Zimonja", "J. Jaglale", "Y. Zhou", "E. Barr", "N. Knoetze", "F.M. Breden", "S. Christley", "Scott", "J. K"], "title": "iReceptor: a platform for querying and analyzing antibody/B-cell and T-cell receptor repertoire data across federated repositories", "venue": "Immunological Reviews,", "year": 2018}, {"authors": ["P. Dash", "A.J. Fiore-Gartland", "T. Hertz", "G.C. Wang", "S. Sharma", "A. Souquette", "J.C. Crawford", "E.B. Clemens", "T.H. Nguyen", "K Kedzierska"], "title": "Quantifiable predictive features define epitope-specific T cell receptor", "venue": "repertoires. Nature,", "year": 2017}, {"authors": ["M. Demircigil", "J. Heusel", "M. L\u00f6we", "S. Upgang", "F. Vermet"], "title": "On a model of associative memory with huge storage capacity", "venue": "Journal of Statistical Physics,", "year": 2017}, {"authors": ["J. Devlin", "Chang", "M.-W", "K. Lee", "K. Toutanova"], "title": "BERT: pre-training of deep bidirectional transformers for language understanding", "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association", "year": 2019}, {"authors": ["T.G. Dietterich", "R.H. Lathrop", "T. Lozano-P\u00e9rez"], "title": "Solving the multiple instance problem with axis-parallel rectangles", "venue": "Artificial Intelligence,", "year": 1997}, {"authors": ["Y. Elhanati", "Z. Sethna", "C.G. Callan Jr.", "T. Mora", "A.M. Walczak"], "title": "Predicting the spectrum of TCR repertoire sharing with a data-driven model of recombination", "venue": "Immunological Reviews,", "year": 2018}, {"authors": ["R.O. Emerson", "W.S. DeWitt", "M. Vignali", "J. Gravley", "J.K. Hu", "E.J. Osborne", "C. Desmarais", "M. Klinger", "C.S. Carlson", "Hansen", "J. A"], "title": "Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire", "venue": "Nature Genetics,", "year": 2017}, {"authors": ["D.S. Fischer", "Y. Wu", "B. Schubert", "F.J. Theis"], "title": "Predicting antigen-specificity of single T-cells based on TCR CDR3 regions", "venue": "bioRxiv,", "year": 2019}, {"authors": ["J. Foulds", "E. Frank"], "title": "A review of multi-instance learning assumptions", "venue": "The Knowledge Engineering Review,", "year": 2010}, {"authors": ["J.D. Galson", "S. Schaetzle", "R.J.M. Bashford-Rogers", "M.I.J. Raybould", "A. Kovaltsuk", "G.J. Kilpatrick", "R. Minter", "D.K. Finch", "J. Dias", "L. James", "G. Thomas", "Lee", "W.-Y. J", "J. Betley", "O. Cavlan", "A. Leech", "C.M. Deane", "J. Seoane", "C. Caldas", "D. Pennington", "P. Pfeffer", "J. Osbourn"], "title": "Deep sequencing of B cell receptor repertoires from COVID-19 patients reveals strong convergent immune signatures", "venue": "bioRxiv,", "year": 2020}, {"authors": ["E.D. Gelasca", "J. Byun", "B. Obara", "B. Manjunath"], "title": "Evaluation and benchmark for biological image segmentation", "venue": "In 2008 15th IEEE International Conference on Image Processing,", "year": 2008}, {"authors": ["G. Georgiou", "G.C. Ippolito", "J. Beausang", "C.E. Busse", "H. Wardemann", "S.R. Quake"], "title": "The promise and challenge of high-throughput sequencing of the antibody repertoire", "venue": "Nature Biotechnology,", "year": 2014}, {"authors": ["S. Gielis", "P. Moris", "W. Bittremieux", "N. De Neuter", "B. Ogunjimi", "K. Laukens", "P. Meysman"], "title": "TCRex: detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires", "venue": "bioRxiv,", "year": 2019}, {"authors": ["J. Glanville", "H. Huang", "A. Nau", "O. Hatton", "L.E. Wagar", "F. Rubelt", "X. Ji", "A. Han", "S.M. Krams", "C Pettus"], "title": "Identifying specificity groups in the T cell receptor repertoire", "year": 2017}, {"authors": ["A. Graves"], "title": "Generating sequences with recurrent neural networks", "venue": "ArXiv, 1308.0850,", "year": 2013}, {"authors": ["V. Greiff", "P. Bhat", "S.C. Cook", "U. Menzel", "W. Kang", "S.T. Reddy"], "title": "A bioinformatic framework for immune repertoire diversity profiling enables detection of immunological status", "venue": "Genome Medicine,", "year": 2015}, {"authors": ["V. Greiff", "C.R. Weber", "J. Palme", "U. Bodenhofer", "E. Miho", "U. Menzel", "S.T. Reddy"], "title": "Learning the high-dimensional immunogenomic features that predict public and private antibody repertoires", "venue": "The Journal of Immunology,", "year": 2017}, {"authors": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "title": "Improving neural networks by preventing co-adaptation of feature", "venue": "detectors. ArXiv,", "year": 2012}, {"authors": ["S. Hochreiter", "J. Schmidhuber"], "title": "Long short-term memory", "venue": "Neural computation,", "year": 1997}, {"authors": ["S. Hochreiter", "M. Heusel", "K. Obermayer"], "title": "Fast model-based protein homology detection without alignment", "year": 2007}, {"authors": ["J.J. Hopfield"], "title": "Neural networks and physical systems with emergent collective computational abilities", "venue": "Proceedings of the National Academy of Sciences,", "year": 1982}, {"authors": ["B. Hu", "Z. Lu", "H. Li", "Q. Chen"], "title": "Convolutional neural network architectures for matching natural language sentences", "venue": "In Advances in Neural Information Processing Systems,", "year": 2014}, {"authors": ["M. Ilse", "J.M. Tomczak", "M. Welling"], "title": "Attention-based deep multiple instance learning", "venue": "International Conference on Machine Learning (ICML),", "year": 2018}, {"authors": ["V.I. Jurtz", "L.E. Jessen", "A.K. Bentzen", "M.C. Jespersen", "S. Mahajan", "R. Vita", "K.K. Jensen", "P. Marcatili", "S.R. Hadrup", "B Peters"], "title": "NetTCR: sequence-based prediction of TCR binding to peptide-MHC complexes using convolutional neural networks. bioRxiv, 2018", "year": 2018}, {"authors": ["D.R. Kelley", "J. Snoek", "J.L. Rinn"], "title": "Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks", "venue": "Genome Research,", "year": 2016}, {"authors": ["S. Kimeswenger", "E. Rumetshofer", "M. Hofmarcher", "P. Tschandl", "H. Kittler", "S. Hochreiter", "W. H\u00f6tzenecker", "G. Klambauer"], "title": "Detecting cutaneous basal cell carcinomas in ultra-high resolution and weakly labelled histopathological", "venue": "images. ArXiv,", "year": 2019}, {"authors": ["D.P. Kingma", "J. Ba"], "title": "Adam: a method for stochastic optimization", "venue": "ArXiv, 1412.6980,", "year": 2014}, {"authors": ["G. Klambauer", "T. Unterthiner", "A. Mayr", "S. Hochreiter"], "title": "Self-normalizing neural networks", "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"authors": ["H. Konishi", "D. Komura", "H. Katoh", "S. Atsumi", "H. Koda", "A. Yamamoto", "Y. Seto", "M. Fukayama", "R. Yamaguchi", "S Imoto"], "title": "Capturing the differences between humoral immunity in the normal and tumor environments from repertoire-seq of B-cell receptors using supervised machine learning", "venue": "BMC Bioinformatics,", "year": 2019}, {"authors": ["A. Kovaltsuk", "J. Leem", "S. Kelm", "J. Snowden", "C.M. Deane", "K. Krawczyk"], "title": "Observed antibody space: a resource for data mining next-generation sequencing of antibody repertoires", "venue": "The Journal of Immunology,", "year": 2018}, {"authors": ["D. Krotov", "J.J. Hopfield"], "title": "Dense associative memory for pattern recognition", "venue": "Advances in Neural Information Processing Systems,", "year": 2016}, {"authors": ["D. Krotov", "J.J. Hopfield"], "title": "Dense associative memory is robust to adversarial inputs", "venue": "Neural Computation,", "year": 2018}, {"authors": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "title": "Gradient-based learning applied to document recognition", "venue": "Proceedings of the IEEE,", "year": 1998}, {"authors": ["J. Lee", "Y. Lee", "J. Kim", "A. Kosiorek", "S. Choi", "Y.W. Teh"], "title": "Set transformer: a framework for attention-based permutation-invariant neural networks", "venue": "In International Conference on Machine Learning,", "year": 2019}, {"authors": ["Lefranc", "M.-P", "C. Pommi\u00e9", "M. Ruiz", "V. Giudicelli", "E. Foulquier", "L. Truong", "V. Thouvenin-Contet", "G. Lefranc"], "title": "Imgt unique numbering for immunoglobulin and t cell receptor variable domains and ig superfamily", "venue": "v-like domains. Developmental & Comparative Immunology,", "year": 2003}, {"authors": ["B. Li", "S.M. Leal"], "title": "Methods for detecting associations with rare variants for common diseases: application to analysis of sequence data", "venue": "The American Journal of Human Genetics,", "year": 2008}, {"authors": ["P. Lucey", "J.F. Cohn", "T. Kanade", "J. Saragih", "Z. Ambadar", "I. Matthews"], "title": "The extended cohnkanade dataset (ck+): A complete dataset for action unit and emotion-specified expression", "venue": "In 2010 ieee computer society conference on computer vision and pattern recognition-workshops,", "year": 2010}, {"authors": ["Q. Marcou", "T. Mora", "A.M. Walczak"], "title": "High-throughput immune repertoire analysis with IGoR", "venue": "Nature Communications,", "year": 2018}, {"authors": ["O. Maron", "T. Lozano-P\u00e9rez"], "title": "A framework for multiple-instance learning", "venue": "In Advances in Neural Information Processing Systems,", "year": 1998}, {"authors": ["E. Miho", "A. Yermanos", "C.R. Weber", "C.T. Berger", "S.T. Reddy", "V. Greiff"], "title": "Computational strategies for dissecting the high-dimensional complexity of adaptive immune repertoires", "venue": "Frontiers in Immunology,", "year": 2018}, {"authors": ["A.A. Minervina", "E.A. Komech", "A. Titov", "M.B. Koraichi", "E. Rosati", "I.Z. Mamedov", "A. Franke", "G.A. Efimov", "D.M. Chudakov", "T. Mora", "A.M. Walczak", "Y.B. Lebedev", "M.V. Pogorelyy"], "title": "Longitudinal high-throughput TCR repertoire profiling reveals the dynamics of T cell memory formation after mild COVID-19 infection", "venue": "bioRxiv,", "year": 2020}, {"authors": ["G. Montavon", "W. Samek", "M\u00fcller", "K.-R"], "title": "Methods for interpreting and understanding deep neural networks", "venue": "Digital Signal Processing,", "year": 2018}, {"authors": ["G. Montavon", "A. Binder", "S. Lapuschkin", "W. Samek", "M\u00fcller", "K.-R"], "title": "Layer-wise relevance propagation: an overview", "venue": "In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning,", "year": 2019}, {"authors": ["P. Moris", "J. De Pauw", "A. Postovskaya", "B. Ogunjimi", "K. Laukens", "P. Meysman"], "title": "Treating biomolecular interaction as an image classification problem \u2013 a case study on T-cell receptorepitope recognition", "year": 2019}, {"authors": ["B.J. Olson", "P. Moghimi", "C. Schramm", "A. Obraztsova", "D.K. Ralph", "J.A. Vander Heiden", "M. Shugay", "A.J. Shepherd", "W.D. Lees", "I Matsen"], "title": "sumrep: a summary statistic framework for immune receptor repertoire comparison and model validation", "venue": "Frontiers in Immunology,", "year": 2019}, {"authors": ["J. Ostmeyer", "S. Christley", "I.T. Toby", "L.G. Cowell"], "title": "Biophysicochemical motifs in T-cell receptor sequences distinguish repertoires from tumor-infiltrating lymphocyte and adjacent healthy tissue", "venue": "Cancer Research,", "year": 2019}, {"authors": ["A. Paszke", "S. Gross", "F. Massa", "A. Lerer", "J. Bradbury", "G. Chanan", "T. Killeen", "Z. Lin", "N. Gimelshein", "L Antiga"], "title": "Pytorch: an imperative style, high-performance deep learning library", "venue": "In Advances in Neural Information Processing Systems,", "year": 2019}, {"authors": ["N. Pawlowski", "S. Bhooshan", "N. Ballas", "F. Ciompi", "B. Glocker", "M. Drozdzal"], "title": "Needles in haystacks: on classifying tiny objects in large", "venue": "images. ArXiv,", "year": 2019}, {"authors": ["K. Preuer", "G. Klambauer", "F. Rippmann", "S. Hochreiter", "T. Unterthiner"], "title": "Interpretable deep learning in drug discovery", "venue": "In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning,", "year": 2019}, {"authors": ["C.R. Qi", "H. Su", "K. Mo", "L.J. Guibas"], "title": "Pointnet: deep learning on point sets for 3D classification and segmentation", "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "year": 2017}, {"authors": ["L. Ralaivola", "S.J. Swamidass", "H. Saigo", "P. Baldi"], "title": "Graph kernels for chemical informatics", "venue": "Neural Networks,", "year": 2005}, {"authors": ["M.I.J. Raybould", "A. Kovaltsuk", "C. Marks", "C.M. Deane"], "title": "CoV-AbDab: the coronavirus antibody", "venue": "database. bioRxiv,", "year": 2020}, {"authors": ["A.M. Rosenfeld", "W. Meng", "E.T. Luning Prak", "U. Hershberg"], "title": "Immunedb, a novel tool for the analysis, storage, and dissemination of immune repertoire sequencing data", "venue": "Frontiers in Immunology,", "year": 2018}, {"authors": ["A.T. Ruiz", "P. Thiam", "F. Schwenker", "G. Palm"], "title": "A $$k$$-nearest neighbor based algorithm for multi-instance multi-label active learning", "venue": "Artificial Neural Networks in Pattern Recognition,", "year": 2018}, {"authors": ["F. Sebastiani"], "title": "Machine learning in automated text categorization", "venue": "ACM computing surveys (CSUR),", "year": 2002}, {"authors": ["I. Setliff", "A.R. Shiakolas", "K.A. Pilewski", "A.A. Murji", "R.E. Mapengo", "K. Janowska", "S. Richardson", "C. Oosthuysen", "N. Raju", "L Ronsard"], "title": "High-throughput mapping of B cell receptor sequences to antigen", "venue": "specificity. Cell,", "year": 2019}, {"authors": ["M. Shugay", "D.V. Bagaev", "M.A. Turchaninova", "D.A. Bolotin", "O.V. Britanova", "E.V. Putintseva", "M.V. Pogorelyy", "V.I. Nazarov", "I.V. Zvyagin", "Kirgizova", "V. I"], "title": "VDJtools: unifying post-analysis of T cell receptor repertoires", "venue": "PLOS Computational Biology,", "year": 2015}, {"authors": ["M. Shugay", "D.V. Bagaev", "I.V. Zvyagin", "R.M. Vroomans", "J.C. Crawford", "G. Dolton", "E.A. Komech", "A.L. Sycheva", "A.E. Koneva", "Egorov", "E. S"], "title": "VDJdb: a curated database of T-cell receptor sequences with known antigen specificity", "venue": "Nucleic Acids Research,", "year": 2018}, {"authors": ["Sidhom", "J.-W", "H.B. Larman", "P. Ross-MacDonald", "M. Wind-Rotolo", "D.M. Pardoll", "A.S. Baras"], "title": "DeepTCR: a deep learning framework for understanding T-cell receptor sequence signatures within complex T-cell repertoires", "venue": "bioRxiv,", "year": 2019}, {"authors": ["I. Springer", "H. Besser", "N. Tickotsky-Moskovitz", "S. Dvorkin", "Y. Louzoun"], "title": "Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide", "venue": "pairs. bioRxiv,", "year": 2020}, {"authors": ["M. Sundararajan", "A. Taly", "Q. Yan"], "title": "Axiomatic attribution for deep networks", "venue": "In Proceedings of the 34th International Conference on Machine Learning-Volume", "year": 2017}, {"authors": ["N. Tomita", "B. Abdollahi", "J. Wei", "B. Ren", "A. Suriawinata", "S. Hassanpour"], "title": "Attention-based deep neural networks for detection of cancerous and precancerous esophagus tissue on histopathological slides", "venue": "JAMA Network Open,", "year": 2019}, {"authors": ["T. Uriot"], "title": "Learning with sets in multiple instance regression applied to remote sensing", "year": 1903}, {"authors": ["A. Vaswani", "N. Shazeer", "N. Parmar", "J. Uszkoreit", "L. Jones", "A.N. Gomez", "\u0141. Kaiser", "I. Polosukhin"], "title": "Attention is all you need", "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"authors": ["X. Wang", "Y. Yan", "P. Tang", "X. Bai", "W. Liu"], "title": "Revisiting multiple instance neural networks", "venue": "Pattern Recognition,", "year": 2018}, {"authors": ["H. Wardemann", "C.E. Busse"], "title": "Novel approaches to analyze immunoglobulin repertoires", "venue": "Trends in Immunology,", "year": 2017}, {"authors": ["C.R. Weber", "R. Akbar", "A. Yermanos", "M. Pavlovi\u0107", "I. Snapkov", "G.K. Sandve", "S.T. Reddy", "V. Greiff"], "title": "immuneSIM: tunable multi-feature simulation of B- and T-cell receptor repertoires for immunoinformatics", "venue": "benchmarking. Bioinformatics,", "year": 2020}, {"authors": ["Wu", "J.-S", "Huang", "S.-J", "Zhou", "Z.-H"], "title": "Genome-wide protein function prediction through multiinstance multi-label learning", "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,", "year": 2014}, {"authors": ["M.C. Wu", "S. Lee", "T. Cai", "Y. Li", "M. Boehnke", "X. Lin"], "title": "Rare-variant association testing for sequencing data with the sequence kernel association test", "venue": "The American Journal of Human Genetics,", "year": 2011}, {"authors": ["K.W. Wucherpfennig", "P.M. Allen", "F. Celada", "I.R. Cohen", "R. De Boer", "K.C. Garcia", "B. Goldstein", "R. Greenspan", "D. Hafler", "P Hodgkin"], "title": "Polyspecificity of T cell and B cell receptor recognition", "venue": "In Seminars in Immunology,", "year": 2007}, {"authors": ["G. Yaari", "S.H. Kleinstein"], "title": "Practical guidelines for B-cell receptor repertoire sequencing analysis", "venue": "Genome Medicine,", "year": 2015}, {"authors": ["Ye", "H.-J", "H. Hu", "Zhan", "D.-C", "F. Sha"], "title": "Learning embedding adaptation for few-shot", "venue": "learning. ArXiv,", "year": 2018}, {"authors": ["H. Zeng", "M.D. Edwards", "G. Liu", "D.K. Gifford"], "title": "Convolutional neural network architectures for predicting DNA\u2013protein", "venue": "binding. Bioinformatics,", "year": 2016}, {"authors": ["Zhang", "Z.-L", "M.-L"], "title": "Multi-instance multi-label learning with application to scene classification", "venue": "In Advances in neural information processing systems,", "year": 2007}, {"authors": ["J. Zhou", "O.G. Troyanskaya"], "title": "Predicting effects of noncoding variants with deep learning\u2013based sequence model", "venue": "Nature Methods,", "year": 2015}], "sections": [{"text": "Introduction\nTransformer architectures (Vaswani et al., 2017) and their attention mechanisms are currently used in many applications, such as natural language processing (NLP), imaging, and also in multiple instance learning (MIL) problems (Lee et al., 2019). In MIL, a set or bag of objects is labelled rather than objects themselves as in standard supervised learning tasks (Dietterich et al., 1997). Examples for MIL problems are medical images, in which each sub-region of the image represents an instance, video\nPreprint. Under review.\nar X\niv :2\n00 7.\n13 50\n5v 1\n[ cs\nclassification, in which each frame is an instance, text classification, where words or sentences are instances of a text, point sets, where each point is an instance of a 3D object, and remote sensing data, where each sensor is an instance (Carbonneau et al., 2018; Uriot, 2019). Attention-based MIL has been successfully used for image data, for example to identify tiny objects in large images (Ilse et al., 2018; Pawlowski et al., 2019; Tomita et al., 2019; Kimeswenger et al., 2019) and transformer-like attention mechanisms for sets of points and images (Lee et al., 2019).\nHowever, in MIL problems considered by machine learning methods up to now, the number of instances per bag is in the range of hundreds or few thousands (Carbonneau et al., 2018; Lee et al., 2019) (see also Tab. A2). At the same time the witness rate (WR), the rate of discriminating instances per bag, is already considered low at 1%\u2212 5%. We will tackle the problem of immune repertoire classification with hundreds of thousands of instances per bag without instance-level labels and with extremely low witness rates down to 0.01% using an attention mechanism. We show that the attention mechanism of transformers is the update rule of modern Hopfield networks (Krotov & Hopfield, 2016, 2018; Demircigil et al., 2017) that are generalized to continuous states in contrast to classical Hopfield networks (Hopfield, 1982). A detailed derivation and analysis of modern Hopfield networks is given in our companion paper (Ramsauer et al., 2020). These novel continuous state Hopfield networks allow to store and retrieve exponentially (in the dimension of the space) many patterns (see next Section). Thus, modern Hopfield networks with their update rule, which are used as an attention mechanism in the transformer, enable immune repertoire classification in computational biology.\nImmune repertoire classification, i.e. classifying the immune status based on the immune repertoire sequences, is essentially a text-book example for a multiple instance learning problem (Dietterich et al., 1997; Maron & Lozano-P\u00e9rez, 1998; Wang et al., 2018). Briefly, the immune repertoire of an individual consists of an immensely large bag of immune receptors, represented as amino acid sequences. Usually, the presence of only a small fraction of particular receptors determines the immune status with respect to a particular disease (Christophersen et al., 2014; Emerson et al., 2017). This is because the immune system has already acquired a resistance if one or few particular immune receptors that can bind to the disease agent are present. Therefore, classification of immune repertoires bears a high difficulty since each immune repertoire can contain millions of sequences as instances with only a few indicating the class. Further properties of the data that complicate\nthe problem are: (a) The overlap of immune repertoires of different individuals is low (in most cases, maximally low single-digit percentage values) (Greiff et al., 2017; Elhanati et al., 2018), (b) multiple different sequences can bind to the same pathogen (Wucherpfennig et al., 2007), and (c) only subsequences within the sequences determine whether binding to a pathogen is possible (Dash et al., 2017; Glanville et al., 2017; Akbar et al., 2019; Springer et al., 2020; Fischer et al., 2019). In summary, immune repertoire classification can be formulated as multiple instance learning with an extremely low witness rate and large numbers of instances, which represents a challenge for currently available machine learning methods. Furthermore, the methods should ideally be interpretable, since the extraction of class-associated sequence motifs is desired to gain crucial biological insights.\nThe acquisition of human immune repertoires has been enabled by immunosequencing technology (Georgiou et al., 2014; Brown et al., 2019) which allows to obtain the immune receptor sequences and immune repertoires of individuals. Each individual is uniquely characterized by their immune repertoire, which is acquired and changed during life. This repertoire may be influenced by all diseases that an individual is exposed to during their lives and hence contains highly valuable information about those diseases and the individual\u2019s immune status. Immune receptors enable the immune system to specifically recognize disease agents or pathogens. Each immune encounter is recorded as an immune event into immune memory by preserving and amplifying immune receptors in the repertoire used to fight a given disease. This is, for example, the working principle of vaccination. Each human has about 107\u2013108 unique immune receptors with low overlap across individuals and sampled from a potential diversity of > 1014 receptors (Mora & Walczak, 2019). The ability to sequence and analyze human immune receptors at large scale has led to fundamental and mechanistic insights into the adaptive immune system and has also opened the opportunity for the development of novel diagnostics and therapy approaches (Georgiou et al., 2014; Brown et al., 2019).\nImmunosequencing data have been analyzed with computational methods for a variety of different tasks (Greiff et al., 2015; Shugay et al., 2015; Miho et al., 2018; Yaari & Kleinstein, 2015; Wardemann & Busse, 2017). A large part of the available machine learning methods for immune receptor data has been focusing on the individual immune receptors in a repertoire, with the aim to, for example, predict the antigen or antigen portion (epitope) to which these sequences bind or to predict sharing of receptors across individuals (Gielis et al., 2019; Springer et al., 2020; Jurtz et al., 2018; Moris et al., 2019; Fischer et al., 2019; Greiff et al., 2017; Sidhom et al., 2019; Elhanati et al., 2018). Recently, Jurtz et al. (2018) used 1D convolutional neural networks (CNNs) to predict antigen binding of T-cell receptor (TCR) sequences (specifically, binding of TCR sequences to peptide-MHC complexes) and demonstrated that motifs can be extracted from these models. Similarly, Konishi et al. (2019) use CNNs, gradient boosting, and other machine learning techniques on B-cell receptor (BCR) sequences to distinguish tumor tissue from normal tissue. However, the methods presented so far predict a particular class, the epitope, based on a single input sequence.\nImmune repertoire classification has been considered as a MIL problem in the following publications. A Deep Learning framework called DeepTCR (Sidhom et al., 2019) implements several Deep Learning approaches for immunosequencing data. The computational framework, inter alia, allows for attention-based MIL repertoire classifiers and implements a basic form of attention-based averaging. Ostmeyer et al. (2019) already suggested a MIL method for immune repertoire classification. This method considers 4-mers, fixed sub-sequences of length 4, as instances of an input object and trained a logistic regression model with these 4-mers as input. The predictions of the logistic regression model for each 4-mer were max-pooled to obtain one prediction per input object. This approach is characterized by (a) the rigidity of the k-mer features as compared to convolutional kernels (Alipanahi et al., 2015; Zhou & Troyanskaya, 2015; Zeng et al., 2016), (b) the max-pooling operation, which constrains the network to learn from a single, top-ranked k-mer for each iteration over the input object, and (c) the pooling of prediction scores rather than representations (Wang et al., 2018). Our experiments also support that these choices in the design of the method can lead to constraints on the predictive performance (see Table 1).\nOur proposed method, DeepRC, also uses a MIL approach but considers sequences rather than k-mers as instances within an input object and a transformer-like attention mechanism. DeepRC sets out to avoid the above-mentioned constraints of current methods by (a) applying transformer-like attention-pooling instead of max-pooling and learning a classifier on the repertoire rather than on the sequence-representation, (b) pooling learned representations rather than predictions, and (c) using less rigid feature extractors, such as 1D convolutions or LSTMs. In this work, we contribute the following: We demonstrate that continuous generalizations of binary modern Hopfield-networks (Krotov &\nHopfield, 2016, 2018; Demircigil et al., 2017) have an update rule that is known as the attention mechanisms in the transformer. We show that these modern Hopfield networks have exponential storage capacity, which allows them to extract patterns among a large set of instances (next Section). Based on this result, we propose DeepRC, a novel deep MIL method based on modern Hopfield networks for large bags of complex sequences, as they occur in immune repertoire classification (Section \"Deep Repertoire Classification). We evaluate the predictive performance of DeepRC and other machine learning approaches for the classification of immune repertoires in a large comparative study (Section \"Experimental Results\")\nExponential storage capacity of continuous state modern Hopfield networks with transformer attention as update rule\nIn this section, we show that modern Hopfield networks have exponential storage capacity, which will later allow us to approach massive multiple-instance learning problems, such as immune repertoire classification. See our companion paper (Ramsauer et al., 2020) for a detailed derivation and analysis of modern Hopfield networks.\nWe assume patterns x1, . . . ,xN \u2208 Rd that are stacked as columns to the matrixX = (x1, . . . ,xN ) and a query pattern \u03be that also represents the current state. The largest norm of a pattern is M = maxi \u2016xi\u2016. The separation \u2206i of a pattern xi is defined as its minimal dot product difference to any of the other patterns: \u2206i = minj,j 6=i ( xTi xi \u2212 xTi xj ) . A pattern is well-separated from the data if \u2206i \u2265 2\u03b2N + 1 \u03b2 log ( 2(N \u2212 1)N\u03b2M2 ) . We consider a modern Hopfield network with current state\n\u03be and the energy function E = \u2212\u03b2\u22121 log (\u2211N i=1 exp(\u03b2x T i \u03be) ) + \u03b2\u22121 logN + 12\u03be T \u03be + 12M\n2. For energy E and state \u03be, the update rule\n\u03benew = f(\u03be;X, \u03b2) = X p = X softmax(\u03b2XT \u03be) (1)\nis proven to converge globally to stationary points of the energy E, which are local minima or saddle points (see (Ramsauer et al., 2020), appendix, Theorem A2 ). Surprisingly, the update rule Eq. (1) is also the formula of the well-known transformer attention mechanism.\nTo see this more clearly, we simultaneously update several queries \u03bei. Furthermore the queries \u03bei and the patterns xi are linear mappings of vectors yi into the space Rd. For matrix notation, we set xi = W TKyi, \u03bei = W T Qyi and multiply the result of our update rule withWV . Using Y = (y1, . . . ,yN )\nT , we define the matricesXT = K = YWK ,Q = YWQ, and V = YWKWV = XTWV , where WK \u2208 Rdy\u00d7dk ,WQ \u2208 Rdy\u00d7dk ,WV \u2208 Rdk\u00d7dv , K \u2208 RN\u00d7dk , Q \u2208 RN\u00d7dk , V \u2208 RN\u00d7dv , and the patterns are now mapped to the Hopfield space with dimension d = dk. We set \u03b2 = 1/ \u221a dk and change softmax to a row vector. The update rule Eq. (1) multiplied byWV performed for all queries simultaneously becomes in row vector notation:\natt(Q,K,V ;\u03b2) = softmax ( \u03b2 QKT ) V = softmax (( 1/ \u221a dk ) QKT ) V . (2)\nThis formula is the transformer attention.\nIf the patterns xi are well separated, the iterate Eq. (1) converges to a fixed point close to a pattern to which the initial \u03be is similar. If the patterns are not well separated the iterate Eq.(1) converges to a fixed point close to the arithmetic mean of the patterns. If some patterns are similar to each other but well separated from all other vectors, then a metastable state between the similar patterns exists. Iterates that start near a metastable state converge to this metastable state. For details see Ramsauer et al. (2020), appendix, Sect. A2. Typically, the update converges after one update step (see Ramsauer et al. (2020), appendix, Theorem A8) and has an exponentially small retrieval error (see Ramsauer et al. (2020), appendix, Theorem A9).\nOur main concern for application to immune repertoire classification is the number of patterns that can be stored and retrieved by the modern Hopfield network, equivalently to the transformer attention head. The storage capacity of an attention mechanism is critical for massive MIL problems. We first define what we mean by storing and retrieving patterns from the modern Hopfield network. Definition 1 (Pattern Stored and Retrieved). We assume that around every pattern xi a sphere Si is given. We say xi is stored if there is a single fixed point x\u2217i \u2208 Si to which all points \u03be \u2208 Si converge,\nand Si \u2229 Sj = \u2205 for i 6= j. We say xi is retrieved if the iteration Eq. (1) converged to the single fixed point x\u2217i \u2208 Si.\nFor randomly chosen patterns, the number of patterns that can be stored is exponential in the dimension d of the space of the patterns (xi \u2208 Rd). Theorem 1. We assume a failure probability 0 < p 6 1 and randomly chosen patterns on the sphere with radius M = K \u221a d\u2212 1. We define a := 2d\u22121 (1 + ln(2 \u03b2 K 2 p (d \u2212 1))), b := 2 K 2 \u03b2 5 , and c = bW0(exp(a + ln(b)) , where W0 is the upper branch of the Lambert W function and ensure\nc \u2265 (\n2\u221a p\n) 4 d\u22121\n. Then with probability 1\u2212 p, the number of random patterns that can be stored is\nN \u2265 \u221ap c d\u22121 4 . (3)\nExamples are c \u2265 3.1546 for \u03b2 = 1, K = 3, d = 20 and p = 0.001 (a + ln(b) > 1.27) and c \u2265 1.3718 for \u03b2 = 1 K = 1, d = 75, and p = 0.001 (a+ ln(b) < \u22120.94).\nSee Ramsauer et al. (2020), appendix, Theorem A5 for a proof. We have established that a modern Hopfield network or a transformer attention mechanism can store and retrieve exponentially many patterns. This allows us to approach MIL with massive numbers of instances from which we have to retrieve a few with an attention mechanism.\nDeep Repertoire Classification\nProblem setting and notation. We consider a MIL problem, in which an input object X is a bag of N instancesX = {s1, . . . , sN}. The instances do not have dependencies nor orderings between them and N can be different for every object. We assume that each instance si is associated with a label yi \u2208 {0, 1}, assuming a binary classification task, to which we do not have access. We only have access to a label Y = maxi yi for an input object or bag. Note that this poses a credit assignment problem, since the sequences that are responsible for the label Y have to be identified and that the relation between instance-label and bag-label can be more complex (Foulds & Frank, 2010).\nA model y\u0302 = g(X) should be (a) invariant to permutations of the instances and (b) able to cope with the fact that N varies across input objects (Ilse et al., 2018), which is a problem also posed by point sets (Qi et al., 2017). Two principled approaches exist. The first approach is to learn an instance-level scoring function h : S 7\u2192 [0, 1], which is then pooled across instances with a pooling function f , for example by average-pooling or max-pooling (see below). The second approach is to construct an instance representation zi of each instance by h : S 7\u2192 Rdv and then encode the bag, or the input object, by pooling these instance representations (Wang et al., 2018) via a function f . An output function o : Rdv 7\u2192 [0, 1] subsequently classifies the bag. The second approach, the pooling of representations rather than scoring functions, is currently best performing (Wang et al., 2018).\nIn the problem at hand, the input object X is the immune repertoire of an individual that consists of a large set of immune receptor sequences (T-cell receptors or antibodies). Immune receptors are primarily represented as sequences si from a space si \u2208 S. These sequences act as the instances in the MIL problem. Although immune repertoire classification can readily be formulated as a MIL problem, it is yet unclear how well machine learning methods solve the above-described problem with a large number of instances N 10, 000 and with instances si being complex sequences. Next we describe currently used pooling functions for MIL problems.\nPooling functions for MIL problems. Different pooling functions equip a model g with the property to be invariant to permutations of instances and with the ability to process different numbers of instances. Typically, a neural network h\u03b8 with parameters \u03b8 is trained to obtain a function that maps each instance onto a representation: zi = h\u03b8(si) and then a pooling function z = f({z1, . . . ,zN}) supplies a representation z of the input object X = {s1, . . . , sN}. The following pooling functions are typically used: average-pooling: z = 1N \u2211N i=1 zi, max-pooling:\nz = \u2211dv m=1 em(maxi,16i6N{zim}), where em is the standard basis vector for dimension m and\nattention-pooling: z = \u2211N i=1 aizi, where ai are non-negative (ai \u2265 0), sum to one ( \u2211N i=1 ai = 1), and are determined by an attention mechanism. These pooling functions are invariant to permutations\nof {1, . . . , N} and are differentiable. Therefore, they are suited as building blocks for Deep Learning architectures. We employ attention-pooling in our DeepRC model as detailed in the following.\nModern Hopfield networks viewed as transformer-like attention mechanisms. The modern Hopfield networks, as introduced above,have a storage capacity that is exponential in the dimension of the vector space and converge after just one update (see (Ramsauer et al., 2020), appendix).Additionally, the update rule of modern Hopfield networks is known as key-value attention mechanism, which has been highly successful through the transformer (Vaswani et al., 2017) and BERT (Devlin et al., 2019) models in natural language processing. Therefore using modern Hopfield networks with the key-value-attention mechanism as update rule is the natural choice for our task. In particular, modern Hopfield networks are theoretically justified for storing and retrieving the large number of vectors (sequence patterns) that appear in the immune repertoire classification task.\nInstead of using the terminology of modern Hopfield networks, we explain our DeepRC architecture in terms of key-value-attention (the update rule of the modern Hopfield network), since it is well known in the deep learning community. The attention mechanism assumes a space of dimension dk in which keys and queries are compared. A set of N key vectors are combined to the matrixK. A set of dq query vectors are combined to the matrixQ. Similarities between queries and keys are computed by inner products, therefore queries can search for similar keys that are stored. Another set of N value vectors are combined to the matrix V . The output of the attention mechanism is a weighted average of the value vectors for each query q. The i-th vector vi is weighted by the similarity between the i-th key ki and the query q. The similarity is given by the softmax of the inner products of the query q with the keys ki. All queries are calculated in parallel via matrix operations. Consequently, the attention function att(Q,K,V ;\u03b2) maps queries Q, keys K, and values V to dv-dimensional outputs: att(Q,K,V ;\u03b2) = softmax(\u03b2QKT )V (see also Eq. (2)). While this attention mechanism has originally been developed for sequence tasks (Vaswani et al., 2017), it can be readily transferred to sets (Lee et al., 2019; Ye et al., 2018). This type of attention mechanism will be employed in DeepRC.\nThe DeepRC method. We propose a novel method Deep Repertoire Classification (DeepRC) for immune repertoire classification with attention-based deep massive multiple instance learning and compare it against other machine learning approaches. For DeepRC, we consider immune repertoires as input objects, which are represented as bags of instances. In a bag, each instance is an immune receptor sequence and each bag can contain a large number of sequences. Note that we will use zi to denote the sequence-representation of the i-th sequence and z to denote the repertoire-representation. At the core, DeepRC consists of a transformer-like attention mechanism that extracts the most important information from each repertoire. We first give an overview of the attention mechanism and then provide details on each of the sub-networks h1, h2, and o of DeepRC. (Overview: Fig. 1; Architecture: Fig. 2; Implementation details: Sect. A2; DeepRC variations: Sect. A10.)\nAttention mechanism in DeepRC. This mechanism is based on the three matrices K (the keys), Q (the queries), and V (the values) together with a parameter \u03b2. Values. DeepRC uses a 1D convolutional network h1 (LeCun et al., 1998; Hu et al., 2014; Kelley et al., 2016) that supplies a sequence-representation zi = h1(si), which acts as the values V = Z = (z1, . . . ,zN ) in the attention mechanism (see Figure 2). Keys. A second neural network h2, which shares its first layers with h1, is used to obtain keysK \u2208 RN\u00d7dk for each sequence in the repertoire. This network uses 2 self-normalizing layers (Klambauer et al., 2017) with 32 units per layer (see Figure 2). Query. We use a fixed dk-dimensional query vector \u03be which is learned via backpropagation. For more attention heads, each head has a fixed query vector. With the quantities introduced above, the transformer attention mechanism (Eq. (2)) of DeepRC is implemented as follows:\nz = att(\u03beT ,K,Z; 1\u221a dk ) = softmax\n( \u03beTKT\u221a\ndk\n) Z, (4)\nwhere Z \u2208 RN\u00d7dv are the sequence\u2013representations stacked row-wise,K are the keys, and z is the repertoire-representation and at the same time a weighted mean of sequence\u2013representations zi. The attention mechanism can readily be extended to multiple queries, however, computational demand could constrain this depending on the application and dataset. Theorem 1 demonstrates that this mechanism is able to retrieve a single pattern out of several hundreds of thousands.\nAttention-pooling and interpretability. Each input object, i.e. repertoire, consists of a large number N of sequences, which are reduced to a single fixed-size feature vector of length dv representing the whole input object by an attention-pooling function. To this end, a transformer-like attention\nmechanism adapted to sets is realized in DeepRC which supplies ai \u2013 the importance of the sequence si. This importance value is an interpretable quantity, which is highly desired for the immunological problem at hand. Thus, DeepRC allows for two forms of interpretability methods. (a) A trained DeepRC model can compute attention weights ai, which directly indicate the importance of a sequence. (b) DeepRC furthermore allows for the usage of contribution analysis methods, such as Integrated Gradients (IG) (Sundararajan et al., 2017) or Layer-Wise Relevance Propagation (Montavon et al., 2018; Arras et al., 2019). See Sect. A8 for details.\nClassification layer and network parameters. The repertoire-representation z is then used as input for a fully-connected output network y\u0302 = o(z) that predicts the immune status, where we found it sufficient to train single-layer networks. In the simplest case, DeepRC predicts a single target, the class label y, e.g. the immune status of an immune repertoire, using one output value. However, since DeepRC is an end-to-end deep learning model, multiple targets may be predicted simultaneously in classification or regression settings or a mix of both. This allows for the introduction of additional information into the system via auxiliary targets such as age, sex, or other metadata.\nNetwork parameters, training, and inference. DeepRC is trained using standard gradient descent methods to minimize a cross-entropy loss. The network parameters are \u03b81,\u03b82,\u03b8o for the sub-networks h1, h2, and o, respectively, and additionally \u03be. In more detail, we train DeepRC using Adam (Kingma & Ba, 2014) with a batch size of 4 and dropout of input sequences.\nImplementation. To reduce computational time, the attention network first computes the attention weights ai for each sequence si in a repertoire. Subsequently, the top 10% of sequences with the highest ai per repertoire are used to compute the weight updates and prediction. Furthermore, computation of zi is performed in 16-bit, others in 32-bit precision to ensure numerical stability in the softmax. See Sect. A2 for details.\nExperimental Results\nIn this section, we report and analyze the predictive power of DeepRC and the compared methods on several immunosequencing datasets. The ROC-AUC is used as the main metric for the predictive power.\nMethods compared. We compared previous methods for immune repertoire classification, (Ostmeyer et al., 2019) (\u201cLog. MIL (KMER)\u201d, \u201cLog. MIL (TCRB)\u201d) and a burden test (Emerson et al., 2017), as well as the baseline methods Logistic Regression (\u201cLog. Regr.\u201d), k-nearest neighbour (\u201cKNN\u201d), and Support Vector Machines (\u201cSVM\u201d) with kernels designed for sets, such as the Jaccard kernel (\u201cJ\u201d) and the MinMax (\u201cMM\u201d) kernel (Ralaivola et al., 2005). For the simulated data, we also added baseline methods that search for the implanted motif either in binary or continuous fashion (\u201cKnown motif b.\u201d, \u201cKnown motif c.\u201d) assuming that this motif was known (for details, see Sect. A4).\nDatasets. We aimed at constructing immune repertoire classification scenarios with varying degree of difficulties and realism in order to compare and analyze the suggested machine learning methods. To this end, we either use simulated or experimentally-observed immune receptor sequences and we implant signals, specifically, sequence motifs or sets thereof (Akbar et al., 2019; Weber et al., 2020),\nat different frequencies into sequences of repertoires of the positive class. These frequencies represent the witness rates and range from 0.01% to 10%. Overall, we compiled four categories of datasets: (a) simulated immunosequencing data with implanted signals, (b) LSTM-generated immunosequencing data with implanted signals, (c) real-world immunosequencing data with implanted signals, and (d) real-world immunosequencing data with known immune status, the CMV dataset (Emerson et al., 2017). The average number of instances per bag, which is the number of sequences per immune repertoire, is \u2248300,000 except for category (c), in which we consider the scenario of low-coverage data with only 10,000 sequences per repertoire. The number of repertoires per dataset ranges from 785 to 5,000. In total, all datasets comprise \u224830 billion sequences or instances. This represents the largest comparative study on immune repertoire classification (see Sect. A3).\nHyperparameter selection. We used a nested 5-fold cross validation (CV) procedure to estimate the performance of each of the methods. All methods could adjust their most important hyperparameters on a validation set in the inner loop of the procedure. See Sect. A5 for details.\nResults. In each of the four categories, \u201creal-world data\u201d, \u201creal-world data with implanted signals\u201d, \u201cLSTM-generated data\u201d, and \u201csimulated immunosequencing data\u201d, DeepRC outperforms all competing methods with respect to average AUC. Across categories, the runner-up methods are either the SVM for MIL problems with MinMax kernel or the burden test (see Table 1 and Sect. A6).\nResults on simulated immunosequencing data. In this setting the complexity of the implanted signal is in focus and varies throughout 18 simulated datasets (see Sect. A3). Some datasets are challenging for the methods because the implanted motif is hidden by noise and others because only a small fraction of sequences carries the motif, and hence have a low witness rate. These difficulties become evident by the method called \u201cknown motif binary\u201d, which assumes the implanted motif is known. The performance of this method ranges from a perfect AUC of 1.000 in several datasets to an AUC of 0.532 in dataset \u201917\u2019 (see Sect. A6). DeepRC outperforms all other methods with an average AUC of 0.846\u00b1 0.223, followed by the SVM with MinMax kernel with an average AUC of 0.827\u00b1 0.210 (see Sect. A6). The predictive performance of all methods suffers if the signal occurs only in an extremely small fraction of sequences. In datasets, in which only 0.01% of the sequences carry the motif, all AUC values are below 0.550. Results on LSTM-generated data. On the LSTM-generated data, in which we implanted noisy motifs with frequencies of 10%, 1%, 0.5%, 0.1%, and 0.05%, DeepRC yields almost perfect predictive performance with an average AUC of 1.000\u00b1 0.001 (see Sect. A6 and A7). The second best method, SVM with MinMax kernel, has a similar predictive\nperformance to DeepRC on all datasets but the other competing methods have a lower predictive performance on datasets with low frequency of the signal (0.05%). Results on real-world data with implanted motifs. In this dataset category, we used real immunosequences and implanted single or multiple noisy motifs. Again, DeepRC outperforms all other methods with an average AUC of 0.980 \u00b1 0.029, with the second best method being the burden test with an average AUC of 0.883 \u00b1 0.170. Notably, all methods except for DeepRC have difficulties with noisy motifs at a frequency of 0.1% (see Tab. A11). Results on real-world data. On the real-world dataset, in which the immune status of persons affected by the cytomegalovirus has to be predicted, the competing methods yield predictive AUCs between 0.515 and 0.825 (see Table 1). We note that this dataset is not the exact dataset that was used in Emerson et al. (2017). It differs in pre-processing and also comprises a different set of samples and a smaller training set due to the nested 5-fold cross-validation procedure, which leads to a more challenging dataset. The best performing method is DeepRC with an AUC of 0.831 \u00b1 0.002, followed by the SVM with MinMax kernel (AUC 0.825 \u00b1 0.022) and the burden test with an AUC of 0.699\u00b1 0.041. The top-ranked sequences by DeepRC significantly correspond to those detected by Emerson et al. (2017), which we tested by a Mann-Whitney U-test with the null hypothesis that the attention values of the sequences detected by Emerson et al. (2017) would be equal to the attention values of the remaining sequences (p-value of 1.3 \u00b7 10\u221293). The sequence attention values are displayed in Tab. A14.\nConclusion. We have demonstrated how modern Hopfield networks and attention mechanisms enable successful classification of the immune status of immune repertoires. For this task, methods have to identify the discriminating sequences amongst a large set of sequences in an immune repertoire. Specifically, even motifs within those sequences have to be identified. We have shown that DeepRC, a modern Hopfield network and an attention mechanism with a fixed query, can solve this difficult task despite the massive number of instances. DeepRC furthermore outperforms the compared methods across a range of different experimental conditions.\nBroader Impact\nImpact on machine learning and related scientific fields. We envision that with (a) the increasing availability of large immunosequencing datasets (Kovaltsuk et al., 2018; Corrie et al., 2018; Christley et al., 2018; Zhang et al., 2020; Rosenfeld et al., 2018; Shugay et al., 2018), (b) further fine-tuning of ground-truth benchmarking immune receptor datasets (Weber et al., 2020; Olson et al., 2019; Marcou et al., 2018), (c) accounting for repertoire-impacting factors such as age, sex, ethnicity, and environment (potential confounding factors), and (d) increased GPU memory and increased computing power, it will be possible to identify discriminating immune receptor motifs for many diseases, potentially even for the current SARS-CoV-2 (COVID-19) pandemic (Raybould et al., 2020; Minervina et al., 2020; Galson et al., 2020). Such results would greatly benefit ongoing research on antibody and TCR-driven immunotherapies and immunodiagnostics as well as rational vaccine design (Brown et al., 2019).\nIn the course of this development, the experimental verification and interpretation of machine-learningidentified motifs could receive additional focus, as for most of the sequences within a repertoire the corresponding antigen is unknown. Nevertheless, recent technological breakthroughs in highthroughput antigen-labeled immunosequencing are beginning to generate large-scale antigen-labeled single-immune-receptor-sequence data thus resolving this longstanding problem (Setliff et al., 2019).\nFrom a machine learning perspective, the successful application of DeepRC on immune repertoires with their large number of instances per bag might encourage the application of modern Hopfield networks and attention mechanisms on new, previously unsolved or unconsidered, datasets and problems.\nImpact on society. If the approach proves itself successful, it could lead to faster testing of individuals for their immune status w.r.t. a range of diseases based on blood samples. This might motivate changes in the pipeline of diagnostics and tracking of diseases, e.g. automated testing of the immune status in regular intervals. It would furthermore make the collection and screening of blood samples for larger databases more attractive. In consequence, the improved testing of immune statuses might identify individuals that do not have a working immune response towards certain diseases to government or insurance companies, which could then push for targeted immunisation of the individual. Similarly to compulsory vaccination, such testing for the immune status could be made\ncompulsory by governments, possibly violating privacy or personal self-determination in exchange for increased over-all health of a population.\nUltimately, if the approach proves itself successful, the insights gained from the screening of individuals that have successfully developed resistances against specific diseases could lead to faster targeted immunisation, once a certain number of individuals with resistances can be found. This might strongly decrease the harm done by e.g. pandemics and lead to a change in the societal perception of such diseases.\nConsequences of failures of the method. As common with methods in machine learning, potential danger lies in the possibility that users rely too much on our new approach and use it without reflecting on the outcomes. However, the full pipeline in which our method would be used includes wet lab tests after its application, to verify and investigate the results, gain insights, and possibly derive treatments. Failures of the proposed method would lead to unsuccessful wet lab validation and negative wet lab tests. Since the proposed algorithm does not directly suggest treatment or therapy, human beings are not directly at risk of being treated with a harmful therapy. Substantial wet lab and in-vitro testing and would indicate wrong decisions by the system.\nLeveraging of biases in the data and potential discrimination. As for almost all machine learning methods, confounding factors, such as age or sex, could be used for classification. This, might lead to biases in predictions or uneven predictive performance across subgroups. As a result, failures in the wet lab would occur (see paragraph above). Moreover, insights into the relevance of the confounding factors could be gained, leading to possible therapies or counter-measures concerning said factors.\nFurthermore, the amount of data available with respec to relevant confounding factors could lead to better or worse performance of our method. E.g. a dataset consisting mostly of data from individuals within a specific age group might yield better performance for that age group, possibly resulting in better or exclusive treatment methods for that specific group. Here again, the application of DeepRC would be followed by in-vitro testing and development of a treatment, where all target groups for the treatment have to be considered accordingly.\nAvailability\nAll datasets and code is available at https://github.com/ml-jku/DeepRC. The CMV dataset is publicly available at https://clients.adaptivebiotech.com/pub/Emerson-2017-NatGen."}, {"heading": "Acknowledgments", "text": "The ELLIS Unit Linz, the LIT AI Lab and the Institute for Machine Learning are supported by the Land Ober\u00f6sterreich, LIT grants DeepToxGen (LIT-2017-3-YOU-003), and AI-SNN (LIT2018-6-YOU-214), the Medical Cognitive Computing Center (MC3), Janssen Pharmaceutica, UCB Biopharma, Merck Group, Audi.JKU Deep Learning Center, Audi Electronic Venture GmbH, TGW, Primal, Silicon Austria Labs (SAL), FILL, EnliteAI, Google Brain, ZF Friedrichshafen AG, Robert Bosch GmbH, T\u00dcV Austria, DCS, and the NVIDIA Corporation. Victor Greiff (VG) and Geir Kjetil Sandve (GKS) are supported by The Helmsley Charitable Trust (#2019PG-T1D011, to VG), UiO World-Leading Research Community (to VG), UiO:LifeSciences Convergence Environment Immunolingo (to VG and GKS), EU Horizon 2020 iReceptorplus (#825821, to VG) and Stiftelsen Kristian Gerhard Jebsen (K.G. Jebsen Coeliac Disease Research Centre, to GKS).\nAppendix\nIn the following, the appendix to the paper \u201cModern Hopfield Networks and Attention for Immune Repertoire Classification\u201d is presented. Here we provide details on DeepRC, the compared methods, and the experimental setup and results. Furthermore, the generation of the immune repertoire classification data using an LSTM network, the interpretation of DeepRC and the extraction of found motifs, and the ablation study using different variants of DeepRC are described.\nContents of Appendix 1 Immune Repertoire Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\nA1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 A2 DeepRC implementation details . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 A3 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\nA3.1 Simulated immunosequencing data . . . . . . . . . . . . . . . . . . . . . . . 15 A3.2 LSTM-generated data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 A3.3 Real-world data with implanted signals . . . . . . . . . . . . . . . . . . . . 16 A3.4 Real-world data: CMV dataset . . . . . . . . . . . . . . . . . . . . . . . . . 17 A3.5 Comparison to other MIL datasets . . . . . . . . . . . . . . . . . . . . . . . 17\nA4 Compared methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 A4.1 Known motif . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 A4.2 Support Vector Machine (SVM) . . . . . . . . . . . . . . . . . . . . . . . . 19 A4.3 K-Nearest Neighbor (KNN) . . . . . . . . . . . . . . . . . . . . . . . . . . 19 A4.4 Logistic regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 A4.5 Burden test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 A4.6 Logistic MIL (Ostmeyer et al) . . . . . . . . . . . . . . . . . . . . . . . . . 20 A5 Hyperparameter selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 A6 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 A7 Repertoire generation via LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 A8 Interpreting DeepRC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 A9 Attention values for previously associated CMV sequences . . . . . . . . . . . . . . . 31 A10 DeepRC variations and ablation study . . . . . . . . . . . . . . . . . . . . . . . . . 32\nList of figures A1 Position encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 A2 Distribution of AAs and k-mers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 A3 Interpretation of the DeepRC classifier . . . . . . . . . . . . . . . . . . . . . . . . . 29 A4 Visualization of the contributions of AA . . . . . . . . . . . . . . . . . . . . . . . . 30\nList of tables A1 Properties of simulated repertoires, variations of motifs, and motif frequencies . . . 17 A2 Overview of MIL datasets and their characteristics . . . . . . . . . . . . . . . . . . 18 A3 DeepRC hyperparameter search space . . . . . . . . . . . . . . . . . . . . . . . . . 21 A5 Hyperparameter search of the KNN baseline . . . . . . . . . . . . . . . . . . . . . . 21 A6 Hyperparameter search of the logistic regression . . . . . . . . . . . . . . . . . . . 22 A7 Hyperparameter search of the burden test . . . . . . . . . . . . . . . . . . . . . . . 22 A8 Hyperparameter search of the logistic MIL baseline . . . . . . . . . . . . . . . . . 22 A9 AUC estimates for all 18 datasets in \"simulated immunosequencing data\" . . . . . 23 A10 AUC estimates for all 5 datasets in \u201cLSTM-generated data\u201d . . . . . . . . . . . . . 24 A11 AUC estimates for all 4 datasets in \u201creal-world data with implanted signals\u201d . . . . 25 A12 Results on the CMV dataset given by AUC, F1 score, balanced accuracy, and accuracy 25 A13 Visualization of extracted motifs . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 A14 TCR\u03b2 sequences re-discovered by DeepRC . . . . . . . . . . . . . . . . . . . . . . 31 A15 Hyperparameter search space for DeepRC variations . . . . . . . . . . . . . . . . 32 A16 Hyperparameter search space for DeepRC variations with LSTM embedding . . . . 33 A17 Impact of hyperparameters on DeepRC with LSTM . . . . . . . . . . . . . . . . . 33 A18 Impact of hyperparameters on DeepRC with 1D CNN . . . . . . . . . . . . . . . . 34\nImmune Repertoire Classification Michael Widrich Bernhard Sch\u00e4fl Milena Pavlovic\u0301 Geir Kjetil Sandve Sepp Hochreiter Victor Greiff G\u00fcnter Klambauer\nA1 Introduction\nIn Section A2 we provide details on the architecture of DeepRC, in Section A3 we present details on the datasets, in Section A4 we explain the methods that we compared, in Section A5 we elaborate on the hyperparameters and their selection process. Then, in Section A6 we present detailed results for each dataset category in tabular form, in Section A7 we provide information on the LSTM model that was used to generate antibody sequences, in Section A8 we show how DeepRC can be interpreted, in Section A9 we show the correspondence of previously identified TCR sequences for CMV immune status with attention values by DeepRC, and finally we present variations and an ablation study of DeepRC in Section A10."}, {"heading": "A2 DeepRC implementation details", "text": "Input layer. For the input layer of the CNN, the characters in the input sequence, i.e. the amino acids (AAs), are encoded in a one-hot vector of length 20. To also provide information about the position of an AA in the sequence, we add 3 additional input features with values in range [0, 1] to encode the position of an AA relative to the sequence. These 3 positional features encode whether the AA is located at the beginning, the center, or the end of the sequence, respectively, as shown in Figure A1. We concatenate these 3 positional features with the one-hot vector of AAs, which results in a feature vector of size 23 per sequence position. Each repertoire, now represented as a bag of feature vectors, is then normalized to unit variance. Since the cytomegalovirus dataset (CMV dataset) provides sequences with an associated abundance value per sequence, which is the number of occurrences of a sequence in a repertoire, we incorporate this information into the input of DeepRC. To this end, the one-hot AA features of a sequence are multiplied by a scaling factor of log(ca) before normalization, where ca is the abundance of a sequence. We feed the sequences with 23 features per position into the CNN. Sequences of different lengths were zero-padded to the maximum sequence length per batch at the sequence ends.\n1D CNN for motif recognition. In the following, we describe how DeepRC identifies patterns in the individual sequences and reduces each sequence in the input object to a fixed-size feature vector. DeepRC employs 1D convolution layers to extract patterns, where trainable weight kernels are convolved over the sequence positions. In principle, also recurrent neural networks (RNNs) or transformer networks could be used instead of 1D CNNs, however, (a) the computational complexity of the network must be low to be able to process millions of sequences for a single update. Additionally, (b) the learned network should be able to provide insights in the recognized patterns in form of motifs. Both properties (a) and (b) are fulfilled by 1D convolution operations that are used by DeepRC.\nWe use one 1D CNN layer (Hu et al., 2014) with SELU activation functions (Klambauer et al., 2017) to identify the relevant patterns in the input sequences with a computationally light-weight\nAA position in sequence\nfe at\nur e\nva lu\ne\n1\n0 sequence\nstart sequence end sequence center\nfeature 2 feature 3\nfeature 1\nFigure A1: We use 3 input features with values in range [0, 1] to encode the relative position of each AA in a sequence with respect to the sequence. \u201cfeature 1\u201d encodes if an AA is close to the sequence start, \u201cfeature 2\u201d to the sequence center, and \u201cfeature 3\u201d to the sequence end. For every position in the sequence, the values of all three features sum up to 1.\noperation. The larger the kernel size, the more surrounding sequence positions are taken into account, which influences the length of the motifs that can be extracted. We therefore adjust the kernel size during hyperparameter search. In prior works (Ostmeyer et al., 2019), a k-mer size of 4 yielded good predictive performance, which could indicate that a kernel size in the range of 4 may be a proficient choice. For dv trainable kernels, this produces a feature vector of length dv at each sequence position. Subsequently, global max-pooling over all sequence positions of a sequence reduces the sequence-representations zi to vectors of the fixed length dv . Given the challenging size of the input data per repertoire, the computation of the CNN activations and weight updates is performed using 16-bit floating point values. A list of hyperparameters evaluated for DeepRC is given in Table A3. A comparison of RNN-based and CNN-based sequence embedding for motif recognition in a smaller experimental setting is given in Sec. A10.\nRegularization. We apply random and attention-based subsampling of repertoire sequences to reduce over-fitting and decrease computational effort. During training, each repertoire is subsampled to 10, 000 input sequences, which are randomly drawn from the respective repertoire. This can also be interpreted as random drop-out (Hinton et al., 2012) on the input sequences or attention weights. During training and evaluation, the attention weights computed by the attention network are furthermore used to rank the input sequences. Based on this ranking, the repertoire is reduced to the 10% of sequences with the highest attention weights. These top 10% of sequences are then used to compute the weight updates and the prediction for the repertoire. Additionally, one might employ further regularization techniques, which we only partly investigated further in a smaller experimental setting in Sec. A10 due to high computational demands. Such regularization techniques include l1 and l2 weight decay, noise in the form of random AA permutations in the input sequences, noise on the attention weights, or random shuffling of sequences between repertoires that belong to the negative class. The last regularization technique assumes that the sequences in positive-class repertoires carry a signal, such as an AA motif corresponding to an immune response, whereas the sequences in negative-class repertoires do not. Hence, the sequences can be shuffled randomly between negative class repertoires without obscuring the signal in the positive class repertoires.\nHyperparameters. For the hyperparameter search of DeepRC for the category \u201csimulated immunosequencing data\u201d, we only conducted a full hyperparameter search on the more difficult datasets with motif implantation probabilities below 1%, as described in Table A3. This process was repeated for all 5 folds of the 5-fold cross-validation (CV) and the average score on the 5 test sets constitutes the final score of a method.\nTable A3 provides an overview of the hyperparameter search, which was conducted as a grid search for each of the datasets in a nested 5-fold CV procedure, as described in Section A4.\nComputation time and optimization. We took measures on the implementation level to address the high computational demands, especially GPU memory consumption, in order to make the large number of experiments feasible. We train the DeepRC model with a small batch size of 4 samples and\nperform computation of inference and updates of the 1D CNN using 16-bit floating point values. The rest of the network is trained using 32-bit floating point values. The Adam parameter for numerical stability was therefore increased from the default value of = 10\u22128 to = 10\u22124. Training was performed on various GPU types, mainly NVIDIA RTX 2080 Ti. Computation times were highly dependent on the number of sequences in the repertoires and the number and sizes of CNN kernels. A single update on an NVIDIA RTX 2080 Ti GPU took approximately 0.0129 to 0.0135 seconds, while requiring approximately 8 to 11 GB GPU memory. Taking these optimizations and GPUs with larger memory (\u2265 16 GB) into account, it is already possible to train DeepRC, possibly with multi-head attention and a larger network architecture, on larger datasets (see Sec. A10). Our network implementation is based on PyTorch 1.3.1 (Paszke et al., 2019).\nIncorporation of additional inputs and metadata. Additional metadata in the form of sequencelevel or repertoire-level features could be incorporated into the input via concatenation with the feature vectors that result from taking the maximum of the 1D CNN outputs w.r.t. the sequence positions. This has the benefit that the attention mechanism and output network can utilize the sequence-level or repertoire-level features for their predictions. Sparse metadata or metadata that is only available during training could be used as auxiliary targets to incorporate the information via gradients into the DeepRC model.\nLimitations. The current methods are mostly limited by computational complexity, since both hyperparameter and model selection is computationally demanding. For hyperparameter selection, a large number of hyperparameter settings have to be evaluated. For model selection, a single repertoire requires the propagation of many thousands of sequences through a neural network and keeping those quantities in GPU memory in order to perform the attention mechanism and weight update. Thus, increased GPU memory would significantly boost our approach. Increased computational power would also allow for more advanced architectures and attention mechanisms, which may further improve predictive performance. Another limiting factor is over-fitting of the model due to the currently relatively small number of samples (bags) in real-world immunosequencing datasets in comparison to the large number of instances per bag and features per instance."}, {"heading": "A3 Datasets", "text": "We aimed at constructing immune repertoire classification scenarios with varying degree of realism and difficulties in order to compare and analyze the suggested machine learning methods. To this end, we either use simulated or experimentally-observed immune receptor sequences and we implant signals, which are sequence motifs (Akbar et al., 2019; Weber et al., 2020), into sequences of repertoires of the positive class. It has been shown previously that interaction of immune receptors with antigens occur via short sequence stretches (Akbar et al., 2019). Thus, implantation of short motif sequences simulating an immune signal is biologically meaningful. Our benchmarking study comprises four different categories of datasets: (a) Simulated immunosequencing data with implanted signals (where the signal is defined as sets of motifs), (b) LSTM-generated immunosequencing data with implanted signals, (c) real-world immunosequencing data with implanted signals, and (d) real-world immunosequencing data. Each of the first three categories consists of multiple datasets with varying difficulty depending on the type of the implanted signal and the ratio of sequences with the implanted signal. The ratio of sequences with the implanted signal, where each sequence carries at most 1 implanted signal, corresponds to the witness rate (WR). We consider binary classification tasks to simulate the immune status of healthy and diseased individuals. We randomly generate immune repertoires with varying numbers of sequences, where we implant sequence motifs in the repertoires of the diseased individuals, i.e. the positive class. The sequences of a repertoire are also randomly generated by different procedures (detailed below). Each sequence is composed of 20 different characters, corresponding to amino acids, and has an average length of 14.5 AAs.\nA3.1 Simulated immunosequencing data\nIn the first category, we aim at investigating the impact of the signal frequency, i.e. the WR, and the signal complexity on the performance of the different methods. To this end, we created 18 datasets, whereas each dataset contains a large number of repertoires with a large number of random AA sequences per repertoire. We then implanted signals in the AA sequences of the positive class\nrepertoires, where the 18 datasets differ in frequency and complexity of the implanted signals. In detail, the AAs were sampled randomly independent of their respective position in the sequence, while the frequencies of AAs, distribution of sequence lengths, and distribution of the number of sequences per repertoire, i.e. the number of instances per bag, are following the respective distributions observed in the real-world CMV dataset (Emerson et al., 2017). For this, we first sampled the number of sequences for a repertoire from a Gaussian N (\u00b5 = 316k, \u03c3 = 132k) distribution and rounded to the nearest positive integer. We re-sampled if the size was below 5k. We then generated random sequences of AAs with a length of N (\u00b5 = 14.5, \u03c3 = 1.8), again rounded to the nearest positive integers. Each simulated repertoire was then randomly assigned to either the positive or negative class, with 2, 500 repertoires per class. In the repertoires assigned to the positive class, we implanted motifs with an average length of 4 AAs, following the results of the experimental analysis of antigenbinding motifs in antibodies and T-cell receptor sequences by (Akbar et al., 2019). We varied the characteristics of the implanted motifs for each of the 18 datasets with respect to the following parameters: (a) \u03c1, the probability of a motif being implanted in a sequence of a positive repertoire, i.e. the average ratio of sequences containing the motif, which is the witness rate. (b) The number of wildcard positions in the motif. A wildcard position contains a random AA, which is randomly sampled for each sequence. Wildcard positions are located in the center of the implanted motif. (c) The number of deletion positions in the implanted motif. A deletion position has a probability of 0.5 of being removed from the motif. Deletion positions are located in the center of the implanted motifs.\nIn this way, we generated 18 different datasets of variable difficulty containing in total roughly 28.7 billion sequences. See Table A1 for an overview of the properties of the implanted motifs in the 18 datasets.\nA3.2 LSTM-generated data\nIn the second dataset category, we investigate the impact of the signal frequency and complexity in combination with more plausible immune receptor sequences by taking into account the positional AA distributions and other sequence properties. To this end, we trained an LSTM (Hochreiter & Schmidhuber, 1997) in a standard next character prediction (Graves, 2013) setting to create AA sequences with properties similar to experimentally observed immune receptor sequences.\nIn the first step, the LSTM model was trained on all immuno-sequences in the CMV dataset (Emerson et al., 2017) that contain valid information about sequence abundance and have a known CMV label. Such an LSTM model is able to capture various properties of the sequences, including positiondependent probability distributions and combinations, relationships, and order of AAs. We then used the trained LSTM model to generate 1, 000 repertoires in an autoregressive fashion, starting with a start sequence that was randomly sampled from the trained-on dataset. Based on a visual inspection of the frequencies of 4-mers (see Section A7), the similarity of LSTM generated sequences and real sequences was deemed sufficient for the purpose of generating the AA sequences for the datasets in this category. Further details on LSTM training and repertoire generation are given in Section A7.\nAfter generation, each repertoire was assigned to either the positive or negative class, with 500 repertoires per class. We implanted motifs of length 4 with varying properties in the center of the sequences of the positive class to obtain 5 different datasets. Each sequence in the positive repertoires has a probability \u03c1 to carry the motif, which was varied throughout 5 datasets and corresponds to the WR (see Table A1). Each position in the motif has a probability of 0.9 to be implanted and consequently a probability of 0.1 that the original AA in the sequence remains, which can be seen as noise on the motif.\nA3.3 Real-world data with implanted signals\nIn the third category, we implanted signals into experimentally obtained immuno-sequences, where we considered 4 dataset variations. Each dataset consists of 750 repertoires for each of the two classes, where each repertoire consists of 10k sequences. In this way, we aim to simulate datasets with a low sequencing coverage, which means that only relatively few sequences per repertoire are available. The sequences were randomly sampled from healthy (CMV negative) individuals from the CMV dataset (see below paragraph for explanation). Two signal types were considered: (a) One signal with one motif. The AA motif LDR was implanted in a certain fraction of sequences. The pattern is randomly altered at one of the three positions with probabilities 0.2, 0.6, and 0.2, respectively. (b) One signal with multiple motifs. One of the three possible motifs LDR, CAS, and GL-N was\nSimulated LSTM gen. Real-world\nseq. per bag N(316k, 132k) N(285k, 156k) 10k repertoires 5, 000 1, 000 1, 500 motif noise 0% 10% \u2217 wildcards {0; 1; 2} 0 0 deletions {0; 1} 0 0 mot. freq. \u03c1 {1; 0.1; {10; 1; 0.5; {1; 0.1} (in %) 0.01} 0.1; 0.05}\nTable A1: Properties of simulated repertoires, variations of motifs, and motif frequencies, i.e. the witness rate, for the datasets in categories \u201csimulated immunosequencing data\u201d, \u201cLSTM-generated data\u201d, and \u201creal-world data with implanted signals\u201d. Noise types for \u2217 are explained in paragraph \u201creal-world data with implanted signals\u201d.\nimplanted with equal probability. Again, the motifs were randomly altered before implantation. The AA motif LDR changed as described above. The AA motif CAS was altered at the second position with probability 0.6 and with probability 0.3 at the first position. The pattern GL-N, where - denotes a gap location, is randomly altered at the first position with probability 0.6 and the gap has a length of 0, 1, or 2 AAs with equal probability.\nAdditionally, the datasets differ in the values for \u03c1, the average ratio of sequences carrying a signal, which were chosen as 1% or 0.1%. The motifs were implanted at positions 107, 109, and 114 according to the IMGT numbering scheme for immune receptor sequences (Lefranc et al., 2003) with probabilities 0.3, 0.35 and 0.2, respectively. With the remaining 0.15 chance, the motif is implanted at any other sequence position. This means that the motif occurrence in the simulated sequences is biased towards the middle of the sequence.\nA3.4 Real-world data: CMV dataset\nWe used a real-world dataset of 785 repertoires, each of which containing between 4, 371 to 973, 081 (avg. 299, 319) TCR sequences with a length of 1 to 27 (avg. 14.5) AAs, originally collected and provided by Emerson et al. (2017). 340 out of 785 repertoires were labelled as positive for cytomegalovirus (CMV) serostatus, which we consider as the positive class, 420 repertoires with negative CMV serostatus, considered as negative class, and 25 repertoires with unknown status. We changed the number of sequence counts per repertoire from \u22121 to 1 for 3 sequences. Furthermore, we exclude a total of 99 repertoires with unknown CMV status or unknown information about the sequence abundance within a repertoire, reducing the dataset for our analysis to 686 repertoires, 312 of which with positive and 374 with negative CMV status.\nA3.5 Comparison to other MIL datasets\nWe give a non-exhaustive overview of previously considered MIL datasets and problems in Table A2. To our knowledge the datasets considered in this work pose the most challenging MIL problems with respect to the number of instances per bag (column 5).\nD at\nas et\nTo ta\nln um\nbe r\nTo ta\nln um\nbe r\nA pp\nro x.\nnu m\nbe ro\nf A\nvg .n\num be\nro f\nSo ur\nce D\nat as et of ba gs of in st an ce s fe at ur es pe ri ns ta nc e in st an ce s pe rb ag re fe re nc\ne\nSi m\nul at\ned im\nm un\no5,\n00 0\n1, 59\n7, 02\n4, 31\n0 14\n.5 x2\n0 A\nA se\nqu en\nce 31\n6, 00\n0 th\nis w\nor k\nse qu\nen ci\nng da\nta (o\nur s)\nx 18\nda ta\nse ts\nL ST\nM -g\nen er\nat ed\nda ta\n(o ur\ns) 1,\n00 0\n30 4,\n82 5,\n67 1\n14 .5\nx2 0\nA A\nse qu\nen ce\n28 5,\n00 0\nth is\nw or k x 5 da ta se ts\nR ea\nlw\nor ld\nda ta\nw ith\n1, 50\n0 14\n,7 15\n,4 21\n14 .5\nx2 0\nA A\nse qu\nen ce\n10 ,0\n00 th\nis w\nor k\nim pl\nan te\nd si\ngn al\ns (o\nur s)\nx 4\nda ta\nse ts\nC M\nV (p\nre -p\nro ce\nss ed\nby us\n) 78\n5 23\n4, 96\n5, 72\n9 14\n.5 x2\n0 A\nA se\nqu en\nce 29\n9, 00\n0 th\nis w\nor k\nE m\ner so\nn et\nal .(\n20 17\n)\nM N\nIS T\nba gs\n50 \u20135\n00 50\n0\u2013 50\n,0 00\n28 x2\n8x 1\nim ag\ne 10\n0 Il\nse et\nal .(\n20 18\n)\nB re\nas tC\nan ce\nr 58\nap pr\nox .3\n9, 00\n0 32\nx3 2x\n3 H\n& E\nim ag\ne 67\n2 Il\nse et\nal .(\n20 18\n) G\nel as\nca et\nal .(\n20 08\n)\nB as\nal ce\nll ca\nrc in\nom as\n82 0\n7, 58\n8, 76\n7 10\n24 x1\n02 4x\n3 H\n& E\nim ag\ne 9,\n05 6\nK im\nes w\nen ge\nre ta\nl. (2\n01 9)\nB ir\nds 54\n8 10\n,2 32\n38 9\nR ui\nz et\nal .(\n20 18\n) B\nri gg\ns et\nal .(\n20 12\n)\nSc en\ne 2,\n00 0\n18 ,0\n00 15\n9 R\nui z\net al\n.( 20\n18 )\nZ ha\nng &\nZ ha\nng (2\n00 7)\nR eu\nte rs\n2, 00\n0 7,\n11 9\n24 3\n4 R\nui z\net al\n.( 20\n18 )\nSe ba\nst ia\nni (2\n00 2)\nC K\n+ 43\n0 7,\n91 5\n4, 39\n1 18\nR ui\nz et\nal .(\n20 18\n) L\nuc ey\net al\n.( 20\n10 )\nU ni\nPr ot\n(G eo\nba ct\ner su\nlf ur\nre du\nce ns\n) 37\n9 1,\n25 0\n21 6\n3 R\nui z\net al\n.( 20\n18 )\nW u\net al\n.( 20\n14 )\nM O\nD IS\n(a er\nos ol\nda ta\n) 1,\n36 4\n13 6,\n40 0\n12 10\n0 U\nri ot\n(2 01\n9) ht\ntp s:\n// ae\nro ne\nt. gs\nfc .n\nas a.\ngo v\nM IS\nR 1\n(a er\nos ol\nda ta\n) 80\n0 80\n,0 00\n16 10\n0 U\nri ot\n(2 01\n9) ht\ntp s:\n// ae\nro ne\nt. gs\nfc .n\nas a.\ngo v\nM IS\nR 2\n(a er\nos ol\nda ta\n) 80\n0 80\n,0 00\n12 54\nU ri\not (2\n01 9)\nht tp\ns: //\nae ro\nne t.\ngs fc\n.n as\na. go\nv\nC O\nR N\n(c ro\np yi\nel d)\n52 5\n52 ,5\n00 92\n10 0\nU ri\not (2\n01 9)\nht tp\ns: //\nae ro\nne t.\ngs fc\n.n as\na. go\nv\nW H\nE A\nT (c\nro p\nyi el\nd) 52\n5 52\n,5 00\n92 10\n0 U\nri ot\n(2 01\n9) ht\ntp s:\n// ae\nro ne\nt. gs\nfc .n\nas a.\ngo v\nTa bl\ne A\n2: M\nIL da\nta se\nts w\nith th\nei rn\num be\nrs of\nba gs\nan d\nnu m\nbe rs\nof in\nst an\nce s.\n\u201ct ot\nal nu\nm be\nro fi\nns ta\nnc es\n\u201d re\nfe rs\nto th\ne to\nta ln\num be\nro fi\nns ta\nnc es\nin th\ne da\nta se\nt. T\nhe si\nm ul\nat ed\nan d\nre al\n-w or\nld im\nm un\nos eq\nue nc\nin g\nda ta\nse ts\nco ns\nid er\ned in\nth is\nw or\nk co\nnt ai\nn a\nby or\nde rs\nof m\nag ni\ntu de\ns la\nrg er\nnu m\nbe ro\nfi ns\nta nc\nes pe\nrb ag\nth an\nM IL\nda ta\nse ts\nth at\nw er\ne co\nns id\ner ed\nby m\nac hi\nne le\nar ni\nng m\net ho\nds up\nto no\nw ."}, {"heading": "A4 Compared methods", "text": "We evaluate and compare the performance of DeepRC against a set of machine learning methods that serve as baseline, were suggested, or can readily be adapted to immune repertoire classification. In this section, we describe these compared methods.\nA4.1 Known motif\nThis method serves as an estimate for the achievable classification performance using prior knowledge about which motif was implanted. Note that this does not necessarily lead to perfect predictive performance since motifs are implanted with a certain amount of noise and could also be present in the negative class by chance. The known motif method counts how often the known implanted motif occurs per sequence for each repertoire and uses this count to rank the repertoires. From this ranking, the Area Under the receiver operator Curve (AUC) is computed as performance measure. Probabilistic AA changes in the known motif are not considered for this count, with the exception of gap positions. We consider two versions of this method: (a) Known motif binary: counts the occurrence of the known motif in a sequence and (b) Known motif continuous: counts the maximum number of overlapping AAs between the known motif and all sequence positions, which corresponds to a convolution operation with a binary kernel followed by max-pooling. Since the implanted signal is not known in the experimentally obtained CMV dataset, this method cannot be applied to this dataset.\nA4.2 Support Vector Machine (SVM)\nThe Support Vector Machine (SVM) approach uses a fixed mapping from a bag of sequences to the corresponding k-mer counts. The function hkmer maps each sequence si to a vector representing the occurrence of k-mers in the sequence. To avoid confusion with the sequence-representation obtained from the CNN layers of DeepRC, we denote ui = hkmer(si), which is analogous to zi. Specifically, uim = (hkmer(si))m = #{pm \u2208 si}, where #{pm \u2208 si} denotes how often the k-mer pattern pm occurs in sequence si. Afterwards, average-pooling is applied to obtain u = 1/N \u2211N i=1 ui, the k-mer representation of the input object X . For two input objects X(n) and X(l) with representations u(n) and u(l), respectively, we implement the MinMax kernel (Ralaivola et al., 2005) as follows:\nk(X(n), X(l)) = kMinMax(u (n),u(l))\n=\n\u2211du m=1 min(u (n) m , u\n(l) m )\u2211du\nm=1 max(u (n) m , u (l) m )\n, (A1)\nwhere u(n)m is them-th element of the vector u(n). The Jaccard kernel (Levandowsky & Winter, 1971) is identical to the MinMax kernel except that it operates on binary u(n). We used a standard C-SVM, as introduced by Cortes & Vapnik (1995). The corresponding hyperparameter C is optimized by random search. The settings of the full hyperparameter search as well as the respective value ranges are given in Table A4a.\nA4.3 K-Nearest Neighbor (KNN)\nThe same k-mer representation of a repertoire, as introduced above for the SVM baseline, is used for the K-Nearest Neighbor (KNN) approach. As this method clusters samples according to distances between them, the previous kernel definitions cannot be applied directly. It is therefore necessary to transform the MinMax as well as the Jaccard kernel from similarities to distances by constructing the following (Levandowsky & Winter, 1971):\ndMinMax(u (n),u(l)) = 1\u2212 kMinMax(u(n),u(l)),\ndJaccard(u (n),u(l)) = 1\u2212 kJaccard(u(n),u(l)).\n(A2)\nThe amount of neighbors is treated as the hyperparameter and optimized by an exhaustive grid search. The settings of the full hyperparameter search as well as the respective value ranges are given in Table A5.\nA4.4 Logistic regression\nWe implemented logistic regression on the k-mer representation u of an immune repertoire. The model is trained by gradient descent using the Adam optimizer (Kingma & Ba, 2014). The learning rate is treated as the hyperparameter and optimized by grid search. Furthermore, we explored two regularization settings using combinations of l1 and l2 weight decay. The settings of the full hyperparameter search as well as the respective value ranges are given in Table A6.\nA4.5 Burden test\nWe implemented a burden test (Emerson et al., 2017; Li & Leal, 2008; Wu et al., 2011) in a machine learning setting. The burden test first identifies sequences or k-mers that are associated with the individual\u2019s class, i.e., immune status, and then calculates a burden score per individual. Concretely, for each k-mer or sequence, the phi coefficient of the contingency table for absence or presence and positive or negative immune status is calculated. Then, J k-mers or sequences with the highest phi coefficients are selected as the set of associated k-mers or sequences. J is a hyperparameter that is selected on a validation set. Additionally, we consider the type of input features, sequences or k-mers, as a hyperparameter. For inference, a burden score per individual is calculated as the sum of associated k-mers or sequences it carries. This score is used as raw prediction and to rank the individuals. Hence, we have extended the burden test by Emerson et al. (2017) to k-mers and to adaptive thresholds that are adjusted on a validation set.\nA4.6 Logistic MIL (Ostmeyer et al)\nThe logistic multiple instance learning (MIL) approach for immune repertoire classification (Ostmeyer et al., 2019) applies a logistic regression model to each k-mer representation in a bag. The resulting scores are then summarized by max-pooling to obtain a prediction for the bag. Each amino acid of each k-mer is represented by 5 features, the so-called Atchley factors (Atchley et al., 2005). As k-mers of length 4 are used, this gives a total of 4\u00d75 = 20 features. One additional feature per 4-mer is added, which represents the relative frequency of this 4-mer with respect to its containing bag, resulting in 21 features per 4-mer. Two options for the relative frequency feature exist, which are (a) whether the frequency of the 4-mer (\u201c4MER\u201d) or (b) the frequency of the sequence in which the 4-mer appeared (\u201cTCR\u03b2\u201d) is used. We optimized the learning rate, batch size, and early stopping parameter on the validation set. The settings of the full hyperparameter search as well as the respective value ranges are given in Table A8."}, {"heading": "A5 Hyperparameter selection", "text": "For all competing methods a hyperparameter search was performed, for which we split each of the 5 training sets into an inner training set and inner validation set. The models were trained on the inner training set and evaluated on the inner validation set. The model with the highest AUC score on the inner validation set is then used to calculate the score on the respective test set. Here we report the hyperparameter sets and search strategy that is used for all methods.\nDeepRC. The set of hyperparameters of DeepRC is shown in Table A3. These hyperparameter combinations are adjusted via a grid search procedure.\nlearning rate 10\u22124 number of kernels (dv) {8; 16; 32; 64\u2217; 128\u2217; 256\u2217} number of CNN layers {1} number of layers in key-NN {2} number of units in key-NN {32} kernel size {5; 7; 9} subsampled seqences 10, 000 batch size 4\nTable A3: DeepRC hyperparameter search space. Every 5 \u00b7 103 updates, the current model was evaluated against the validation fold. The early stopping hyperparameter was determined by selecting the model with the best loss on the validation fold after 105 updates. \u2217: Experiments for {64; 128; 256} kernels were omitted for datasets with motif implantation probabilities \u2265 1% in the category \u201csimulated immunosequencing data\u201d.\nKnown motif. This method does not have hyperparameters and has been applied to all datasets except for the CMV dataset.\nSVM. The corresponding hyperparameter C of the SVM is optimized by randomly drawing 103 values in the range of [\u22126; 6] according to a uniform distribution. These values act as the exponents of a power of 10 and are applied for each of the two kernel types (see Table A4a).\nC 10{\u22126;6} type of kernel {MinMax; Jaccard} number of trials 103\n(a)\nSettings used in the hyperparameter search of the SVM baseline approach. The number of trials defines the quantity of random values of the C penalty term (per type of kernel).\nKNN. The amount of neighbors is treated as the hyperparameter and optimized by grid search operating in the discrete range of [1; max{N, 103}] with a step size of 1. The corresponding tight upper bound is automatically defined by the total amount of samples N \u2208 N>0 in the training set, capped at 103 (see Table A5).\nnumber of neighbors {1; max{N, 103}} type of kernel {MinMax; Jaccard}\nTable A5: Settings used in the hyperparameter search of the KNN baseline approach. The number of trials (per type of kernel) is automatically defined by the total amount of samples N \u2208 N>0 in the training set, capped at 103.\nLogistic regression. The hyperparameter optimization strategy that was used was grid search across hyperparameters given in Table A6.\nlearning rate 10\u2212{2;3;4} batch size 4 max. updates 105 coefficient \u03b21 (Adam) 0.9 coefficient \u03b22 (Adam) 0.999 weight decay weightings {(l1 = 10\u22127, l2 = 10\u22123); (l1 = 10\u22127, l2 = 10\u22125)}\nTable A6: Settings used in the hyperparameter search of the logistic regression baseline approach.\nBurden test. The burden test selects two hyperparameters: the number of features in the burden set and the type of features, see Table A7.\nnumber of features in burden set {50, 100, 150, 250} type of features {4MER; sequence}\nTable A7: Settings used in the hyperparameter search of the burden test approach.\nLogistic MIL. For this method, we adjusted the learning rate as well as the batch size as hyperparameters by randomly drawing 25 different hyperparameter combinations from a uniform distribution. The corresponding range of the learning rate is [\u22124.5;\u22121.5], which acts as the exponent of a power of 10. The batch size lies within the range of [1; 32]. For each hyperparameter combination, a model is optimized by gradient descent using Adam, whereas the early stopping parameter is adjusted according to the corresponding validation set (see Table A8).\nlearning rate 10{\u22124.5;\u22121.5} batch size {1; 32} relative abundance term {4MER; TCR\u03b2} number of trials 25 max. epochs 102 coefficient \u03b21 (Adam) 0.9 coefficient \u03b22 (Adam) 0.999\nTable A8: Settings used in the hyperparameter search of the logistic MIL baseline approach. The number of trials (per type of relative abundance) defines the quantity of combinations of random values of the learning rate as well as the batch size."}, {"heading": "A6 Results", "text": "In this section, we report the detailed results on all four categories of datasets (a) simulated immunosequencing data (Table A9) (b) LSTM-generated data (Table A10), (c) real-world data with implanted signals (Table A11), and (d) real-world data on the CMV dataset (Table A12), as discussed in the main paper.\nID 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 avg.\nmotif freq. \u03c1 1% 0.1% 0.01% 1% 0.1% 0.01% 1% 0.1% 0.01% 1% 0.1% 0.01% 1% 0.1% 0.01% 1% 0.1% 0.01% \u2013 implanted motif SFEN SFEN SFEN SFdEN SFdEN SFdEN SFZN SFZN SFZN SFdZN SFdZN SFdZN SZZN SZZN SZZN SZdZN SZdZN SZdZN \u2013\nDeepRC 1.000 1.000 0.703 1.000 1.000 0.600 1.000 1.000 0.509 1.000 1.000 0.492 1.000 0.997 0.487 0.999 0.942 0.492 0.864\n\u00b1 0.000 \u00b1 0.000 \u00b1 0.271 \u00b1 0.000 \u00b1 0.000 \u00b1 0.218 \u00b1 0.000 \u00b1 0.000 \u00b1 0.029 \u00b1 0.000 \u00b1 0.001 \u00b1 0.017 \u00b1 0.001 \u00b1 0.002 \u00b1 0.023 \u00b1 0.001 \u00b1 0.048 \u00b1 0.013 \u00b1 0.223\nSVM (MinMax) 1.000 1.000 0.764 1.000 1.000 0.603 1.000 0.998 0.539 1.000 0.994 0.529 1.000 0.741 0.513 1.000 0.706 0.503 0.827\n\u00b1 0.000 \u00b1 0.000 \u00b1 0.016 \u00b1 0.000 \u00b1 0.000 \u00b1 0.021 \u00b1 0.000 \u00b1 0.002 \u00b1 0.024 \u00b1 0.000 \u00b1 0.004 \u00b1 0.016 \u00b1 0.000 \u00b1 0.024 \u00b1 0.006 \u00b1 0.000 \u00b1 0.013 \u00b1 0.013 \u00b1 0.210\nSVM (Jaccard) 0.783 0.505 0.500 0.656 0.504 0.492 0.629 0.499 0.505 0.594 0.508 0.497 0.620 0.496 0.506 0.595 0.507 0.505 0.550\n\u00b1 0.010 \u00b1 0.009 \u00b1 0.010 \u00b1 0.009 \u00b1 0.018 \u00b1 0.018 \u00b1 0.011 \u00b1 0.010 \u00b1 0.009 \u00b1 0.007 \u00b1 0.017 \u00b1 0.013 \u00b1 0.007 \u00b1 0.006 \u00b1 0.019 \u00b1 0.013 \u00b1 0.012 \u00b1 0.017 \u00b1 0.080\nKNN (MinMax) 0.669 0.802 0.503 0.722 0.757 0.493 0.766 0.678 0.496 0.762 0.652 0.489 0.797 0.512 0.498 0.796 0.511 0.503 0.634\n\u00b1 0.204 \u00b1 0.265 \u00b1 0.038 \u00b1 0.214 \u00b1 0.255 \u00b1 0.017 \u00b1 0.241 \u00b1 0.165 \u00b1 0.014 \u00b1 0.237 \u00b1 0.139 \u00b1 0.015 \u00b1 0.271 \u00b1 0.023 \u00b1 0.014 \u00b1 0.270 \u00b1 0.037 \u00b1 0.006 \u00b1 0.129\nKNN (Jaccard) 0.516 0.493 0.497 0.506 0.500 0.492 0.509 0.493 0.497 0.495 0.504 0.500 0.502 0.497 0.500 0.502 0.503 0.513 0.501\n\u00b1 0.035 \u00b1 0.020 \u00b1 0.013 \u00b1 0.015 \u00b1 0.019 \u00b1 0.014 \u00b1 0.017 \u00b1 0.011 \u00b1 0.018 \u00b1 0.013 \u00b1 0.004 \u00b1 0.017 \u00b1 0.011 \u00b1 0.017 \u00b1 0.022 \u00b1 0.015 \u00b1 0.020 \u00b1 0.012 \u00b1 0.007\nLogistic regression 1.000 1.000 0.786 1.000 1.000 0.607 1.000 0.997 0.527 1.000 0.992 0.526 1.000 0.719 0.505 1.000 0.694 0.510 0.826\n\u00b1 0.000 \u00b1 0.000 \u00b1 0.009 \u00b1 0.000 \u00b1 0.000 \u00b1 0.025 \u00b1 0.000 \u00b1 0.002 \u00b1 0.018 \u00b1 0.000 \u00b1 0.004 \u00b1 0.019 \u00b1 0.000 \u00b1 0.019 \u00b1 0.015 \u00b1 0.001 \u00b1 0.021 \u00b1 0.017 \u00b1 0.211\nLogistic MIL (KMER) 1.000 1.000 0.509 1.000 0.783 0.489 1.000 0.544 0.517 1.000 0.529 0.483 0.579 0.498 0.502 0.550 0.488 0.498 0.665\n\u00b1 0.000 \u00b1 0.000 \u00b1 0.039 \u00b1 0.000 \u00b1 0.216 \u00b1 0.023 \u00b1 0.000 \u00b1 0.038 \u00b1 0.018 \u00b1 0.000 \u00b1 0.043 \u00b1 0.007 \u00b1 0.042 \u00b1 0.017 \u00b1 0.018 \u00b1 0.051 \u00b1 0.009 \u00b1 0.005 \u00b1 0.224\nLogistic MIL (TCR\u03b2) 0.544 0.505 0.493 0.487 0.476 0.500 0.520 0.495 0.510 0.492 0.506 0.503 0.509 0.505 0.500 0.475 0.489 0.500 0.501\n\u00b1 0.078 \u00b1 0.014 \u00b1 0.018 \u00b1 0.021 \u00b1 0.019 \u00b1 0.022 \u00b1 0.053 \u00b1 0.009 \u00b1 0.022 \u00b1 0.014 \u00b1 0.019 \u00b1 0.010 \u00b1 0.034 \u00b1 0.009 \u00b1 0.011 \u00b1 0.013 \u00b1 0.024 \u00b1 0.019 \u00b1 0.016\nBurden test 0.770 0.523 0.510 0.666 0.510 0.509 0.652 0.508 0.505 0.583 0.508 0.509 0.564 0.508 0.507 0.536 0.508 0.504 0.549\n\u00b1 0.013 \u00b1 0.013 \u00b1 0.014 \u00b1 0.011 \u00b1 0.009 \u00b1 0.007 \u00b1 0.008 \u00b1 0.011 \u00b1 0.012 \u00b1 0.012 \u00b1 0.007 \u00b1 0.014 \u00b1 0.017 \u00b1 0.010 \u00b1 0.020 \u00b1 0.012 \u00b1 0.016 \u00b1 0.016 \u00b1 0.074\nKnown motif b. 1.000 1.000 0.973 1.000 1.000 0.865 1.000 1.000 0.700 1.000 0.989 0.609 1.000 0.946 0.570 1.000 0.834 0.532 0.890\n\u00b1 0.000 \u00b1 0.000 \u00b1 0.004 \u00b1 0.000 \u00b1 0.000 \u00b1 0.004 \u00b1 0.000 \u00b1 0.000 \u00b1 0.020 \u00b1 0.000 \u00b1 0.002 \u00b1 0.017 \u00b1 0.000 \u00b1 0.010 \u00b1 0.024 \u00b1 0.000 \u00b1 0.016 \u00b1 0.020 \u00b1 0.168\nKnown motif c. 0.999 0.720 0.529 0.999 0.698 0.534 0.999 0.694 0.532 1.000 0.696 0.527 0.997 0.666 0.520 0.998 0.668 0.509 0.738\n\u00b1 0.001 \u00b1 0.014 \u00b1 0.020 \u00b1 0.001 \u00b1 0.013 \u00b1 0.017 \u00b1 0.001 \u00b1 0.012 \u00b1 0.012 \u00b1 0.001 \u00b1 0.018 \u00b1 0.018 \u00b1 0.002 \u00b1 0.010 \u00b1 0.009 \u00b1 0.002 \u00b1 0.012 \u00b1 0.013 \u00b1 0.202\nTable A9: AUC estimates based on 5-fold CV for all 18 datasets in category \u201csimulated immunosequencing data\u201d. The reported errors are standard deviations across the 5 cross-validation folds except for the last column \u201cavg.\u201d, in which they show standard deviations across datasets. Wildcard characters in motifs are indicated by Z, characters with 50% probability of being removed by d.\nID 0 1 2 3 4 avg.\nmotif freq. \u03c1 10% 1% 0.5% 0.1% 0.05% \u2013\nimplanted motif GrSrArFr GrSrArFr GrSrArFr GrSrArFr GrSrArFr \u2013\nDeepRC 1.000 \u00b1 0.000 1.000 \u00b1 0.000 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.998 \u00b1 0.002 1.000 \u00b1 0.001\nSVM (MinMax) 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.999 \u00b1 0.001 0.999 \u00b1 0.002 0.985 \u00b1 0.014 0.997 \u00b1 0.007\nSVM (Jaccard) 0.981 \u00b1 0.041 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.904 \u00b1 0.036 0.768 \u00b1 0.068 0.931 \u00b1 0.099\nKNN (MinMax) 0.699 \u00b1 0.272 0.717 \u00b1 0.263 0.732 \u00b1 0.263 0.536 \u00b1 0.156 0.516 \u00b1 0.153 0.640 \u00b1 0.105\nKNN (Jaccard) 0.698 \u00b1 0.285 0.606 \u00b1 0.237 0.523 \u00b1 0.164 0.550 \u00b1 0.186 0.539 \u00b1 0.194 0.583 \u00b1 0.071\nLogistic regression 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.934 \u00b1 0.147 0.604 \u00b1 0.193 0.427 \u00b1 0.156 0.793 \u00b1 0.262\nLogistic MIL (KMER) 0.997 \u00b1 0.004 0.718 \u00b1 0.112 0.637 \u00b1 0.144 0.571 \u00b1 0.146 0.528 \u00b1 0.129 0.690 \u00b1 0.186\nLogistic MIL (TCR\u03b2) 0.541 \u00b1 0.086 0.566 \u00b1 0.162 0.468 \u00b1 0.086 0.505 \u00b1 0.067 0.500 \u00b1 0.121 0.516 \u00b1 0.038\nBurden test 1.000 \u00b1 0.000 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.999 \u00b1 0.003 0.792 \u00b1 0.280 0.958 \u00b1 0.093\nKnown motif b. 1.000 \u00b1 0.000 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.999 \u00b1 0.003 0.999 \u00b1 0.003 1.000 \u00b1 0.001\nKnown motif c. 1.000 \u00b1 0.000 1.000 \u00b1 0.000 0.989 \u00b1 0.011 0.722 \u00b1 0.085 0.626 \u00b1 0.094 0.867 \u00b1 0.180\nTable A10: AUC estimates based on 5-fold CV for all 5 datasets in category \u201cLSTM-generated data\u201d. The reported errors are standard deviations across the 5 cross-validation folds except for the last column \u201cavg.\u201d, in which they show standard deviations across datasets. Characters affected by noise, as described in A3, paragraph \u201cLSTM-generated data\u201d, are indicated by r."}, {"heading": "A7 Repertoire generation via LSTM", "text": "We trained a conventional next-character LSTM model (Graves, 2013) based on the implementation in https://github.com/spro/practical-pytorch (access date 1st of May, 2020) using PyTorch 1.3.1 (Paszke et al., 2019). For this, we applied an LSTM model with 100 LSTM blocks in 2 layers, which was trained for 5, 000 epochs using the Adam optimizer (Kingma & Ba, 2014) with learning rate 0.01, an input batch size of 100 character chunks, and a character chunk length of 200. As input we used the immuno-sequences in the CDR3 column of the CMV dataset, where we repeated sequences according to their counts in the repertoires, as specified in the templates column of the CMV dataset. We excluded repertoires with unknown CMV status and unknown sequence abundance from training.\nAfter training, we generated 1, 000 repertoires using a temperature value of 0.8. The number of sequences per repertoire was sampled from a Gaussian N (\u00b5 = 285k, \u03c3 = 156k) distribution, where the whole repertoire was generated by the LSTM at once. That is, the LSTM can base the generation of the individual AA sequences in a repertoire, including the AAs and the lengths of the sequences, on the generated repertoire. A random immuno-sequence from the trained-on repertoires was used as initialization for the generation process. This immuno-sequence was not included in the generated repertoire.\nFinally, we randomly assigned 500 of the generated repertoires to the positive (diseased) and 500 to the negative (healthy) class. We then implanted motifs in the positive class repertoires as described in Section A3.2.\nAs illustrated in the comparison of histograms given in Fig. A2, the generated immuno-sequences exhibit a very similar distribution of 4-mers and AAs compared to the original CMV dataset.\nReal-world data LSTM-generated data\na) b)\nc) d)\ne) f)\nFigure A2: Distribution of AAs and k-mers in real-world CMV dataset and LSTM-generated data. Left: Histograms of real-world data. Right: Histograms of LSTM-generated data. a) Frequency of AAs in sequences of the CMV dataset. b) Frequency of AAs in sequences of the LSTM-generated datasets. c) Frequency of top 200 4-mers in sequences of the CMV dataset. d) Frequency of top 200 4-mers in sequences of the LSTM-generated datasets. e) Frequency of top 20 4-mers in sequences of the CMV dataset. f) Frequency of top 20 4-mers in sequences of the LSTM-generated datasets. Overall the distributions of AAs and 4-mers are similar in both datasets.\nA8 Interpreting DeepRC\nDeepRC allows for two forms of interpretability methods. (a) Due to its attention-based design, a trained model can be used to compute the attention weights of a sequence, which directly indicates its importance. (b) DeepRC furthermore allows for the usage of contribution analysis methods, such as Integrated Gradients (IG) (Sundararajan et al., 2017) or Layer-Wise Relevance Propagation (Montavon et al., 2018; Arras et al., 2019; Montavon et al., 2019; Preuer et al., 2019). We apply IG to identify the input patterns that are relevant for the classification. To identify AA patterns with high contributions in the input sequences, we apply IG to the AAs in the input sequences. Additionally, we apply IG to the kernels of the 1D CNN, which allows us to identify AA motifs with high contributions. In detail, we compute the IG contributions for the AAs and positional features in the kernels for every repertoire in the validation and test set, so as to exclude potential artifacts caused by over-fitting. Averaging the IG values over these repertoires then results in concise AA motifs. We include qualitative visual analyses of the IG method on different datasets below.\nHere, we provide examples for the interpretation of trained DeepRC models using Integrated Gradients (IG) (Sundararajan et al., 2017) as contribution analysis method. The following illustrations were created using 50 IG steps, which we found sufficient to achieve stable IG results.\nA visual analysis of DeepRC models on the simulated datasets, as illustrated in Tab. A13 and Fig. A3, shows that the implanted motifs can be successfully extracted from the trained model and are straightforward to interpret. In the real-world CMV dataset, DeepRC finds complex patterns with high variability in the center regions of the immuno-sequences, as illustrated in figure A4.\na)\nb)\nc)\nFigure A3: Integrated Gradients applied to input sequences of positive class repertoires. Three sequences with the highest contributions to the prediction of their respective repertoires are shown. a) Input sequence taken from \u201csimulated immunosequencing data\u201d with implanted motif SZdZdN and motif implantation probability 0.1%. The DeepRC model reacts to the S and N at the 5th and 8th sequence position, thereby identifying the implanted motif in this sequence. b) and c) Input sequence taken from \u201creal-world data with implanted signals\u201d with implanted motifs {LrDrRr; CrArS; GrL-N} and motif implantation probability 0.1%. The DeepRC model reacts to the fully implanted motif CAS (b) and to the partly implanted motif AAs C and A at the 5th and 7th sequence position (c), thereby identifying the implanted motif in the sequences. Wildcard characters in implanted motifs are indicated by Z, characters with 50% probability of being removed by d, and gap locations of random lengths of {0; 1; 2} by -. Larger characters in the sequences indicate higher contribution, with blue indicating positive contribution and red indicating negative contribution towards the prediction of the diseased class.\nFigure A4: Visualization of the contributions of characters within a sequence via IG. Each sequence was selected from a different repertoire and showed the highest contribution in its repertoire. The model was trained on CMV dataset, using a kernel size of 9, 32 kernels and 137 repertoires for early stopping. Larger characters in the extracted motifs indicate higher contribution, with blue indicating positive contribution and red indicating negative contribution towards the prediction of the disease class."}, {"heading": "A9 Attention values for previously associated CMV sequences", "text": "Table A14 lists sequences of the CMV dataset that were previously associated with CMV immune status and their assigned high attention values by DeepRC."}, {"heading": "41 CASSLGHRDPNTGELFF 0.981 0.958 82 CASSLQGYSNQPQHF 1.000 0.999 123 CASSQDPRGTEAFF 0.950 0.905 164 CASSQGLQETQYF 0.996 0.990", "text": ""}, {"heading": "40 CASSESGHRNQPQHF 0.999 0.997 81 CASSLGDRAYNEQFF 0.996 0.988 122 CASRTDSGANVLTF 0.994 0.986 163 CSARRGPGELFF 0.839 0.749", "text": ""}, {"heading": "39 CSASPGQGASYGYTF 0.987 0.969 80 CAWRGTGNSPLHF 0.964 0.927 121 CASRRGSSYEQYF 0.999 0.998 162 CASSDRGNTGELFF 0.995 0.986", "text": ""}, {"heading": "38 CASSLVASGRETQYF 0.997 0.991 79 CASRPTGYEQYF 0.987 0.969 120 CASSPGSGANVLTF 0.999 0.997 161 CASSYAGDGYTF 0.992 0.980", "text": ""}, {"heading": "37 CSVRDNYNQPQHF 0.998 0.993 78 CASSISAGEAFF 0.992 0.979 119 CASSRPGQGNTEAFF 0.994 0.984 160 CATSREGSGYEQYF 0.987 0.969", "text": ""}, {"heading": "36 CATSDGETQYF 0.998 0.994 77 CASSLRGSSYNEQFF 0.999 0.998 118 CASSWDRGTEAFF 0.999 0.999 159 CASSLGWTEAFF 0.999 0.997", "text": ""}, {"heading": "35 CATSDGDTQYF 0.996 0.989 76 CASSYGGEGYTF 0.999 0.996 117 CASRDRDRVNTEAFF 0.970 0.938 158 CASSPLGGTTEAFF 0.995 0.988", "text": ""}, {"heading": "34 CASSQVPGQGDNEQFF 0.983 0.961 75 CASSLEGQQPQHF 0.994 0.984 116 CASSPRWQETQYF 0.991 0.978 157 CASSPPAGTNYGYTF 0.947 0.900", "text": ""}, {"heading": "33 CASMGGASYEQYF 0.991 0.978 74 CASSLQGADTQYF 0.997 0.991 115 CASSQGRHTDTQYF 0.960 0.921 156 CASSSGTGDEQYF 1.000 1.000", "text": ""}, {"heading": "32 CASSLGLKGTQYF 0.964 0.928 73 CASSEAPSTSTDTQYF 0.989 0.973 114 CASSLQGINQPQHF 0.999 0.997 155 CASSTSGNTIYF 1.000 0.999", "text": ""}, {"heading": "31 CASSPAGLNTEAFF 0.996 0.988 72 CASSLEAENEQFF 0.973 0.943 113 CASSPGGTQYF 0.999 0.996 154 CASRPQGNYGYTF 0.998 0.996", "text": ""}, {"heading": "30 CSVEEDEGIYGYTF 0.964 0.927 71 CASRSDSGANVLTF 0.973 0.942 112 CASRGQGAGELFF 0.987 0.969 153 CASSLTDTGELFF 0.994 0.984", "text": ""}, {"heading": "29 CASSPSTGTEAFF 0.997 0.992 70 CASSTGTSGSYEQYF 0.999 0.998 111 CATSRVAGETQYF 0.980 0.955 152 CASSYPGETQYF 0.997 0.992", "text": ""}, {"heading": "28 CASSYGGLGSYEQYF 0.995 0.987 69 CASSEARGGVEKLFF 0.989 0.974 110 CASSSRGTGELFF 0.999 0.997 151 CASSRGTGATDTQYF 0.999 0.998", "text": ""}, {"heading": "27 CATSRDSQGSYGYTF 0.980 0.955 68 CASSLGGPGDTQYF 0.993 0.982 109 CASSLVGDGYTF 1.000 1.000 150 CASSLGASGSRTDTQYF 0.932 0.876", "text": ""}, {"heading": "26 CASSPGDEQFF 0.999 0.997 67 CASSPSRNTEAFF 0.999 0.998 108 CASSLLWDQPQHF 0.986 0.967 149 CASSTGGAQPQHF 0.998 0.993", "text": ""}, {"heading": "25 CASSIWGLDTEAFF 0.959 0.919 66 CASSHRDRNYEQYF 0.987 0.969 107 CSALGHSNQPQHF 0.926 0.867 148 CASSLQAGANEQFF 0.969 0.935", "text": ""}, {"heading": "24 CASSEIPNTEAFF 0.997 0.992 65 CASSVLAGPTDTQYF 0.951 0.906 106 CASSEGARQPQHF 0.999 0.998 147 CASSLAVLPTDTQYF 0.996 0.989", "text": ""}, {"heading": "23 CASSLPSGLTDTQYF 0.994 0.985 64 CASSTTGGDGYTF 0.978 0.952 105 CASSSGQVQETQYF 0.997 0.993 146 CASSALGGAGTGELFF 0.985 0.964", "text": ""}, {"heading": "22 CASSPGDEQYF 0.998 0.993 63 CASSIQGYSNQPQHF 0.993 0.983 104 CASSFPGGETQYF 0.992 0.979 145 CASSQNRAQETQYF 0.984 0.962", "text": ""}, {"heading": "21 CASSFPTSGQETQYF 0.982 0.959 62 CASSLTGGRNQPQHF 0.999 0.997 103 CASSLETYGYTF 0.998 0.995 144 CASSPISNEQFF 0.967 0.933", "text": ""}, {"heading": "20 CASSRLAGGTDTQYF 0.999 0.998 61 CASSPLSDTQYF 0.998 0.994 102 CASSEEGIQPQHF 0.998 0.994 143 CASSIRTNYYGYTF 0.996 0.990", "text": ""}, {"heading": "19 CATSRDTQGSYGYTF 0.917 0.854 60 CASSSPGRSGANVLTF 0.995 0.986 101 CASSSGQVYGYTF 0.999 0.996 142 CASSLGIDTQYF 0.997 0.991", "text": ""}, {"heading": "18 CASSFHGFNQPQHF 0.991 0.978 59 CATSDSRTGGQETQYF 0.900 0.829 100 CASSLEGQGFGYTF 0.944 0.895 141 CASTPGDEQFF 0.988 0.971", "text": ""}, {"heading": "17 CASSLRREKLFF 0.998 0.993 58 CASSPPGQGSDTQYF 0.975 0.946 99 CASSLGDRPDTQYF 0.940 0.889 140 CASSRNRAQETQYF 0.994 0.984", "text": ""}, {"heading": "16 CASSLVIGGDTEAFF 0.966 0.931 57 CASSVTGGTDTQYF 1.000 0.999 98 CASSSDRVGQETQYF 0.980 0.955 139 CASSGLNEQFF 0.994 0.984", "text": ""}, {"heading": "15 CASSQTGGRNQPQHF 0.997 0.992 56 CASSRLAASTDTQYF 0.992 0.979 97 CASRDWDYTDTQYF 0.994 0.984 138 CASSLGRGYEKLFF 0.985 0.965", "text": ""}, {"heading": "14 CSVRDNFNQPQHF 0.915 0.851 55 CASSLGHRDSSYEQYF 0.987 0.969 96 CASSQVETDTQYF 0.994 0.984 137 CASSSRTGEETQYF 0.996 0.988", "text": ""}, {"heading": "13 CASSLIGVSSYNEQFF 0.983 0.961 54 CASSYNPYSNQPQHF 0.892 0.819 95 CASRGQGWDEKLFF 0.994 0.984 136 CASASANYGYTF 0.816 0.720", "text": ""}, {"heading": "12 CASSLAPGATNEKLFF 0.976 0.949 53 CASSEARTRAFF 0.927 0.869 94 CASSPHRNTEAFF 0.999 0.998 135 CASSVETGGTEAFF 0.995 0.986", "text": ""}, {"heading": "11 CASSPQRNTEAFF 1.000 0.999 52 CASSRNRESNQPQHF 0.968 0.934 93 CASSLVAAGRETQYF 0.959 0.919 134 CASSPTGGELFF 0.989 0.974", "text": ""}, {"heading": "10 CASSQNRGQETQYF 0.995 0.987 51 CATSDSVTNTGELFF 0.989 0.973 92 CASSPGQEAGANVLTF 0.823 0.728 133 CAISESQDRGHEQYF 0.823 0.728", "text": ""}, {"heading": "9 CASSAGQGVTYEQYF 0.998 0.995 50 CASSLGVGPYNEQFF 0.986 0.967 91 CASSWDRDNSPLHF 0.918 0.855 132 CASSEEAGGSGYTF 0.982 0.959", "text": ""}, {"heading": "8 CASSRGRQETQYF 0.997 0.993 49 CASSLNRGQETQYF 0.996 0.988 90 CSASDHEQYF 0.995 0.986 131 CASSESGDPSSYEQYF 0.980 0.955", "text": ""}, {"heading": "7 CASSLVAGGRETQYF 0.988 0.971 48 CASSGDRLYEQYF 0.998 0.994 89 CASSPNQETQYF 0.999 0.996 130 CSVEVRGTDTQYF 0.955 0.912", "text": ""}, {"heading": "6 CATSDGDEQFF 0.998 0.996 47 CASSPPSGLTDTQYF 0.978 0.951 88 CAWSVSDLAKNIQYF 0.954 0.911 129 CASSVDGGRGTEAFF 0.995 0.987", "text": ""}, {"heading": "5 CASSIEGNQPQHF 0.993 0.983 46 CATSRGTVSYEQYF 0.990 0.975 87 CASGRDTYEQYF 0.999 0.997 128 CASSSDSGGTDTQYF 0.951 0.906", "text": ""}, {"heading": "4 CASSLEAEYEQYF 0.992 0.980 45 CASSAQGAYEQYF 0.998 0.995 86 CASSRDRNYGYTF 0.998 0.995 127 CASRTGESGYTF 0.985 0.965", "text": ""}, {"heading": "3 CASSPDRVGQETQYF 0.995 0.987 44 CSVRDNHNQPQHF 0.965 0.929 85 CASSLGAGNQPQHF 1.000 0.999 126 CASSLGQGLAEAFF 0.996 0.989", "text": ""}, {"heading": "2 CASSIGPLEHNEQFF 0.947 0.900 43 CASNRDRGRYEQYF 0.991 0.978 84 CASSLAGVDYEQYF 0.999 0.996 125 CASSRNRGQETQYF 0.978 0.952", "text": ""}, {"heading": "1 CASSGQGAYEQYF 1.000 0.999 42 CASSLGGAGDTQYF 1.000 1.000 83 CASSYVRTGGNYGYTF 0.967 0.932 124 CASSLTGGNSGNTIYF 0.991 0.977", "text": ""}, {"heading": "A10 DeepRC variations and ablation study", "text": "In this section we investigate the impact of different variations of DeepRC on the performance on the CMV dataset. We consider both a CNN-based sequence embedding, as used in the main paper, and an LSTM-based sequence embedding. In both cases we vary the number of attention heads and the \u03b2 parameter for the softmax function the attention mechanism (see Eq. 2 in main paper). For the CNN-based sequence embedding we also vary the number of CNN kernels and the kernel sizes used in the 1D CNN. For the LSTM-based sequence embedding we use one one-directional LSTM layer, of which the output values at the last sequence position (without padding) are taken as embedding of the sequence. Here we vary the number of LSTM blocks in the LSTM layer. To counter over-fitting due to the increased complexity of these DeepRC variations, we added a l2 weight penalty to the training loss. The factor with which the l2 weight penalty contributes to the training loss is varied over 3 orders of magnitudes, where suitable value ranges were manually determined on one of the training folds beforehand.\nTo reduce the computational effort, we do not consider all numbers of kernels that were considered in the main paper. Furthermore, we only compute the AUC scores on 3 of the 5 cross-validation folds. The hyperparameters, which were used in a grid search procedure, are listed in Tab. A15 for the CNN-based sequence embedding and Tab. A16 for the LSTM-based sequence embedding.\nResults. We show performance in terms of AUC score with single hyperparameters set to fixed values so as to investigate their influence in Tab. A18 for the CNN-based sequence embedding and Tab. A17 for the LSTM-based sequence embedding. We note that due to restricted computational resources this study was conducted with fewer different numbers of CNN kernels, with the AUC estimated from only 3 of the 5 cross-validation folds, which leads to a slight decrease of performance in comparison to the full hyperparameter search and cross-validation procedure used in the main paper. As can be seen in Tab. A18 and A17, the LSTM-based sequence embedding generalizes slightly better than the CNN-based sequence embedding. The performance of DeepRC, however, remains rather robust w.r.t. the different hyperparameter settings."}], "title": "Modern Hopfield Networks and Attention for Immune Repertoire Classification", "year": 2020}