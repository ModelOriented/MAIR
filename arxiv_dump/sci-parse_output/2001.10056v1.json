{"abstractText": "Recently, the term explainable AI became known as an approach to produce models from artificial intelligence which allow interpretation. Since a long time, there are models of symbolic regression in use that are perfectly explainable and mathematically tractable: in this contribution we demonstrate how to use symbolic regression methods to infer the optimal control of a dynamical system given one or several optimization criteria, or cost functions. In previous publications, network control was achieved by automatized machine learning control using genetic programming. Here, we focus on the subsequent analysis of the analytical expressions which result from the machine learning. In particular, we use AUTO to analyze the stability properties of the controlled oscillator system which served as our model. As a result, we show that there is a considerable advantage of explainable models over less accessible neural networks.", "authors": [{"affiliations": [], "name": "Markus Quade"}, {"affiliations": [], "name": "Thomas Isele"}, {"affiliations": [], "name": "Markus Abel"}], "id": "SP:a66fe3f996810e58d8bee70561dcdf6551b48968", "references": [{"authors": ["R. Goebel", "A. Chander", "K. Holzinger", "F. Lecue", "Z. Akata", "S. Stumpf", "P. Kieseberg", "A. Holzinger"], "title": "Explainable ai: The new 42", "venue": "in: A. Holzinger, P. Kieseberg, A. M. Tjoa, E. Weippl (Eds.), Machine Learning and Knowledge Extraction, Springer International Publishing, Cham, 2018, pp. 295\u2013 303 ", "year": 2018}, {"authors": ["E. Ott", "C. Grebogi", "J.A. Yorke"], "title": "Controlling chaos", "venue": "Phys. Rev. Lett. 64 (11) (1990) 1196\u20131199 ", "year": 1990}, {"authors": ["H. Haken"], "title": "Brain Dynamics: Synchronization and Activity Patterns in Pulse-Coupled Neural Nets with Delays and Noise", "venue": "Springer Series in Synergetics, Springer Berlin Heidelberg, 2006 ", "year": 2006}, {"authors": ["J.M. Schwalb", "C. Hamani"], "title": "The history and future of deep brain stimulation", "venue": "Neurotherapeutics 5 (1) (2008) 3\u201313 ", "year": 2008}, {"authors": ["A. Pikovsky", "M. Rosenblum", "J. Kurths"], "title": "Synchronization", "venue": "Cambridge University Press, 2001 ", "year": 2001}, {"authors": ["S.H. Strogatz"], "title": "Sync: How order emerges from chaos in the universe", "venue": "nature, and daily life, Hyperion, 2003 ", "year": 2003}, {"authors": ["J. Gout", "M. Quade", "K. Shafi", "R.K. Niven", "M. Abel"], "title": "Synchronization control of oscillator networks using symbolic regression", "venue": "Nonlinear Dynamics 91 (2) (2018) 1001\u20131021 ", "year": 2018}, {"authors": ["Z. Li", "X. Cao", "N. Ding"], "title": "Adaptive fuzzy control for synchronization of nonlinear teleoperators with stochastic time-varying communication delays", "venue": "IEEE Trans. Fuzzy Syst. 19 (4) (2011) 745\u2013757 ", "year": 2011}, {"authors": ["H. Shokri-Ghaleh", "A. Alfi"], "title": "Optimal synchronization of teleoperation systems via cuckoo optimization algorithm", "venue": "Nonlinear Dyn 78 (4) (2014) 2359\u2013 2376 ", "year": 2014}, {"authors": ["C. Hammond", "H. Bergman", "P. Brown"], "title": "Pathological synchronization in Parkinson\u2019s disease: Networks", "venue": "models and treatments, Trends in Neurosciences 30 (7) (2007) 357\u2013364 ", "year": 2007}, {"authors": ["F. Dorfler", "M. Chertkov", "F. Bullo"], "title": "Synchronization in complex oscillator networks and smart grids", "venue": "Proceedings of the National Academy of Sciences 110 (6) (2013) 2005\u20132010 ", "year": 2013}, {"authors": ["D.E. Kirk"], "title": "Optimal control theory: An introduction", "venue": "Courier Corporation, 2012 ", "year": 2012}, {"authors": ["S. Sra", "S. Nowozin", "S.J. Wright"], "title": "Optimization for Machine Learning", "venue": "MIT Press, Cambridge, USA, 2011 ", "year": 2011}, {"authors": ["V. Becerra"], "title": "Optimal control", "venue": "Scholarpedia 3 (1) (2008) 5354 ", "year": 2008}, {"authors": ["J.R. Koza"], "title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection", "venue": "MIT Press, 1992 ", "year": 1992}, {"authors": ["M. Schmidt", "H. Lipson"], "title": "Distilling free-form natural laws from experimental data", "venue": "Science 324 (5923) (2009) 81\u201385 ", "year": 2009}, {"authors": ["E. Vladislavleva", "G. Smits"], "title": "D", "venue": "den Hertog, Order of nonlinearity as a complexity measure for models generated by symbolic regression via Pareto genetic programming, IEEE Trans. Evol. Computat. 13 (2) (2009) 333\u2013349 ", "year": 2009}, {"authors": ["M. Quade", "M. Abel", "K. Shafi", "R.K. Niven", "B.R. Noack"], "title": "Prediction of dynamical systems by symbolic regression", "venue": "Phys. Rev. E 94 (1) ", "year": 2016}, {"authors": ["H. Shokri-Ghaleh", "A. Alfi"], "title": "A comparison between optimization algorithms applied to synchronization of bilateral teleoperation systems against time delay and modeling uncertainties", "venue": "Applied Soft Computing 24 (2014) 447\u2013 456 ", "year": 2014}, {"authors": ["M. Quade", "J. Gout"], "title": "M", "venue": "Abel, Ambrosys/glyph: V0.3.2 ", "year": 2017}, {"authors": ["D.A. Wiley", "S.H. Strogatz", "M. Girvan"], "title": "The size of the sync basin", "venue": "Chaos 16 (1) (2006) 015103 ", "year": 2006}, {"authors": ["E.J. Doedel", "T.F. Fairgrieve", "B. Sandstede", "A.R. Champneys", "Y.A. Kuznetsov", "X. Wang"], "title": "Auto-07p: Continuation and bifurcation software for ordinary differential equations", "venue": "Tech. rep. ", "year": 2007}, {"authors": ["H.H. Goldstine"], "title": "A History of the Calculus of Variations from the 17th through the 19th Century", "venue": "Springer New York, 1980 ", "year": 1980}, {"authors": ["W.H. Press"], "title": "Numerical recipes 3rd edition: The art of scientific computing", "venue": "Cambridge university press, 2007 ", "year": 2007}, {"authors": ["F.L. Lewis", "D.L. Vrabie", "V.L. Syrmos"], "title": "Optimal Control", "venue": "John Wiley & Sons, Inc., 2012 ", "year": 2012}, {"authors": ["M. Athans", "P.L. Falb"], "title": "Optimal Control: An Introduction to the Theory and Its Applications", "venue": "Dover Publications, 2006 ", "year": 2006}, {"authors": ["K. Ahnert", "M. Abel"], "title": "Numerical differentiation of experimental data: local versus global methods", "venue": "Computer Physics Communications 177 (10) (2007) 764 \u2013 774 ", "year": 2007}, {"authors": ["G.F. Franklin", "J.D. Powell", "A. Emami-Naeini"], "title": "Feedback Control of Dynamic Systems", "venue": "7th Edition, Pearson, 2014 ", "year": 2014}, {"authors": ["H.U. Voss", "P. Kolodner", "M. Abel", "J. Kurths"], "title": "Amplitude equations from spatiotemporal binary-fluid convection data", "venue": "Phys. Rev. Lett. 83 (1999) 3422\u20133425 ", "year": 1999}, {"authors": ["H. Voss", "M.J. B\u00fcnner", "M. Abel"], "title": "Identification of continuous", "venue": "spatiotemporal systems, Phys. Rev. E 57 (1998) 2820\u20132823 ", "year": 1998}, {"authors": ["N.L. Cramer"], "title": "A representation for the adaptive generation of simple sequential programs", "venue": "in: J. J. Grefenstette (Ed.), Proceedings of an International Conference on Genetic Algorithms and the Applications, Psychology Press, 1985, pp. 183\u2013187 ", "year": 1985}, {"authors": ["X.-S. Yang"], "title": "Metaheuristic optimization", "venue": "Scholarpedia 6 (8) (2011) 11472 ", "year": 2011}, {"authors": ["Y. Kuramoto"], "title": "Lecture notes in physics", "venue": "in: H. Araki (Ed.), International Symposium on Mathematical Problems in Theoretical Physics, Vol. 39, Springer, 1975, p. 420 ", "year": 1975}, {"authors": ["Y. Kuramoto"], "title": "Chemical Oscillations", "venue": "Waves, and Turbulence, Springer Berlin Heidelberg, 1984 ", "year": 1984}, {"authors": ["L. Cohen"], "title": "Time Frequency Analysis: Theory and Applications", "venue": "1st Edition, Prentice Hall, 1994 ", "year": 1994}, {"authors": ["S.H. Strogatz"], "title": "Nonlinear Dynamics And Chaos", "venue": "2nd Edition, Westview Press, 2015 ", "year": 2015}, {"authors": ["M. Matsumoto", "T. Nishimura"], "title": "Mersenne twister: A 623-dimensionally equidistributed uniform pseudo-random number generator", "venue": "ACM Trans. Model. Comput. Simul. 8 (1) (1998) 3\u201330 ", "year": 1998}], "sections": [{"text": "Recently, the term explainable AI became known as an approach to produce models from artificial intelligence which allow interpretation. Since a long time, there are models of symbolic regression in use that are perfectly explainable and mathematically tractable: in this contribution we demonstrate how to use symbolic regression methods to infer the optimal control of a dynamical system given one or several optimization criteria, or cost functions. In previous publications, network control was achieved by automatized machine learning control using genetic programming. Here, we focus on the subsequent analysis of the analytical expressions which result from the machine learning. In particular, we use AUTO to analyze the stability properties of the controlled oscillator system which served as our model. As a result, we show that there is a considerable advantage of explainable models over less accessible neural networks.\nKeywords: Explainable AI, Machine Learning Control, Dynamical systems, Synchronization Control, Genetic programming"}, {"heading": "1. Introduction", "text": "Machine learning and artificial intelligence have recently rediscovered socalled explainable methods [1]. Whereas this sounds appealing, researchers\n\u2217Corresponding author Email address: markus.abel@ambrosys.de (Markus Abel)\nPreprint submitted to Physica D January 29, 2020\nar X\niv :2\n00 1.\n10 05\n6v 1\n[ cs\nagree that explainability and interpretability is neither a new concept nor new in artificial intelligence or machine learning. The wish for it arose in recent years with the understanding that the very successful methods of deep learning with neural networks are not directly interpretable. On the other hand, symbolic regression methods are not so new but very explainable, in particular genetic programming methods are extremely general, but their convergence and solutions are not as performant as are neural network methods. Generalized regression methods, on the other hand are very performant, but not so flexible. Here, we demonstrate the power such models reveal by extending a previous analysis of network machine learning control by a subsequent stability analysis.\nAs an example for the control of dynamical systems in physics [2, 3] or medicine [4, 5] we chose the control of synchronization. Synchronization is a widespread phenomenon observed in many natural and engineered complex systems whereby locally interacting components of a complex system tend to coordinate and exhibit collective behavior [6, 7]. In [8] synchronization in networks is investigated by multiple weakly coupled independent oscillating systems; the control then influences the overall dynamics of the system. The role control is to drive the system into or out of synchronization by applying an external control signal [6] that in turn depends on the state itself. The realization of this technique resembles reinforcement learning and differences and similarities are discussed elsewhere. There are significant implications for numerous domains in engineering and science, including communications [9], teleoperations [10, 11] and brain modeling [12]. The special topic, especially phase oscillators, is reviewed in [13]. Depending on the system, control may be those based on control theory [14], mathematical and numerical optimization [15] and computational intelligence [16] techniques. The \u201coptimal control\u201d methods [17] aim at driving and maintaining a dynamical system in a desired state. This is typically achieved by finding a control law, in the form of a set of differential equations, which optimizes (by maximizing or minimizing) a cost function related to the control task. If the control is useful is decided heavily by the stability of the controlled system.\nThis stability can be determined by standard mathematical methods for linear theory can be used [18, 19]. However, for nonlinear, extended and consequently complex systems, linear theory to determine a control may fail. In such cases, the more general methods used here can be of use, where analytical expressions are determined in a deterministic or evolutionary way. I.e. control laws are inferred from an arbitrary domainusing evolutionary machine learning methods as a suitable source of algorithms. Specifically, we refer to genetic programming (GP) [20] to control synchronization in coupled networks, including a hierarchical network of coupled oscillators. Unlike neural networks and other black-box artificial intelligence methods, GP allows dynamically learning complex control laws in an interpretable symbolic form \u2014 a method that is referred as symbolic regression [21, 22, 23]. In particular, we focus on the subsequent rigorous analysis of the optimal laws found. In contrast to previous works a full expression is optimized, and not only parameters [11, 24].\nBased on the previous results, we demonstrate the effectiveness of the con-\ntrol and rigorous analysis exemplary by the analysis of control solutions for two oscillators found by symbolic regression to synchronize or de-synchronize the oscillators. Further application to the control of entire networks is straightforward and is to be included in the future in the fully automatized software framework Glyph [25]. The motivation is not only motivated by brain disorder problems in the medical domain like body tremors occur when firing neurons synchronize in regions of brain [4], but may find broad application in any control setup, e.g. in machinery [26]. In the case of brain states, if the firing of neurons is periodic, which may appear due to the inherent dynamics of the excitable neurons, a mutual influence may give rise to synchronization [6, 27]. If the coupling term is very large, this synchronization may extend over a whole region in our brain and thus over many neurons. Eventually this collective firing leads to shaky movements of hands, arms or the head, and is treated as a brain disorder. One remedy to this problem is to implant a control device which resets the neurons and counteracts the collective synchronization. An evident question then is how to design such a controller which also minimizes design cost, energy consumption, or other medical constraints but is as stable and reliable as possible. We analyze the found control technically by the well-known package AUTO [28].\nTo the best of our knowledge, this is the is first demonstration of machine learning control followed by automatized stability analysis. The extension and generalization is straightforward subject of an extension of existing software. GP is used to learn a control that brings a network of self-sustained oscillators in a desired, synchronized or de-synchronized state and back. In Sec. 3, the results of our study of GP application to networked dynamic systems is presented with focus on the stability analysis.\nThis publication is structured as follows: in Sec. 2 we recall the methods used and previous insights, in Sec. 3 we reiterate results for machine learning control and discuss in great detail the stability analysis and thereby robustness of control for an exemplary control term, the publication ends with a discussion and conclusion in Sec. 4. In the appendix we provide details on the parameters used for system integration and GP setup."}, {"heading": "2. Methods", "text": "In this section, we briefly recall the concept of MLC (machine learning control) and the method used here to solve the problem.To control a dynamical system, one determines a manipulation of the trajectory of the system in phase space to drive it to and keep it in a desired state. This control problem is typically formulated as an optimization problem with an objective function that is to be minimized. In the control setup, this objective is formulated as the deviation of the state of the system from its desired one. Consequently, an optimal control problem is formulated as a mathematical model of the system, a cost function or performance index, a specification of boundary conditions on states, and additional constraints. According to the type of problem, it is classified roughly according to Fig. 1"}, {"heading": "2.1. Machine Learning Control", "text": "Here, we focus on continuous-time optimal control. If there are no constraints on the states or the control variables, and if the initial and final conditions are fixed, it reads: Find the control vector ~u : Rnx \u00d7 [ts, tf ] 7\u2192 Rnu that minimizes the cost function\n\u0393 = \u03d5(~x(tf )) + \u222b tf ts L(~x(t), ~u(~x, t), t)dt, (1)\nsubject to\n~\u0307x = ~\u0303 f(~x, ~u, t), ~x(ts) = ~xs, (2)\nwhere [ts, tf ] is the time interval of interest; ~x:[ts, tf ] 7\u2192 Rnx is the state vector; \u03d5 : Rnx 7\u2192 R is a terminal cost function; L:Rnx\u00d7Rnu\u00d7R 7\u2192 R is an intermediate cost function; and ~\u0303 f : Rnx \u00d7Rnu \u00d7R 7\u2192 Rnx is a vector field. Eq. (2) represents the dynamics of the system and its initial state. This problem definition is known as the Bolza problem; which for \u03d5(x(tf )) = 0 and ~u = ~\u0307x(t) it is known as the Lagrange problem [29]. The cost function (or performance index) \u0393 is a functional, which assigns a real value to each control function ~u.\nOften, the solution to a control problems cannot be found by analytical means. Then, computational methods are used to solve such problems. Depending on the types of cost functions, time domain, and constraints in Eqs. (1)-(2) different methods may be applied, cf. Fig. 1. The direct methods use a discretization of the control problem and solve it using nonlinear programming approaches. Other methods involve the discretization of the differential equations by defining a grid of N points covering the time interval [ts, tf ], ts = t1 < t2 < . . . < tN = tf , and solving these equations using suitable numerical methods [30]. Thereby, the differential equations become equality constraints of the nonlinear programming problem. Other direct methods involve the approximation of control and states using basis functions, such as splines or Lagrange polynomials.\nDynamic programming is an alternative to the variational approach to optimal control. It was proposed by Bellman in the 1950s and is an extension of Hamilton\u2013Jacobi theory. A number of books exist on these topics including\n[31, 18, 32]. A general overview of the optimal control methods for dynamical systems can be found in [17]. For further details, see [33].\nOur approach to solve a control problem uses machine learning to determine the optimal control. Therefore, we adopt the continuous-time formulation given in Eqs. (1) and (2). For multi-objective optimization, the reader is referred to [8]. In real-worl problems, often the derivatives are not given and one has to reconstruct them; then it is particularly important to respect the accuracy of measured data as described in [34]. For the particular control scheme considered here, ~\u0303 f and ~u are slightly reformulated, as will be described next.\nSimilar to reinforcement learning, a feedback control scheme [35] is used here to implement the control. In Fig. 2 the architecture is depicted. To follow this scheme, we rewrite Eq. (2):\n~\u0307x = ~f(~x, t) + ~a, ~x(ts) = ~xs,\nsuch that the uncontrolled system ~\u0307x = ~f(~x, t) is controlled by an additive actuator term ~a, and the control function ~u depends on sensor measurements ~s \u2208 Rns :\n~a = ~u(~s, t).\nThese measurements might be nonlinear functions of the state ~x. For simplicity, external perturbations to the dynamic system are not considered here."}, {"heading": "2.2. Genetic Programming", "text": "To obtain a solution for the control, we use the fairly general genetic programming (GP). This choice is motivated by its generality: in contrast to, e.g., generalized linear regression, no additive structure is needed as used already 20\nyears ago in [36, 37]. GP [20, 38] is an evolutionary algorithm for global optimization. Similar to a genetic algorithm (GA), GP uses the natural selection metaphor to evolve a set of solutions using a cost-based selection mechanism. Often the bio-inspired terms population and individual are used correspondingly. The evolution occurs over a number of iterations (generations). GP differs from GA mainly in the representation of a solution: In GP, it is generally represented using lists or expression trees. Expression trees are constructed from the elements of two predefined primitive sets: a function set consisting of mathematical operators and functions, such as {+, -, *, cos, sin}, and a terminal set consisting of variables and constants, such as { x, y, b}. Function symbols represent the internal nodes of a tree; and terminal symbols are used in the leaf nodes. For example, 3 shows the tree representation for the expression b \u00b7x+ cos(y). All elements of the tree are drawn from the aforementioned primitive sets: the variables and constants in the terminal set (x, y, and b) form the leaves of the tree and the mathematical symbols in the functional set (\u00b7, +, and cos) are used in forming the tree\u2019s internal nodes.\nAlgorithm 1 Top level description of a GP algorithm\nprocedure main G0 \u2190 random(\u03bb) evaluate(G0) t\u2190 1 repeat\nOt \u2190 breed(Gt\u22121, \u03bb) evaluate(Ot) Gt \u2190 select(Ot, Gt\u22121, \u00b5) t\u2190 t+ 1 until t > T or Gt = good() end procedure\nThe GP algorithm is described below ( 1): it starts with the initial generation of a population of random solutions G0. A random solution is generated with a set maximum tree depth by choosing randomly operators, functions and\nvariables. Each solution is then evaluated using the cost function that belongs to the problem. This cost is assigned to each solution, typically how closely a solution predicted the target function output. A new population of solutions Ot is then generated by: (i) probabilistic selection of parent solutions from the existing population using a cost-proportional selection mechanism, and (ii) creation of offsprings by recombination (or crossover) and variation (or mutation) operators (see 4). This procedure is repeated until the cost is reasonably low (the exact definition of low depends on the problem) or a certain preset number of solutions (a fixed population size) is reached. The validity of generated solutions is ensured by a closure property, both for the initialization and breeding operations. Often, convergence is sped-up choosing a reproduction of the best N solutions (elitist approach), then these best solutions are copied to the next-generation population Gt+1. The selection, evaluation and reproduction processes are repeated until one of the above criteria is met. For further details about GP operation, see [39, 40].\nTo solve a general control problem with GP, it is formulated as a learning and optimization task. That is, we learn a control function using GP which drives and keeps a dynamical system in a desired state. The typical choice for the cost function (~\u0393) is the difference between a given state in time and the desired state. This function ~\u0393 can possess complex properties, like nonlinearity, multi-modality, multi-variability and discontinuity. Many traditional direct and gradient methods can not handle such properties, however, metaheuristic methods, such as GP, are suitable candidates for this task. In Fig. 5 a GP-based dynamic controller within a feedback control loop is sketched, shown in 2.\nThe treatment of multiobjectivity and constant optimization is explained in [8] and will not be touched here. Rather we focus on the analysis of the analytical expressions resulting from our control optimization. To reproduce the results shown below, we have given the concrete setup for GP used here in the appendix 5."}, {"heading": "3. Results", "text": "In this section, we explain the concrete application we use to illustrate the power of our explainable GP: in a previous publication, GP-based control has been used for the control of networks of oscillators [8]. Such networks are used to model highly nonlinear complex systems, including the human brain. For our purposes, we systematically investigate the results of our method starting using two coupled oscillators. The extension to many oscillators is straightforward and subject of ongoing implementation activities to include a stability analysis automatically into Glyph [41].\nThe aim, of our consideration is to control the synchronization behavior of the coupled oscillators. This can be done in two ways: starting from a synchronization regime and forcing the system into de-synchronization or vice versa, i.e., starting from a de-synchronized regime and forcing the system into synchronization. Both control goals are evaluated in [8]. Here, we focus on synchronization control, since we mainly want to demonstrate the power of symbolic regression methods as explainable, rigorously treatable models and control terms, respectively.\nLet us first and briefly discuss synchronization again. The synchronization of dynamical systems is well-known exhibited by a huge variety of oscillators and\noscillatory media [6]. Here, we use a popular model, the van der Pol oscillator, also used as a simple model for neurons:\nx\u0308 = \u2212\u03c92x+ \u03b1x\u0307 ( 1\u2212 \u03b2x2 ) =: fvdP(x, x\u0307), (3)\nwhere x is the state and \u03c9, \u03b1, \u03b2 > 0 are model parameters. The parameter \u03c9 is the frequency at which the system oscillates without any driving or damping force. The parameter \u03b1 controls the non-linearity of the system: if \u03b1 = 0, Eq. (3) is a harmonic oscillator equation. The damping parameter \u03b2 controls the nonlinear deformation of the trajectory in phase space. See Fig. 6. In our setup, we reproduce the results of [8] and use linear coupling. An uncontrolled system of N coupled van der Pol oscillators can be stated as follows:\nx\u0308i = fvdP(xi, x\u0307i) + c1 N\u22121\u2211 j=0 \u03baijxj + c2 N\u22121\u2211 j=0 \u03b5ij x\u0307j (i = 0, . . . , N \u2212 1) (4)\nwith initial conditions\nxi(t0) = xi,0, x\u0307i(t0) = x\u0307i,0,\nwhere c1,2 are the global coupling constants and (\u03baij) and (\u03b5ij) are the respective coupling matrices. This allows for several types of coupling such as direct, diffusive, and global coupling, or any other kind of network-like coupling. In the following experiments, we will use diffusive coupling in x\u0307i. For GP, we use the same setup described above (Sec. 5)."}, {"heading": "3.1. Two Coupled Oscillators", "text": "For our further investigations we use the simplest system showing synchronization: two diffusively coupled van der Pol oscillators:\nx\u03080 = fvdP(x0, x\u03070) + c (x\u03071 \u2212 x\u03070) , x\u03081 = fvdP(x1, x\u03071) + c (x\u03070 \u2212 x\u03071) .\n(5)\nThe coupling is restricted to x\u0307i, in which case the coupling constants from (4) are set to c1 = 0, c2 = c, and the remaining coupling matrix reads (\u03b5ij) =[ \u22121 1 1 \u22121 ] . In the case of zero coupling, c = 0, some parameter combinations (\u03b1, \u03b2) allow stable limit cycles with characteristic frequencies \u03c90,1. If the coupling constant c 6= 0, a range of frequencies with \u03c90 6= \u03c91 exists, where both oscillators oscillate with exactly the same frequency \u2126 in a common mode. This range of frequencies is called the synchronization region. With variation of the coupling constant this region changes in width.\nFor an illustration, we chose quite arbitrary \u03b1 = 0.1, \u03b2 = 1, with \u03c90 = 1.386. The harmonic frequency \u03c91 of the second oscillator is varied in the range [\u03c90 \u2212 0.06, \u03c90 + 0.06]. By the above explanation, one expects a range where both oscillators have a common, observed frequency \u21260 = \u21261 = \u2126, such that \u2206\u2126 = \u21261 \u2212\u21260 = 0, and a range with \u2206\u2126 6= 0. This frequency \u2126 is determined numerically by Fourier transform.\nFor a visualization, \u2206\u2126, is plotted against the difference in their characteristic frequencies, \u2206\u03c9 := \u03c91 \u2212 \u03c90, cf. Fig. 7. Regions of synchronization show up as horizontal segments at \u2206\u2126 = 0 (also, note the symmetry about \u2206\u03c9 = 0). If we do this for several values c in the range [0, 0.4] we can trace out the regions of synchronization: The result is a typical V-shaped plateau, the Arnold tongue. Reading off suitable parameters from Fig. Fig. 7 allows to choose appropriate parameters \u03c91 and c to setup the system for control, such that, in its uncontrolled state, it follows either the synchronization regime or the de-synchronization regime. This same approach is taken for all the experiments presented in this section, but will not be explicitly stated beyond this point. We show results only for a control of the state into synchronization, the desynchronization way works very similar, however the tracing of the stability of the solution becomes more tedious, because the solution is generically quasiperiodic and no longer periodic (if the two frequencies \u03c90, \u03c91 are incommensurate).\nLet us add the control function, u, to the equations (5) of the uncontrolled system:\nx\u03080 = fvdP(x0, x\u03070) + c (x\u03071 \u2212 x\u03070) + u(~\u0307x), x\u03081 = fvdP(x1, x\u03071) + c (x\u03070 \u2212 x\u03071) + u(~\u0307x).\n(6)\nThe actuation u may depend on x\u03070 and x\u03071, summarized in vector notation as ~\u0307x = (x\u03070, x\u03071); it is added as a global actuator term with equal influence on both oscillators, this role may be changed into more complex scenarios."}, {"heading": "3.1.1. Forced Synchronization", "text": "The system setup for forced synchronization of the two coupled van der Pol oscillators is presented in the appendix, Tab.Tab. 4. The parameters \u03c91 and c are chosen according to Fig. 7, such that the uncontrolled system follows a de-synchronization regime at a distance, \u2206\u03c9, approximately half the plateau from the closest synchronization point. The initial conditions are the same for both oscillators.\nThe degree of de-synchronization is encompassed by the cost functional\n\u03931 := |\u21260 \u2212 \u21261|. (7)\nIt measures the difference in observed frequencies exhibited by the two oscillators: smaller differences reduce the cost on this objective.\nAs stated in the previous section, the actual frequencies, \u21260 and \u21261, are numerically determined by counting zero crossings of the trajectory x \u2212 \u3008x\u3009. This requires a careful choice of the time range [t0, tn] of observation, since the number of periods, NP , fitting into this interval determines an upper bound in absolute accuracy (\u223c 12NP ) of measuring \u21260, \u21261. Here, NP = 2000 to yield an absolute accuracy well below 10\u22123 in the frequency range of interest.\nThe top six control laws found are given in Tab. Tab. 1. The algorithm stopped after one generation, providing six simple results optimally satisfying \u03931, the synchronization criterion. At this point we can start already to explain the results. First, one notes that for each term in x0 we find a counterpart in x1. This can be explained by the symmetry in Eqs. (6). But why, then, are the control terms not symmetric themselves, in the frequencies? This is at first\nsight not logical, however, if we check our cost functional, we recognize that we only enforce synchronization, and not symmetry of the solution. In particular, we note that the amplitude of one oscillator might vanish while the other one is controlling it. That way, the result makes sense. A deep learning result would not allow immediately such a simple and clear insight. To demonstrate the\ncontrol effect Fig. 8 shows the Kuramoto order parameter, r, for the particular solution u(~\u0307x) = \u2212x\u03070. The parameter represents phase-coherence over time [42, 43] and is defined as\nr = \u2223\u2223\u2223\u2223\u2223\u2223 1N N\u22121\u2211 j=0 ei\u03d5j \u2223\u2223\u2223\u2223\u2223\u2223 , with \u03d5j being the continuous phase of the j-th oscillator. This continuous phase is computed from the analytic signal of the trajectory using the Hilbert transform, cf. [44]. The plot shows, that the controlled system completely synchronizes (r \u2248 const.) after passing through a short initial period of desynchronization; whereas the uncontrolled system exhibits a permanent phase shift resulting in an oscillating graph. Now it is of highest interest to understand how robust the found control law is against perturbation. This is a serious study one has to do. Using explainable MLC we can use the well understood and rigorous mathematical framework of stability analysis. In particular for nonlinear and complex systems that leads us onto safe ground whereas a neural network solution would require more, mor complicated and very expensive studies. Before going into detail with stability in Sec. Sec. 3.1.3 we reiterate results for forced de-synchronization."}, {"heading": "3.1.2. Forced De-Synchronization", "text": "The system setup for forced de-synchronization is given in the appendix in Tab. Tab. 4. The parameters \u03c91 and c are, again, chosen according to Fig. 7. This time, such that the uncontrolled system follows a synchronization regime well inside the plateau. The measure for the degree of synchronization is now reciprocal to the previous case\n\u03931 := exp(\u2212|\u21260 \u2212 \u21261|), (8)\nand penalizes synchronization of the two oscillators. Other GP parameters are the same as for forced synchronization.\nIn Tab. Tab. 2, we show results from the GP run. These results are, again, exact reproductions of [8]. Interestingly, of the 8 solutions found, only the best two are worth being called desynchronized. It indicates that it is much harder to synchronize a desynchronized solution than vice versa. Then, the control term is a long expression in contrast to the ones found for synchronization. As a further fact, constant optimization seems to fail in all cases where a constant is present (this is expressed by a value k = 1, which corresponds to the initial guess of the optimization procedure). Still, the oscillating Kuramoto parameter, r, of the controlled system in Fig. 9 shows, that the best solution with respect to \u03931 performs well in de-synchronizing the oscillators.\nNow let us interpret this solution. A look shows u(~\u0307x) = \u2212x\u03070 \u00b7 exp(exp(k) + cos(k)) = \u2212k\u0303x\u03070, with k\u0303 \u2248 26. This term has the same structure as one of the best solutions found to enforce synchronization, namely the control law u(~\u0307x) = \u2212kx\u03070, with coefficient k = 1. Both are analyzed in more detail in Sec. 3.1.3.\nThe simplification u(~\u0307x) = \u2212x\u03070 \u00b7 exp(exp(k) + cos(k)) to u(~\u0307x) = \u221226 \u00b7 x\u03070, suggests the question, why the GP algorithm did not directly generate this simpler solution. One reason is the stop criterion which prevents solutions to converge further to simplified version. On the other hand, on failure, the least squares algorithm returns the result of the last internal iteration. This return value might be entirely inadequate for k, which, in turn, could lead to an large cost \u03931, and by further integration of the dynamic system (6) the corresponding solution is discarded."}, {"heading": "3.1.3. Control Terms and Bifurcation Analysis", "text": "The objective of this section is to analyze the effect of control exhibited by the particular results u(~\u0307x) = \u2212k \u00b7 x\u03070 found on the synchronization (and desynchronization) of the two oscillators. To study synchronization, we first note that it is adequate to reduce Eqs. 5 by one dimension. This is done by splitting off the fast oscillation and averaging methods [6]. The result is a system of three first order ODEs which can be studied with respect to stability. We use the well-known package [28] to track branches of their solutions. This would not be possible at all for a neural network control due to the complex network structure and high dimension.\nLet us first dwell on the analytical work we can do now. One plugs u(~\u0307x) = \u2212kx\u03070 into the first oscillator equation from (6):\nx\u03080 = \u2212\u03c920x0 + \u03b1x\u03070 ( 1\u2212 \u03b2x20 ) + c (x\u03071 \u2212 x\u03070)\u2212 kx\u03070\n= \u2212\u03c920x0 + (\u03b1\u2212 c\u2212 k)x\u03070 \u2212 \u03b1\u03b2x\u03070x20 + cx\u03071 = \u2212\u03c920x0 + a0x\u03070 \u2212 bx\u03070x20 + c0x\u03071,\n(9)\nwith a0 := \u03b1 \u2212 c \u2212 k, b := \u03b1\u03b2, and c0 := c. For the second oscillator equation\none obtains\nx\u03081 = \u2212\u03c921x1 + \u03b1x\u03071 ( 1\u2212 \u03b2x21 ) + c (x\u03070 \u2212 x\u03071)\u2212 kx\u03070\n= \u2212\u03c921x1 + (\u03b1\u2212 c)x\u03071 \u2212 \u03b1\u03b2x\u03071x21 + (c\u2212 k)x\u03070 = \u2212\u03c921x1 + a1x\u03071 \u2212 bx\u03071x21 + c1x\u03070,\n(10)\nwhere a1 := \u03b1\u2212 c and c1 := c\u2212 k. This way, one obtains another system of two coupled van der Pol oscillators, however, with direct coupling in place.\nAs indicated, this system can be analyzed in the framework of synchronization theory which uses the method of averaging [6] under the assumption that the system is weakly nonlinear. We repeat the calculations here for our system. In essence, the second-order equations are rewritten as two first-order equations x\u0307j = y, y\u0307j = r.h.s. (j = 0, 1), where r.h.s. denotes the right hand side of (9) and (10) respectively. Next, the transformation\nxj = 1\n2 (Aje\ni\u03c9t +A\u2217je \u2212i\u03c9t), (11)\nyj = 1\n2 (i\u03c9Aje\ni\u03c9t \u2212 i\u03c9A\u2217je\u2212i\u03c9t), (12)\nis applied, where j = 0, 1, and Aj(t) = Rj(t)e i\u0398j(t) is the time-dependent complex amplitude. This ansatz yields differential equations for the real amplitude R and the phase \u0398, which are both slowly varying. They result from the collection of terms with vanishing fast oscillation.\nWhen one writes the equations (9) and (10) as\ny\u03070 = \u2212\u03c920x0 + a0y0 \u2212 by0x20 + c0y1, (13) y\u03071 = \u2212\u03c921x1 + a1y1 \u2212 by1x21 + c1y0, (14)\nwith the corresponding approximations (first order nonlinearities, slow dynamics) one arrives at new equations for A\nA\u03070 = \u2212i\u22060A0 + a0 2 A0 \u2212 b 8 |A0|2A0 + c0A1, (15) A\u03071 = \u2212i\u22061A1 + a1 2 A1 \u2212 b 8 |A1|2A1 + c1A0, (16)\nwith \u2206j = \u03c9j \u2212 \u03c9 (j = 0, 1). For the real phases and amplitudes of A(t) one then obtains a system of four real equations\nR\u03070 = a0 2 R0 \u2212 b 8 |R0|2R0 + c0R1 cos(\u03981 \u2212\u03980), R\u03071 = a1 2 R1 \u2212 b 8 |R1|2R1 + c1R0 cos(\u03980 \u2212\u03981), \u0398\u03070 = \u2212\u22060 + c0 R1 R0 sin(\u03981 \u2212\u03980), \u0398\u03071 = \u2212\u22061 + c1 R0 R1 sin(\u03980 \u2212\u03981).\n(17)\nFor the phase difference \u03981 \u2212\u03980 an asymmetric so-called Adler-type equation results, which may or may not show synchronization for the given parameters:\n\u2206\u0398\u0307 = \u2212\u2206\u03c9 \u2212 (c0 R1 R0 + c1 R0 R1 ) sin(\u03981 \u2212\u03980). (18)\nwith \u2206\u03c9 := \u03c91\u2212\u03c90. If the stationary state for the phase difference \u2206\u0398\u0307 = 0 has a solution, one can find synchronization, else not. A special solution where also the amplitudes are stationary (R\u03070 = R\u03071 = 0) has to be determined numerically.\nThus, the full coupled system for stationary solutions of (17) reads:\n0 = a0 2 R0 \u2212 b 8 |R0|2R0 + c0R1 cos(\u2206\u0398), 0 = a1 2 R1 \u2212 b 8 |R1|2R1 + c1R0 cos(\u2206\u0398), 0 = \u2212\u2206\u03c9 + (c0 R1 R0 \u2212 c1 R0 R1 ) sin(\u2206\u0398),\n(19)\nwith parameters a0 = \u03b1 \u2212 c \u2212 k, a1 = \u03b1 \u2212 c, b0 = \u03b1 \u00b7 \u03b2, b1 = \u03b1 \u00b7 \u03b2, c0 = c, c1 = c\u2212 k and \u2206\u0398 = \u03980 \u2212\u03981.\nFirst one can observe, that the term kx\u0307i (i = 0, 1) introduces an asymmetry in the equations (17), such that one or the other oscillator might be \u201cfavored\u201d by the dynamics, since it may have a different damping depending on the parameter settings. In an uncoupled system (c = 0) this is of course relevant if one needs to study a real application. For a better understanding of the implications of the control term kx\u03071 we note that in the uncoupled case, the first equation of (19) reduces to\n0 = a\n2 R0 \u2212\nb 8 |R0|2R0, (20)\nwith rescaled parameters a = \u03b1 \u2212 k, b = \u03b1 \u00b7 \u03b2. This is the normal form of a pitchfork bifurcation. In the original, non-averaged system, this corresponds to a Hopf-bifurcation because the full system shows oscillations.\nTo this end, we use the path-following and bifurcation analysis package AUTO-07p [28]. In the scope of this work, this analysis has been done manually, it is however straightforward to extend the MLC software to do this in an automated fashion for any control term found.\nThe paths of stationary solutions, as observed in the following, are interpreted by comparing to the standard textbook examples, as can be found in e.g. [45]. First, we consider the uncoupled case (c = 0) for varying k. Next, solutions for R0, R1,\u2206\u0398 are tracked against varying k, or c, respectively, for several values of c, or k, respectively, cf.Fig. Fig. 12 and Fig. Fig. 11, respectively. Finally, contour lines for fixed component values of the stationary solution to (19) are shown demonstrating that a wide variety of choices of particular synchronization details is possible by tuning the k and c parameters to the right values (Fig. 13).\nThe uncoupled case (c = 0). of (19) is shown in Fig. 10 Since the radius equations are cubic, one obtains three solutions until the damping (introduced by k) becomes stronger than energy input and no nontrivial solution is possible. The control term introduces a coupling \u201cthrough the backdoor\u201d into the second equation of the system via the term c1R0 cos(\u2206\u0398). So, when varying k, the bifurcation diagram of R0 shows a plain pitchfork bifurcation, the one for R1 shows a distorted version of the pitchfork bifurcation due to this quasi-coupling.\nThe coupled case (c 6= 0). is visualized for varying parameter c in Fig. 11 and for varying k in Fig. 12. Note that even in the case of vanishing control k and non-zero coupling c, there is an asymmetry between R0 and R1 that is mediated by the third equation when \u2206\u03c9 6= 0. In Fig. 11, one can see a transition from the uncontrolled system to the controlled, pushing the right bifurcation point to higher values of c with increasing coupling k. At the same time, stationary solutions for the low end of c cease to exist somewhere between k = 0.04 and k = 0.06. The exact mechanism of this transition is out of the scope of this publication and will done in subsequent work together with a full bifurcation and stability analysis of this system.\nAn understanding comes from the following argument: In a three-dimensional system with cubic terms one can obtain, in principle, more than three solutions. Since we have no additional objective in the GP run, it is clear that the particular choice of k in such a simple control term as kx\u0307i is just a representative of a larger class of control laws. To fix it to a specific value, or to enforce a symmetric situation, one has to add the corresponding terms in the cost function. Since\nthe control term is asymmetric, with increasing k, one changes the bifurcation scenario from perfect to imperfect. This qualitative behavior is found in all graphs shown hereafter.\nThe behavior of R0 and R1 with increasing coupling and fixed control can be also be understood with a close look at Fig. 11. At highest values of c where stationary solutions exist, the values of R0 and R1 are approximately equal. As the coupling strength diminuishes, the two radii take increasingly different values as for low values of c, the coupling is dominated by the asymmetric terms with k. As the control strength k is increased, stationary solutions at higher coupling strenghts exist and this behavior becomes more and more strongly pronounced where high c values dominate the coupling which is thus symmetric.\nHowever, beyond a certain control, k, no synchronization can be found at all \u2013 the sudden stop of the curves is no artifact, but rather a true dynamical effect, this is seen in Fig. 12. The overall behavior is clearly correct as the benchmark graph c = 0 shows that the solution is lost at k = \u03b1. A similar observation holds for Fig. 11, where stationary solutions of (19) cease to exist above some critical value of c.\nThese observations explain also, why the simple control term kx\u0307i can push dynamics from synchronized to de-synchronized: it adds a damping of one oscillator i that desynchronizes the two oscillators. The value can be read off of the figures Fig. 12 for a given coupling strength.\nThe GP-algorithm yields a value of k = 1, clearly this is larger than the critical value of approximately 0.05 (For c = 0.022, see Tab. 5), read off Fig. 12. Now, one may ask why this value is chosen and not another one k > 0.05. The reason is simple, but it is hidden in the problem formulation: The objective\nfunction only requires that synchronization be destroyed. This is possible for many functions and in particular for many simple functions with complexity 2. Among them, the control function kx\u0307 is particularly appealing due to its simplicity. The algorithm is now free to choose any k > 0.05 and so it does. The value 1 is probably appearing because it is the first guess for a constant in the constant-optimization step of the algorithm and because it satisfies the objective.\nThe mathematical analysis also allows fine-tuning the control by varying the control parameter k e.g. when the coupling strength changes and certain characteristics of the solution are to be kept. Such adjustments could for example be read off Fig. 13 where the height lines of certain values of the solutions parameters are tracked in the c\u2212 k plane.\nAs a consequence, one can conclude that a careful formulation of the objective helps in obtaining a unique answer. In the following we will not comment further on these details. They must be considered in any application of the method, though. We demonstrated that the symbolic regression performed by the GP algorithm produces results which are interpretable and tractable with mathematical methods, here within the framework of dynamical systems. This allows the subsequent step of exactly understanding the implications of a particular choice of control and choosing the one that is best suited to the needs of the particular problem at hand. Moreover, once the dynamics with included control have been understood, the method allows tweaks to the control term (like adjusting the value of k) while understanding what will be happening. Neither the analytical interpretation of the control nor the possibility of tweaking the control would not have been possible for a control achieved by a neural network\ndue to its black box nature."}, {"heading": "4. Discussion and Conclusion", "text": "In this work we demonstrate the use of explainable MLC methods -symbolic regression by GP- for rigorous analysis. We found several control laws results with similar score lead to different results with respect to stability analysis. In a general context, this result means that we can automatize analysis of the top models with rigorous mathematical methods, where stability is just one among others. For the big questions, though, like climate change, vehicle optimization (e.g. fuel reduction or predictive, automatized maintenance ), autonomous drive and alike this is of primordial importance.\nWe analyzed explainable MLC using a well-known control problem in dynamical systems: coupled self-sustained oscillators which exhibit synchronized behaviour or desynchronized one, depending on the system parameters. In a previous study, we applied our control approach to dynamical systems composed of networks of coupled oscillators, starting from two coupled van der Pol oscillators up to a hierarchical network consisting of a few hundred oscillators. In this work, we reproduced and used these results for a subsequent stability analysis. Such rigorous analyses are definitely not accessible using black-box or qualitative methods like, e.g., neural networks. The comparatively complex handling of GP in comparison with other symbolic methods like generalized regression is paid off if explainable solutions are needed. Due to the evolutionary nature of the method, it is not guaranteed that the global optimum is found, consequently a subsequent rigorous analysis is of great value.\nAs a result we find terms of different complexity leading to different levels of synchronization control, where synchronization is measured using the Kuramoto parameter. In both cases, synchronization and desynchronisaton, the found control laws are tested for stability. In Section 3.1.3, we demonstrate the potential of the methods by following the solutions numerically. We do not even touch a detailed analysis of eigenvalues and Lyapunov exponents which play a very important role in the dynamics of dynamical systems in general.\nCurrent efforts go to an automatization of this analysis following an explainable method, as well the fast sparse methods of generalized regression. To this end we plan to extend our existing framework Glyph. Using this kind of analysis will extend the range of explainable MLC to result in robust and interpretable control laws, a fact which is a unique selling point for explainable MLC. Clearly, this can end in a round trip where better objective functions are designed, taking into consideration the rigorous analysis and possibly prior domain knowledge, e.g. in the form of additive symmetry terms. In conclusion, we state that in terms of mathematical rigor, versatility and adaptability, the crystal-box method of GP is superior to other rather black-box methods, as artificial neural networks or support vector machines."}, {"heading": "Acknowledgements", "text": "We thank A. Pikovsky for synchronization wisdom, M. Rosenblum for providing input with respect to an application to human brain dynamics."}, {"heading": "5. Appendix", "text": "In this section, we give a brief summary of the implementation details and the parameters used in our setup. Hyperparameters have been chosen empirically such that they lead to plausible and interpretable results on the chosen set of examples. We did not optimize the hyperparameters for convergence.\nOur software is based on Glyph, a package developed by ourselves [41], which in turn uses other, standard python packages, e.g., constant optimization is conducted using the Levenberg-Marquardt least squares algorithm (scipy) and numerical integration using the dopri5 solver (also scipy). Random numbers are generated using the Mersenne Twister pseudo-random number generator provided by the random module [46]. Finally, the sympy module is used for\nthe simplification of symbolic mathematical expressions generated from the GP runs [47], for more details see [41].\nTab. 3 gives an overview of the methods and parameters used for the GP runs. Actual implementations can be found under the same name in the deap module.\nThe following tables 4 and 5 list the setup used for two coupled oscillators forced to to synchronization and de-synchronization, respectively."}], "title": "Explainable Machine Learning Control - robust control and stability analysis", "year": 2020}