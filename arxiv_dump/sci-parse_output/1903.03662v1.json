{"abstractText": "The do-calculus is a well-known deductive system for deriving connections between interventional and observed distributions, and has been proven complete for a number of important identifiability problems in causal inference [1, 8, 18]. Nevertheless, as it is currently defined, the docalculus is inapplicable to causal problems that involve complex nested counterfactuals which cannot be expressed in terms of the \u201cdo\u201d operator. Such problems include analyses of pathspecific effects and dynamic treatment regimes. In this paper we present the potential outcome calculus (po-calculus), a natural generalization of do-calculus for arbitrary potential outcomes. We thereby provide a bridge between identification approaches which have their origins in artificial intelligence and statistics, respectively. We use po-calculus to give a complete identification algorithm for conditional path-specific effects with applications to problems in mediation analysis and algorithmic fairness.", "authors": [{"affiliations": [], "name": "Daniel Malinsky"}, {"affiliations": [], "name": "Ilya Shpitser"}, {"affiliations": [], "name": "Thomas Richardson"}], "id": "SP:c7814e86839b9f3b7082c2da53e9f3c85036292b", "references": [{"authors": ["Thomas S. Richardson", "Robin J. Evans", "James M. Robins", "Ilya Shpitser"], "title": "Nested Markov properties for acyclic directed mixed graphs", "year": 2017}, {"authors": ["Thomas S. Richardson", "Jamie M. Robins"], "title": "Single world intervention graphs (SWIGs): A unification of the counterfactual and graphical approaches to causality", "venue": "preprint: http://www.csss.washington.edu/Papers/wp128.pdf,", "year": 2013}, {"authors": ["Ilya Shpitser"], "title": "Counterfactual graphical models for longitudinal mediation analysis with unobserved confounding", "venue": "Cognitive Science (Rumelhart Special Issue),", "year": 2013}, {"authors": ["Ilya Shpitser", "Judea Pearl"], "title": "Identification of conditional interventional distributions", "venue": "In Proceedings of the 22nd Conference on Uncertainty in Artificial Intelligence", "year": 2006}, {"authors": ["Ilya Shpitser", "Judea Pearl"], "title": "Identification of joint interventional distributions in recursive semi-Markovian causal models", "venue": "In Proceedings of the Twenty-First AAAI Conference on Artificial Intelligence", "year": 2006}, {"authors": ["Ilya Shpitser", "Eli Sherman"], "title": "Identification of personalized effects associated with causal pathways", "venue": "In Proceedings of the 34th Conference on Uncertainty in Artificial Intelligence", "year": 2018}, {"authors": ["Ilya Shpitser", "Eric J. Tchetgen Tchetgen"], "title": "Causal inference with a graphical hierarchy of interventions", "venue": "Annals of Statistics,", "year": 2016}], "sections": [{"text": "ar X\niv :1\n90 3.\n03 66\n2v 1\n[ st\nat .M\nE ]\n8 M\nThe do-calculus is a well-known deductive system for deriving connections between interventional and observed distributions, and has been proven complete for a number of important identifiability problems in causal inference [1, 8, 18]. Nevertheless, as it is currently defined, the docalculus is inapplicable to causal problems that involve complex nested counterfactuals which cannot be expressed in terms of the \u201cdo\u201d operator. Such problems include analyses of pathspecific effects and dynamic treatment regimes. In this paper we present the potential outcome calculus (po-calculus), a natural generalization of do-calculus for arbitrary potential outcomes. We thereby provide a bridge between identification approaches which have their origins in artificial intelligence and statistics, respectively. We use po-calculus to give a complete identification algorithm for conditional path-specific effects with applications to problems in mediation analysis and algorithmic fairness."}, {"heading": "1 Introduction", "text": "Pearl\u2019s do-calculus [6, 7, 8] is an abstract set of rules for reasoning about interventions that has proven to be influential in settings, such as computer science and artificial intelligence, where graphical models are used to represent causal relationships. In statistics and some social/biomedical sciences, the potential outcome framework [4, 15] is more commonly used to express causal assumptions and reason about interventions. Richardson and\nProceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR: Volume 89. Copyright 2019 by the author(s).\nRobins [11] have made an important contribution by unifying causal formalisms grounded in graphical causal models with the potential outcomes framework. In this paper we build on those connections, presenting a calculus for reasoning about interventions in the potential outcomes notation that is equivalent to Pearl\u2019s do-calculus for standard interventions, but allows generalizations to nested causal quantities pertinent to evaluating (e.g.) dynamic treatment regimes or path-specific interventions (for which the \u201cdo\u201d notation is insufficiently expressive). We show how the new calculus can be applied to problems in mediation analysis, specifically the identification of conditional path-specific causal effects. We introduce a procedure which is complete for expressing such quantities as functions of the observed data distribution, i.e., an algorithm which will produce an identifying expression for a conditional path-specific effect if and only if the effect is identifiable.\nConditional path-specific effects are quantified via conditional distributions over potential outcomes, where treatment variables are assigned to possibly distinct values for different causal pathways. In mediation analysis, functions of such distributions are used to isolate the effect of a drug, therapy, or other treatment assignment along a specific pathway in a specific subpopulation, defined by pre-treatment variables (such as age or gender) or posttreatment variables (such as adverse reactions to the treatment). Importantly, there are settings where the marginal path-specific effect is identified but the conditional pathspecific effect is not identified; we later discuss one simple example shown in Fig. 1.\nAnother context in which conditional path-specific effects may be of interest is in the study of algorithmic fairness. Recent papers [2, 3, 21] have proposed to combat disparities perpetuated by some automated decision-making systems by identifying, estimating, and constraining unfair causal influences that propagate along certain pathways, e.g., the direct effect of gender on hiring outcomes or the indirect effect of race on criminal justice outcomes via geographical factors. It may also be desirable to constrain such\npath-specific effects for certain subpopulations, which requires identifying conditional path-specific effects.\nWe begin by introducing potential outcomes, causal models, graphs, and some relevant results. Then we review the do-calculus, propose our potential outcome calculus, demonstrate they are equivalent, and give some simple derivations to establish the soundness of the rules in the language of potential outcomes. Finally, we introduce a formalism for expressing path-specific effects (PSEs) and a complete identification procedure for conditional PSEs."}, {"heading": "2 Potential Outcomes, the Do Operator and Causal Models", "text": "Fix a set of indices K \u2261 {1, . . . , k} under a total ordering \u227a. For each random variable Vi, i \u2208 K , define a state space Xi, and the sets Prei \u2261 {1, . . . , i \u2212 1}. Given A \u2286 K , we will denote subsets of random variables indexed by A with VA and elements vA of XA by a (lowercase letters).\nWe assume the existence of all one-step-ahead potential outcome random variables (a.k.a. counterfactuals) of the form Vi(pai) \u2261 Vi(vPai), where Pai is a fixed subset of Prei, and pai \u2261 vPai is any element in XPai . The variable Vi(pai) denotes the value of Vi had the set of direct causes of Vi, or VPai , been set, possibly contrary to fact, to values pai. The existence of a total ordering\u227a on indices, and the fact that Pai \u2286 Prei precludes the existence of cyclic causation. (That is, we consider causal models that are recursive.) Vi(pai) may be conceptualized as the output of a structural equation fi : XPai \u222a{\u01ebi} 7\u2192 Xi, a function representing a causal mechanism that maps values of Pai, as well as the value of an exogenous disturbance variable \u01ebi, to values of Vi. We define causal models as sets of densities over the set of random variables\nV \u2261 {Vi(pai) | i \u2208 {1, . . . , k}, pai \u2208 XPai}.\nFor simplicity of presentation, we assume Xi is always finite, and thus ignore the measure theoretic complications that arise with defining densities over sets of random variables above in the case where some state spaces on Pai are infinite.1\nGiven a set of one-step-ahead potential outcomesV, for any A \u2286 K and i \u2208 K we define the potential outcome Vi(a), the response of Vi had variables in VA been set to a, by the definition known as recursive substitution:\nVi(a) \u2261 Vi(a \u2229 pai, {Vj(a) | j \u2208 Pai \\A}). (1)\nIn words, this states that Vi(a) is the potential outcome where variables Pai in A are set to their corresponding val-\n1The set of p(V) for a particular set of Pai and an ordering \u227a was called the finest causally interpretable structured tree graph (FCISTG) in [12].\nues in a, and all elements of Pai not in A are set to whatever values their recursively defined counterfactual versions would have had had A been set to a. Equivalently, Vi(a) is the random variable induced by a modified set of structural equations: specifically the set of functions fj for all Vj \u2208 A are replaced by constant functions f \u2217 j that set Vj to the corresponding value in a.\nWe denote by V\u2217 the set of all variables derived by (1) from V, together with V. In addition, for notational conciseness, we will use index sets to denote sets of potential outcomes themselves. That is, for Y \u2286 K , A \u2286 K , we will denote the set {Vi(a) | i \u2208 Y } by Y (a). Note that we allow Y and A to intersect. Thus, we allow sets of potential outcomes of the form A(a), which denote the sets {Vi(a) | i \u2208 A}, where each Vi(a) is defined using (1) above. In particular, if A = {Vi} (a singleton), Vi(vi) is defined in our notation to be the random variable Vi, not the constant vi.\nIn cases where Y and A do not intersect, the distribution p(Y (a)) has been denoted by Pearl as p(Y | do(a)) [8]. This formulation places emphasis on the intervention operator do(a), which replaces structural equations by constants.\nRecursive substitution provides a link between observed variables and potential outcomes. In particular, it implies the consistency property:2 for any disjoint A,B \u2286 K , i \u2208 K \\ (A \u222aB), a \u2208 XA, b \u2208 XB ,\nB(a) = b implies Vi(a, b) = Vi(a). (2)\nProposition 1 (consistency) Given V\u2217 derived from V via (1), then (2) holds.\nProof: By (1), Vi(a) and Vi(a, b) are defined as\nVi(aPai ,{Vj(a)|j\u2208Pai\\(A \u222aB)},{Vj(a)=bj |j\u2208B\u2229Pai})\nand Vi(aPai ,{Vj(a, b)|j\u2208Pai\\(A \u222aB)},bPai),\nrespectively. The conclusion follows immediately.\n(1) implies that every Vi(a) is can be written as a function of a unique minimally causally relevant subset of a.\nProposition 2 (causal irrelevance) Given V\u2217 derived from V via (1), let Vi(a) \u2208 V \u2217, and let A\u2217 be the maximal subset of A such that for every Aj \u2208 A \u2217, there exists a sequence Vw1 , . . . , Vwm that does not intersect A, where Aj \u2208 Paw1 , Vwi \u2208 Pawi+1 , for i = 1, . . .m \u2212 1, and Vwm \u2208 Pai. Then Vi(a) = Vi(a \u2217).\nProof: Follows by definition of A\u2217 and (1).\n2Some readers may be more familiar with the simpler formulation where a = \u2205, so \u201cB = b implies Vi(b) = Vi.\u201d Our reasons for allowing multiple intervention sets will become clear in what follows.\nA functional causal model (a.k.a. a non-parametric structural equation model with independent errors, NPSEM-IE) asserts that the sets of variables\n{{Vi(pai) | pai \u2208 XPai} | i \u2208 {1, . . . , k}} (3)\nare mutually independent. Phrased in terms of structural equations, the functional causal model states that the joint distribution of the disturbance terms factorizes into a product of marginals: p(\u01eb1, . . . , \u01ebk) = \u220fk i=1 p(\u01ebi).\nAlternative causal models, which make fewer assumptions than the functional model but are sufficient for all inferences we aim to make in this paper, are discussed in [11, 20]. We focus on the functional causal model here, since it is simpler to describe and the original setting of Pearl\u2019s do-calculus. We discuss how our results apply to a weaker causal model [11] in the Supplement."}, {"heading": "3 Graphical Models", "text": "Much conceptual clarity may be gained by viewing causal models as graphs. We will consider graphs with either directed edges only (\u2192), or mixed graphs with both directed and bidirected (\u2194) edges. Vertices correspond to random variables, and we simplify notation by using Vi to refer to both the graph vertex and corresponding random variable. In all cases we will require the absence of directed cycles, meaning that whenever the graph contains a path of the form Vi \u2192 \u00b7 \u00b7 \u00b7 \u2192 Vj , the edge Vj \u2192 Vi cannot exist. Directed graphs with this property are called directed acyclic graphs (DAGs), and mixed graphs with this property are called acyclic directed mixed graphs (ADMGs). We will refer to graphs by G(V ), where V is the set of random variables indexed by {1, . . . , k}. We will use the following standard definitions for sets of vertices in a graph:\nPaGi \u2261 {Vj | Vj \u2192 Vi in G} (parents of Vi) AnGi \u2261 {Vj | Vj \u2192 \u00b7 \u00b7 \u00b7 \u2192 Vi in G} (ancestors of Vi) DeGi \u2261 {Vj | Vj \u2190 \u00b7 \u00b7 \u00b7 \u2190 Vi in G} (descendants of Vi)\nBy convention, we assume Vi \u2208 An G i and Vi \u2208 De G i . We will generally drop the superscript G if the relevant graph is obvious and sometimes write G in place of G(V ) when the\nvertex set is clear. Given a DAG G(V ), a statistical DAG model (a.k.a. a Bayesian network) associated with G(V ) is a set of distributions that are Markov relative to G(V ), i.e., the set of distributions that can be written as the following product of conditional densities:\np(V ) =\nk \u220f\ni=1\np(Vi | Pai). (4)\nGiven p(V ) that is Markov relative to a DAG G(V ), conditional independence relations (written: (Y \u22a5\u22a5 Z | X), where X,Y, Z are disjoint subsets of the index set K) satisfied by p(V ) can be derived using the well-known dseparation criterion [5], which we reproduce in the Supplement. We write (Y \u22a5\u22a5d Z | X)G(V ) when Y is d-separated from Z given X in G(V ). If p(V ) is Markov relative to G(V ), then the following global Markov property holds: for any disjoint X,Y, Z\n(Y \u22a5\u22a5d Z | X)G(V ) \u21d2 (Y \u22a5\u22a5 Z | X) in p(V ).\nFunctional causal models may also be associated with a DAG G by identifying Pai with the graphical parents of Vi in G(V ). Given a functional causal model for DAG G, the joint distribution for any V (a) derived from V using (1) is identified via the following formula:\np(V (a)) = K \u220f\ni=1\np(Vi | Pai \\A, a \u2229 pai), (5)\nprovided ( \u220f\naj\u2208a p(aj | Paj \\A, a \u2229 paj)\n)\n> 0. See [11]\nfor a simple proof. The modified factorization (5) is known as the extended g-formula [11, 13]. Note that (5) has a term for every Vi \u2208 V , just like (4).\nThe formula (5) resembles (4) and in fact may be viewed as a factorization of p(V (a)) with respect to a certain graph derived from G. Such graphs, called Single World Intervention Graphs (SWIGs), were introduced in [11]. SWIGs are graphical representations of potential outcome densities that help unify the graphical and potential outcome formalisms. Given a set A of variables which are assigned to values a, a SWIG G(a) is constructed from G(V ) by splitting all vertices in A into a random half and a fixed half,\nwith the random half inheriting all edges with an incoming arrowhead and the fixed half inheriting all outgoing directed edges. Then, all random vertices Vi are re-labelled as Vi(a) or equivalently (due to Proposition 2) as Vi(a\u2229an \u2217 i ), where an\u2217i consists of values of the ancestors of Vi in the split graph. In [11], unsplit vertices were drawn as circles, and split nodes as half circles, with fixed nodes denoted by a lowercase. Fixed nodes are enclosed by a double line. For an example of a SWIG representing the joint density p(Y (a),M(a), C(a), A(a)) = p(Y (a),M(a), C,A), see Fig. 2 (b). Because of the resemblance of (5) to a DAG factorization, we say that p(V (a)) is Markov relative to a SWIG G(a) if p(V (a)) may be written as (5).\nA SWIG G(a) is a DAG with a vertex set {V (a), a}, and may be viewed as a conditional graph, with vertices in V (a) corresponding to random variables, and vertices in a corresponding to variables fixed to a value. We extend the notion of d-separation to allow fixed vertices. Specifically, we allow d-separation statements of the form (Y (a), a\u2032 \u22a5\u22a5d Z(a) | X(a))G(a), for disjoint random subsets Y (a), Z(a), X(a) of V (a) and a\u2032 a subset of a. Note that a possibly d-connecting path may only contain random nodes as non-endpoint vertices (as in [11] where fixed nodes are always blocked). Our extension here consists only in allowing fixed vertices to also appear as one endpoint in a d-separation statement. Just as (4) implied the global Markov property for a DAG, the modified factorization (5) implies a global Markov property for a SWIG.\nProposition 3 (SWIG global Markov property) If p(V (a)) is Markov relative to G(a), then for any disjoint subsets Y (a), Z(a), X(a) of V (a) and a subset a\u2032 of a, if (Y (a), a\u2032 \u22a5\u22a5d Z(a) | X(a))G(a) then, for some f(\u00b7),\np(Z(a)|Y (a), X(a)) = p(Z(a)|X(a)) = f(Z,X, a \\ a\u2032).\nProof: The first equality is due to Theorem 12 in [11], the second follows from Theorem 19 in [10].\nNote that f(Z,X, a\\a\u2032) is not necessarily equal to p(Z(a\\ a\u2032) | X(a \\ a\u2032)).\nThe SWIG global Markov property implies the following\nintuitive result (proved in the Supplement) relating independence statements in p(V (a)) for various sets A. Specifically, the result is that interventions \u201calways help\u201d when it comes to conditional independence.\nProposition 4 (intervention monotonicity) For any disjoint subsets Y (a), Z(a), X(a) of V (a) and a subset a\u2032 of a, if (Y (a), a\u2032 \u22a5\u22a5 Z(a) | X(a))G(a) then for any A\n\u2032\u2032 \u2287 A, (Y (a\u2032\u2032), a\u2032 \u22a5\u22a5 Z(a\u2032\u2032) | X(a\u2032\u2032))G(a\u2032\u2032).\nGraphical Models With Hidden Variables\nWe also consider causal models where some variables are unmeasured (a.k.a. \u201clatent\u201d or \u201chidden\u201d variables). Given a DAG G(V \u222a H), define a latent projection mixed graph G(V ) as follows. V is the vertex set of G(V ), and for any Vi, Vj \u2208 V there is an edge Vi \u2192 Vj if there exists a directed path from Vi to Vj in G(V \u222aH), with all intermediate nodes on the path in H ; there is an edge Vi \u2194 Vj if there exists a path from Vi to Vj of the form Vi \u2190 \u00b7 \u00b7 \u00b7 \u2192 Vj , where every intermediate node on the path is in H and no consecutive edges on the path are of the form \u2192 Hk \u2190 for Hk \u2208 H . The latent projection G(V ) obtained from a DAG G(V \u222a H) is always an ADMG. Our results in this paper apply to ADMGs, and indeed this is the intended setting for Pearl\u2019s do-calculus (he used the terminology \u201csemiMarkovian models\u201d).\nThe definition of d-separation naturally generalizes to ADMGs with minor modification for bidirected edges; the resulting criterion is called m-separation [9]. We write (Y \u22a5\u22a5m Z | X)G(V ) if Y is m-separated from Z given X in ADMG G(V ). In the following we sometimes drop the d or m subscripts and just write \u22a5\u22a5, where the relevant criterion is implicit.\nGiven an ADMG G(V ), we define a SWIG G(V )(a) by the analogous node splitting construction as for DAGs. Specifically, each node is split into a random half and a fixed half, with random halves inheriting all incoming directed and bidirected edges, and fixed halves inheriting all outgoing directed edges. Alternatively given a SWIG G(a) derived from a DAG G(V \u222a H), we define the latent pro-\njection operation in the natural way, yielding the SWIG G(a)(V ) with random vertices V , fixed vertices a, and directed edges from ai \u2208 a or Vi \u2208 V to Vj \u2208 V if there is a directed path from the corresponding vertices in G(a) with all intermediate vertices in H , and bidirected edges from Vi \u2208 V to Vj \u2208 V if there exists a path from Vi to Vj of the form Vi \u2190 . . . \u2192 Vj , where every intermediate node on the path is in H and no consecutive edges on the path are of the form\u2192 Hk \u2190 for Hk \u2208 H . These operations commute, and we can derive independence statements via m-separation on G(V )(a), as we prove in the Supplement."}, {"heading": "4 Do-Calculus and Potential Outcomes Calculus", "text": "Pearl formulated the do-calculus originally as follows:\n1 : p(y | z, w, do(x)) = p(y | w, do(x))\nif (Y \u22a5\u22a5 Z |W,X)GX 2 : p(y | z, w, do(x)) = p(y | w, do(z), do(x))\nif (Y \u22a5\u22a5 Z |W,X)GX,Z\n3 : p(y | w, do(z), do(x)) = p(y | w, do(x))\nif (Y \u22a5\u22a5 Z |W,X)G X,Z(W )\nwhere GX denotes the graph obtained from G by removing all edges with arrowheads into X , GZ denotes the graph obtained from G by removing all directed edges out of Z , and Z(W ) \u2261 Z \\AnGX (W ).\nHere we present the do-calculus entirely in terms of potential outcomes (the \u201cpotential outcomes calculus\u201d or \u201cpocalculus\u201d for short). The conditions are phrased in terms of conditional independencies implied by SWIGs, e.g., G(x) for the SWIG where X is assigned value x. We restate the rules as follows:\n1 : p(Y (x) | Z(x),W (x)) = p(Y (x) |W (x))\nif (Y (x) \u22a5\u22a5 Z(x) |W (x))G(x)\n2 : p(Y (x, z) |W (x, z)) = p(Y (x) |W (x), Z(x) = z)\nif (Y (x, z) \u22a5\u22a5 Z(x, z) |W (x, z))G(x,z)\n3 : p(Y (x, z) |W (x, z)) = p(Y (x) |W (x))\nif (Y (x, z1),W (x, z1) \u22a5\u22a5 z1)G(x,z1) and\n(Y (x, z1) \u22a5\u22a5 Z2(x, z1) |W (x, z1))G(x,z1)\nwhere Z1 = Z \\AnG(x)(W ),\nZ2 = Z \u2229 AnG(x)(W )\nRecall that random variables in a SWIG G(x) are labelled Vi(x) or equivalently as Vi(x\u2229an \u2217 i ), where an \u2217 i consists of values of the ancestors of Vi in the split graph. We can view Rule 1 as the fragment of the SWIG global Markov property that pertains to random variables in V (a). Rule 2 may be called \u201cgeneralized conditional ignorability\u201d because it is a general version of the standard ignorability assumption\nused in causal inference settings, where (Y (a) \u22a5\u22a5 A | C), or equivalently (Y (a) \u22a5\u22a5 A(a) | C(a)), enables identification of (e.g.) the average treatment effect by adjusting for C. Note that Rule 3 does not have a simple interpretation, as it involves an equality of interventional distributions in two distinct \u201cworlds,\u201d given an independence condition in a third. However, below we suggest an alternative, simpler rule which may be used without loss of generality, and is more intuitive. First, we state some basic results.\nProposition 5 Rule 1 of po-calculus holds if and only if Rule 1 of do-calculus holds.\nProof: Follows from the definition of G(x) and GX , and the definition of m-separation.\nProposition 6 Rule 2 of po-calculus holds if and only if Rule 2 of do-calculus holds.\nProof: Follows from the definition of G(x, z) and GX,Z , and the definition of m-separation in G(x, z).\nProposition 7 Rule 3 of po-calculus holds if and only if Rule 3 of do-calculus holds.\nProof: Since path separation criteria on graphs quantify over elements in vertex sets, and since Z is a disjoint union of Z1 (Z(W ) in Pearl\u2019s terminology) and Z2, the precondition in Rule 3 of do-calculus may be written as two preconditions: (Y \u22a5\u22a5 Z1 | W,X)GX,Z1 and (Y \u22a5\u22a5 Z2 | W,X)GX,Z1 .\nBy definition of Z1, it contains only non-ancestors of W in GX (and therefore also in GX,Z1 , which is an edge subgraph of GX ). Since Z1 only has adjacent outgoing directed arrows in GX,Z1 , all elements of W are marginally m-separated from Z1 in GX,Z1 . Thus, (W (x, z1) \u22a5\u22a5 z1)G(x,z1) by the definition of G(x, z1). Furthermore, no element of Z1 can be an ancestor of Y in GX,Z1 . To see this, suppose an element Zi of Z1 were an ancestor of Y . Then since (Y \u22a5\u22a5 Z1 | W,X)GX,Z1\n, the directed path from Zi must be blocked byW andX . W cannot be on this directed path because it is non-descendant of Z1, and X cannot be on the path because GX,Z1 has no directed edges into X . So we conclude that Zi is not an ancestor of Y in GX,Z1 and therefore (Y (x, z1) \u22a5\u22a5 z1)G(x,z1) by the definition of G(x, z1). Thus, if do-calculus Rule 3 precondition holds, po-calculus Rule 3 precondition holds.\nWe now prove the converse. If (Y (x, z1) \u22a5\u22a5 z1)G(x,z1) then Z1 is not an ancestor of Y in GX,Z1 . Similarly if (W (x, z1) \u22a5\u22a5 z1)G(x,z1) then Z1 is not an ancestor of W in GX,Z1 . Since Z1 only has adjacent edges that are outgoing directed edges, this implies (Y,W \u22a5\u22a5 Z1 | X)GX,Z1 holds. Since semi-graphoid axioms hold for m-separation, this implies (Y \u22a5\u22a5 Z1 | W,X)GX,Z1 holds. Finally, (Y (x, z1) \u22a5\u22a5 Z2(x, z1) | W (x, z1))G(x,z1) holds if and\nonly if (Y \u22a5\u22a5 Z2 |W,X)GX,Z1 holds, by the definitions of G(x, z1), GX,Z1 , and m-separation.\nWe now briefly demonstrate the soundness of the three rules of the po-calculus using only potential outcomes machinery and our background assumptions.\nProposition 8 Rules 1, 2, and 3 are sound.\nProof: Proposition 3 licenses deriving conditional independence statements corresponding to the graphical conditions in each rule. Then we have the following derivations:\nRule 1: p(Y (x)|Z(x),W (x)) = p(Y (x)|W (x)) by Y (x) \u22a5\u22a5 Z(x) |W (x).\nRule 2: p(Y (x, z)|W (x, z)) = p(Y (x, z)|Z(x, z) = z,W (x, z)) = p(Y (x)|Z(x),W (x)) by Y (x, z) \u22a5\u22a5 Z(x, z) |W (x, z) and consistency.\nRule 3: p(Y (x)|W (x)) = p(Y (x, z1)|W (x, z1))\nsince Y (x, z1),W (x, z1) \u22a5\u22a5 z1.\n= p(Y (x, z1)|Z2(x, z1) = z2,W (x, z1))\nsince Y (x, z1) \u22a5\u22a5 Z2(x, z1)|W (x, z1).\n= p(Y (x, z1, z2)|Z2(x, z1, z2) = z2,W (x, z1, z2))\nby consistency.\n= p(Y (x, z)|Z2(x, z) = z2,W (x, z))\nsince Y (x, z1) \u22a5\u22a5 Z2(x, z1) | W (x, z1),\nZ2 \u2286 Z , and so by Proposition 4,\n= p(Y (x, z)|W (x, z))\nThe proof of Proposition 8 has a number of interesting consequences. First, the soundness of Rule 2 follows by Rule 1 and consistency. Second, the soundness of Rule 3 follows by applications of Rule 1, Rule 2, consistency, causal irrelevance, and intervention monotonicity.\nCausal irrelevance, as used in the proof, is implied by mseparation statements in the SWIG G(x, z1); however this property, like consistency, follows by (1) alone and does not require any assumption regarding the distributions p(V (a)) for any A \u2286 V ; specifically, (5) is not required. As a result the three rules of po-calculus, taken as a whole, are consequences of consistency and causal irrelevance, which hold in any recursive causal model, together with the SWIG Markov property for random variables in V (a). (Intervention monotonicity follows from these.)\nThe proof of Proposition 8 also implies that a simpler reformulation of po-calculus suffices without loss of generality. Specifically, this reformulation replaces Rule 3 by the following simpler rule (encoding causal irrelevance in graphical form):\n3\u2217 : p(Y (x, z)) = p(Y (x)) if (Y (x, z) \u22a5\u22a5 z)G(x,z).\nA benefit of translating the do-calculus exactly into our potential outcomes formulation is that the do-calculus rules as stated have been shown to be sufficient for a wide class of possible derivations on distributions expressible in terms of the do operator [1, 18]. However, since we phrased the rules for arbitrary potential outcomes, they may be applied to causal contrasts not expressible in standard do notation. We illustrate this by applying these rules to mediation analysis."}, {"heading": "5 Path-Specific Effects and Extended Graphs", "text": "The identification theory for path-specific effects generally proceeds by considering nested, path-specific potential outcomes. Fix a set of treatment variables A, and a subset of proper causal paths \u03c0 from any element in A. A proper causal path only intersects A at the source node. Next, pick a pair of value sets a and a\u2032 for elements in A. For any Vi \u2208 V , define the potential outcome Vi(\u03c0, a, a\n\u2032) by setting A to a for the purposes of paths in \u03c0, and to a\u2032 for the purposes of proper causal paths from A to Y not in \u03c0. Formally, the definition is as follows, for any Vi \u2208 V :\nVi(\u03c0, a, a \u2032) \u2261 a if Vi \u2208 A (6) Vi(\u03c0, a, a \u2032) \u2261\nVi({Vj(\u03c0, a, a \u2032) | Vj \u2208 Pa \u03c0 i }, {Vj(a \u2032) | Vj \u2208 Pa \u03c0 i })\nwhere Vj(a \u2032) \u2261 a\u2032 if Vj \u2208 A, and given by (1) otherwise, Pa\u03c0i is the set of parents of Vi along an edge which is a part of a path in \u03c0, and Pa\u03c0i is the set of all other parents of Vi.\nA counterfactual Vi(\u03c0, a, a \u2032) is said to be edge inconsistent if counterfactuals of the form Vj(ak, . . .) and Vj(a \u2032 k, . . .) occur in Vi(\u03c0, a, a \u2032), otherwise it is said to be edge consistent. It is well known that a joint distribution p(V (\u03c0, a, a\u2032)) containing an edge-inconsistent counterfactual Vi(\u03c0, a, a\n\u2032) is not identified in the functional causal model (nor weaker causal models) with a corresponding graphical criterion on \u03c0 and G(V ) called the \u2018recanting witness\u2019 [16, 20]. For example, in Fig. 2 (a), given \u03c0 = {C \u2192 A \u2192 Y }, Y (\u03c0, c, c\u2032) \u2261 Y (c\u2032,M(c\u2032, A(c\u2032)), A(c)), while given \u03c0 = {A \u2192 Y }, Y (\u03c0, a, a\u2032) \u2261 Y (C, a,M(a\u2032, C)). Note that Y (\u03c0, c, c\u2032) is edge inconsistent due to the presence of A(c) and A(c\u2032), while Y (\u03c0, a, a\u2032) is edge consistent.\nCounterfactuals defined by (6) form the basis for direct, indirect, and path-specific effects estimated in the mediation analysis literature. There are generalizations where elements in A are set to arbitrary values for different paths, under the name of path interventions [20]. Similarly, edge consistent counterfactuals V (\u03c0, a, a\u2032) generalize to responses to edge interventions [20]. We do not discuss this further here in the interests of space, although the results presented below generalize without issue. Note that edge consistent counterfactuals cannot, in general, be phrased in\nterms of the do operator.\nWe have the following the result, proven in [20].\nTheorem 1 If V (\u03c0, a, a\u2032) is edge consistent, then under the functional causal model for DAG G,\np(V (\u03c0, a, a\u2032)) =\nK \u220f\ni=1\np(Vi | a \u2229 pa \u03c0 i , a \u2032 \u2229 pa\u03c0,PaGi \\A).\n(7)\nAs an example, the distribution p(Y (\u03c0, a, a\u2032)) = p(Y (C, a,M(a\u2032, C))) of the edge consistent counterfactual in Fig. 2 (a) is identified as a marginal distribution derived from (7), specifically \u2211\nC,M p(Y | a,M,C)p(M | a\u2032, C)p(C). The po-calculus as presented above may be applied to any sort of potential outcome, including nested potential outcomes representing path-specific effects. In the following, we exploit an equivalence between path-specific potential outcomes and standard potential outcomes defined from an extended graph Ge, which is constructed from G following [14]. This both simplifies complex nested potential outcome expressions and enables us to leverage a series of prior results to identify conditional PSEs.\nGiven an ADMG G(V ), define for each Ai \u2208 A \u2286 V the set of variables AChi \u2261 {A j i | Vj \u2208 Chi}, and let ACh \u2261 \u22c3\nAi\u2208A AChi . We define the extended graph of\nG(V ), written Ge(V \u222a ACh), as the graph with the vertex set V \u222a ACh, with edges of the form Ai \u2192 A j i \u2192 Vj if and only if Ai \u2192 Vj is present in G(V ), for Ai \u2208 A, Vj \u2208 V ; furthermore, Vi \u2194 Vj in G\ne(V \u222aACh) if and only if Vi \u2194 Vj is present for Vi, Vj \u2208 V in G(V ). As an example, the extended graph for the DAG in Fig. 2 (a), with A = V , is shown in Fig. 2 (c). For conciseness, we will generally drop explicit references to vertices V \u222aACh, and denote extended graph of G(V ) by Ge. Extended graphs as we define them here are straightforward generalizations of those presented in [14], where they only consider \u201cnode copies\u201d of a single \u201ctreatment\u201d variable, whereas here extended graphs have \u201ccopies\u201d corresponding to every parentchild relationship of a set of treatments A.\nThe edges Ai \u2192 A j i in G e are understood to represent deterministic relationships. More precisely, we associate a causal model with Ge as follows. For G we had associated a set of potential outcomes V, and for Ge we have Ve. For every Vi(pai) \u2208 V, we let Vi(pai) be in V e. Note that this is well-defined, since Vi in G and G e share the number of parents, and the parent sets for every Vi share state spaces. In addition, for every Aji \u2208 A Ch, we let Aji (ai) for ai \u2208 XAi be in V e. By assumption, every Aji \u2208 A Ch has a single parent Ai, and we further require that p(A j i (ai)) is a deterministic density, with p(Aji (ai) = ai) = 1. To fix intuitions, consider the example of Pearl\u2019s discussed in [14]. They consider an analysis where Ai corresponds to smoking status, and affects hypertensive status Vj as\nwell as myocardial infarction status Vk through nicotine Aji and non-nicotine A k i components respectively. The relationships Ai \u2192 A j i and Ai \u2192 A k i are deterministic relationships between smoking and exposure to nicotine/nonnicotine components. [14] go on to consider potential outcomes of the form Vk(a j i , a k i ) (where the \u201cnode copies\u201d A j i and Aki are assigned to perhaps different values) inspired by a hypothetical intervention on the nicotine components of cigarette exposure that fixes non-nicotine components at some reference value (e.g., a new nicotine-free cigarette). In this case, the path-specific effect of smoking on outcome via nicotine components is easy to write down and identify, at the price of introducing new variables and deterministic relationships into the model.\nWe now show the following two results. First, we show that an edge-consistent V (\u03c0, a, a\u2032) may be represented without loss of generality by a counterfactual response to an intervention on a subset of ACh in Ge with the causal model defined above. Second, we show that this response is identified by the same functional (7).\nGiven an edge consistent V (\u03c0, a, a\u2032), define Ge via A \u2286 V . We define a\u03c0 that assigns ai to A j i \u2208 A Ch if Ai \u2192 Vj in G(V ) is in \u03c0, and assigns a\u2032i to A j i \u2208 A\nCh if Ai \u2192 Vj in G(V ) is not in \u03c0. The resulting set of counterfactuals V (a\u03c0) is well defined in the model for Ve, and we have the following result, proved in the Supplement.\nProposition 9 Fix an element p(V) in the causal model for a DAG G(V ), and consider the corresponding element pe(Ve) in the restricted causal model associated with a DAG Ge(V \u222a ACh). Then p(V ) = pe(V \u222a ACh) and p(V (\u03c0, a, a\u2032)) = pe(V (a\u03c0)).\nCorollary 1 Given an extended DAG Ge,\np(V (a\u03c0)) =\nK \u220f\ni=1\npe(Vi | a \u03c0 \u2229 pai,Pa\nGe i \\A).\nProof: This follows from Proposition 9, and the fact that the functional in (7) in p(V ) is equal to \u220fK\ni=1 p e(Vi | a \u03c0 \u2229\npai,Pa Ge i \\A) in p e(V \u222aACh).\nIn the causal models derived from DAGs with unobserved variables (e.g., G(V \u222aH)), identification of distributions on potential outcomes such as p(V (a)) or p(V (\u03c0, a, a\u2032)) may be stated without loss of generality on the latent projection ADMG G(V ). A complete algorithm for identification of path-specific effects in hidden variable models was given in [16] and presented in a more concise form in [19]. We describe this form in detail in the Supplement. We also note (and prove in the Supplement) that the latent projection and the extended graph operations commute.\nWe now show that identification theory for p(V (\u03c0, a, a\u2032)) in latent projection ADMGs G(V ) may be restated, without\nloss of generality, in terms of identification of p(V (a\u03c0)) in Ge(V \u222aACh).\nProposition 10 For any Y \u2286 V , p(Y (\u03c0, a, a\u2032)) is identified in the ADMG G(V ) if and only if p(Y (a\u03c0)) is identified in the ADMG Ge(V,ACh). Moreover if p(Y (a\u03c0)) is identified, it is by the same functional as p(Y (\u03c0, a, a\u2032)).\nNote that this Proposition is a generalization of Corollary 1 from DAGs to latent projection ADMGs. The proof of this claim, and all claims in the next section, are given in the Supplement."}, {"heading": "6 Identification of Conditional PSEs", "text": "Having established that we can identify path-specific effects by working with potential outcomes derived from the Ge model, we turn to the identification of conditional pathspecific effects using the po-calculus. In [17], the authors present the conditional identification (IDC) algorithm for identifying quantities of the form p(Y (x)|W (x)) (in our notation), given an ADMG. Since conditional path-specific effects correspond to exactly such quantities defined on the extended model Ge, we can leverage their scheme for our purposes. The idea is to reduce the conditional problem, identification of p(Y (a\u03c0)|W (a\u03c0)), to an unconditional (joint) identification problem for which a complete identification algorithm already exists.\nThe algorithm has three steps: first, exhaustively apply Rule 2 of the po-calculus to reduce the conditioning set as much as possible; second, identify the relevant joint distribution using Proposition 10 and the complete algorithm in [19]; third, divide that joint by the marginal distribution of the remaining conditioning set to yield the conditional path-specific potential outcome distribution. The procedure is presented formally as Algorithm 1, with the subroutine corresponding to Proposition 10 named PS-ID.\nNote that we make use of SWIGs defined from extended graphs, e.g., Ge(a\u03c0 , z). Beginning with Ge the SWIG Ge(a\u03c0, z) is constructed by the usual node-splitting operation: split nodes Z and Aji into random and fixed halves, where Aji is has fixed copy a if Ai \u2192 Vj in G(V ) is in \u03c0, and a\u2032i if Ai \u2192 Vj in G(V ) is not in \u03c0. Relabeling of random nodes proceeds as previously described.\nThe following two results are adapted from [17]; they are simply translated into potential outcomes and applied to extended graphs Ge.\nProposition 11 If (Y (x, z) \u22a5\u22a5 Z(x, z) | W (x, z))Ge(x,z) and T \u2286 W then (Y (x, t) \u22a5\u22a5 T (x, t) | Z(x, t), W1(x, t))Ge(x,t) if and only if (Y (x, z, t) \u22a5\u22a5 T (x, z, t) | W1(x, z, t))Ge(x,z,t), where W1 = W \\ T .\nCorollary 2 For any Ge(x) and any conditional distribution p(Y (x)|W (x)), there exists a unique maximal\nset Z(x) = {Zi(x) \u2208 W (x) | p(Y (x)|W (x)) = p(Y (x, zi)|W (x, zi) \\ {Zi(x, zi)})} such that Rule 2 applies for Z(x, z) in Ge(x, z) for p(Y (x, z)|W (x, z)).\nAlgorithm 1 PS-IDC(Y, a\u03c0,W,Ge) Input: outcome Y , path-specific setting a\u03c0, conditioning set W , and graph G Output: p(Y (a\u03c0)|W (a\u03c0)) 1: if \u2203Z \u2208 W s.t.\n(Y (a\u03c0, z) \u22a5\u22a5 Z(a\u03c0, z) |W (a\u03c0, z))Ge(a\u03c0,z) return PS-IDC(Y, a\u03c0 \u222a z,W \\ Z,Ge)\n2: else let p\u2032(Y (a\u03c0),W (a\u03c0))\u2190 PS-ID(Y \u222aW,a\u03c0,Ge) return p\u2032(Y (a\u03c0),W (a\u03c0))/ \u2211\ny p \u2032(Y (a\u03c0),W (a\u03c0))\nThe following is similar to Theorem 6 in [17], but extended to path-specific queries in extended graphs. The proof is in the Supplement.\nTheorem 2 Let p(Y (\u03c0, a, a\u2032) | W (\u03c0, a, a\u2032)) be a conditional path-specific distribution in the causal model for G, and let p(Y (a\u03c0) | W (a\u03c0)) be the corresponding distribution in the extended causal model for Ge(V \u222a ACh). Let Z be the maximal subset of W such that p(Y (a\u03c0) | W (a\u03c0)) = p(Y (a\u03c0 , z) | W (a\u03c0 , z) \\ Z(a\u03c0, z)). Then p(Y (a\u03c0) | W (a\u03c0)) is identifiable in Ge if and only if p(Y (a\u03c0, z),W (a\u03c0, z) \\ Z(a\u03c0, z)) is identifiable in Ge.\nWe then have by Corollary 2, Theorem 2, and completeness of the identification algorithm for path-specific effects [19]:\nTheorem 3 Algorithm 1 is complete.\nAs an example, p(Y (a,M(a\u2032))) is identified from p(C,A,M, Y ) in the causal model in Fig. 1 (a), via\n\u2211\nM\n\u2211 C p(Y,M | a, C)p(C) \u2211 C p(M | a \u2032, C)p(C)\n\u2211 C p(M | a, C)p(C) .\nHowever p(Y (a,M(a\u2032))|C) is not identified, since PSIDC concludes p(Y (a,M(a\u2032)), C) must first be identified, and this joint distribution is not identified via results in [16]. On the other hand, p(Y (a,M(a\u2032))|C) is identified from p(C,A,M, Y ) in a seemingly similar graph in Fig. 1 (b), via \u2211\nM p(Y |M,a,C)p(M | a \u2032, C)."}, {"heading": "7 Conclusion", "text": "In this paper we introduced the potential outcomes calculus, a generalization of do-calculus that applies to arbitrary potential outcomes. We have shown that potential outcome calculus is equivalent to Pearl\u2019s do-calculus for standard interventional quantities, and is a logical consequence of the properties of consistency and causal irrelevance, as well as the global Markov property associated with SWIGs. Finally, we used the potential outcomes calculus to give\na sound and complete algorithm for conditional distributions defined on potential outcomes associated with pathspecific effects. This algorithm may be viewed as a pathspecific generalization of the identification algorithm for conditional interventional distributions in [17]."}, {"heading": "8 Acknowledgments", "text": "The authors would like to thank the American Institute of Mathematics for supporting this research via the SQuaRE program. This project is sponsored in part by the National Institutes of Health grant R01 AI127271-01 A1, and the Office of Naval Research grants N00014-18-1-2760 and N00014-15-1-2672. The authors would like to thank James M. Robins for helpful discussions."}, {"heading": "A Complete Identification Algorithm For Path-Specific Counterfactual Distributions In", "text": "Hidden Variable Causal Models\nHere we introduce a concise formulation of the complete identification algorithm for edge-consistent path-specific counterfactual distributions given in [6] via kernels, conditional graphs, and the fixing operation.\nKernels, Conditional Graphs, and Fixing\nA kernel qV (V | W ) is a mapping from XW to densities over V . Given A \u2286 V , we define conditioning and marginalization in the usual way:\nqV (A|W ) \u2261 \u2211\nV \\A\nqV (V |W ); qV (V \\A|A,W ) \u2261 qV (V |W )\nqV (A|W ) .\nA conditional graph G(V,W ) is a graph with two types of vertices, random V and fixed W , with the property that for\nany fixed vertex in W , its set of parents is empty.1 We will consider conditional ADMGS (CADMGs), or conditional DAGs (CDAGs) as a special case. A SWIG G(V (a)) may be viewed as a conditional graph of the form G(V (a), a), where we denote the set of fixed vertices by a.\nFor a CADMG G(V,W ), and Vi \u2208 V , define\nDisGi \u2261 {Vj | Vj \u2194 . . .\u2194 Vi in G} (district of Vi).\nNote that districts are only defined for, and may only contain, random vertices in V not fixed vertices in W . The set of districts in G is denoted by D(G).\nA vertex Vi \u2208 V in a CADMG G(V,W ) is said to be fixable if Dei \u2229Disi = \u2205. For such a vertex, define the operator \u03c6i(G) that yields a new CADMG G(V \\ {Vi},W \u222a {Vi}), obtained by removing all edges with arrowheads into Vi, and keeping all other edges in G(V,W ).\nGiven a CADMG G(V,W ), and a kernel qV (V |W ), if Vi is fixable, define the operator \u03c6i(qV ;G) as yielding a new kernel\nqV \\{Vi}(V \\ {Vi}|W \u222a {Vi}) \u2261 qV (V |W )\nqV (Vi | Mb G i ,W )\n,\nwhere MbGi , the Markov blanket of Vi in G, is defined to be DisGi \u222a{Pa G j | Vj \u2208 Dis G i }.\nA set of vertices Z \u2286 V is said to be fixable in G(V,W ), if there exists a fixable sequence Z1, . . . , Zk on vertices in Z such that Z1 is fixable in G, Z2 is fixable in \u03c61(G), Z3 is fixable in \u03c62(\u03c61(G)), and so on. Given a sequence \u03b1Z for elements in Z , we define \u03c6\u03b1Z (G) and \u03c6\u03b1Z (qV ;G) in the natural way by operator composition. For any two valid fixing sequences \u03b1Z , \u03b2Z for a fixable set Z , \u03c6\u03b1Z (G) = \u03c6\u03b2Z (G). Hence, for a fixable Z , we define \u03c6Z(G) to mean \u201cfix elements in Z in G by any fixable sequence.\u201d\nGiven a CADMG G(V,W ), if Z \u2286 V is fixable, then R \u2261 V \\ Z is called a reachable set. A reachable set R such that D(\u03c6Z (G(V,W ))) contains a single element is called intrinsic. If there exists a set of kernels\n{qD(D|PaD,W )|D is intrinsic in G(V,W )} ,\nwhere PaD \u2261 \u22c3\nVi\u2208D {Pai \\D | Vi \u2208 D}, such that for all\nfixable sets Z in G(V,W ), and all fixable sequences \u03b1Z , we have\n\u03c6\u03b1Z (qV (V |W );G(V,W )) = \u220f\nD\u2208D(\u03c6Z(G(V,W )))\nqD(D|PaD,W ),\nwe say qV (V | W ) is in the nested Markov model of G(V,W ).\n1Note that some elements of V may have an empty parent set as well.\nFor any such qV (V | W ), it can be shown that for any fixable Z in G(V,W ), and any fixable sequences \u03b1, \u03b2 for Z , \u03c6\u03b1Z (qV (V |W );G(V,W )) = \u03c6\u03b2Z (qV (V |W );G(V,W )). As a result, we write \u03c6Z(qV (V |W );G(V,W )) to mean \u201cfix elements in Z in qV (V |W ) using any fixable sequence.\u201d\nMoreover, we have\n{qD(D|PaD,W )|D is intrinsic in G(V,W )}\n= {\u03c6V \\D(qV (V |W );G(V,W ))| is intrinsic in G(V,W )}.\nWe have the following important results.\nProposition 14 If qV \u222aH(V \u222a H |W ) is in the Markov model for the CDAG G(V \u222a H,W ), then qV (V |W ) \u2261 \u2211\nH qV \u222aH(V \u222a H |W ) is in the nested Markov model for the latent projection CADMG G(V,W ).\nProof: This is shown in [1].\nThe complete algorithm for an edge-consistent p(Y (\u03c0, a, a\u2032)) for Y \u2286 V is stated as follows.\nProposition 15 Let Y \u2217 \u2261 anGV \\A(Y ). Then p(Y (\u03c0, a, a\u2032)) is identified in G(V ) if and only if for every D \u2208 D(GY \u2217), paG(D) \u2229 A are assigned to either a subset of a or a subset of a\u2032, and D is intrinsic in G(V ). Moreover, if p(Y (\u03c0, a, a\u2032)) is identified, we have\np(Y (\u03c0, a, a\u2032)) = \u2211\nY \u2217\\Y\n\u220f\nD\u2208D(GY \u2217 )\n\u03c6V \\D(p(V );G(V )) \u2223 \u2223\na\u0303D ,\n(8)\nwhere a\u0303D is defined to be the appropriate subset of a associated with paG(D) \u2229 A if those elements are assigned by the definition of Y (\u03c0, a, a\u2032), and the appropriate subset of a\u2032 associated with paG(D) \u2229 A otherwise.\nProof: This is shown in [6].\nNote that the kernels \u03c6V \\D(.) are well defined by Proposition 14, since causal inference always starts with a causal model that implies a distribution that factorizes with respect to a (possibly hidden variable) DAG.\nRemaining Proofs\nNow we turn to proving results related to Sections 5 and 6 in the main paper.\nProposition 9 Fix an element p(V) in the causal model for a DAG G(V ), and consider the corresponding element pe(Ve) in the restricted causal model associated with a DAG Ge(V \u222a ACh). Then p(V ) = pe(V,ACh) and p(V (\u03c0, a, a\u2032)) = pe(V (a\u03c0)).\nProof: By definition of the causal model for G, we have\np(V (\u03c0, a, a\u2032) = v)= \u2211\n\u01ebi:fi(aPa\u03c0 i ,a\u2032\nPa\u03c0 i\n,vPai \\A)=vi\np(\u01eb1, . . . , \u01ebk),\nwhere for each Vi, Pa \u03c0 i is the subset ofPai \u2229A with an edge from Pai to Vi in \u03c0, and Pa \u03c0 i is the subset of Pai \u2229A with an edge from Pai to Vi not in \u03c0. Similarly, by definition of the restricted causal model for Ge(V \u222aACh), we have\npe(V (a\u03c0) = v) = \u2211\n\u01ebi:fi(a\u03c0 Pai \u2229A Ch ,vPai \\A)=vi\np(\u01eb1, . . . , \u01ebk).\nThe equivalence follows immediately. Note that the same argument establishes p(V ) = pe(V,ACh), by letting \u03c0 be the empty set of paths, and A = \u2205.\nProposition 16 Assume there exists elements p1(V), p2(V) in the causal model for G such that p1(V ) = p2(V ), but p1(V (\u03c0, a, a\n\u2032)) 6= p2(V (\u03c0, a, a\u2032)). Then p(V (a\u03c0)) is not identified in the restricted causal model for Ge(V \u222a ACh).\nProof: Follows immediately by Proposition 9.\nWe state formally our claim in the main paper that the latent projection and extended graph operations commute.\nProposition 17 Fix a DAG G(V \u222a H), and let A \u2286 V . Then Ge(V \u222a ACh), the latent projection onto V \u222a ACh of Ge(V \u222a H \u222a ACh) is equal to the extended graph G(V \u222a ACh)e applied to the latent projection G(V ).\nProof: By definition, the two graphs have the same vertices. That the two graphs share the same edges follows from the definition of Ge, which stipulates that the only edge into each variable in ACh is from the corresponding variable in A, i.e., there are no directed paths from any H into any element of ACh not through some element of A. So, all bidirected edges induced by the latent projection operation are between vertices in V , which are shared between the two graphs.\nProposition 10 For any Y \u2286 V , p(Y (\u03c0, a, a\u2032)) is identified in the ADMG G(V ) if and only if p(Y (a\u03c0)) is identified in the ADMG Ge(V,ACh). Moreover if p(Y (a\u03c0)) is identified, we have\npe(Y (a\u03c0)) = \u2211\nY \u2217\\Y\n\u220f\nD\u2208D(Ge Y \u2217 )\n\u03c6(V \u222aACh)\\D(p e(V,ACh);Ge)\n\u2223 \u2223\na\u0303D\n(9)\nwhere Y \u2217 \u2261 anGe V \\ACh (Y ), and a\u0303D is defined to be the appropriate subset of a\u03c0 associated with paG(D) \u2229 A Ch.\nProof: Assume p(Y (\u03c0, a, a\u2032)) is identified in G(V ) via (8). The conclusion follows from Proposition , and the fact that the functional in (8) in p(V ) is equal to (9) in pe(V,ACh).\nAssume p(Y (\u03c0, a, a\u2032)) is not identified, and fix a witness of this fact, which is either a hedge or a district with a recanting set of parents in A. If the witness is a hedge,\nthe construction in [5] yields p1(V) and p2(V), such that p1(V ) = p2(V ), but p1(Y (\u03c0, a, a\n\u2032)) 6= p2(Y (\u03c0, a, a\u2032)) If the witness is a recanting district, the construction in [3], described also in [6], yields p1(V) and p2(V), such that p1(V ) = p2(V ), but p1(Y (\u03c0, a, a \u2032)) 6= p2(Y (\u03c0, a, a \u2032)). In both cases, this immediately implies the conclusion by Corollary 16.\nProposition 11 If (Y (x, z) \u22a5\u22a5 Z(x, z) | W (x, z))Ge(x,z) and T \u2286 W then (Y (x, t) \u22a5\u22a5 T (x, t) | Z(x, t), W1(x, t))Ge(x,t) if and only if (Y (x, z, t) \u22a5\u22a5 T (x, z, t) | W1(x, z, t))Ge(x,z,t), where W1 = W \\ T .\nProof: The set of possible d-connecting paths from Y (x, z, t) to T (x, z, t) in Ge(x, z, t) is a subset of the set of possible d-connecting paths from Y (x, t) to T (x, t) in Ge(x, t). For any such path that exists in both graphs, if it is blocked by W1(x, t) in Ge(x, t), it will be blocked by W1(x, z, t) in Ge(x, z, t). If it is blocked by Z(x, t) in Ge(x, t), the path will be blocked in Ge(x, z, t) by construction of Ge(x, z, t). If it is blocked by collider without Z(x, t),W1(x, t) descendants in Ge(x, t), the same will remain true in Ge(x, z, t). Thus, if (Y (x, t) \u22a5\u22a5 T (x, t) | Z(x, t), W1(x, t))Ge(x,t), then (Y (x, z, t) \u22a5\u22a5 T (x, z, t) | W1(x, z, t))Ge(x,z,t).\nNow, assume for contradiction, (Y (x, z, t) \u22a5\u22a5 T (x, z, t) | W1(x, z, t))Ge(x,z,t), but (Y (x, t) 6\u22a5\u22a5 T (x, t) | Z(x, t), W1(x, t))Ge(x,t), with a witnessing d-connecting path from some Y1(x, t) to some T1(x, t). If this path is not a possible d-connecting path in Ge(x, z, t), it must contain a noncollider through an element of Z , and thus is blocked by Z(x, t) in Ge(x, t). If this path is a possible d-connecting path in Ge(x, z, t) it must be blocked by a collider which contains no descendants in W1(x, z, t) in Ge(x, z, t), but remains open due to this collider containing descendants in Z(x, t) in Ge(x, t).\nBut this implies the existence of a d-connecting path in Ge(x, t) from an element Y1(x, t) in Y (x, t) to an element Z1(x, t) in Z(x, t) given W1(x, t), and thus also given W (x, t) (since no element in T (x, t) will block this path by construction). Since we can choose Z1(x, t) to be the closest element in Z(x, t) to Y1(x, t) involved in the witnessing path, we obtain that Y1(x, z) 6\u22a5\u22a5 Z1(x, z) |W (x, z), which is a contradiction.\nCorollary 2 For any Ge(x) and any conditional distribution p(Y (x)|W (x)), there exists a unique maximal set Z(x) = {Zi(x) \u2208 W (x) | p(Y (x)|W (x)) = p(Y (x, zi)|W (x, zi) \\ {Zi(x, zi)})} such that Rule 2 applies for Z(x, z) in Ge(x, z) for p(Y (x, z)|W (x, z)).\nProof: Fix two maximal sets Z1(x) and Z2(x) such that Rule 2 applies for Z(x, z) in Ge(x, z) for p(Y (x, z)|W (x, z)). If Z1(x) 6= Z2(x), fix T (x) \u2208 Z1(x) \\Z2(x). By the previous proposition, Rule 2 applies for Z2(x) \u222a T (x), contradicting our assumption.\nTheorem 2 Let p(Y (\u03c0, a, a\u2032) | W (\u03c0, a, a\u2032)) be a conditional path-specific distribution in the causal model for G, and let p(Y (a\u03c0) | W (a\u03c0)) be the corresponding distribution in the extended causal model for Ge(V \u222a ACh). Let Z be the maximal subset of W such that p(Y (a\u03c0) | W (a\u03c0)) = p(Y (a\u03c0 , z) | W (a\u03c0 , z) \\ Z(a\u03c0, z)). Then p(Y (a\u03c0) | W (a\u03c0)) is identifiable in Ge if and only if p(Y (a\u03c0, z),W (a\u03c0, z) \\ Z(a\u03c0, z)) is identifiable in Ge.\nProof: The proof strategy follows that of the completeness argument in [4]. We expand the argument here to be more transparent. In addition, we must handle an additional case of non-identifiability that arises in mediation problems, that has to do with structures called recanting districts in [3].\nIf p(Y (a\u03c0, z),W (a\u03c0, z)\\Z(a\u03c0, z)) is identified in Ge, then p(Y (a\u03c0) |W (a\u03c0)) is identifiable in Ge since\np(Y (a\u03c0)|W (a\u03c0)) = p(Y (a\u03c0, z)|W (a\u03c0, z) \\ Z(a\u03c0, z))\n= p(Y (a\u03c0, z),W (a\u03c0, z) \\ Z(a\u03c0, z))\np(W (a\u03c0, z) \\ Z(a\u03c0, z)) .\nNow assume p(Y (a\u03c0, z),W (a\u03c0, z) \\ Z(a\u03c0, z)) is not identified in Ge. Either p(W (a\u03c0, z)) is identified or not. If p(W (a\u03c0, z)) is identified, p(Y (a\u03c0, z)|W (a\u03c0, z) \\ Z(a\u03c0, z)) is identified if and only if p(Y (a\u03c0, z),W (a\u03c0, z) \\ Z(a\u03c0, z)) is. Since the latter is false by assumption, our conclusion follows.\nAssume p(W (a\u03c0 , z)) is not identified. Let a\u0303 = a \u222a z, and \u03c0\u0303 be the set comprised of \u03c0 and all outgoing directed edges from elements in Z . Then the distribution p(W (a\u03c0, z)) is equal to p(W (a\u0303\u03c0\u0303)), which in turn is equivalent to p(W (\u03c0\u0303, a\u0303, a\u2032)).\np(W (\u03c0\u0303, a\u0303, a\u2032)) could fail to be identified in the causal model for G for two reasons. Either there could exist a hedge structure [5] for p(W (a)), or there could exist a recanting district structure [3] in D(GW\u2217 ), where W \u2217 \u2261 An GV \\A W . We consider these cases in turn.\nIf there exists a hedge structure, fix a district D inD(GW\u2217), where W \u2217 \u2261 An GV \\A W , such that there is a larger district D\u2032 containing D that forms the hedge structure with D. Further, find the minimal subset W \u2032 of W such that the set of all childless vertices in the hedge structure (contained in D\u2032) is in An GV \\A W \u2032 . Let H be the smallest set of vertices that contains W \u2032, D\u2032, and such that the set of childless vertices in the hedge structure is in AnGHW \u2032 .\nAssume without loss of generality that each vertex in GH has at most one child. We construct elements p1(H) and p2(H) in the causal model in GH as follows. In p1(H) each structural equation is a bit parity function of the parents, and each bidirected arc corresponds to a binary latent common parent where each such latent is involved in precisely two functions. Moreover, each such latent variable \u01ebij that is a parent of Vi and Vj is drawn from a uniform distribution p(\u01ebij). In p2(H) the same is true, except\nno element in D\u2032 \\ D is involved in the structural equation for any element in D, and no \u01ebij that is a parent of an element in D\u2032 \\ D and an element in D exists. It has been shown in [5] that if p1(H) and p2(H) are constructed in this way, they induce p1(H), p1(W\n\u2032(aH\u2229A)) and p2(H), p2(W\n\u2032(aH\u2229A)) respectively, such that p1(H) = p2(H) (i.e., the induced observational distributions are the same), but p1(W\n\u2032(aH\u2229A)) 6= p2(W \u2032(aH\u2229A)) (i.e., the induced potential outcome distributions are distinct).\nSpecifically, let R be the set of childless vertices in GD\u2032 . Then it has been shown that p1(D \u2032) = p2(D \u2032) is a distribution uniform over any assignment to D\u2032 such that the number of 1 values in R is even. At the same time, p1(R(aH\u2229A)) is a uniform distribution over assignments with even number of 1 values, while p2(R(aH\u2229A)) is a uniform distribution. Since each element in H \\ R has a single parent in GH , the bit parity function for those elements simply reduces to the identity function. Note that more general structural equations suffice for the argument, as long as the linear transformation that maps p(D\u2032(aH\u2229A)) to p(W \u2032(aH\u2229A)) \u2261 \u2211 D\u2032 p(W \u2032(aH\u2229A) | D\u2032(aH\u2229A))p(D \u2032(aH\u2229A)) is one to one.\nConsider a path \u03c0 in G(a) from some element Wi in W \u2032 to an element Yj in Y , such that Wi is m-connected to Y given W , and the edge on the path adjacent to Wi has an arrowhead into Wi (Pearl called such paths backdoor paths). Such a path must exist by construction of W . In addition, consider the smallest subset W \u2032\u2032 of W such that Wi is mconnected to Yj given W\n\u2032\u2032 in G(a). Pick the smallest set H \u2032 containing H such that the above m-connection statement holds in G(a)H\u2032 . We now extend p1(H) and p2(H) to p1(H \u2032) and p2(H \u2032) to show p(Yj(aH\u2032\u2229A) |W \u2032(aH\u2032\u2229A)) is not identified.\nWe have three base cases. The first case assumes the first node Zj on \u03c0 not in H is a parent of an element Zi in H . Let the structural equation corresponding to Zi be the bit parity function of all its parents in GH\u2032 , including Zj in both p1(H \u2032) and p2(H \u2032), and let p(Zj) be the uniform distribution on a binary variable.\nIn this case, the observed data distributions are p1(H | Zj)p1(Zj) and p2(H | Zj)p2(Zj). p1(Zj) = p2(Zj) by construction. Next, note that p1(H | Zj = 0) = p2(H | Zj = 0) equal to the distributions p1(H) = p2(H) given in the previous construction. Specifically these distributions are uniform on all assignments to R with an even number of 1 values. By symmetry, p1(H | Zj = 1) = p2(H | Zj = 1), with the distributions being uniform on all assignments to R with an odd number of 1 values. By above construction and results in [5], p1(H(aH\u2229A) | Zj(aH\u2229A) = 0) = p1(H | Zj = 0), while p2(H(aH\u2229A) | Zj(aH\u2229A) = 0) is a uniform distribution. Since p1(Zj(aH\u2229A)) = p1(Zj) = p2(Zj) = p2(Zj(aH\u2229A)), we have that p1(Zj(aH\u2229A), R(aH\u2229A))\nonly has positive probability if the number of 1 values in {Zj} \u222a R is even, while p2(Zj(aH\u2229A), R(aH\u2229A)) is a uniform distribution. This implies p1(Zj(aH\u2229A) = 0 | R(aH\u2229A) = 0) = 1, while p2(Zj(aH\u2229A) = 0 | R(aH\u2229A) = 0) < 1, which establishes the base case.\nThe second case assumes the first node Zj on \u03c0 not in H is a child of an element Zi in H . We also consider the third case where Yj \u2208 H , here by letting Yj = Zi. If p(Zj(aH\u2032\u2229A) | W \u2032(aH\u2032\u2229A)) (or p(Yj(aH\u2032\u2229A) | W \u2032(aH\u2032\u2229A))) is not identified, we are done. Otherwise, we assume p(Zj(aH\u2032\u2229A) |W \u2032(aH\u2032\u2229A)) is identified. Consider the edge subgraph G\u2032H\u2032 of GH\u2032 that lacks the outgoing directed edges from Zi within H .\nSince the childless vertices in the hedge structure are in AnGHW \u2032 , if Zi is not in the hedge structure in H , it must be on a directed path in GH from some childless vertex in the hedge structure to an element of W \u2032. Since we assumed each vertex in GH has at most one child, removing the outgoing arrow from Zi in GH\u2032 results in G\u2032H\u2032 containing the hedge structure for p(Zj(aH\u2032\u2229A),W\n\u2032\u2032(aH\u2032\u2229A)), where W \u2032\u2032 = W \u2032 \\ {Wi} and Wi is W \u2032 \u2229DeGH\u2032 (Zj). If p(W \u2032\u2032(aH\u2032\u2229A)) is identified, we are done, since we established the base case where p(Zj(aH\u2032\u2229A) | W \u2032\u2032(aH\u2032\u2229A)) is not identified. If p(W\n\u2032\u2032(aH\u2032\u2229A)) is not identified, note that W \u2032\u2032 is a strictly smaller set then W \u2032, and we restart the base case argument, finding a hedge or a recanting district for this smaller set, constructing a new set H , and a new backdoor path to an element in Y . Since the new subset of W is strictly smaller, we can only do this a finite number of times before encountering another base case.\nIf Zi is in the hedge structure in H , then the resulting graph G\u2032H\u2032 contains a hedge structure for p(Zj(aH\u2032\u2229A),W\n\u2032(aH\u2032\u2229A)) with the set of childless vertices of the previous hedge and also Zi (since it is now childless in H). Given the hedge construction above, we have p1(Zj(aH\u2032\u2229A) = 0 | W \u2032(aH\u2032\u2229A) = 0) < 1, while p2(Zj(aH\u2032\u2229A) = 0 | W \u2032(aH\u2032\u2229A) = 0) = 1, and we are done.\nWe now consider the inductive cases on the path \u03c0. Consider Zk and Zk+1 on the path, where Zk+1 is closer to Yj on the path. We have the following cases.\nIf Zk+1 is a parent of Zk, or Zk+1 is a child of Zk, then in G\u2032H\u2032 :\np1(Zk+1(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A)) = \u2211\nZk\np1(Zk(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A))p1(Zk+1(aH\u2032\u2229A)|Zk(aH\u2032\u2229A))\np2(Zk+1(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A)) = \u2211\nZk\np2(Zk(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A))p2(Zk+1(aH\u2032\u2229A)|Zk(aH\u2032\u2229A)).\nLet\np1(Zk+1(aH\u2032\u2229A)|Zk(aH\u2032\u2229A)) = p2(Zk+1(aH\u2032\u2229A)|Zk(aH\u2032\u2229A)).\nThen we have\np1(Zk+1(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A)) 6= p2(Zk+1(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A))\nif and only if\np1(Zk(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A)) 6= p2(Zk(aH\u2032\u2229A)|W \u2032(aH\u2032\u2229A)).\nThese latter distributions are not equal in p1(H \u2032) and\np2(H \u2032) by the inductive hypothesis.\nIf Zk+1 is a sibling of Zk, we repeat the above two cases, since this case may be rephrased without loss of generality in terms of an unobserved variable Hk that is a parent of both Zk+1 and Zk.\nIf Zk+1 and Zk are both parents of a variable Ck which is an ancestor of element Wk in W \u2032, we have:\np1(Zk+1(aH\u2032\u2229A)|Wk(aH\u2032\u2229A),W \u2032(aH\u2032\u2229A)) =\n\u2211\nZk\np1(Zk+1|Wk, Zk)\u00d7\np1(Wk|Zk) \u2211\nZk p1(Wk|Zk)p1(Zk|W \u2032(aH\u2032\u2229A))\np1(Zk|W \u2032(aH\u2032\u2229A))\np2(Zk+1(aH\u2032\u2229A)|Wk(aH\u2032\u2229A),W \u2032(aH\u2032\u2229A)) =\n\u2211\nZk\np2(Zk+1|Wk, Zk)\u00d7\np2(Wk|Zk) \u2211\nZk p2(Wk|Zk)p2(Zk|W \u2032(aH\u2032\u2229A))\np2(Zk|W \u2032(aH\u2032\u2229A))\nAssume Wk = Ck. We must choose\np1(Zk+1,Wk | Zk) = p2(Zk+1,Wk | Zk)\nsuch that\np1(Zk+1(aH\u2032\u2229A)|Wk(aH\u2032\u2229A),W \u2032(aH\u2032\u2229A)) 6=\np2(Zk+1(aH\u2032\u2229A)|Wk(aH\u2032\u2229A),W \u2032(aH\u2032\u2229A))\nif\np1(Zk|W \u2032(aH\u2032\u2229A)) 6= p2(Zk|W \u2032(aH\u2032\u2229A)),\n(which is true by the inductive hypothesis).\nFor a fixed Wk , we have 5 degrees of freedom: p(Zk+1), p(Wk|Zk+1, Zk), p(Wk|Zk+1, 1 \u2212 Zk), p(Wk|1\u2212 Zk+1, Zk), and p(Wk|1\u2212 Zk+1, 1\u2212 Zk).\nIt suffices to specify these in such a way that the linear mapping induced by\np(Zk+1 |Wk, Zk) = p(Zk+1)p(Wk | Zk+1, Zk) \u2211\nZk+1 p(Zk+1)p(Wk | Zk+1, Zk)\nis a one-to-one mapping, and for some Wk , c = p1(Wk | Zk) = p2(Wk | Zk), and k = p1(Wk | 1\u2212Zk) = p2(Wk | 1\u2212 Zk) are chosen such that\np1(Zk|W \u2032(aH\u2032\u2229A)) p2(Zk|W \u2032(aH\u2032\u2229A)) 6= k + p1(Zk|W \u2032(aH\u2032\u2229A))(c\u2212 k) k + p2(Zk|W \u2032(aH\u2032\u2229A))(c\u2212 k) ,\nfor some p1(Zk|W \u2032(aH\u2032\u2229A)) 6= p2(Zk|W \u2032(aH\u2032\u2229A)). But there are sufficient degrees of freedom to satisfy both properties. In particular, we can choose p1(Zk|W \u2032(aH\u2032\u2229A)) and p2(Zk|W \u2032(aH\u2032\u2229A)) to be distinct one-to-one mappings (since these are 2 by 2 matrices, and almost all such matrices are full column rank) and c 6= k to obtain the above inequality.\nIf Wk 6= Ck , the above construction may be trivially extended by letting all variables on the directed path from Ck to Wk be identity functions of their parents.\nAssume there exists a recanting district D in D(GW\u2217), where W \u2217 \u2261 AnGV \\A(W ). Further, find the minimal subset W \u2032 of W such that the set of all childless vertices in D is in AnGV \\A(W\n\u2032). Let H be the smallest set of vertices that contains W \u2032, D, an element Ai \u2208 A \u2229 PaG(D) with a conflicting treatment assignment, and such that the set of childless vertices in D is in AnGH (W \u2032).\nConsider any edge subgraph of GH such that each vertex has at most one child. We construct elements p1(H) and p2(H) in the causal model in GH as follows. In p1(H) each structural equation is a bit parity function of the parents, and each bidirected arc between Vi and Vj corresponds to a binary latent common parent \u01ebij where each such latent is involved in precisely two functions. Moreover p(\u01ebij) is a uniform distribution. In p2(H) the same is true, except Ai is not involved in the structural equation for any element in D. It has been shown in [3] that p1(H) = p2(H), but p1(W \u2032(\u03c0, ai, a \u2032 i)) 6= p2(W \u2032(\u03c0, ai, a \u2032 i)).\nAs before, consider a backdoor path \u03c0 in G(a) from some elementWi in W\n\u2032 to an element Yj in Y , such that Wi is mconnected to Y given W , and the edge on the path adjacent to Wi has an arrowhead into Wi. Such a path must exist by construction of W . In addition, consider the smallest subset W \u2032\u2032 of W such that Wi is m-connected to Yj given W \u2032\u2032 in GV \\A. Pick the smallest set H\n\u2032 containing H such that the above m-connection statement holds in GH\u2032 . We now extend p1(H) and p2(H) to p1(H \u2032) and p2(H \u2032) to show p(Yj(aH\u2032\u2229A) |W \u2032(aH\u2032\u2229A)) is not identified.\nWe have three base cases. The first case assumes the first node Zj on \u03c0 not in H is a parent of an element Zi. In this case, we let Zi be the bit parity function of all its parents in GH\u2032 , including Zj in both p1(H\u2032) and p2(H\u2032). By reasoning analogous to the hedge case, this implies p1(H\n\u2032) = p2(H\n\u2032), but p1(Zj(aH\u2032\u2229A) = 0 | W \u2032(aH\u2032\u2229A) = 0) < 1, while p2(Zj(aH\u2032\u2229A) = 0 |W \u2032(aH\u2032\u2229A) = 0) = 1.\nThe second case assumes the first node Zj on \u03c0 not in H is a child of an elementZi inH . The third case, which we also\nconsider here, assumes Y \u2208 H , in which case we let Y = Zi. If p(Zj(\u03c0, ai, a \u2032 i) | W \u2032(\u03c0, ai, a \u2032 i)) (or p(Y (\u03c0, ai, a \u2032 i) | W \u2032(\u03c0, ai, a \u2032 i))) is not identified, we are done. Otherwise, we assume p(Zj(\u03c0, ai, a \u2032 i) | W \u2032(\u03c0, ai, a \u2032 i)) is identified. Consider the edge subgraph G\u2032H\u2032 of GH\u2032 that lacks the outgoing directed edges from Zi within H .\nIf Zi is not in D, by reasoning analogous to reasoning in the hedge case, GH\u2032 contains the recanting district structure for p(Zj(\u03c0, a, a\n\u2032),W \u2032\u2032(\u03c0, a, a\u2032)), where W \u2032\u2032 = W \u2032 \\{Wi} and Wi is W \u2032 \u2229 DeGH\u2032 (Zj). If p(W \u2032\u2032(\u03c0, a, a\u2032)) is identified, we are done, since we established the base case where p(Zj(\u03c0, a, a \u2032) | W \u2032\u2032(\u03c0, a, a\u2032)) is not identified. If p(W \u2032\u2032(\u03c0, a, a\u2032)) is not identified, note that W \u2032\u2032 is a strictly smaller set then W \u2032, and we restart the base case argument, finding either a hedge or a recanting district for this smaller set, constructing a new set H , and a new backdoor path to an element in Y . Since the new subset of W is strictly smaller, we can only do this a finite number of times before encountering another base case.\nIf Zi is in D, then the resulting graphG \u2032 H\u2032 contains a recanting district structure for p(Zj(\u03c0, a, a \u2032),W \u2032(\u03c0, a, a\u2032)) with the set of childless vertices of the previous district and also Zi (since it is now childless in H). Given the recanting district construction, p1(Zj(\u03c0, a, a\n\u2032) = 0 | W \u2032(\u03c0, a, a\u2032) = 0) < 1, while p2(Zj(\u03c0, a, a\n\u2032) = 0 | W \u2032(\u03c0, a, a\u2032) = 0) = 1, and we are done.\nSince we now established bases for the induction for the recanting district case, we can apply the inductive argument for the hedge case to conclude p(Y (\u03c0, ai, a \u2032 i) | W \u2032(\u03c0, ai, a \u2032 i)) is not identified, as above. Having established that p(Y (\u03c0, ai, a \u2032 i) | W \u2032(\u03c0, ai, a \u2032 i)) is not identified in GH\u2032 or G\u2032H\u2032 , it is trivial to extend p1(H \u2032) and p2(H\n\u2032) to p1(V) and p2(V) for G(V ).\nFinally, our conclusion is established for Ge(V,ACh) and p(Y (a\u03c0) |W (a\u03c0)) by Proposition ."}, {"heading": "A Weaker Causal Model", "text": "We phrased all our discussion in terms of the functional causal model, defined by the restriction (3). A weaker causal model called the finest fully randomized causally interpretable structured tree graph (FFRCISTG) suffices for many causal inference tasks. This model asserts that the variables,\n{Vi(pai) | i \u2208 {1, . . . , k}} , (10)\nare mutually independent for every v \u2208 XV , where pai is the subset of v associated with Pai. Note that the set of independences asserted by (10) is a subset of the set of independences asserted by (3). In particular, (10) only asserts independences among a set of potential outcomes associated with a globally consistent intervention operation, while (3) may allow independences among potential\noutcomes with inconsistent interventions. For example, a model defined by (3) may assert that Y (a,m) \u22a5\u22a5 M(a\u2032), while (10) never asserts such an independence if a 6= a\u2032.\nSince the SWIG global Markov property only asserts independences on random variables associated with a globally consistent intervention operation, it is implied not only by (3) but also the weaker model represented by (10) [2]. Potential outcomes like p(Y (a,M(a\u2032))) that arise in mediation analysis are not identified under (10), but are sometimes identified under (3); see [7] for details. Note, however, that our rephrasing of edge-consistent counterfactuals p(Vi(\u03c0, a, a \u2032)) in the causal model for G(V ) in terms of an intervention p(Vi(a \u03c0)) in the extended causal model for Ge(V \u222a ACh) leads to an identification theory for which model (10) for the variables in Ve is sufficient. The reason that counterfactuals p(Vi(\u03c0, a, a \u2032)) requiring the stronger set of assumptions (3) may be rephrased as counterfactuals p(Vi(a \u03c0)) only requiring the weaker set of assumptions (10) has to do with the specific way in which Ge was constructed. Specifically, Ge implicitly imposed strong restrictions on the associated FFRCISTG, having to do with deterministic relationships between Ai and A j i as well as absences of edges between any element Aji in A Ch and any element in ChGi other than Vj . Had these edges not been absent in Ge, identification would no longer be possible. In some sense, Ge is the graph corresponding to the \u201cweakest\u201d FFRCISTG that encodes assumptions associated with the functional model on G. These assumptions may be viewed informally as stating that a treatment variable Ai in A may be decomposed into components that only influence particular children (immediate effects) of Ai, and no other children of Ai."}], "title": "A Potential Outcomes Calculus for Identifying Conditional Path-Specific Effects", "year": 2019}