{"abstractText": "Recommendation systems are an integral part of Artificial Intelligence (AI) and have become increasingly important in the growing age of commercialization in AI. Deep learning (DL) techniques for recommendation systems (RS) provide powerful latent-feature models for effective recommendation but suffer from the major drawback of being non-interpretable. In this paper we describe a framework for explainable temporal recommendations in a DL model. We consider an LSTM based Recurrent Neural Network (RNN) architecture for recommendation and a neighbourhoodbased scheme for generating explanations in the model. We demonstrate the effectiveness of our approach through experiments on the Netflix dataset by jointly optimizing for both prediction accuracy and explainability.", "authors": [{"affiliations": [], "name": "Homanga Bharadhwaj"}, {"affiliations": [], "name": "Shruti Joshi"}], "id": "SP:03c0463b817f98e68707ece2c6517f1463bdf8a0", "references": [{"authors": ["Abadi et al", "2016] Mart\u0131\u0301n Abadi", "Paul Barham", "Jianmin Chen", "Zhifeng Chen", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Geoffrey Irving", "Michael Isard"], "title": "Tensorflow: A system for large-scale machine learning", "venue": "In OSDI,", "year": 2016}, {"authors": ["Abdollahi", "Nasraoui", "2016a] Behnoush Abdollahi", "Olfa Nasraoui"], "title": "Explainable matrix factorization for collaborative filtering", "venue": "In Proceedings of the 25th International Conference Companion on World Wide Web,", "year": 2016}, {"authors": ["Behnoush Abdollahi", "Olfa Nasraoui"], "title": "Explainable restricted boltzmann machines for collaborative filtering", "venue": "arXiv preprint arXiv:1606.07129,", "year": 2016}, {"authors": ["Alexander Binder", "Sebastian Bach", "Gregoire Montavon", "Klaus-Robert M\u00fcller", "Wojciech Samek. Layer-wise relevance propagation for deep neural network architectures"], "title": "In Information Science and Applications (ICISA) 2016", "venue": "pages 913\u2013922. Springer,", "year": 2016}, {"authors": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "title": "On the properties of neural machine translation: Encoder-decoder approaches", "venue": "arXiv preprint arXiv:1409.1259,", "year": 2014}, {"authors": ["Robin Devooght", "Hugues Bersini. Long", "short-term recommendations with recurrent neural networks"], "title": "In Proceedings of the 25th Conference on User Modeling", "venue": "Adaptation and Personalization, pages 13\u201321. ACM,", "year": 2017}, {"authors": ["Diao et al", "2014] Qiming Diao", "Minghui Qiu", "Chao-Yuan Wu", "Alexander J Smola", "Jing Jiang", "Chong Wang"], "title": "Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)", "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discov-", "year": 2014}, {"authors": ["Tim Donkers", "Benedikt Loepp", "J\u00fcrgen Ziegler. Sequential user-based recurrent neural network recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems"], "title": "pages 152\u2013 160", "venue": "ACM,", "year": 2017}, {"authors": ["He et al", "2015] Xiangnan He", "Tao Chen", "Min-Yen Kan", "Xiao Chen"], "title": "Trirank: Review-aware explainable recommendation by modeling aspects", "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "year": 2015}, {"authors": ["Jonathan L Herlocker", "Joseph A Konstan", "John Riedl. Explaining collaborative filtering recommendations"], "title": "In Proceedings of the 2000 ACM conference on Computer supported cooperative work", "venue": "pages 241\u2013250. ACM,", "year": 2000}, {"authors": ["Hidasi et al", "2016] Bal\u00e1zs Hidasi", "Massimo Quadrana", "Alexandros Karatzoglou", "Domonkos Tikk"], "title": "Parallel recurrent neural network architectures for feature-rich", "year": 2016}, {"authors": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber. Long short-term memory"], "title": "Neural computation", "venue": "9(8):1735\u20131780,", "year": 1997}, {"authors": ["Yifan Hu", "Yehuda Koren", "Chris Volinsky. Collaborative filtering for implicit feedback datasets. In Data Mining"], "title": "2008", "venue": "ICDM\u201908. Eighth IEEE International Conference on, pages 263\u2013272. Ieee,", "year": 2008}, {"authors": ["Diederik P Kingma", "Jimmy Ba"], "title": "Adam: A method for stochastic optimization", "venue": "arXiv preprint arXiv:1412.6980,", "year": 2014}, {"authors": ["Yehuda Koren. Collaborative filtering with temporal dynamics"], "title": "Communications of the ACM", "venue": "53(4):89\u201397,", "year": 2010}, {"authors": ["Pasquale Lops", "Marco De Gemmis", "Giovanni Semeraro"], "title": "Content-based recommender systems: State of the art and trends", "venue": "Recommender systems handbook, pages 73\u2013105. Springer,", "year": 2011}, {"authors": ["Andriy Mnih", "Ruslan R Salakhutdinov. Probabilistic matrix factorization"], "title": "In Advances in neural information processing systems", "venue": "pages 1257\u20131264,", "year": 2008}, {"authors": ["Michael J Pazzani", "Daniel Billsus. Content-based recommendation systems. In The adaptive web"], "title": "pages 325\u2013341", "venue": "Springer,", "year": 2007}, {"authors": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "title": "Dropout: A simple way to prevent neural networks from overfitting", "venue": "The Journal of Machine Learning Research, 15(1):1929\u20131958,", "year": 2014}, {"authors": ["Nava Tintarev", "Judith Masthoff. Designing", "evaluating explanations for recommender systems. In Recommender systems handbook"], "title": "pages 479\u2013510", "venue": "Springer,", "year": 2011}, {"authors": ["Chao-Yuan Wu", "Amr Ahmed", "Alex Beutel", "Alexander J Smola", "How Jing. Recurrent recommender networks. In Proceedings of the Tenth ACM International Conference on Web Search", "Data Mining"], "title": "pages 495\u2013503", "venue": "ACM,", "year": 2017}, {"authors": ["Ye Zhang", "Byron Wallace"], "title": "A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classification", "venue": "arXiv preprint arXiv:1510.03820,", "year": 2015}, {"authors": ["Yongfeng Zhang. Incorporating phrase-level sentiment analysis on textual reviews for personalized recommendation. In Proceedings of the eighth ACM international conference on web search", "data mining"], "title": "pages 435\u2013440", "venue": "ACM,", "year": 2015}], "sections": [{"heading": "1 Introduction", "text": "Explainability in machine learning models has been a topic of intense research and debate. The issue of explainability in recommendation systems (RS) is all the more pertinent due to their sheer ubiquity. RS have become embedded in all forms of user-interface interaction and now form the core of our every day activities. So, to improve users\u2019 experience and trust, transparency and explainability are increasingly being incorporated in practical recommender systems. For instance, Netflix justifies the movies recommended by displaying similar movies obtained through the social network of users. Similarly, Amazon justifies its recommendations by showing similar items obtained through neighbourhood based Collaborative Filtering (CF). There has been growing research in Deep Learning (DL) based models for recommendations which are known for giving excellent prediction accuracies. Now there is almost a universal consensus regarding the fact that the main drawback of Deep Learning models is their non-interpretability, however there have been recent efforts towards mitigating this drawback such as [Binder et al., 2016; Zhang and Wallace, 2015].\nFor RS, most explanation based methods either fall into the classical neighbourhood based Collaborative Filtering (CF) or rule-based methods [Pazzani and Billsus, 2007;\nLops et al., 2011]. CF based recommendation methods, which leverage the wisdom of the crowd are more popular due to their scalability and robustness. Some recent works such as [Abdollahi and Nasraoui, 2016a] and [Abdollahi and Nasraoui, 2016b] have integrated explanations into Matrix Factorization (which is a latent factor model), and into Restricted Boltzmann Machines respectively. These however cannot be applied to temporal recommendations which seek to model user preferences over time. Modeling temporal evolution of user preferences and item states for effective recommendation systems (RS) is an active area of research and recent publications have illustrated the effectiveness of Recurrent Neural Networks (RNN) [Wu et al., 2017; Hidasi et al., 2016] for the same.\nRecurrent Recommender Networks [Wu et al., 2017] is a powerful technique of temporal recommendations. We build our model on top of this architecture by incorporating a neighbourhood-style explanation scheme. Here, LSTM [Hochreiter and Schmidhuber, 1997] based RNNs are used for modelling user and item latent states. The specific domain of movie recommendation is targeted in the experiments but the method is fairly generalizable across domains. We first formalize the notion of explainability by defining a timevarying bipartite graph between users and items such that the edge weights measure a notion of explainability of an item for a user by exploiting ratings of other users similar to the one in question. To optimize for explainability in addition to the prediction accuracy, we include a term in the optimization objective that seeks to minimize the distance between latent features of items and users weighed by their explainability as defined previously."}, {"heading": "2 Related Works", "text": ""}, {"heading": "2.1 Explainable Recommendations", "text": "Explanations in recommendation systems has been a topic of active research for a very long time, motivated by the general consensus that modern RS algorithms have been black boxes offering no transparency or human-interpretable insights. Although the underlying algorithm of a recommendation framework may influence the type of explanations generated, it is also an ecologically valid method to have a completely separate engine for generating explanations [Tintarev and Masthoff, 2011]. This is particularly interesting for com-\nar X\niv :1\n80 7.\n06 16\n1v 1\n[ cs\n.A I]\n1 7\nJu l 2\n01 8\nplex RS models like those using collaborative filtering and/or deep learning techniques [Herlocker et al., 2000; Hu et al., 2008]. Some methods generate explanations based on auxiliary data like review texts [Zhang, 2015] while others do not require additional information (apart from that used in the recommendation algorithm) for generating explanations [Abdollahi and Nasraoui, 2016b; Abdollahi and Nasraoui, 2016a; Herlocker et al., 2000]."}, {"heading": "2.2 Temporal Recommendations", "text": "The temporal evolution of user preferences and item states has been discussed in multiple previous works. Recent papers which have been very impactful include [Donkers et al., 2017] and RRN [Wu et al., 2017]. [Donkers et al., 2017] developed a Gated Recurrent Unit(GRU) [Cho et al., 2014] based RNN for sequential modelling of user preferences. A rectified linear integration of user states is done in their modified GRU cell to evolve each user state for personalized recommendation. On the other hand, RRN targeted movie recommendation tasks by exploiting explicit feedback from users. Customized LSTM cells were used for modelling the function through which user and item latent states evolve. [Devooght and Bersini, 2017] leverage sequence information to mitigate the scarcity of user-item interactions and identify items that will be eventually preferred and that those that will be immediately desired. Since our architecture is built over RRN, we elaborate on the details in Section 3.2."}, {"heading": "3 The Model", "text": ""}, {"heading": "3.1 Explanations", "text": "Our model uses only the users\u2019 movie rating data for predicting as well as explaining recommendations. This is in contrast to many previous studies that consider other data variables such as user demographics, text reviews [Zhang, 2015], user preferences for entities associated with the items to be recommended [He et al., 2015], etc for predicting recommendations, as well as studies that use these data variables as auxiliary information for only explaining their recommendations [Herlocker et al., 2000]. We employ a neighbourhood based explanation scheme which is similar to [Abdollahi and Nasraoui, 2016b] and formalize the definition of neighbourhood and explainability as follows.\nNeighbourhood is calculated based on discounted cosine similarity between the users\u2019 (say user i and user k) as simi,k = \u2211 t,m \u03b3trim|t \u00b7 rkm|t, where the discounting factor, \u03b3t = 11+t and rim|t represents user i\u2019s rating at time t for a movie m. We then pick the p most similar users as the neighbourhood of user i.\nThis notion of a neighbourhood style explanation has also been employed in various graph based models such as [He et al., 2015]. We define a temporally varying bipartite graph between the set of users and the set of items with the following edge weight matrix\nMumt =\n\u2211 z\u2208Qpt (u) rzm|t\np\u00d7max{rzm|t\u2200z \u2208 Qpt (u)} (1)\nHere Qpt (u) is the set of p neighbours for user u and rzm|t is the rating of user z of movie m at time step t. It is important\nto note thatMumt, which represents the edge-weight between user u and movie m at time step t is a real number between 0 and 1. It has the interpretation of being a quantification of how explainable is movie m for user u. rzm|t is 0 if user z has not rated item m at time step t. So, a value of Mumt = 0 would mean that none of the users in the neighborhood of user u have rated movie m at time step t and hence movie m is not explainable to user u at that time step.\nIn addition, since we postulate that there are stationary components as well in the latent features of users and items (Section 3.2) we also develop a stationary bipartite graph between the set of users and the set of items for explanations. This is in addition to the above time varying interpretation. For this bipartite graph, the edge weight matrix is described as\nMum =\n\u2211 z\u2208Qp(u) rzm\np\u00d7max{rzm\u2200z \u2208 Qp(u)} (2)\nHere, all the terms have the same meaning as in the previous equation, but they appear without the time index."}, {"heading": "3.2 The Rating Prediction Model", "text": "We use LSTM based Recurrent Neural Networks for modelling the temporal evolution of user and movie latent states. The approach is essentially matrix factorization through time with the temporal evolution of latent factors being modelled by LSTM based Recurrent Neural Networks. This approach is similar in spirit to RRN [Wu et al., 2017] and the novelty of our method is the incorporation of explainability which we describe in Section 3.3.\nWe denote by uit and mjt, the latent features of user i and movie j respectively at time index t. Let r\u0302ij|t denote the predicted rating for user i on movie j at time index t and let rij|t be the actual rating. {rij|t}j denotes the set of ratings for all movies j. We define the following model for updates\nr\u0302ij|t = f(uit,mjt)\nui,t+1 = g(uit, {rij|t}j) mi,t+1 = h(mit, {rij|t}j)\nThe functions f, g, h are learned by the model to infer user and movie states. Section 3.1 of the RRN paper [Wu et al., 2017] elaborates on the user and movie state formulation, which we mention briefly below.\nyt = V [xt, 1, \u03c4t, \u03c4t\u22121], ut = LSTM(ut\u22121, yt)\nHere \u03c4t represents the wallclock at time t, xt is the rating vector for the user and V represents the transformation. Similar to the approach followed in RRN [Wu et al., 2017], we include the profile identities of the user and the movie as the stationary components of the rating in addition to their time varying state vectors. So,\nr\u0302ij|t = f(uit,mjt, ui,mj)\n= \u3008u\u0303it, m\u0303jt\u3009+ \u3008ui,mj\u3009 where u\u0303it = Auit + c & m\u0303jt = Bmjt + d. This decomposition makes it evident how RRN is essentially matrix factorization through time as mentioned earlier."}, {"heading": "3.3 Incorporating Explainability in the Model", "text": "Since the user and item (movie) states are time varying, we need a time varying bipartite graph which is defined by a time varying edge-weight matrix Mijt. If movie j is explainable to user i in at time step t, then their latent representations m\u0303jt and u\u0303it respectively must be close. Based on this intuition, we include the term (m\u0303jt\u2212 u\u0303it)2Mijt in our minimization objective. We formulate the overall objective in such a way that both prediction accuracy as well as explainability are optimized. So, if there are two movies which are likely to be equally preferred by the user, the model will recommend the movie which is more explainable. It is important to note that explainability and prediction accuracy may be at odds for some user-movie pairs and hence we need to define a joint objective function including both the aspects, which is defined as follows\nL = \u2211 i,j ( \u2211 t (rij|t \u2212 r\u0302ij|t(\u03b8))2 + \u03b1(m\u0303jt \u2212 u\u0303it)2Mijt)\n+\u03b2(mjt \u2212 uit)2Mij) +R(\u03b8) The benefit of having temporally varying explanationgraphs is that the generated explanations aren\u2019t the conventional \u20187/10 people with similar interests as you have rated this movie 4 and higher\u201d but can employ information related to rating distribution across time too, as seen in Figure 1.\nIf we use the heuristic that explanations in the near past are more relevant than those in the far past, we can weigh the term (m\u0303jt \u2212 u\u0303it)2Mijt for explanations by a temporally\ndecaying factor \u03b1(t). In this paper, we use the specific form of \u03b1(t) to be exp (\u2212\u03b1t) but there are other popular choices of this discount factor as well [cite other decaying functions used in ML training]. So, the modified objective function becomes\nL\u2032 = \u2211 i,j ( \u2211 t (rij|t \u2212 r\u0302ij|t(\u03b8))2 + e(\u2212\u03b1t)(m\u0303jt \u2212 u\u0303it)2Mijt)\n+\u03b2(mjt \u2212 uit)2Mij) +R(\u03b8)\nHere, we call the model corresponding to the objective function L as TempEx-Dry and the one corresponding to L\u2019 as TempEx-Fluid. We then perform simulations for both the objective functions and compare their pros and cons empirically."}, {"heading": "3.4 Training", "text": "Although the conventional method of training Recurrent Neural Networks is Backpropagation Through Time (BPTT), as mentioned in [Wu et al., 2017], backpropagation through two sequences (rating depends on both user state RNN and item state RNN) is computationally infeasible. We adopt the strategy of subspace descent as done in [Wu et al., 2017] to alleviate this problem. In practice, we found that using Dropout [Srivastava et al., 2014] helps in stabilizing the gradients and preventing over-fitting due to the additional terms introduced in the minimization objective. The hyperparameters \u03b1 and \u03b2 were tuned by a grid-search in the range 0 to 1 and the tuned value of \u03b1 is kept at 0.4, while that of \u03b2 is kept at 0.6 throughout all experiments."}, {"heading": "4 Simulation Studies", "text": ""}, {"heading": "4.1 Setup", "text": "Through a series of simulation experiments, we seek to understand two basic questions, 1) How effective is the model in generating explanations? and 2) What is the trade-off between prediction accuracy and explainability? All our experiments have been done using Tensorflow r1.4 [Abadi et al., 2016] in Python 3. We use ADAM optimizer during training [Kingma and Ba, 2014]. We perform all experiments on a timestamped Netflix dataset used in [Wu et al., 2017], which was first used in [Diao et al., 2014]. It consists of 100M movie ratings from 1999 to 2005, where each data point is a (user-id, item-id, time-stamp, rating) tuple with a time stamp granularity of 1 day. For consistency, we use the same preprocessing and train-test split as in [Wu et al., 2017]."}, {"heading": "4.2 Benefit of Explanations", "text": "To answer 1), we use standard IR metrics like precision and recall with the notion of explainability. [Abdollahi and Nasraoui, 2016b] introduces Mean Explainable Precision (MEP) and Mean Explainable Recall (MER) metrics. To state briefly, MEP is defined as the ratio of the number of explainable items recommended to the total recommended items for each user averaged over all users. Similarly, MER is the number of explainable items recommended to the total number of explainable items for each user averaged over all users. We benchmark our performance against state of the art models such\nTable 1: RMSE and MRR for benchmark models at p = 50 for the Netflix dataset\nRRN T-SVD PMF ERBM EMF TempEx-Dry TempEx-Fluid\nMRR 0.371 0.342 0.322 0.321 0.318 0.374 0.382 RMSE 0.922 0.927 0.925 0.931 0.934 0.923 0.919\nFigure 2: MEP, MER, Mean Average Precision (MAP) and MR (Mean Recall) for benchmark models with varying number of neighbours. All the values are averaged over the test set for all users\nas RRN, T-SVD, PMF and recent explainable CF methods like EMF and ERBM [Wu et al., 2017; Mnih and Salakhutdinov, 2008; Koren, 2010; Abdollahi and Nasraoui, 2016a; Abdollahi and Nasraoui, 2016b]. We also evaluate two versions of our model- without incorporation of the temporally weighted explanation term (TempEx-Dry), and with an exponentially decaying temporal weight on explanations (TempEx-Fluid).\nAs revealed in the top row of Figure 2, TempEx-Fluid has the best measure of explainability across all values of p and it also performs consistently better than TempEx-Dry. So, temporally weighing the explainability term indeed leads to a more explainable model."}, {"heading": "4.3 Tradeoff between Explanations and Prediction Accuracy", "text": "To answer 2), we evaluate the performance of our model against benchmark models on standard metrics like RMSE, Mean Average Precision (MAP), Mean Recall (MR) and Mean Reciprocal Rank (MRR). The purpose of this evaluation is to see whether incorporation of the explainability terms in the optimization objective leads to substantial gains /losses on the actual prediction accuracy of ratings.\nTable 1 and the bottom row of Figure 2 shows the results of our analysis. At p = 50 we observe that the RMSE and MRR values of TempEx-Fluid are higher than the standard RRN model. This indicates that incorporating explainability also\nimproves the prediction accuracy on the test set by imposing an additional regularizer in the model. The bottom row of Figure 2 shows that TempEx-Fluid consistently has better performance on Mean Average Precision and Mean Recall for all values of p. This leads further credence to the fact that there is no compromise being made on prediction accuracy by including explainability. Also, a comparison between TempEx-Dry and TempEx-Fluid reveals that TempEx-Fluid performs consistently better for all values of p. This is due to the more nuanced temporal decay in the optimization objective which appropriately weighs down past effects."}, {"heading": "5 Conclusion", "text": "In this paper, we devised a methodology of incorporating explanations in time-series recommendation. We devised a time-varying neighbourhood style explanation scheme and jointly optimized for prediction accuracy and explainability. Through simulation results we demonstrated the efficacy of the proposed framework. It is important to note that our method of explanation is different from the core recommendation algorithm, which is a common practice in explainable RS. However, as future work we plan to devise an explanation scheme that tries to explain the recommendation algorithm. Since, our algorithm is a deep learning model, we need to incorporate schemes like layer-wise relevance propagation that seek to propagate the relevance of the output through the layers of the network and assign relevance to the inputs."}], "title": "Explanations for Temporal Recommendations", "year": 2020}