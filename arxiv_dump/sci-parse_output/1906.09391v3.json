{
  "abstractText": "The interpretability of machine learning, particularly for deep neural networks, is crucial for decision making in real-world applications. One approach is replacing the un-interpretable machine learning model with a surrogate model, which has a simple structure for interpretation. Another approach is understanding the target system by using a simulation modeled by human knowledge with interpretable simulation parameters. Recently, simulator calibration has been developed based on kernel mean embedding to estimate the simulation parameters as posterior distributions. Our idea is to use a simulation model as an interpretable surrogate model. However, the computational cost of simulator calibration is high owing to the complexity of the simulation model. Thus, we propose a \u201cmodel-bridging\u201d framework to bridge machine learning models with simulation models by a series of kernel mean embeddings to address these difficulties. The proposed framework enables us to obtain predictions and interpretable simulation parameters simultaneously without the computationally expensive calculations of the simulations. In this study, we apply the proposed framework to essential simulations in the manufacturing industry, such as production simulation and fluid dynamics simulation.",
  "authors": [
    {
      "affiliations": [],
      "name": "Keiichi Kisamori"
    },
    {
      "affiliations": [],
      "name": "Keisuke Yamazaki"
    },
    {
      "affiliations": [],
      "name": "Yuto Komori"
    },
    {
      "affiliations": [],
      "name": "Hiroshi Tokieda"
    }
  ],
  "id": "SP:3f4ec19185aeae180b0e19bd99a7a1d1c591c1c3",
  "references": [
    {
      "authors": [
        "Y. Chen",
        "M. Welling",
        "A. Smola"
      ],
      "title": "Super-samples from kernel herding",
      "venue": "Proceedings of the Twenty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence pp. 109\u2013116",
      "year": 2010
    },
    {
      "authors": [
        "A. Christmann",
        "I. Steinwart"
      ],
      "title": "Universal Kernels on Non-Standard Input Spaces",
      "venue": "Advances in Neural Information Processing Systems",
      "year": 2010
    },
    {
      "authors": [
        "F. Doshi-Velez",
        "B. Kim"
      ],
      "title": "Towards A Rigorous Science of Interpretable Machine Learning (2017)",
      "year": 2013
    },
    {
      "authors": [
        "K. Fukumizu",
        "L. Song",
        "A. Gretton"
      ],
      "title": "Kernel Bayes\u2019 Rule: Bayesian Inference with Positive Definite Kernels",
      "venue": "Journal of Machine Learning Research 14, 3753\u20133783",
      "year": 2013
    },
    {
      "authors": [
        "R. Guidotti",
        "A. Monreale",
        "S. Ruggieri",
        "F. Turini",
        "D. Pedreschi",
        "F. Giannotti"
      ],
      "title": "A Survey Of Methods For Explaining Black Box Models (2018)",
      "year": 2018
    },
    {
      "authors": [
        "G. Hinton",
        "O. Vinyals",
        "J. Dean"
      ],
      "title": "Distilling the Knowledge in a Neural Network",
      "venue": "arXiv:1503.02531v1",
      "year": 2015
    },
    {
      "authors": [
        "M. Kanagawa",
        "P. Hennig",
        "D. Sejdinovic",
        "B.K. Sriperumbudur"
      ],
      "title": "Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences",
      "venue": "arXiv:1807.02582v1",
      "year": 2018
    },
    {
      "authors": [
        "M.C. Kennedy",
        "A. O\u2019Hagan"
      ],
      "title": "Bayesian calibration of computer models",
      "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology) 63(3), 425\u2013464",
      "year": 2001
    },
    {
      "authors": [
        "K. Kisamori",
        "M. Kanagawa",
        "K. Yamazaki"
      ],
      "title": "Simulator Calibration under Covariate Shift with Kernels",
      "venue": "Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics",
      "year": 2020
    },
    {
      "authors": [
        "S.Y. Kung"
      ],
      "title": "Kernel Methods and Machine Learning",
      "venue": "Cambridge University Press",
      "year": 2014
    },
    {
      "authors": [
        "H.C.L. Law",
        "D.J. Sutherland",
        "D. Sejdinovic",
        "S. Flaxman"
      ],
      "title": "Bayesian Approaches to Distribution Regression",
      "venue": "Proceedings of the 21st International Conference on Artificial Intelligence and Statistics",
      "year": 2017
    },
    {
      "authors": [
        "J. Lee",
        "Y. Bahri",
        "R. Novak",
        "S.S. Schoenholz",
        "J. Pennington",
        "J. Sohl-Dickstein"
      ],
      "title": "Deep Neural Networks as Gaussian Process",
      "venue": "Proceedings of The International Conference on Learning Representations",
      "year": 2018
    },
    {
      "authors": [
        "S.M. Lundberg",
        "S.I. Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "Advances in Neural Information Processing Systems",
      "year": 2017
    },
    {
      "authors": [
        "C. Molnar"
      ],
      "title": "Interpretable Machine Learning",
      "venue": "Christoph Molnar",
      "year": 2019
    },
    {
      "authors": [
        "K. Muandet",
        "K. Fukumizu",
        "B. Sriperumbudur",
        "B. Scholkopf"
      ],
      "title": "Kernel Mean Embedding of Distributions: A Review and Beyonds",
      "venue": "arXiv:1605.09522 p.133",
      "year": 2016
    },
    {
      "authors": [
        "S. Nakagome",
        "K. Fukumizu",
        "S. Mano"
      ],
      "title": "Kernel approximate Bayesian computation in population genetic inferences",
      "venue": "Statistical Applications in Genetics and Molecular Biology 12(6), 667\u2013678",
      "year": 2013
    },
    {
      "authors": [
        "R.M. Neal"
      ],
      "title": "Bayesian Learning for Neural Networks",
      "venue": "Springer",
      "year": 1996
    },
    {
      "authors": [
        "J.B. Oliva",
        "J. Schneider"
      ],
      "title": "Distribution to Distribution Regression",
      "venue": "Proceedings of The 30th International Conference on Machine Learning",
      "year": 2013
    },
    {
      "authors": [
        "M.T. Ribeiro",
        "S. Singh",
        "C. Guestrin"
      ],
      "title": "Why Should I Trust You?\u201d Explaining the Predictions of Any Classifier",
      "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
      "year": 2016
    },
    {
      "authors": [
        "Z. Szabo",
        "B. Sriperumbudur",
        "B. Poczos",
        "A. Gretton"
      ],
      "title": "Learning Theory for Distribution Regression",
      "venue": "Journal of Machine Learning Research 17, 1\u201340",
      "year": 2016
    },
    {
      "authors": [
        "T. Wang"
      ],
      "title": "Gaining Free or Low-Cost Transparency with Interpretable Partial Substitute",
      "venue": "Proceedings of the 36th International Conference on Machine Learning",
      "year": 2019
    }
  ],
  "sections": [
    {
      "text": "Keywords: Interpretability \u00b7 Simulation model \u00b7 Kernel mean embedding \u00b7 Data assimilation."
    },
    {
      "heading": "1 Introduction",
      "text": "The interpretability of machine learning, especially for deep neural networks, is crucial for decision making in real-world applications. In recent years, many studies have addressed the interpretability of neural networks [6,4,15]. One of the approaches is replacing the un-interpretable machine learning model with a surrogate model, which has a simple structure for interpretation. This approach is a type of model compression. For instance, the \u201cdistillation\u201d of a neural network model [7] is one of the representative methods for model compression for replacing a complex model with a simplified model; however, there is no interpretability for a small surrogate neural network model. There are some methods to obtain an interpretable model, such as LIME [20], SHAP [14], and a method\nar X\niv :1\n90 6.\n09 39\n1v 3\n[ st\nat .M\nL ]\n2 1\nJu l 2\nTable 1. Comparison between machine learning models and simulation models.\nmachine learning model simulation model\ninterpretability of parameter un-interpretable interpretable computational cost of the model not expensive expensive\nSimulation model: \" = $%&'(); +)\n- = ./, 1/\nMachine learning model: \" = $'2(); 3)\n(Surrogate) Model bridging\nData: Simulator CalibrationMachine learning\nparameter 3 parameter +\nRKHS (eg. + is elapsed time of \u201cProcess A\u201d.)(eg. 3 is weight of NN.)\nFig. 1. Basic idea of the model-bridging framework.\ncombined with a rule-based model [22]. These methods do not provide a clear pathway toward obtaining the interpretability of a neural network, as there are limitations to obtain local interpretability regarding the decision boundary of the prediction result [6,4].\nAnother approach for understanding the target system is by employing a simulation that might be outside the scope of conventional machine learning. In some application fields, simulations such as multi-agent simulation, traffic simulation, production simulation, or simulation of the dynamics of the physical system have already been used to understand the target system and to predict future behavior. Simulation modeling is implemented to describe the fundamental law of the objective system, using human knowledge with interpretable simulation parameters. The recently developed \u201csimulator calibration\u201d [9,10,3] is a method in which the simulation parameters are estimated as posterior distributions in the context of machine learning. Simulator calibration can provide a predictive result with interpretable simulation parameters. Our idea is to use a simulation model as an interpretable surrogate model. However, the difficulty of simulator calibration is attributed to a substantial computational cost; it typically takes more than one hour owing to the complexity of the simulation model (Table 1). In real-world applications, a predictive result and its reason often should be required to obtain within a minute.\nWe propose a \u201cmodel-bridging (MB) \u201d framework to predict using a machine learning model as well as obtain interpretable simulation parameters simultaneously without expensive calculation of a simulation model. The idea of this framework is to map the un-interpretable parameters of the machine learning model and the interpretable parameters of the simulation model (Fig. 1). The algorithm has to learn the relation of the posterior distribution estimated from each dataset between the machine learning model and the simulation model in advance; this framework can be considered as a meta-learning for each dataset.\nLet us consider the example of production simulation for predicting the efficiency of manufacturing production, implementing a series of processes for production (example in Fig. 4). The production simulation aims to obtain a production efficiency and the reason for it simultaneously within a minute to improve the production efficiency. We formulate this problem setting. Assume that we obtain the dataset {Xn, Y n} = {X1, ..., Xn, Y1, ..., Yn}, where input Xi \u2208 Rdx is the number of products to be manufactured in unit time and output Yi \u2208 Rdy is the efficiency of production. The simulation parameter \u03b8 \u2208 Rd\u03b8 is the elapsed time for each process, which undergoes a probabilistic behavior. The parameter \u03b8 is interpretable and helpful in understanding the system and decision making. Thus, we need to obtain the prediction Y\u0302n+1 for new data Xn+1 as well as obtain the interpretable simulation parameters \u03b8 representing the elapsed time of each process, which provides information regarding the occurrence of \u201cbottleneck processes.\u201d Here, the observed data and its generation process are considered to drift gradually, for example, the daily production of the factory due to the load of labors and machine environment factors such as temperature. The detailed assumption is described in a later section.\nNote that this study considered a different problem setting from the conventional methods with simplified surrogate models, such as LIME, SHAP, and rule-based model; the interpretable model of the proposed method, i.e., simulation model, is complex and computationally expensive. There is no existing method for solving this new problem setting, where it is difficult to show the baseline for the evaluation. Experimentally, we confirm that the estimation of model bridging is reasonable in comparison with simulator calibration as a baseline with a significantly fast process owing to no execution of the simulation.\nThe main contribution of this paper is to propose a novel framework for bridging machine learning and simulation, which has never been discussed before from the context of machine learning and to demonstrate its effectiveness in realworld applications. The technical contribution is to expend the distribution-todistribution regression on reproducing kernel Hilbert space (RKHS), as a suitable method for bridging function. The rest of this paper is organized as follows. We briefly review a series of applications of kernel mean embedding as the building blocks for the proposed framework. Subsequently, we propose the model-bridging framework. Finally, we confirm the accuracy of the proposed method for three cases of simulation."
    },
    {
      "heading": "2 Related Works",
      "text": "We briefly introduce simulator calibration and distribution regression based on kernel mean embedding as a building block of the proposed framework."
    },
    {
      "heading": "2.1 Simulator Calibration",
      "text": "\u201cSimulator calibration\u201d [10] is a method for estimating the simulation parameter as the posterior distribution to reproduce real data. Simulator calibration is an\nexample of data assimilation. The simulation model is treated as a regression function fsim(x; \u03b8) by combining a series of kernel mean embedding methods. The conventional statistical methods of parameter estimation are not applicable to simulator calibration owing to the properties of the likelihood function: intractable or nondifferentiable. When Gaussian noise is employed with regression function fsim(x; \u03b8), the likelihood is expressed as\np(y|x, \u03b8) = 1\u221a 2\u03c0\u03c320 exp\n{ \u2212 1\n2\u03c320 \u2016y \u2212 fsim(x; \u03b8)\u20162\n} ,\nwhere \u03c30 > 0 is a constant of observation noise. This likelihood function is nondifferentiable owing to the simulation model fsim(x; \u03b8). The posterior mean to be obtained is formulated as p(\u03b8|Xn, Y n) = p(Y n|Xn, \u03b8)\u03c0(\u03b8)/Z(Xn, Y n), where \u03c0(\u03b8) is the prior distribution and Z(Xn, Y n) is the regularization constant. In this application, simulator calibration estimated the simulation parameter \u03b8 as a kernel mean of the posterior distribution by using kernel approximated Bayesian computation (kernel ABC) [17,5]. After obtaining the kernel mean of the posterior distribution, a posterior sample is obtained using kernel herding [1]."
    },
    {
      "heading": "2.2 Application of Kernel Mean Embedding",
      "text": "As an application of kernel mean embedding [16], we briefly review the kernel ABC and kernel herding. The kernel mean embedding is a framework for mapping distributions into a RKHS H as a feature space. Kernel herding is a sampling method from the embedded distribution in RKHS that has the opposite operation of kernel mean embedding. Figure 2 shows a schematic of the relation of kernel ABC and kernel herding.\nKernel ABC: Kernel ABC [17,5] is a method for computing the kernel mean of the posterior distribution from a sample of parameter \u03b8, generated by the prior distribution \u03c0(\u03b8). The assumption is that the explicit form of the likelihood function is unavailable, while the sample from the likelihood function is available. The kernel ABC allows us to calculate the kernel mean of the posterior distribution as follows. First, the sample {\u03b81, ..., \u03b8m} is generated from prior distribution \u03c0(\u03b8) and pseudo-data {Y\u0304 n1 , ..., Y\u0304 nm}, as a sample from p(y|x, \u03b8j) for j = 1, ...,m. Next, the empirical kernel mean of the posterior distribution\n\u00b5\u0302\u03b8|Y X = m\u2211 j=1 wjk\u03b8(\u00b7, \u03b8j) (1)\nis calculated, where k\u03b8 is a kernel of \u03b8. Weight wj is calculated by\n(w1, ..., wm) T = (Gy +m\u03b4I) \u22121ky(Y n) \u2208 Rm\nGy = {ky(Y\u0304 nj , Y\u0304 nj\u2032 )}mj,j\u2032=1 \u2208 Rm\u00d7m (2) ky(Y n) = (ky(Y\u0304 n 1 , Y n), ..., ky(Y\u0304 n m, Y n)) \u2208 Rm.\nThe \u03b4 \u2265 0 is a regularization constant, I is an identity matrix, and ky is a kernel of y. The kernel ky(Y\u0304 n j , Y n) indicates the \u201csimilarity\u201d between pseudodata Y\u0304 nj and real data Y n. The calculations of the kernel mean corresponds to the estimation of the posterior distribution as an element in H. Kernel Herding: Kernel herding [1] is a method used for sampling data from the kernel mean representation of a distribution, which is an element of the RKHS. Kernel herding can be considered as an opposite operation to that of kernel ABC. Kernel herding greedily obtains samples of \u03b8 by updating Eqs.(1) and (2) as given in Chen et al. [1]."
    },
    {
      "heading": "2.3 Distribution Regression",
      "text": "Distribution regression is a regression for dx-dimensional \u201cdistributions\u201d represented by samples. In contrast, normal regression is regression for dx-dimensional \u201cpoint.\u201d There are several studies of distribution regression, including distributionto-distribution regression [19] and distribution-to-point regression [21,12]. Oliva et al. [19] employed the idea of approximating a density function by kernel density estimation, rather than using RKHS. Szabo\u0301 et al. [21] proposed the distributionto-point with the kernel ridge regression method on RKHS; however, no methods are available for distribution-to-distribution regression on RKHS."
    },
    {
      "heading": "3 Proposed Framework: Model Bridging",
      "text": "We propose a novel framework to bridge the un-interpretable machine learning model and the interpretable simulation model. In this study, we assume a machine learning model, such as a Bayesian neural network (BNN) [18], as a parametric model and a Gaussian process as a non-parametric model. This proposed framework is applicable to any model. In this section, first, we confirm the problem setting and framework of model bridging. Second, we propose the algorithm of distribution-to-distribution regression, which is suitable for the proposed framework. Thereafter, we propose the formulation of the input of distribution-to-distribution regression for the parametric model, assuming BNN, and the non-parametric model, assuming the Gaussian process. Figure 3 and Alg. 1 shows an overview of the framework."
    },
    {
      "heading": "3.1 Problem Setting, Assumption, and Usage of Model Bridging",
      "text": "We define the problem setting of the model-bridging framework. Let L be dataset {Xnl , Y nl }Ll=1 (Xnl \u2208 Rn\u00d7dx , Y nl \u2208 Rn\u00d7dy ), given in the pre-learning phase. For\nsimplicity of explanation, we use the unique number of the data n and sample size m for all datasets. However, it can be different numbers generally, such as nl and ml. The purpose is to predict Y\u0302L+1,n+1 and simultaneously obtain interpretable simulation parameter \u03b8\u0302MBL+1 to reproduce YL+1,n+1 = fsim(XL+1,n+1; \u03b8\u0302 MB L+1) without the expensive calculation of simulation model fsim(x; \u03b8), when we obtain new dataset {XnL+1, Y nL+1}. The assumptions of the problem setting are as follows. These assumptions are prevalent for many applications of a simulation.\n\u2013 The existing simulation model fsim(x; \u03b8) with interpretable simulation parameter \u03b8 \u2208 Rd\u03b8 and a machine learning model fml(x; \u03be) that is sufficiently accurate to predict a typical regression problem while having un-interpretable parameter \u03be \u2208 Rd\u03be . \u2013 The cost of simulator calibration is much higher than that of learning for the machine learning model. For instance, it takes more than one hour for simulator calibration of one dataset {Xnl , Y nl }, while learning of BNN takes less than a minute. \u2013 Dataset {Xnl , Y nl } has dependency of parameter \u03b8l for each l = 1, ..., L. Let us assume the following situation. {Xnl , Y nl } is obtained in one day with the same conditions, described as parameter \u03b8l, while the conditions are changed for the following day, described as \u03b8l+1. \u2013 The time for offline calculation of simulator calibration is sufficient, while the time for prediction is restricted.\nOnce we obtain the model-bridging function as a mapping from the machine learning model to the simulation model, we can obtain an accurate prediction\nAlgorithm 1: Model bridging 1) Pre-learning for each dataset : Input: Dataset {Xnl , Y nl }Ll=1,\nmachine learning model fml(x, \u03be) and simulation model fsim(x, \u03b8)\nOutput: {\u00b5\u0302ml1 , ..., \u00b5\u0302mlL } and {\u00b5\u0302sim1 , ..., \u00b5\u0302simL } for l = 1 to L do\nEstimation for \u00b5\u0302mll by Eq. (7) Estimation for \u00b5\u0302siml by Eq. (1)\nend for 2) Learning for model-bridging function T\u0302 : Input: {\u00b5\u0302ml1 , ..., \u00b5\u0302mlL } and {\u00b5\u0302sim1 , ..., \u00b5\u0302simL } Output: Model-bridging function T\u0302 Learning for T\u0302 by Eq. (3) 3) Prediction: Input: Dataset {XnL+1, Y nL+1} and XL+1,n+1 Output: Y\u0302L+1,n+1 and \u03b8\u0302L+1 Estimation for \u03beL+1 and \u00b5\u0302 ml L+1 Prediction for Y\u0302L+1,n+1 by fml(x; \u03beL+1) Estimation for \u00b5\u0302MBL+1 = T\u0302 (\u00b5\u0302 ml L+1) by Eq. (5) Sampling for \u03b8\u0302MBL+1 by Eq. (6)\nfor Y\u0302L+1,n+1 by both the machine learning model and interpretable \u03b8\u0302 MB L+1 by the simulation model for new dataset {XnL+1, Y nL+1} without an expensive calculation from the simulation model."
    },
    {
      "heading": "3.2 Distribution-to-Distribution Regression",
      "text": "We present the regression algorithm between the conditional kernel mean of the machine learning model \u00b5ml \u2208 H and that of the simulation model \u00b5sim \u2208 H, as a model-bridging function \u00b5sim = T (\u00b5ml). We develop the algorithm based on kernel ridge regression, which is suitable for kernel mean input and output on RKHS. This is the extension of the distribution-to-point regression method proposed by Szabo\u0301 et al. [21] for the distribution output.\nKernel Ridge Regression for Kernel Mean The formulation to be solved as an analogy of normal kernel ridge regression is as follows:\nT\u0302 = arg max T\u2208F\n1\nL L\u2211 l=1 \u2016\u00b5\u0302siml \u2212 T (\u00b5\u0302mll )\u20162F + \u03bb\u2016T\u20162F , (3)\nwhere \u03bb \u2265 0 is a regularization constant. F is a function space of kernel mean embeddings following Christmann et al. [2] and \u2016 \u00b7 \u2016F is its norm. The difference from ordinary kernel ridge regression is that the inputs and outputs are kernel means. Therefore, we define kernel \u03ba \u2208 F , as a function of kernel mean \u00b5 \u2208 H.\nWe employ a Gaussian-like kernel as\n\u03ba(\u00b5, \u00b5\u2032) = exp { \u2212 1\n2\u03c32\u00b5 \u2016\u00b5\u2212 \u00b5\u2032\u20162H\n} \u2208 F , (4)\nwhere constant \u03c3\u00b5 > 0 is the width of kernel \u03ba and \u2016 \u00b7 \u2016H is RKHS norm. The kernel \u03ba is also a positive definite kernel [2].\nFollowing the representor theorem of kernel ridge regression [11], the estimated model-bridging function T\u0302 for new \u00b5\u0302mlL+1 is described as\n\u00b5\u0302MBL+1 = T\u0302 (\u00b5\u0302 ml L+1) = L\u2211 l=1 vl\u00b5\u0302 sim l \u2208 F , (5)\nwhere v = (v1, ..., vL) T = (G\u00b5 + \u03bbLI) \u22121k\u00b5(\u00b5\u0302 ml L+1) \u2208 RL. Gram matrix G\u00b5 and the vector k\u00b5(\u00b5\u0302 ml L+1) are described as follows:\nG\u00b5 = { \u03ba(\u00b5\u0302mll , \u00b5\u0302 ml l\u2032 ) }L l,l\u2032=1 \u2208 RL\u00d7L\nk\u00b5(\u00b5\u0302 ml L+1) = ( \u03ba(\u00b5\u0302ml1 , \u00b5\u0302 ml L+1), ..., \u03ba(\u00b5\u0302 ml L , \u00b5\u0302 ml L+1) )T \u2208 RL. Kernel Herding from Kernel Mean \u00b5\u0302MBl After obtaining the kernel mean of \u00b5\u0302MBL+1, kernel herding can be applied to sample \u03b8\u0302 MB L+1 = {\u03b8\u0302L+1,1, ..., \u03b8\u0302L+1,m}, where \u03b8\u0302L+1,j \u2208 Rd\u03b8 . The explicit form of the update equation for sample j = 1, ...,m iteration of kernel herding with kernel mean \u00b5\u0302MBL+1 is as follows:\n\u03b8\u0302L+1,j = arg max \u03b8 L\u2211 l=1 m\u2211 j\u2032=1 vlwl,j\u2032k\u03b8(\u03b8, \u03b8l,j\u2032)\u2212 1 j j\u22121\u2211 j\u2032=1 k\u03b8(\u03b8, \u03b8j\u2032) \u2208 Rd\u03b8 , (6)\nfor j = 2, ...,m. For initial state j = 1, the update equation constitutes only the first term of Eq. (6). The weight of wl,j is calculated by kernel ABC for dataset {Xnl , Y nl } in Eq.(2)."
    },
    {
      "heading": "3.3 Input of Distribution-to-Distribution Regression",
      "text": "We present the explicit formulation for calculating the kernel means of the machine learning model \u00b5\u0302mll , as an input of the distribution-to-distribution regression. First, we present the formulation of BNN, as BNN is a useful model for many applications as a parametric Bayesian model. Second, we present the formulation for Gaussian process regression as a non-parametric Bayesian model. We consider the Gaussian process regression as a non-parametric alternative to BNN. The equivalence between the Gaussian process and BNN with one hidden layer with infinite nodes is well known [18]. Furthermore, a recent study reveals the kernel formulation that is equivalent to multi-layered BNN, as an extension of the Gaussian process [13]. We directly obtain empirical kernel mean without calculation of kernel from parameters in the parametric model for using Gaussian process regression.\nParametric Model: Bayesian Neural Network We assume the BNN model fml(x; \u03be) with a few hidden layers, where \u03be is a parameter, such as weights for each node and bias terms of each layer. We can obtain the posterior distribution of \u03bel for l = 1, ..., L by the Markov Chain Monte Carlo method or variational approximation. Then, the empirical kernel mean of the posterior distribution is represented as \u00b5\u0302mll = \u2211m j=1 k\u03be(\u00b7, \u03bel,j) \u2208 H for l = 1, ..., L dataset, where k\u03be is kernel of \u03be. We employ Gaussian-like kernel \u03ba as an function of \u00b5\u0302mll \u2208 H as\n\u03ba(\u00b5\u0302mll , \u00b5\u0302 ml l\u2032 ) = exp\n{ \u2212 1\n2\u03c32\u00b5 \u2225\u2225\u00b5\u0302mll \u2212 \u00b5\u0302mll\u2032 \u2225\u22252H} \u2208 F = exp \u2212 1\u03c32\u00b5 1\u2212 m\u2211\nj=1 m\u2032\u2211 j\u2032=1 k\u03be(\u03bel,j , \u03bel\u2032,j\u2032)  . The relation \u3008\u00b5\u0302mll , \u00b5\u0302mll\u2032 \u3009 = \u2211m j=1 \u2211m\u2032 j\u2032=1 k\u03be(\u03bel,j , \u03bel\u2032,j\u2032) is used, where \u3008\u00b7, \u00b7\u3009 represents the inner product.\nNon-Parametric Model: Gaussian Process Regression We use the Gaussian process regression as a non-parametric model. In this case, we can directly obtain empirical kernel mean without the calculation of kernel from parameters, such as \u03be in the parametric model. We present that the prediction with Gaussian process regression can be considered as a conditional kernel mean. As a result of Gaussian process regression, we can express the mean of the predictive distribution in general for l-th dataset {Xn, Y n} as\ny = \u00b5\u0302Y |X,l(x) = n\u2211 i=1 ul,i(x)ky(\u00b7, Yl,i), (7)\nwhere ul,i(x) = {(Gx + n\u03bb\u2032I)\u22121kx(x)}i. The Gx is the Gramm matrix, \u03bb\u2032 \u2265 0 is regularization constant, and kx is kernel of x. This formulation is clear if we remember the equivalence between Gaussian process regression and kernel ridge regression [8]. As a predictor of Y\u0302l,n+1 for new Xl,n+1, we can calculate Y\u0302l,n+1 = \u00b5\u0302Y |X,l(Xl,n+1). Note that this \u00b5\u0302Y |X,l is interpreted as the kernel mean of the Y nl conditioned by X n l . Thus, we can use \u00b5\u0302Y |X,l as the input of the distribution-to-distribution regression, represented as \u00b5\u0302mll . We employ Gaussianlike kernel \u03ba as an function of \u00b5\u0302mll as\n\u03ba(\u00b5\u0302mll , \u00b5\u0302 ml l\u2032 ) = exp \u2212 1\u03c32\u00b5 1\u2212 n\u2211\ni=1 n\u2032\u2211 i\u2032=1 ul,iul\u2032,i\u2032ky(Yl,i, Yl\u2032,i\u2032)  . There is a difference between the proposed non-parametric method and parametric method. In the parametric method, the distribution of parameter \u03bel is the input of the distribution-to-distribution regression, while in the non-parametric method, the distribution of data Y nl conditioned by X n l is the input."
    },
    {
      "heading": "4 Experiment",
      "text": "This framework is widely applicable to various domains for industries that include multi-agent simulation, traffic simulation, and simulation of dynamics of physical systems, such as thermomechanics, structural mechanics, and electromagnetic mechanics. We present the applications of the model-bridging framework for three simulations: 1) a simple production simulation to show and explain the framework effectiveness in detail, 2) a realistic production simulation to show the capability for realistic application, and 3) a simulation of fluid dynamics to show of the applicability to a wide variety of simulation fields. The detailed information on the three experiments is provided in the supplemental material owing to page limitations.\nThrough the three experiments, we confirm that model bridging enables us to predict Y\u0302L+1,n+1 for new XL+1,n+1, using a machine learning model, and obtain the interpretable simulation parameter \u03b8\u0302MBL+1 without an expensive calculation of the simulation when we obtain the L + 1-th dataset {XnL+1, Y nL+1}. We also investigate the accuracy of the estimation of the parameter \u03b8\u0302MBL+1 and compared the execution time with simulator calibration as a baseline. Note that these experiments cannot be compared with other state-of-the-art surrogate approaches, such as LIME, SHAP, and other methods with model compression, because no other methods exist that simultaneously obtain the prediction result and interpretable simulation parameters."
    },
    {
      "heading": "4.1 Common Setting of Experiments",
      "text": "In practice, the effective hyperparameter for model-bridging function to be tuned is the regularization constant \u03bb for distribution-to-distribution regression. The hyperparameter \u03bb can stabilize the calculation of the inverse Gram matrix. This hyperparameter should be determined by cross-validation. Further, as a common hyperparameter of the kernel method, the width of the kernel must be selected to measure the similarity between the data. We employed a Gaussian kernel for ky, kx, k\u03b8, and k\u03be for all experiments. The typical setting of the width of the kernel, in practice, is the median of Euclid distance of the input data of a kernel. In all the experiments performed in this study, we apply this setting and confirmed that all kernels perform adequately. We used a PC equipped with a 3.4-GHz Intel core i7 quad-core processor and 16GB memory. The main computational cost is for a simulation in the pre-learning phase of this framework."
    },
    {
      "heading": "4.2 Experiment with Simple Production Simulator",
      "text": "Setting Production simulators are widely used simulation software for discrete and interconnection systems to model various processes, such as production, logistics, transportation, and office works. We used a WITNESS, a popular software package of production simulation1. We examined the regression problem\n1 https://www.lanner.com/en-us/technology/witness-simulation-software.\nhtml\nusing a simulation model that has a simple four-dimensional simulation parameter \u03b8 \u2208 R4 (Fig. 4). We defined the simulation input x = Xi \u2208 R as the number of products to be manufactured, output Yi = fsim(Xi, \u03b8) \u2208 R as the total time to manufacture all the Xi-th products, and parameter \u03b8 as the time required for each procedure on the production line. Moreover, the time required for \u201cASSEMBLY\u201d is N (\u03b81, \u03b82), and that for \u201cINSPECTION\u201d is N (\u03b83, \u03b84), where N (\u00b5ND, \u03c3ND) is the normal distribution with mean \u00b5ND and standard deviation \u03c3ND. We assumed that the elapsed time of each process would increase considerably, owing to an increasing load, if the number of products to be manufactured also increases. To create this situation artificially, we set different true parameters between the observed data region \u03b8(0) and the predictive region \u03b8(1). We set \u03b8(0) = (2, 0.5, 5, 1)T if x \u2264 110 and \u03b8(1) = (3.5, 0.5, 7, 1)T if x > 110. The shift in parameters \u03b81 and \u03b83 between \u03b8\n(0) and \u03b8(1) is the sigmoid function. For each l-th dataset, the observed data of size n = 50 and sample size m = 100 are generated by ql(x) = N (\u03c7l, 5), where \u03c7l is uniform distribution in [70, 130] for l = 1, ..., L. The number of training datasets, L, is 100. We defined the prior distribution as the uniform distribution over [0, 5] \u00d7 [0, 2] \u00d7 [0, 10] \u00d7 [0, 2]. We used a BNN having two fully connected hidden layers with three nodes and bias nodes for each layer, as a machine learning model. The activation function is ReLU. The regularization constant is \u03bb = 1.0\u00d7 10\u22126 for this experiment.\nResult The execution time of model bridging is 9.6 [s] in the presented computational environment, while simulator calibration requires about 3.1 [h] for\nL + 1-th dataset. Simulator calibration requires m \u00d7 n execution of simulation and each simulation takes 2 [s] in this case. As representatives of all test datasets, the results of the model-bridging framework for two different datasets (l-th and l\u2032-th dataset), which are randomly selected, are shown in Fig. 5. Figure 5 (A) shows the observed data for l-th dataset as red squares and the l\u2032-th dataset as red triangles. The solid line and dashed line are the fitted results by BNN with variational approximation. Figure 5 (B) shows the estimated posterior distributions of simulation parameters by model bridging \u03b8\u0302MBl each dataset. The red markers show the true parameter, green markers show the estimated result of simulator calibration, and blue markers show the mean of the distribution. Each square denotes the l-th dataset and each triangle denotes the l\u2032-th dataset. We can see a reasonably accurate estimation of \u03b8MBl and \u03b8 MB l\u2032 model-bridging framework in comparison with simulator calibration for the two different datasets with two different true parameters \u03b8.\nNote that from the perspective of interpretability, we can clearly see the practical effectiveness of simultaneously obtaining the prediction result with interpretable parameters, such as \u201celapsed time of a process.\u201d From these interpretable parameters, we can understand that the production efficiency is decreased (l\u2032-th dataset in Fig.5) mainly because of the increased elapsed time of \u201cINSPECTION\u201d (= \u03b81).\nWe also investigated \u2016\u00b5\u0302MBL+1\u2212 \u00b5\u0302simL+1\u20162H to confirm the convergence of the proposed distribution-to-distribution regression in the model-bridging framework. The detailed formulation for the numerical calculation is presented in the supplementary material. Figure 6 shows the mean and standard deviation of one-leaveout cross-validation of the test dataset. The horizontal axis shows the number of training datasets. We can see the convergence for bias that originates from simulator calibration."
    },
    {
      "heading": "4.3 Experiment with Realistic Production Simulator",
      "text": "Setting We used a model to reproduce a real metal-processing factory that manufactures valves from metal pipes, with six primary processes: \u201csaw,\u201d \u201ccoat,\u201d\n\u201cinspection,\u201d \u201charden,\u201d \u201cgrind,\u201d and \u201cclean,\u201d in the order shown in the supplementary material. Each process is composed of complex procedures, such as the preparation rule, waiting, and machine repair during trouble. The purpose of this production simulation is also to predict the total production time Yi \u2208 R when the number of units Xi \u2208 R3 for three types of products to be manufactured is set. Each of the six processes contains two parameters of machine downtime owing to failure: mean time between failures (TBF) and mode time required for repair (TR). We defined these parameters as twelve-dimensional parameter \u03b8 \u2208 R12 (see Table 2). The distribution of the mean time between failures is represented as a negative exponential distribution. The distribution of the time required for repair is represented as an Erlang distribution with the mode time and shape parameter set at three.\nSimilar to the simple experiment discussed in the previous section, we set the true parameter as \u03b8(0) if x \u2264 30 and \u03b8(1) if x > 30. The summary of the true parameter is shown in Table 2. The shift in parameter \u03b85 between \u03b8 (0) and \u03b8(1) is a sigmoid function. The observed data of size is n = 30 by N (\u03c7l, 3) where \u03c7l is generated by uniform distribution in [20, 40]. The number of parameter samples is m = 50 and the number of datasets is L = 40. We defined the prior distribution as the uniform distribution over [60, 140]\u00d7[15, 35]\u00d7[100, 200]\u00d7[3, 10]\u00d7[60, 140]\u00d7 [15, 35] \u00d7 [100, 200] \u00d7 [3, 10] \u00d7 [50, 100] \u00d7 [10, 20] \u00d7 [100, 200] \u00d7 [15, 35]. We use Gaussian process regression as a machine learning model. The hyperparameter of the regularization constant \u03bb is 0.1.\nResult The execution time of model bridging is 1.1 [s] in the presented computational environment, while simulator calibration requires about 1.3 [h] for L+1-th dataset. The simulator calibration requires m \u00d7 n execution of simulation, and each simulation takes 3 [s] in this case. The results of the mean and standard de-\nviation of the estimated parameters for one-leave-out cross-validation are shown in the bottom rows in Table 2. All parameters of estimation by the modelbridging framework are accurate within the standard deviation for \u03b8(0) and \u03b8(1), respectively. We can see the effectiveness of a high-dimensional parameter space with a realistic experiment. From the estimated result of simulation parameters, we can understand that the difference in \u03b85 results in different predictions for each situation, while other parameters are constant. This insight obtained from the interpretable parameters leads to improvements in the production process."
    },
    {
      "heading": "4.4 Experiment with Simulator for Fluid Dynamics",
      "text": "Setting Through computer-aided engineering (CAE) simulations, we confirmed that our model-bridging algorithm is applicable to the simulation of fluid-dynamics systems. We employed the typical benchmark in this field, called \u201ccavity flow experiment,\u201d with OpenFOAM R\u00a92 3 (Fig. 7 (A)). We considered a two-dimensional squared space called \u201ccavity\u201d fulfilled with a fluid having an unknown Reynolds number. The Reynolds number is used to help predict flow patterns and velocities in fluid dynamics. Turbulent flow is somewhat challenging to predict, even though it is ubiquitous in real-world situations. In this experiment, input Xi \u2208 R is the velocity of the material on top of the cavity; the output Yi \u2208 R is the velocity at the particular point (see Fig. 7 (A)); and parameter \u03b8 \u2208 R is the Reynolds number (see supplementary material for details). The number of data n = 50, the number of samples m = 41, and the number of dataset L = 41 are generated by different true \u03b8l(= \u03b8 true l ). The prior distribution is defined as the\n2 https://www.openfoam.com/ 3 https://www.openfoam.com/documentation/tutorial-guide\nuniform distribution over [20000, 65000]. We used Gaussian process regression as a machine learning model. The hyperparameter of regularization is \u03bb = 1.0\u22125.\nResult The execution time of model bridging is 2.6 [s] in the presented computational environment, while the simulator calibration requires about 9 [h]. Each simulation takes about 17 [s] in this case. Figure 7 (B) shows the estimated result of \u03b8\u0302sim by simulator calibration and \u03b8\u0302MB by model bridging as a function of true \u03b8 for L = 41 dataset with one-leave-out cross-validation. The dashed line in Fig. 7 (B) shows \u03b8true = \u03b8\u0302MB(= \u03b8\u0302sim) to ensure that the estimation is accurate if the result is on the dashed line. We can see a reasonable estimation of \u03b8\u0302MB. The result of the velocity prediction of velocity Yi is also reasonably accurate (see the supplementary material). Human experts can understand why the Reynolds number causes such flow of fluid."
    },
    {
      "heading": "5 Discussion",
      "text": "There are many possible options to be discussed in the proposed framework for the individual-use case. In this study, we assume the given observed dataset as the problem setting. Further, there are two other possible ways for problem setting with the assumption of the data generation process: 1) generate data from fml(x; \u03be) and 2) generate data from fsim(x; \u03b8). Considering another case with these assumptions of data generation might be meaningful, e.g., when the real observed data are limited or when the simulation has high confidence. Another option to be discussed is the parametric or non-parametric regression model for the model-bridging function T\u0302 . In this study, we present the practical effectiveness of the model-bridging framework, while a theoretical analysis of the asymptotic behavior of this framework is still desired."
    },
    {
      "heading": "6 Conclusion",
      "text": "We propose a novel framework named \u201cmodel bridging\u201d to bridge from the uninterpretable machine learning model to the simulation model with interpretable parameters. The model-bridging framework enables us to obtain precise predictions from the machine learning model as well as obtain the interpretable simulation parameter simultaneously without the expensive calculations of a simulation. We confirmed the effectiveness of the model-bridging framework and accuracy of the estimated simulation parameter using production simulation and simulation of fluid dynamics, which are widely used in the real-world manufacturing industry."
    },
    {
      "heading": "A. Explicit Formulation of Norm of Empirical Kernel Mean",
      "text": "We present the explicit formulation of \u2016\u00b5\u0302MBL+1 \u2212 \u00b5\u0302simL+1\u20162H. The key for the calculation is the relation \u3008\u00b5\u0302, \u00b5\u0302\u2032\u3009 = \u2211\u2211 k\u03b8(\u03b8, \u03b8\u2032) for \u03b8 kernel. The RKHS norm between estimated \u00b5\u0302MBL+1 and target \u00b5\u0302 sim L+1 is described as follows:\n\u2016\u00b5\u0302MBL+1 \u2212 \u00b5\u0302simL+1\u20162H = 2 { 1\u2212 \u3008\u00b5\u0302MBL+1, \u00b5\u0302simL+1\u3009 }\n= 2 1\u2212 L\u2211 l=1 m\u2211 j=1 m\u2211 j\u2032=1 vlwl,jwL+1,j\u2032k\u03b8(\u03b8L+1,j\u2032 , \u03b8L+1,j)  . Then, the norm of the empirical kernel mean is obtained."
    },
    {
      "heading": "B. Detailed Setting of Experiment for Simple Production Simulation",
      "text": "A production simulation is a general-purpose simulation software package for discrete and interconnected systems, which is used to model various processes such as production, logistics, transportation, and office work. All processes are implemented in WITNESS, which is a general-purpose simulation software package for discrete and interconnected systems. The purpose of the production simulation in this experiment is to predict the total production time when the number of products to be manufactured is set. Figure 4 shows a typical assembly process for one product with four parts used in this experiment. The product consists of a \u201cTOPS\u201d part, a \u201cBOTTOMS\u201d part, and two \u201cSCREWS.\u201d The products assembled in the \u201cASSEMBLY\u201d machine are inspected by the \u201cINSPECTION\u201d machine before shipping. The \u201cINSPECTION\u201d machine starts when four assembled products arrive, and it can inspect four assembled products simultaneously. The parameters \u03b81 and \u03b82 represent the mean and standard deviation in a normal distribution of elapsed time for the \u201cASSEMBLY\u201d machine, respectively. The parameters \u03b83 and \u03b84 represent the mean and standard deviation in a normal distribution of elapsed time for the \u201cINSPECTION\u201d machine, respectively."
    },
    {
      "heading": "C. Details of the Experiment with Realistic Production Simulator",
      "text": "As a realistic experimental setting for a factory manufacturing valves, the process details are described below. All processes are implemented in WITNESS, which is a general-purpose simulation software package for discrete and interconnection systems. Figure 8 is an illustration of the simulation model for a realistic\nexperiment. We defined the total production time as Yi \u2208 R when the number of units Xi \u2208 R3 for three types of products to be manufactured. Each type of product has different elapsed times at the \u201cSAW\u201d process. Figure 9 shows the two datasets and regression results by BNN as representatives for all datasets. The discrete data is originated from a series of batch processing in the simulation model.\nCutting process: The first phase of the manufacturing process begins with the arrival of a pipe having the same diameter and length, 30 cm. The pipes arrive at a fixed time interval based on the vendor\u2019s supply schedule. Subsequently, each pipe is cut to 10-cm sections along the length. Thus, three parts can be obtained from one pipe. For the cutting process, a worker who performs changeover, repair, and disconnection is assigned. The worker goes for a lunch break once every eight hours. Thereafter, the parts are transferred from the cutting process to the coating process on a conveyor belt.\nCoating process: The cut parts are coated for protection. In the coating machine, six parts are batch-processed at once. The coating material must be\nprepared in the coating machine prior to the part. Otherwise, the parts will be degraded by the heat. When the parts ride on the belt conveyor, the sensor detects them, and the coating material is prepared.\nInspection process: After being coated, each part is placed in the inspection waiting buffer before the inspection step. The inspector will remove the parts individually from the waiting buffer and inspect the coating quality. If the part fails the quality inspection, the inspector places the part in the recoating waiting buffer. The coating machine must process the parts of the recoating buffer preferentially. When the part passes the quality inspection, the inspector sends the part to the curing step.\nHarden process: In the harden (quenching) process, up to 10 parts are processed simultaneously on a first-come first-out basis, and each part is quenched for at least one hour.\nGrind process: The quenched parts are polished for satisfying the customer\u2019s specifications. Two polishing machines with the same priority are available. Each machine uses special jigs to process four parts simultaneously. Each of the two polishing machines produces two different types of valves. Further, 10 jigs exist in the system, and when not in use, they are placed in the jig storage buffer. A loader fixes the four parts with a jig and sends it to the polishing machine. The polishing machine sends the jig and four parts to the unloader after the polishing is finished. The unloader sends the finished parts to the valve storage area and the jig to the jig return area. The two types of valves are separated and placed in a dedicated valve storage buffer. As the jig needs to be used again, it is returned from the jig return conveyor to the jig storage buffer.\nCleaning process: The valves removed from the valve storage area are cleaned before shipment. In the washing machine, five stations are available where the valves can be placed one at a time, and the valves are cleaned in these stations. Up to 10 valves of each type can be washed simultaneously. When the valve type is changed, the cleaning head must be replaced."
    },
    {
      "heading": "D. Details of the Experiment with Fluid-Dynamics Simulator",
      "text": "These experiments are performed using the general-purpose open CAE simulators using the Finite Element Method (FEM) solver; OpenFOAM R\u00a9. OpenFOAM R\u00a9 includes some realistic problems as a tutorial. The example of \u201ccavity flow\u201d is one of the typical benchmarks. Figure 10 shows illustrations of the experiment of \u201ccavity flow\u201d that are simulated in this study. Most of the initial experimental settings, such as the number of FEM meshes, cavity size, and so on, were the same as in the tutorial. The range of the Reynolds number (Re) used was 10000 < Re < 70000. These settings cause the typical turbulent flow, as shown in Fig. 10.\nTime-series data are observed where the center of flow is moving, as shown in Fig. 10 (a) to (d). Part (a) of Fig. 10 shows the state at t = 0 [s] (initial state), (b) at t = 1.0 [s], (c) at t = 2.5 [s], and (d) at t = 5.5 [s]. In this experiment,\nXi \u2208 R is velocity of the material on top of the cavity; Yi \u2208 R is the velocity at the particular x-marked point at t = 5.5 [s] (Fig. 10 (d)); and parameter \u03b8 \u2208 R is the Reynolds number. Figure 11 shows the relation between Xi and Yi for five different dataset as representatives. It is difficult to select the parametric statistical model as a regression function owing to the non-trivial relation."
    }
  ],
  "title": "Model Bridging: Connection between Simulation Model and Neural Network",
  "year": 2020
}
