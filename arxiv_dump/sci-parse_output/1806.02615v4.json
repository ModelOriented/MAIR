{
  "abstractText": "Academic performance is perceived as a product of complex interactions between students\u2019 overall experience, personal characteristics and upbringing. Data science techniques, most commonly involving regression analysis and related approaches, serve as a viable means to explore this interplay. However, these tend to extract factors with wideranging impact, while overlooking variations specific to individual students. Focusing on each student\u2019s peculiarities is generally impossible with thousands or even hundreds of subjects, yet data mining methods might prove effective in devising more targeted approaches. For instance, subjects with shared characteristics can be assigned to clusters, which can then be examined separately with machine learning algorithms, thereby providing a more nuanced view of the factors affecting individuals in a particular group. In this context, we introduce a data science workflow allowing for fine-grained analysis of academic performance correlates that captures the subtle differences in students\u2019 sensitivities to these factors. Leveraging the Local Interpretable Model-Agnostic Explanations (LIME) algorithm from the toolbox of Explainable Artificial Intelligence (XAI) techniques, the proposed pipeline yields groups of students having similar academic attainment indicators, rather than similar features (e.g. familial background) as typically practiced in prior studies. As a proof-of-concept case study, a rich longitudinal dataset is selected to evaluate the effectiveness of the proposed approach versus a standard regression model.",
  "authors": [
    {
      "affiliations": [],
      "name": "Anahit Sargsyan"
    },
    {
      "affiliations": [],
      "name": "Areg Karapetyan"
    },
    {
      "affiliations": [],
      "name": "Wei Lee Woon"
    },
    {
      "affiliations": [],
      "name": "Aamena Alshamsi"
    }
  ],
  "id": "SP:d1b719883a37a8bee29b13d3f91816ffc5ac5d63",
  "references": [
    {
      "authors": [
        "R. Asif",
        "A. Merceron",
        "M.K. Pathan"
      ],
      "title": "Predicting student academic performance at degree level: a case study",
      "venue": "International Journal of Intelligent systems and applications 7(1), 49",
      "year": 2014
    },
    {
      "authors": [
        "R. Colom",
        "S. Escorial",
        "P.C. Shih",
        "J. Privado"
      ],
      "title": "Fluid intelligence, memory span, and temperament difficulties predict academic performance of young adolescents",
      "venue": "Personality and Individual differences 42(8), 1503\u20131514",
      "year": 2007
    },
    {
      "authors": [
        "T.R. Coyle",
        "D.R. Pillow"
      ],
      "title": "Sat and act predict college gpa after removing g",
      "venue": "Intelligence 36(6), 719\u2013729",
      "year": 2008
    },
    {
      "authors": [
        "J. Ermisch",
        "M. Francesconi"
      ],
      "title": "Family matters: Impacts of family background on educational attainments",
      "venue": "Economica 68(270), 137\u2013156",
      "year": 2001
    },
    {
      "authors": [
        "P.A. Graziano",
        "R.D. Reavis",
        "S.P. Keane",
        "S.D. Calkins"
      ],
      "title": "The role of emotion regulation in children\u2019s early academic success",
      "venue": "Journal of school psychology 45(1), 3\u201319",
      "year": 2007
    },
    {
      "authors": [
        "L.A. Jackson",
        "A. Von Eye",
        "F.A. Biocca",
        "G. Barbatsis",
        "Y. Zhao",
        "H.E. Fitzgerald"
      ],
      "title": "Does home internet use influence the academic performance of low-income children",
      "venue": "Developmental psychology 42(3),",
      "year": 2006
    },
    {
      "authors": [
        "H. Joshi",
        "E. Fitzsimons"
      ],
      "title": "The millennium cohort study: the making of a multipurpose resource for social science and policy",
      "venue": "Longitudinal and Life Course Studies 7(4), 409\u2013430",
      "year": 2016
    },
    {
      "authors": [
        "K. Laidra",
        "H. Pullmann",
        "J. Allik"
      ],
      "title": "Personality and intelligence as predictors of academic achievement: A cross-sectional study from elementary to secondary school",
      "venue": "Personality and individual differences 42(3), 441\u2013451",
      "year": 2007
    },
    {
      "authors": [
        "S.M. Lundberg",
        "S.I. Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "Advances in Neural Information Processing Systems 30, pp. 4765\u20134774. Curran Associates, Inc.",
      "year": 2017
    },
    {
      "authors": [
        "V.C. McLoyd"
      ],
      "title": "Socioeconomic disadvantage and child development",
      "venue": "American psychologist 53, 185",
      "year": 1998
    },
    {
      "authors": [
        "F. Pajares",
        "J. Hartley",
        "G. Valiante"
      ],
      "title": "Response format in writing self-efficacy assessment: Greater discrimination increases prediction",
      "venue": "Measurement and evaluation in counseling and development 33(4), 214",
      "year": 2001
    },
    {
      "authors": [
        "A.K. Pal",
        "S. Pal"
      ],
      "title": "Analysis and mining of educational data for predicting the performance of students",
      "venue": "International Journal of Electronics Communication and Computer Engineering 4(5), 1560\u20131565",
      "year": 2013
    },
    {
      "authors": [
        "M. Pandey",
        "V.K. Sharma"
      ],
      "title": "A decision tree algorithm pertaining to the student performance analysis and prediction",
      "venue": "International Journal of Computer Applications 61(13)",
      "year": 2013
    },
    {
      "authors": [
        "M.E. Pritchard",
        "G.S. Wilson"
      ],
      "title": "Using emotional and social factors to predict student success",
      "venue": "Journal of college student development 44(1), 18\u201328",
      "year": 2003
    },
    {
      "authors": [
        "N.E. Reichman",
        "J.O. Teitler",
        "I. Garfinkel",
        "S.S. McLanahan"
      ],
      "title": "Fragile families: sample and design",
      "venue": "Children and Youth Services Review 23(4), 303\u2013326",
      "year": 2001
    },
    {
      "authors": [
        "M.T. Ribeiro",
        "S. Singh",
        "C. Guestrin"
      ],
      "title": "Why should i trust you?: Explaining the predictions of any classifier",
      "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 1135\u20131144. ACM",
      "year": 2016
    },
    {
      "authors": [
        "C. Romero",
        "S. Ventura"
      ],
      "title": "Educational data mining: a review of the state of the art",
      "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 40(6), 601\u2013618",
      "year": 2010
    },
    {
      "authors": [
        "M. Salanova",
        "W. Schaufeli",
        "I. Mart\u0301\u0131nez",
        "E. Bres\u00f3"
      ],
      "title": "How obstacles and facilitators predict academic performance: The mediating role of study burnout and engagement",
      "venue": "Anxiety, stress & coping 23(1), 53\u201370",
      "year": 2010
    },
    {
      "authors": [
        "M.J. Salganik",
        "I. Lundberg",
        "A.T. Kindel",
        "C.E. Ahearn",
        "K Al-Ghoneim"
      ],
      "title": "Measuring the predictability of life outcomes with a scientific mass collaboration",
      "venue": "Proceedings of the National Academy of Sciences 117(15), 8398\u20138403",
      "year": 2020
    },
    {
      "authors": [
        "K.H. Tillman"
      ],
      "title": "Family structure pathways and academic disadvantage among adolescents in stepfamilies",
      "venue": "Sociological Inquiry 77(3), 383\u2013424",
      "year": 2007
    },
    {
      "authors": [
        "S.A. Tross",
        "J.P. Harper",
        "L.W. Osher",
        "L.M. Kneidinger"
      ],
      "title": "Not just the usual cast of characteristics: Using personality to predict college performance and retention",
      "venue": "Journal of College Student Development 41(3), 323",
      "year": 2000
    }
  ],
  "sections": [
    {
      "text": "ar X\niv :1\n80 6.\n02 61\n5v 4\n[ cs\n.C Y\nKeywords: Explainable AI \u00b7 LIME \u00b7 Data Science \u00b7 Machine Learning \u00b7 Computational Social Science \u00b7 Academic Performance \u00b7GPA Prediction."
    },
    {
      "heading": "1 Introduction",
      "text": "With far-ranging consequences on young people\u2019s lives and careers, academic performance is susceptible to various types and forms of influence. It is often\npath-dependent, correlating with an individual\u2019s past performance [3, 18]. Furthermore, factors with significant impact on academic performance can be specific to the subject in question, such as intelligence and determination [2,11,21], or exogenous, resulting from the social, emotional and socioeconomic environment in which the individual was raised [5, 10, 14]. Therefore, in general, investigation of academic performance predictors is attained through longitudinal studies [5, 8].\nMainly, two directions are evidenced in this line of research. The first, followed in [6,20], relies on statistical models to measure the correlation of a few variables that were premised on prior results in the literature. The second, attended in [1, 12,13,17], resorts to data science and machine learning techniques for extracting informative predictors from large datasets with thousands of candidate features.\nWhile both approaches recognize the uniqueness of the students\u2019 backgrounds, the effect of the correlates is still determined as an aggregate over the entire study population/group, leaving the subtle variations between individuals largely overlooked. In particular, the former assumes that all the subjects are impacted by the same set of selected correlates in the same manner, whereas the latter seeks to derive a predictive model with high accuracy that generalizes to the overall population. However, no two subjects are identical, and factors profoundly affecting one individual might have a merely negligible impact on another person, even under comparable circumstances.\nAgainst this backdrop, we introduce a novel data science approach in which (i) the predictors of academic performance for each student are identified and quantified (ii) the study population is segmented into clusters based on the obtained values. The proposed pipeline allows the groups with similar success indicators to be analyzed collectively, which should enable their effects to reinforce each other and be more readily discoverable.\nTo quantify academic performance predictors specific to individual students, we avail of a recently developed XAI algorithm, known as LIME [16]. The outputs from LIME serve as \u201cexplanations\u201d, which are localized in that a unique explanation is generated for each subject. Though descriptive on an individual case basis, these explanations are intrinsically disassociated, and thus their direct interpretation (one by one) becomes intractable with a growing number of subjects. This paper presents an efficient solution by grouping the students according to LIME coefficients, as detailed in Section 3. Distinctively, under such clustering criterion, the subsequent analysis is explicitly centered at groups of students who share similar academic performance correlates, as opposed to the classical approach of clustering in the feature space (i.e., based on observable characteristics such as gender, familial background or financial class). In a sense, with this scheme in place, it proves possible for subjects with fairly diverse backgrounds and needs to be grouped together, provided they share common markers of academic attainment.\nAs one demonstration, the proposed approach is benchmarked on a longitudinal dataset, released for the Fragile Families Challenge (FFC) competition, against a standard regression model. The results reveal a striking difference in\nthe depth of insights gained, with the devised pipeline featuring prominently. While intended as a proof-of-concept, this preliminary study unveils findings on academic performance indicators that could serve social and data science communities. Furthermore, the workflow proposed herein can potentially pave the way towards more efficient and targeted intervention strategies by providing insights that would be inconceivable to achieve with traditional methods."
    },
    {
      "heading": "2 Data and Pre-processing",
      "text": ""
    },
    {
      "heading": "2.1 FFC Dataset",
      "text": "The examined dataset stems from the Fragile Families and Child Wellbeing study that documented the lives of over 4000 births occurring between 1998 and 2000 in U.S. cities with at least 200, 000 population. As such, the study was carried out in the form of questionnaire surveys and interviews with parents shortly after the children\u2019s birth, and when the infants were 1, 3, 5 and 9 years old (overall five waves). The elicited data covered essential temporal information on the children\u2019s attitudes, parenting behavior, demographic characteristics, to name a few (further details of the dataset can be consulted in [15]). The data was released within the scope of FFC competition which sought to predict 6 life outcomes, including Grade Point Average (GPA), based on these data records. Analysis of the overall results and ensuing findings of the competition are summarized in [19].\nIn total, the dataset comprises 4, 242 rows (one per child) and 12, 943 columns, including the unique numeric identifier. During FFC, however, only half of the data rows were released as a training set. Of these, 956 entries had GPA values missing, and therefore the final dataset analyzed in this study totalled 1, 165 subjects, as appears in Fig. 6 in the Appendix."
    },
    {
      "heading": "2.2 Pre-processing and Feature Selection",
      "text": "Before proceeding with this step, we remark that it is stipulated exclusively by nature (e.g., missing values) and properties (e.g., dimensionality) of the dataset under study and per se is not a principal constituent of the developed pipeline. Indeed, it is tailored specifically for the FFC dataset and might very well be substituted by any other appropriate routine yielding a sufficiently informative feature subset (i.e., with a decent predictive accuracy) of reasonable cardinality. Thus, for clarity of exposition, the respective particulars are deferred to the Appendix.\nThe target subset of optimally descriptive features, as revealed through extensive experimentation and validated by its predictive accuracy1, contained 65 features, tabulated in Table 1 in the Appendix. This pool of features forms the\n1 A mean squared error (MSE) of approximately 0.359 was achieved under 3-fold cross-validation (a result of comparable fidelity, submitted during the FFC, secured a place in the top quartile of the scoreboard).\ninput for the proceeding analysis laid out in Section 3. Figure 1 depicts the spread of these 65 features across the 5 waves (i.e., over the trajectory of children\u2019s lives). For each wave, the features are arranged into the following six categories: {familial, financial, academic, social, personality, other} and their respective counts are illustrated in Fig 1 as a stacked bar chart.\nAs deduced from Fig. 1, the distribution of features in familial and financial categories is skewed towards the early span of children\u2019s lives. For the correlates falling in academic, social and personality categories, the opposite trend is evidenced."
    },
    {
      "heading": "3 Comparative Analysis",
      "text": "This section contrasts the proposed approach against a conventional regression model, as illustrated in Fig.2, and discusses the results.\nWe cast the problem as a classification task by discretizing the GPA scores into three classes, Low, Middle and Top, defined respectively by the following ranges: [1, 2.5], (2.5, 3.25), [3.25, 4]. Consequently, only the subjects falling into the Top and Low categories were retained (861 in total). The motivation is to steer the focus of classification algorithms towards the aspects discerning high and low performers. Indeed, the factors responsible for \u201cborderline\u201d performances are likely the ones with negligible impact, hence inferring them might obscure the results. On the other hand, omitting a large group of subjects could lead to the loss of pertinent data. Thus, the above thresholds were set according to the top and bottom 30% percentiles of GPA score records. This ensured a solid number of participant students while retaining a sizable gap between the two classes."
    },
    {
      "heading": "3.1 General Indicators",
      "text": "Following the common practice of previous works, in this initial phase, we employed the logistic regression algorithm to screen the selected features that broadly correlate with academic performance. The subjects from the Top and Low categories were fit to the model and the resulting coefficients, under L1 regularization, are presented in Fig. 3.\nAs observed from Fig. 3, test grades, along with other early metrics of academic performance, are imperative, and so are the factors associated with the child\u2019s social background. In particular, the indicators in familial and financial categories appear to influence children\u2019s academic performance predominantly at an early age. Whereas the correlates associated with scholastic aptitude manifest their effect mostly at later stages of subjects\u2019 lives. These observations are consistent with prior findings in the literature, providing some measure of validation. Overall, the most influential predictors are listed below.\n1. The two most important factors relate to the parents\u2019 education [4]. 2. The Peabody Picture Vocabulary Test (PPVT) percentile rank correlated\nwith academic performance. PPVT is a standardized test designed to measure an individual\u2019s vocabulary and comprehension and provide a quick estimate of verbal ability or scholastic aptitude. Another standard test\u2019s (known as Woodcock Johnson Test) percentile rank was identified as a significant indicator as well. 3. Interestingly, the fact that the father has been incarcerated2 - a proxy for family support - affects children\u2019s performance negatively. Contrariwise, the\n2 Note that in Fig. 3 the positive correlation of this feature is due to the reversed order of values (i.e., the highest value indicates the father has not spent time in jail.)\ncomplexity/rank of the mother\u2019s job, a surrogate for the financial situation, conduced to enhanced academic performance.\nThe emerging picture is compelling and multifaceted. On the one hand, test scores and academic aptitude occupy a central role, which is to be expected. Yet, there are indications that, beyond this, other features reflective of social and financial stability could also play a part, which strongly motivates the second, targeted part of this study."
    },
    {
      "heading": "3.2 Proposed Methodology: Targeted Indicators",
      "text": "While the insights highlighted in Section 3.1 were illuminating, they were extracted from the entire dataset, and the perspectives obtained were thus quite broad. To further extract targeted or localized indicators of academic success, we resorted to LIME [16]. For each instance, LIME produces a localized explanation of the classifier output by perturbing the feature values to generate a set of synthetic data points in the vicinity of the true instance. The posterior probability for each data point is estimated using the trained classifier, and a linear regression model is trained using the synthetic points as the inputs, and the posterior probabilities as the targets. The localized regression coefficients obtained in this way can then be interpreted as the importance of a feature, and are estimated separately for each subject.\nThis technique was adapted for the present context as follows. First, Random Forest classifier is trained on the data and is invoked to estimate the posterior probability for each instance. Then, LIME is applied to subjects falling into the Top and Low groups to produce feature weights specific to each subject, which are then clustered with the k-means algorithm. Each cluster is then characterized by the centroid of the LIME coefficients for the instances therein."
    },
    {
      "heading": "3.3 Results and Discussion",
      "text": "The k-means clustering results, with parameter k = 4 (i.e., four clusters), appear in Fig. 4. This choice of k enables a compact yet expressive representation of the underlying insights. In general, the higher the k, the more likely the groups are to resemble each other closely. On the other hand, when k is small, one might possibly overlook factors critical to some subset of subjects.\nIn Fig. 4, to emphasize the differences between clusters, we focus on each feature\u2019s relative weights. That is, a cluster is represented in terms of the difference between its centroid and population means. As the figure suggests, the characteristics of the subjects vary significantly between the clusters. In particular, the salient patterns observed were as follows:\n\u2013 Cluster 1 (189 subjects): The subjects in this cluster appear to be strongly influenced by features 51, 58, 61 and 63, which are all linked to test scores.\nWhereas features 59 and 60, related to the ability to pay attention, appeared to be less important.\n\u2013 Cluster 2 (141 subjects): This cluster was similar to Cluster 1 except that features 59 and 60 were more important than average.\n\u2013 Cluster 3 (297 subjects): In this cluster, features 51, 58 and 63 (all test score related), were all less important than average.\n\u2013 Cluster 4 (234 subjects): Here, feature 61 (the Woodcock Johnson Test score) was significantly less important, while features 51, 58 and 63 all had slightly stronger impacts on performance.\nOverall, the features with values close to zero are the ones with a uniform effect on all individuals regardless of a cluster.\nThese results are deeply compelling in a number of ways. While Fig. 3 (results of the standard regression model) provided a broad overview of the overall success factors, the relative importance of each of these factors differed substantially among subjects. For example, in clusters 1 and 2, test scores appeared to have a substantial impact on future academic performance, while the opposite was observed in cluster 3. Also, features 59 and 60, which measure a student\u2019s general attentiveness, seemed relatively peripheral in cluster 1 and crucial in cluster 2 (and close to the average in clusters 3 and 4).\nAnother interesting observation was the spread of feature values within clusters, which is depicted in Fig. 5 (representing three selected numerical features). In particular, note the spread of values for feature 26, which is the total expense for food used at home. Apparently, the feature values in the LIME clusters exhibit a far greater range compared to the conventional clusters, which tend to group people with similar financial situations. For the other features, the results are slightly less straightforward, but LIME clusters 3 and 4, in particular, also exhibit a much broader spread of values. This underscores that clustering with the LIME coefficients does not merely group students based on their personal or social circumstances, but rather in terms of the factors which affect their future academic performance."
    },
    {
      "heading": "4 Future Work",
      "text": "The present findings indicate the potential effectiveness of the proposed methodology in analyzing causal relationships in datasets alike FFC. However, this work was intended as a proof-of-concept case study, leaving open several avenues for future investigations. In particular, below listed are several promising directions.\n1. Analyze comparable data sets (e.g., The Millennium Cohort Study [7]), to test whether certain aspects of the observations are data-specific, or reflect true underlying patterns. 2. Perform a thorough sensitivity analysis on the chosen subset of features as well as incorporate XAI techniques alternative to LIME (e.g., SHapley Additive exPlanations [9]). 3. Apply the proposed approach to more diverse and larger datasets to demonstrate its generalizability to other use cases/study domains."
    },
    {
      "heading": "5 Concluding Remarks",
      "text": "In this study, a novel data science pipeline is proposed, which conduces the identification of the specific features associated with academic performance in different groups of students. A clustering algorithm was employed to group these subjects, then targeted success indicators were extracted from each of these groups and scrutinized. We note that the present findings rely on a technique (LIME), which was developed relatively recently and should be treated as preliminary. However, if and when superior methods are proposed, they can similarly be incorporated into the devised workflow.\nThe key point is that such localized models are vital if we are to obtain a more nuanced view of the actual success indicators for specific children and families. The findings suggest that the children of fragile families can be given the best chance of success through interventions that are tailored to their individual needs, e.g. in some families, a small home loan could be the difference between a star student and a dropout, whereas in others a free mentoring scheme might turn more valuable.\nAppendix\nThis section details the employed pre-processing and feature selection steps, portrayed as a flowchart in Fig. 6, along with the list of selected 65 features."
    },
    {
      "heading": "A Details of the Pre-processing and Feature Selection Phase",
      "text": "Due to the nature of the dataset under study, there were numerous instances of missing values where respondents either refused or were unavailable to answer. This was resolved through the judicious combination of data transformation, reduction, and imputation techniques, as listed below.\n\u2013 All missing and negative values were replaced by NaN and the columns with 0 variance were removed. Then, only the columns having at least 400 nonNaN values were retained. \u2013 Features with less than 20 unique values were treated as categorical and a simple median imputation was applied to replace the missing values. \u2013 The variant of kNN (k-Nearest Neighbors) imputation algorithm, implemented in the Python package Fancyimpute, was leveraged, with value of 100 for the parameter k, to estimate the remaining NaN values.\nThe number of features in the resulting dataset was reduced from over 12, 900 to 6, 609. However, this number of covariates was still exceedingly high, necessitating a subsequent feature selection phase. An array of filter- and wrapper-based methods, including Principal Component Analysis, Lasso, and Gradient Boosting Regression, were attempted in search of the most informative feature subset of reasonable cardinality. These methods were applied to the extracted pool of 6, 609 features, both recursively and explicitly, and probed under diverse parameter settings. The acquired subsets were then evaluated for their predictive accuracy across various models trained, effectively providing a means of validation. In essence, the latter step intends to establish the overall validity of the model underlying the proceeding analysis, thereby solidifying credibility of the explanations derived therein.\nThe target subset of optimally descriptive features was obtained by the following means. Feature importances were estimated by the Extra Trees Regressor algorithm (with 500 estimators) and Randomized Lasso, and the top 500 features were retained from each. For the latter, two different values were considered for the regularization parameter \u03b1, namely 0.004 and 0.000004, thus resulting in two separate feature subsets. The intersection of these three subsets, containing 65 features, led to maximized GPA prediction accuracy. In particular, with the Random Forest algorithm, an MSE of approximately 0.359 was achieved under 3-fold cross-validation.\nB Selected Features\n29 Did (you/a family member living w you) use government food stamps, last month home visit 4 30 Woodcock Johnson Test 10 age equivalency home visit 5 31 You could ask child\u2019s mother\u2019s parents/relatives for\nhelp/advice father 5 32 Feature f5g3513 father 5 33 I get in trouble for talking and disturbing others kid 5 34 Child shows off or clowns primary care-\ngiver 5\n35 Child\u2019s science and social studies teacher 5 36 Child has participated in Title I ESL/bilingual teacher 5 37 Father has spent any time in jail mother 5 38 Child repeated 4th grade primary care-\ngiver 5\n39 You could ask friends/neighbors/co-workers for help/advice mother 5 40 Child is disobedient at home primary caregiver 5 41 Child keeps desk clean and neat without being reminded teacher 5 42 Child is inattentive or easily distracted primary caregiver 5 43 It\u2019s hard for me to pay attention kid 5 44 You could ask child\u2019s mother for help/advice father 5 45 Child can\u2019t concentrate, can\u2019t pay attention for long primary care-\ngiver 5\n46 Child\u2019s language and literacy skills teacher 5 47 It\u2019s hard for me to finish my schoolwork kid 5 48 I worry about doing well in school kid 5 49 I worry about taking tests kid 5 50 Number of families on block know well primary care-\ngiver 5\n51 PPVT percentile rank home visit 5 52 Child shows anxiety about being with a group of\nchildren teacher 5 53 Child finishes class assignments with time limits teacher 5 54 Child uses free time in an acceptable way teacher 5 55 Child says nice things about self/others when ap-\npropriate teacher 5\n56 Who usually initiated the contact primary caregiver 5 57 Number of child\u2019s close friends you primary caregiver 5\n4 See https://codalab.fragilefamilieschallenge.org/f/api/codebook/ for the description\n58 PPVT age equivalency home visit 5 59 Child attends to your instructions teacher 5 60 Child ignores peer distractions when doing class\nwork teacher 5 61 Woodcock Johnson Test 10 percentile rank home visit 5 62 Frequency kids picked on you or said mean things\nto you kid 5 63 PPVT standard score home visit 5 64 Being a parent is harder than I thought it would be father 5"
    }
  ],
  "title": "Explainable AI as a Social Microscope: A Case Study on Academic Performance",
  "year": 2020
}
