{"abstractText": "While deep learning has achieved great success in many fields, one common criticism about deep learning is its lack of interpretability. In most cases, the hidden units in a deep neural network do not have a clear semantic meaning or correspond to any physical entities. However, model interpretability and explainability are crucial in many biomedical applications. To address this challenge, we developed the Factor Graph Neural Network model that is interpretable and predictable by combining probabilistic graphical models with deep learning. We directly encode biological knowledge such as Gene Ontology as a factor graph into the model architecture, making the model transparent and interpretable. Furthermore, we devised an attention mechanism that can capture multi-scale hierarchical interactions among biological entities such as genes and Gene Ontology terms. With parameter sharing mechanism, the unrolled Factor Graph Neural Network model can be trained with stochastic depth and generalize well. We applied our model to two cancer genomic datasets to predict target clinical variables and achieved better results than other traditional machine learning and deep learning models. Our model can also be used for gene set enrichment analysis and selecting Gene Ontology terms that are important to target clinical variables.", "authors": [{"affiliations": [], "name": "Tianle Ma"}, {"affiliations": [], "name": "Aidong Zhang"}], "id": "SP:be3e443e9cdc2c4b489b599ce1340c239fdc7763", "references": [{"authors": ["B. Alipanahi", "A. Delong", "M.T. Weirauch", "B.J. Frey"], "title": "Predicting the sequence specificities of dna-and rna-binding proteins by deep learning", "venue": "Nature biotechnology,", "year": 2015}, {"authors": ["P.W. Battaglia", "J.B. Hamrick", "V. Bapst", "A. Sanchez-Gonzalez", "V. Zambaldi", "M. Malinowski", "A. Tacchetti", "D. Raposo", "A. Santoro", "R Faulkner"], "title": "Relational inductive biases, deep learning, and graph networks", "venue": "arXiv preprint arXiv:1806.01261,", "year": 2018}, {"authors": ["S. Ghosal", "D. Blystone", "A.K. Singh", "B. Ganapathysubramanian", "A. Singh", "S. Sarkar"], "title": "An explainable deep machine vision framework for plant stress phenotyping", "venue": "Proceedings of the National Academy of Sciences,", "year": 2018}, {"authors": ["D. Gunning"], "title": "Explainable artificial intelligence (xai)", "venue": "Defense Advanced Research Projects Agency (DARPA), nd Web,", "year": 2017}, {"authors": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "title": "Deep residual learning for image recognition", "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,", "year": 2016}, {"authors": ["G. Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "Mohamed", "A.-r", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "Sainath", "T. N"], "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "venue": "IEEE Signal processing magazine,", "year": 2012}, {"authors": ["G. Huang", "Y. Sun", "Z. Liu", "D. Sedra", "K.Q. Weinberger"], "title": "Deep networks with stochastic depth", "venue": "In European Conference on Computer Vision,", "year": 2016}, {"authors": ["G. Huang", "Z. Liu", "L. Van Der Maaten", "K.Q. Weinberger"], "title": "Densely connected convolutional networks", "venue": "In CVPR,", "year": 2017}, {"authors": ["D.P. Kingma", "M. Welling"], "title": "Auto-encoding variational bayes", "venue": "arXiv preprint arXiv:1312.6114,", "year": 2013}, {"authors": ["T.N. Kipf", "M. Welling"], "title": "Semi-supervised classification with graph convolutional networks", "venue": "arXiv preprint arXiv:1609.02907,", "year": 2016}, {"authors": ["D. Koller", "N. Friedman", "F. Bach"], "title": "Probabilistic graphical models: principles and techniques", "venue": "MIT press,", "year": 2009}, {"authors": ["T. Pham", "T. Tran", "D. Phung", "S. Venkatesh"], "title": "Deepcare: A deep dynamic memory model for predictive medicine", "venue": "In Pacific-Asia Conference on Knowledge Discovery and Data Mining,", "year": 2016}, {"authors": ["R. Salakhutdinov", "H. Larochelle"], "title": "Efficient learning of deep boltzmann machines", "venue": "In Proceedings of the thirteenth international conference on artificial intelligence and statistics,", "year": 2010}, {"authors": ["F. Scarselli", "M. Gori", "A.C. Tsoi", "M. Hagenbuchner", "G. Monfardini"], "title": "The graph neural network model", "venue": "IEEE Transactions on Neural Networks,", "year": 2009}, {"authors": ["J. Snell", "K. Swersky", "R. Zemel"], "title": "Prototypical networks for few-shot learning", "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"authors": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "title": "Dropout: a simple way to prevent neural networks from overfitting", "venue": "The Journal of Machine Learning Research,", "year": 1929}, {"authors": ["C.J. Vaske", "S.C. Benz", "J.Z. Sanborn", "D. Earl", "C. Szeto", "J. Zhu", "D. Haussler", "J.M. Stuart"], "title": "Inference of patient-specific pathway activities from multi-dimensional cancer genomics data using paradigm", "venue": "Bioinformatics, 26(12):i237\u2013i245,", "year": 2010}, {"authors": ["A. Vaswani", "N. Shazeer", "N. Parmar", "J. Uszkoreit", "L. Jones", "A.N. Gomez", "\u0141. Kaiser", "I. Polosukhin"], "title": "Attention is all you need", "venue": "In Advances in Neural Information Processing Systems,", "year": 2017}, {"authors": ["D. Wang", "A. Khosla", "R. Gargeya", "H. Irshad", "A.H. Beck"], "title": "Deep learning for identifying metastatic breast cancer", "venue": "arXiv preprint arXiv:1606.05718,", "year": 2016}], "sections": [{"heading": "1 Introduction", "text": "In computational biology, we often need to build predictive models using data-driven approaches. The predictors are usually a set of observable variables which we usually call features, and the targets are variables of interests we want to predict from the observable data. For instance, we may want to use gene expression data to predict disease status.\nWith a sufficient amount of data, machine learning especially deep learning models can achieve very high prediction accuracies. In fact, deep learning has already brought about breakthroughs in computer vision (He et al., 2016), speech recognition (Hinton et al., 2012), natural language processing (Vaswani et al., 2017) and many other fields (LeCun et al., 2015). However, conventional deep learning models require massive training data with clearly defined structure (such as images, audio, and natural languages), and are not directly suitable for many tasks in the biomedical domain. Currently, deep learning is also insufficient to deal with the \u201cbig p, small n\u201d problem (the number of features is large while the number of samples is relatively small) in many biomedical problems.\nOne common criticism about deep learning is its lack of interpretability (Gunning, 2017). In a deep neural network model, the hidden units are unknown and not interpretable. Intriguingly, neural network models with a different number of layers and hidden units can often generate very similar results. Explainability and interpretability are crucial in many biomedical problems, for example,\nar X\niv :1\n90 6.\n00 53\n7v 1\n[ q-\nbi o.\nG N\n] 3\nmedical diagnoses. Developing predictable and explainable deep learning models (Ghosal et al., 2018) is in urgent need.\nIn this paper, we present the Factor Graph Neural Network (FGNN) model, which directly encodes biological knowledge such as Gene Ontology into the model architecture. Unlike the hidden nodes in conventional deep learning models which do not have a physical meaning, each node (i.e., \u201cneuron\u201d) in the Factor Graph Neural Network model corresponds to some biological entity (such as genes or Gene Ontology terms), making the model transparent and interpretable. We not only address the model interpretability challenge but also make the model generalize well by directly incorporating biological knowledge as inductive biases Battaglia et al. (2018) into the model architecture. We also devised a parameter sharing mechanism to significantly reduce the number of model parameters and yet maintain the high representation power of deep learning models. Furthermore, we applied the attention mechanism to capture hierarchical multi-scale interactions between Gene Ontology terms and genes. Our model can be used for gene set enrichment analysis as well. Extensive experiments on two cancer genomic datasets demonstrated the effectiveness of the proposed model.\nIn the following, we briefly review some related work, then describe the proposed model followed by the experimental results. Finally, we conclude the paper with some discussion."}, {"heading": "2 Related work", "text": "Factor graphs have been studied in probabilistic graphical models (Koller et al., 2009). Messagepassing algorithms such as the sum-product algorithm are widely used for inference on factor graphs. Factor graphs have been used to infer patient-specific pathway activity with probabilistic inferences (Vaske et al., 2010). These traditional algorithms are often not end-to-end differentiable and require a large amount of data to learn the model parameters. Recently, with the success of deep learning in many fields such as vision, language and game play (LeCun et al., 2015), Bayesian deep learning combining Bayesian approaches and deep learning has drawn a lot of attention. For example, Variational AutoEncoder (VAE) (Kingma & Welling, 2013) used the reparameterization trick to enable gradient descent through random nodes in a neural network. However, the hidden nodes in the VAE model still lack a clear semantic meaning.\nAs graphs are commonly used in many applications, novel deep learning models on graphs have been developed, including Graph Neural Network (Scarselli et al., 2009), Graph Convolutional Neural Network (Kipf & Welling, 2016), and so on. Graph Attention Model (GAM) (Velickovic et al., 2017) also applied the attention mechanism to learn graph embeddings. These approaches mainly focus on predictive tasks on a single graph, such as predicting node categories in a graph. By contrast, our proposed Factor Graph Neural Network model uses graphs from domain knowledge as model architecture and predicts clinical target variables.\nDeep learning approaches had also been applied to sequencing data (Alipanahi et al., 2015), imaging data (Wang et al., 2016), and medical records (Pham et al., 2016). However, one drawback of most deep learning models is their lack of interpretability (Gunning, 2017). Recently, Ghosal et al. (2018) proposed an explainable deep machine vision framework for plant stress phenotyping by selecting the top-K high-resolution feature maps. However, this framework only works for visionrelated convolutional neural network (CNN) models. For other fields, the feature maps in the convolutional layers are hardly interpretable. Our proposed Factor Graph Neural Network model is highly expressive and interpretable by combining the strength of interpretability of factor graphs in probabilistic graphical models and the supreme representation power of deep neural networks.\nModel generalizability is crucial in many real-world applications. Many regularization techniques have been introduced to deep learning models to make them generalize better. Dropout (Srivastava et al., 2014) prevents overfitting by randomly setting part of the layer output to zero during training. Relational inductive biases within deep learning model can facilitate interpretable relational reasoning (Battaglia et al., 2018), and can also help the model generalize well. Huang et al. (2016) proposed to train a deep neural network with stochastic depth by randomly dropping out layers during training. This can be seen as an \u201cimplicit\u201d ensemble of ResNet (He et al., 2016) models and can generalize better than a single ResNet model with fixed depth. With parameter sharing mechanism, our proposed Factor Graph Neural Network model can also be trained with stochastic depth, which can further boost the model generalizability.\nIn computer vision, it is amazing that convolutional neural networks (CNN) with more than one thousand layers can still surpass human-level performance for image classification tasks (Huang et al., 2016). One key to the success of CNN and other deep learning models is the use of proper relational inductive biases (Battaglia et al., 2018). For CNN, the inductive biases include the locality (parameter sharing) and the translational invariance.\nTo build predictable and generalizable deep learning models in the biomedical domain, we can incorporate some prior knowledge as inductive bias into the model, too. In this paper, our Factor Graph Neural Network model encodes the factor graph from domain knowledge as an inductive bias into the model architecture. It generalizes the Graph Convolutional Network (GCN) (Kipf & Welling, 2016) and can capture hierarchical multi-scale interactions with attention mechanisms."}, {"heading": "3 Factor Graph Neural Network Model", "text": "In many applications, there are two types of variables: observable variables and latent variables. Latent variables can be seen as \u201cfactors\u201d that are related to observable variables. For example, gene expressions are measured in many genetic disease studies. These gene expressions are observable variables. A pathway or Gene Ontology (GO) term involves multiple genes and gene products, but their activities are not directly observable. These pathways and GO terms constitute various factors in a gene network. Since these hidden factors are not directly observable, many models directly use observable variables for predicting target variables such as clinical outcomes.\nFig. 1 shows a simple linear predictive model using the observable gene expressions x to predict the clinical outcomes y.\ny = \u03b20 + p\u2211 i=1 \u03b2i \u2217 xi (1)\nIn this simple linear model Eq. 1, x1, x2, \u00b7 \u00b7 \u00b7 , xn are the predictors, and y is the target. We can apply more complex transformations to the predictors and to model the relationship between x and y. In order to learn the model parameters, we need to construct a dataset consisting of both predictors and targets and train the model with supervised learning. Note this model is \u201cshallow\u201d, which can be seen as a one-layer neural network (we often do not count the input layer).\nWhile shallow models such as generalized linear model and SVM have a limited representation power, they are still widely used in various applications, especially when the model interpretability and generalizability are crucial and the dataset is small. On the other hand, deep neural network models have more representation power to approximate almost any complex nonlinear transformations. However, most deep learning models still lack interpretability and explainability. Deep learning models usually have millions or even billions of parameters. We cannot assign semantic meanings to the hidden units and the parameters in a conventional neural network model. They can easily overfit almost any dataset with proper training, however, the model may not be able to generalize well on a new dataset.\nIn order to make our Factor Graph Neural Network model predictable and generalizable, we incorporate prior knowledge such as Gene Ontology annotations as the inductive bias into the model\narchitecture. Genes and Gene Ontology (GO) terms form a bipartite graph. There are two types of nodes (i.e., gene nodes and GO nodes). Each GO term is associated with a number of genes and gene products. GO terms are treated as factors in the Factor Graph Neural Network model. (Note we can also use pathways or other gene sets derived from biological knowledgebase as factors.) Based on Gene Ontology annotations, we can build a factor graph with GO terms as factors and genes as observable variables. This factor graph encodes domain knowledge and can be used as an inductive bias for constructing the Factor Graph Neural Network model.\nSuppose there are k factors (i.e.\u201e GO terms) F = {f1, f2, \u00b7 \u00b7 \u00b7 , fk} and n observable variables (i.e., genes) X = {x1, x2, \u00b7 \u00b7 \u00b7 , xn}. Each factor fj has its domain on a subset of the observable variables Dj \u2282 X .\nfj = \u03c6j(Dj), j = 1, 2, \u00b7 \u00b7 \u00b7 , k (2)\n\u03c6j in Eq. 2 is an unknown complex function that maps the set of observable variables Dj to factor fj . We can use a neural network to approximate \u03c6j .\nFig. 2 shows a simple two-layer Factor Graph Neural Network model. The nodes in the input layer are genes, and the nodes in the hidden layer are GO terms. The output layer is the target clinical outcomes. There is an edge between a gene and a GO term if and only if the gene is included in the GO term. Therefore the network is not fully connected between the input layer and the hidden layer. Instead, the connections are determined by the relationships between GO terms (factors) and genes (observable variables).\nEach GO term is modeled by a small neural network model (Eq. 2). In total, we will have k neural network models to approximate k GO terms (factors). Note we have combined all the k neural network models into one model with sparse connections in Fig. 2. We can then use these k factors to make predictions on the target clinical variable. The overall model can be seen as a network of networks. Each GO term (biological pathway) form a subnetwork, and all different GO terms (pathways) interact with each other forming a complex network of subnetworks."}, {"heading": "3.1 Unrolled Factor Graph Neural Network model", "text": "The two-layer Factor Graph Neural Network model as shown in Fig. 2 is a two-layer neural network with its hidden layer corresponding to Gene Ontology terms and the edges determined by the Gene Ontology annotations. It is usually not sufficient for modeling complex nonlinear transformations with a \u201cshallow\u201d architecture. In order to make this model more expressive to model complex nonlinear transformations, we can unroll this Factor Graph Neural Network model to make it have more layers as deep neural networks can have more expressive power.\nFig. 3 shows an unrolled factor graph neural network model with six layers. The input layer is the observable gene expressions x. The first hidden layer corresponds to the GO terms. The second hidden layer corresponds to some latent state of genes. The rest of the hidden layers all correspond to latent states of genes or GO terms. The output layer is the target clinical variable y.\nBy unrolling the factor graph neural network model, we introduced multiple composable nonlinear transformations, making the model able to approximate any complex nonlinear functions. This unrolling operation is inspired by the efficient learning of deep Boltzmann machines (Salakhutdinov & Larochelle, 2010)."}, {"heading": "3.1.1 Parameter sharing among layers", "text": "Though Fig. 3 only shows a six-layer factor graph neural network model, there can be infinitely many layers by unrolling the model. If each layer has a different set of parameters as in widely used convolutional neural networks, then the number of parameters will be too large for most datasets in the biomedical domain which usually have the \u201cbig p, small n\u201d problem. In order to reduce the risk of overfitting, we adopt a parameter sharing mechanism similar to recurrent neural networks and the Transformer model (Vaswani et al., 2017). Different from convolutional neural networks where parameter sharing is within a single layer, our factor graph neural network model shares parameters across layers.\nThere are two set of parameters in this unrolled factor graph neural network model: one used to map genes to GO terms, and the other map GO terms to genes. We have introduced the transformations \u03c6j from a subset of gene variables Dj to GO factor fj (Eq. 2). We can also infer or reconstruct the hidden states of gene variables X from the GO factors F .\nxi = \u03d5i(Di), i = 1, 2, \u00b7 \u00b7 \u00b7 , n (3)\nxi is the ith variable (e.g., gene), while Di \u2282 F is a subset of factors (GO terms) that include xi. In an unrolled factor graph neural network model with multiple layers, we can share these two set of parameters (corresponding to the two set of transformations from variables to factors and vice versa) across layers. As the same set of parameters are used between variables and factors in all the layers, we can significantly reduce the number of model parameters. Since there can be multiple layers corresponding to genes and GO terms, we can add skip connections as in ResNet (He et al., 2016) to connect the previous gene/GO layers to the current gene/GO layers. This can help gradient flow and speed up training.\nTrain the model with stochastic depth With parameter sharing in the unrolled factor graph neural network model, we can train the model with stochastic depth (Huang et al., 2016). This can serve as an implicit regularizer similar to a Dropout layer."}, {"heading": "3.2 Attention mechanism for hierarchical multi-scale interactions", "text": "Up to now we only considered immediate interactions among nodes in a factor graph, i.e., the direct connection between observable variables and factors. With unrolled factor graph neural network, we can naturally incorporate multi-scale hierarchical interactions into the model using attention mechanisms.\nTo enable multi-scale hierarchical interaction in an unrolled factor graph neural network model, we connect the lth layer with all previous (l \u2212 1) layers, similar to DenseNet (Huang et al., 2017). However, we do not use dense connections between layers. Instead, we only connect nodes that can reach each other in the factor graph within a number of steps.\nMore specifically, the connections between lth layer and (l \u2212 1)th layer are simply the edges in the factor graph. There will be an edge between a node in the lth layer and a node in the (l\u2212 1)th layer if and only if node i can reach node j in the factor graph in one step. In other words, j is the direct neighbor of i. Similarly, there will be an edge between node i in the lth layer and node j in the (l \u2212 k)th layer if and only if node i can reach node j in k steps. For example, when k = 2, node i and j are connected through one neighbor, and all the connections capture neighbors of neighbors in the factor graph.\nThis idea is very much like convolutional neural networks (CNN) on graphs, where the neurons in the high-level layers will have a larger reception field. The difference is that in a CNN model, the number of neurons in each layer will be decreased by a factor of the stride, and the new feature plane no longer has a clear interpretable physical meaning. By contrast, every neuron in the factor graph neural network model corresponds to some physical entity (genes or GO terms), making the model transparent and interpretable. In the following, we present the algorithm to calculate the attention matrices that are used to connect all the layers in a factor graph neural network model to capture multi-scale hierarchical interactions."}, {"heading": "3.2.1 Attention matrices for capturing multi-scale hierarchical interactions", "text": "Instead of simply connecting nodes across layers based on hierarchical interactions, we apply the attention mechanism to assign weights to connections between different layers. The unrolled factor graph neural network model is based on the factor graph which encodes biological knowledge such as Gene Ontology annotations. (Note a factor graph is a data structure encoding biomedical domain knowledge, while the factor graph neural network model is a deep neural network model which uses the domain knowledge factor graph as the model backbone.) A factor graph can be seen as an undirected bipartite graph. There are two node sets: source variables and target factors. Based on the network topology, we can calculate the state transition matrices from source to target and vice versa. One simplest state transition matrix is the normalized adjacency matrix. Algorithm 1 shows how to calculate the attention matrices from the state transition matrices. Since the lth layer is connected to all previous l \u2212 1 layers in a factor graph neural network model, there are l \u2212 1 attention matrices for the lth layer used to attend each of the previous l \u2212 1 layers. These attention matrices provide with the weights for the connections across different layers, which capture multi-scale hierarchical interactions among nodes. Note we can apply Algorithm 1 to non-bipartite graphs as well by setting the source nodes and target nodes the same."}, {"heading": "3.2.2 Layer normalization", "text": "Since we connect each layer with all the previous layers, the outputs from higher layers may become larger and larger. To ensure the outputs of all layers are on the same scale, we apply layer normalization before producing the final output of each layer.\nhi = hi \u2212 \u00b5 \u03c3\n\u00b5 = 1\nn n\u2211 i=1 hi\n\u03c32 = 1\nn\u2212 1 n\u2211 i=1 (hi \u2212 \u00b5)2\n(4)\nHere, \u00b5 and \u03c3 are layer mean and standard deviation. By applying layer normalization, we ensure that the output of each layer is on the same scale. This will stabilize training and make the learned representations for all the nodes (source variables or target factors) lie on the same manifold.\nAlgorithm 1: Generate attention matrices for a factor graph neural network model Input :The state transition matrix from source variables to target factors of a factor graph: Ms The state transition matrix from target factors to source variables: Mt (for undirected graph: Mt =M\nT s ) Number of levels: l\nOutput :A lists of attention matrices from the source variables to the nodes in all previous layers: As A lists of attention matrices from the factors to the nodes in all previous layers: At\nAs = [Ms], At = [Mt] for i\u2190 2 to l do\nM \u2032 s =Ms,M \u2032\nt =Mt for j \u2190 i\u2212 1 to 1 do\nif (i\u2212 j)%2 = 0 then // Layer i and j correspond to the same node set M \u2032 s =M \u2032\ns \u00b7Ms M \u2032 t =M \u2032\nt \u00b7Mt if (i\u2212 j)%2 6= 0 then // i and j correspond to different node sets\nM \u2032 s =M \u2032\ns \u00b7Mt M \u2032 t =M \u2032 t \u00b7Ms\nAs = As + [M \u2032T s ], At = At + [M \u2032T t ]"}, {"heading": "3.2.3 Forward pass of the factor graph neural network model", "text": "Since each factor has a different domain (reception field), we need to compute each factor separately. Sequential computation is time-consuming if the number of factors is large. With parameter sharing, we can parallelize the computation.\nWe use matrix Ms to store all the weights used to transform from source variables (i.e., genes) to target factors (i.e., GO terms), and Mt to store all the weights used to reconstruct source variables (or their hidden states) from the factors.\nLet As and At be the list of attention matrices generated by Algorithm 1 from gene layer and GO layer to all the previous layers. The forward pass algorithm of an unrolled factor graph neural network model is shown in Algorithm 2.\nIn Algorithm 2, we randomly choose l(N \u2264 l \u2264M) as the number of layers for training the model with stochastic depth. We use attention matrices As and At to capture the weighted multi-scale interactions among nodes in the factor graph.\nFor supervised learning, we can add a classification head or regression head using the output of the last layer(s). We can use stochastic gradient descent to update model parameters Ms and Mt. The whole framework is end-to-end differentiable.\nApply to interaction networks Our factor graph neural network model can be applied to nonbipartite graphs as well. For non-bipartite graphs, we can treat the source and target nodes as the same set of nodes and set model parameters Ms =Mt in Algorithm 2. The whole framework can work seamlessly for non-bipartite graphs as well.\nEncode network hierarchy If we have additional topological information about the factors such as Gene Ontology hierarchical structure, we can also encode the network hierarchy in the Factor Graph Neural Network model. A hierarchical network such as Gene Ontology can be encoded as a list of < child, parent, is \u2212 a > relations. For example GO:0000038 is a GO:0006631. (Here GO:0000038 is the child node and GO:0006631 is the parent node.) This hierarchical network can be seen as a directed acyclic graph. Each node can be seen as a factor with its domain being all its children. Thus the factor graph neural network can be applied to encode network hierarchy as well.\nFactor Graph Neural Network for Gene Set Enrichment Analysis The factor graph neural network model can also be used for gene set enrichment analysis (GSEA). Currently, gene set\nAlgorithm 2: Forward pass of the factor graph neural network model Input :Feature matrix X of observable variables (source nodes)\nThe weight matrix from source to target: Ms The weight matrix from target to source: Mt (for undirected graph: Mt =MTs ) A lists of attention matrix from the source nodes to the nodes in previous layers: As A lists of attention matrix from the target nodes to the nodes in previous layers: At Maximal number of layers: M Minimal number of layers: N\nOutput :The outputs of each layer H Randomly choose a number l(N \u2264 l \u2264M) H = [X] for i\u2190 2 to l do\nY = [ ] for j \u2190 i\u2212 1 to 1 do\nif i%2 = 0 & j%2 = 0 then // Layer i and j are source nodes y = H[j] \u00b7As[i\u2212 j]\nif i%2! = 0 & j%2 = 0 then // Layer i is target and j is source y = H[j] \u00b7Ms \u00b7At[i\u2212 j]\nif i%2 = 0 & j%2! = 0 then // Layer i and j are target nodes y = H[j] \u00b7At[i\u2212 j]\nif i%2 = 0 & j%2! = 0 then // Layer i is source and j is target y = H[j] \u00b7Mt \u00b7As[i\u2212 j]\nY = Y + [y]\nH = H + [mean(Y )]\nenrichment analysis mainly employs statistical approaches to identify the enriched gene sets. The factor graph neural network can be used to identify gene sets that are relevant to target clinical variables of interest based on stochastic gradient descent.\nIn fact, each GO term is associated with a set of genes and can thus be seen as a gene set. Our approach can be applied to identify enriched gene sets by training the model end-to-end. The weights of the last layer from the gene sets to the target clinical variable can be used to select gene sets that are most relevant to the target variable."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Dataset", "text": "We downloaded the harmonized gene expression datasets for Lung Squamous Cell Carcinoma (project ID: TCGA-LUSC) and Kidney Renal Clear Cell Carcinoma (project ID: TCGA-KIRC) from Genomic Data Commons Data Portal (https://portal.gdc.cancer.gov/). First, we are trying to use gene expression profiles to predict tumor stage. We selected 246 Lung Squamous Cell Carcinoma primary solid tumor samples from two different tumor stages (\u201cstage ib\u201d: 152 samples, \u201cstage iib\u201d: 94 samples), and 476 Kidney Renal Clear Cell Carcinoma primary solid tumor samples from three different stages (\u201cstage i\u201d: 271 samples, \u201cstage iv\u201d: 82 samples, \u201cstage iii\u201d: 123 samples). Other stages have too few samples and are thus being discarded. The tumor stage information was also retrieved from Genomic Data Commons Data Portal.\nFor our factor graph neural network model and Graph Convolutional Neural Network model, we also need Gene Ontology (GO) information. We downloaded and processed the current release of the human Gene Ontology Annotation file from ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/ HUMAN/."}, {"heading": "4.2 Data preprocessing", "text": "For gene expression data (RNA-seq HTSeq counts), we performed log2 transformation and selected top 5000 most variant genes for downstream analysis. We normalized gene expression data to have mean equal to 0 and standard deviation equal to 1 for all samples.\nAfter filtering out GO terms that have less than five genes in the selected gene set, 2597 GO terms had been selected as factors for the TCGA-LUSC project, and 2630 GO terms for the TCGA-KIRC project.\nFor the experiments, we randomly split the dataset into three sets: 70% for training, 10% for validation, and 20% for testing. We trained different models on the training set, and evaluated them on the validation set. We chose the model with the best validation accuracy to make predictions on the test set, and reported the precision, recall and F1 values on the test set. We shuffled the data and repeated the process ten times, and reported the average metrics for comparing model performances.\nWe compared our methods with traditional machine learning methods Random Forest, Decision Tree and Multilayer Perceptron (MLP), as well as two recent deep learning methods including Graph Convolutional Neural Network (GCN) Kipf & Welling (2016), and Prototypical Network Snell et al. (2017).\nTable 1 and Table 2 showed the experimental results on the lung cancer and kidney cancer datasets. On both datasets, the proposed factor graph neural network model achieved the best precision, recall and F1 scores.\nIn order to see the contribution of incorporating Gene Ontology into the model, we randomly assign genes to gene sets and build a random factor graph for the model. The model performed much worse after randomization on both dataset: the F1 score dropped from 0.566 to 0.539 on the lung cancer dataset and from 0.563 to 0.532 on the kidney cancer dataset."}, {"heading": "4.3 Predicting tumor-normal sample type", "text": "We also used our proposed method to classify sample types (primary solid tumor and solid tissue normal) on Kidney Renal Clear Cell Carcinoma dataset which has 538 tumor samples and 72 normal samples. By comparing the tumor samples with the normal samples, we can get insights about the molecular underpinning of tumors.\nAs normal samples and tumor samples are very different and are almost linearly separable, we used 5% of the data (29 samples) as the training set, 5% (29 samples) as the validation set, and the rest 90% (552 samples) as the test set. Both the Factor Graph Neural Network and Multilayer Perceptron\n(MLP) achieved 98% accuracy on the test set. However, our Factor Graph Neural Network model is interpretable while MLP and other models are not.\nIn the Factor Graph Neural Network model, the last layer is a linear classifier. The input of the classifier is the learned representations of Gene Ontology terms. The weight matrix of the linear classifier can be used to select Gene Ontology terms that are important to distinguish tumor and sample types.\nWe plotted the weights for 2678 GO terms in the last hidden layer of the model. Before training the model parameters are randomly initialized as shown in Figure. 4a. After training, most GO terms have a small weight in absolute value, while only a few have high weights as shown in Figure. 4b. Table 3 shows the top ten GO terms with the highest absolute weights learned by the factor graph neural network model. The relevance of these GO terms to the kidney cancer can be verified by the domain experts."}, {"heading": "5 Conclusion", "text": "While data is abundant in many domains such as text, images, videos, etc., biomedical data including genomic data is usually not sufficient for large-scale machine learning. In order to build a predictable and generalizable deep learning model, we usually need to incorporate some biological knowledge as an inductive bias into the model.\nIn this paper, we presented the Factor Graph Neural Network model. The model architecture is based on biomedical knowledge (i.e., Gene Ontology annotations). Each node in the Factor Graph Neural Network model corresponds to some biological entity such as genes or Gene Ontology terms, making the model transparent and interpretable.\nIn order to make the model expressive enough to capture any complex nonlinear relationships, we can unroll the Factor Graph Neural Network model to have infinitely many layers. With parameter sharing, the model can be trained with stochastic depth which can help the model generalize better. We also devised an attention mechanism to capture the multi-scale interactions among biological entities such as genes and Gene Ontologies terms.\nThe experimental results on two cancer genomic datasets show that our proposed model outperformed other methods including Graph Convolutional Network (Kipf & Welling, 2016). Though we mainly focused our discussion on biomedical data analysis, as a general framework, the Factor Graph Neural Network can be applied to any other data with a graph as prior knowledge for interpretable deep learning."}], "title": "Incorporating Biological Knowledge with Factor Graph Neural Network for Interpretable Deep Learning", "year": 2019}