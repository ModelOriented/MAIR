{
  "abstractText": "As we rely more and more on machine learning models for real-life decision-making, being able to understand and trust the predictions becomes ever more important. Local explainer models have recently been introduced to explain the predictions of complex machine learning models at the instance level. In this paper, we propose Local Rule-based Model Interpretability with k-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains k-optimal association rules from a neighbourhood of the instance to be explained. Compared to other rule-based approaches in the literature, we argue that the most predictive rules are not necessarily the rules that provide the best explanations. Consequently, the LoRMIkA framework provides a flexible way to obtain predictive and interesting rules. It uses an efficient search algorithm guaranteed to find the koptimal rules with respect to objectives such as strength, lift, leverage, coverage, and support. It also provides multiple rules which explain the decision and counterfactual rules, which give indications for potential changes to obtain different outputs for given instances. We compare our approach to other stateof-the-art approaches in local model interpretability on three different datasets, and achieve competitive results in terms of local accuracy and interpretability.",
  "authors": [
    {
      "affiliations": [],
      "name": "Dilini Rajapaksha"
    },
    {
      "affiliations": [],
      "name": "Christoph Bergmeir"
    }
  ],
  "id": "SP:d860af7ddb637a12d9be3913b3a5e0ca61aab24c",
  "references": [
    {
      "authors": [
        "M.T. Ribeiro",
        "S. Singh",
        "C. Guestrin"
      ],
      "title": "Why should I trust you?: Explaining the predictions of any classifier",
      "venue": "Proceedings of the 22nd TABLE VI NUMBER OF FEATURES IN THE EXPLANATION Dataset Compas Adult German Blackbox Anchor LORE LoRMIkA Anchor LORE LoRMIkA Anchor LORE LoRMIkA SVM 1.71 1.36 1.21 2.61 1.24 1.41 2.87 1.10 1.0 LR 2.08 1.28 1.5 2.72 1.9 1.27 2.8 1.85 1.75 RF 4.2 1.61 1.8 3.46 2.04 1.72 3.1 2.5 1.27 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135\u20131144, ACM, Aug. 2016.",
      "year": 2016
    },
    {
      "authors": [
        "S.M. Lundberg",
        "S.-I. Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "Advances in Neural Information Processing Systems 30 (I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.), pp. 4765\u20134774, Curran Associates, Inc., 2017.",
      "year": 2017
    },
    {
      "authors": [
        "M.T. Ribeiro",
        "S. Singh",
        "C. Guestrin"
      ],
      "title": "Anchors: High-precision model-agnostic explanations",
      "venue": "AAAI Conference on Artificial Intelligence, 2018.",
      "year": 2018
    },
    {
      "authors": [
        "H. Lakkaraju",
        "S.H. Bach",
        "L. Jure"
      ],
      "title": "Interpretable decision sets: A joint framework for description and prediction",
      "venue": "KDD, vol. 2016, pp. 1675\u20131684, Aug. 2016.",
      "year": 2016
    },
    {
      "authors": [
        "N. Puri",
        "P. Gupta",
        "P. Agarwal",
        "S. Verma",
        "B. Krishnamurthy"
      ],
      "title": "MAGIX: model agnostic globally interpretable explanations",
      "venue": "CoRR, vol. abs/1706.07160, 2017.",
      "year": 2017
    },
    {
      "authors": [
        "E. Kaufmann",
        "S. Kalyanakrishnan"
      ],
      "title": "Information complexity in bandit subset selection",
      "venue": "Conference on Learning Theory, pp. 228\u2013251, June 2013.",
      "year": 2013
    },
    {
      "authors": [
        "R. Guidotti",
        "A. Monreale",
        "S. Ruggieri",
        "D. Pedreschi",
        "F. Turini",
        "F. Giannotti"
      ],
      "title": "Local rule-based explanations of black box decision systems",
      "venue": "CoRR, vol. abs/1805.10820, 2018.",
      "year": 1805
    },
    {
      "authors": [
        "L. Geng",
        "H.J. Hamilton"
      ],
      "title": "Interestingness measures for data mining: A survey",
      "venue": "ACM Computing Surveys (CSUR), vol. 38, p. 9, Sept. 2006.",
      "year": 2006
    },
    {
      "authors": [
        "R. Agrawal",
        "T. Imieli\u0144ski",
        "A. Swami"
      ],
      "title": "Mining association rules between sets of items in large databases",
      "venue": "SIGMOD Rec., vol. 22, pp. 207\u2013216, June 1993.",
      "year": 1993
    },
    {
      "authors": [
        "G.I. Webb"
      ],
      "title": "Filtered-top- k association discovery",
      "venue": "WIREs Data Mining Knowl Discov, vol. 1, pp. 183\u2013192, May 2011.",
      "year": 2011
    },
    {
      "authors": [
        "P.K. Novak",
        "N. Lavra\u010d",
        "G.I. Webb"
      ],
      "title": "Supervised descriptive rule discovery: A unifying survey of contrast set, emerging pattern and subgroup mining",
      "venue": "J. Mach. Learn. Res., vol. 10, no. Feb, pp. 377\u2013403, 2009.",
      "year": 2009
    },
    {
      "authors": [
        "E. Cohen",
        "M. Datar",
        "S. Fujiwara",
        "A. Gionis",
        "P. Indyk",
        "R. Motwani",
        "J.D. Ullman",
        "C. Yang"
      ],
      "title": "Finding interesting associations without support pruning",
      "venue": "IEEE Trans. Knowl. Data Eng., vol. 13, pp. 64\u201378, Jan. 2001.",
      "year": 2001
    },
    {
      "authors": [
        "G.I. Webb"
      ],
      "title": "OPUS: An efficient admissible algorithm for unordered search",
      "venue": "J. Artif. Intell. Res., vol. 3, pp. 431\u2013465, Dec. 1995.",
      "year": 1995
    },
    {
      "authors": [
        "X. Yin",
        "J. Han"
      ],
      "title": "CPAR: Classification based on predictive association rules",
      "venue": "Proceedings of the 2003 SIAM International Conference on Data Mining, Proceedings, pp. 331\u2013335, Society for Industrial and Applied Mathematics, May 2003.",
      "year": 2003
    },
    {
      "authors": [
        "W.W. Cohen"
      ],
      "title": "Fast effective rule induction",
      "venue": "Proceedings of the Twelfth International Conference on International Conference on Machine Learning, ICML\u201995, (San Francisco, CA, USA), pp. 115\u2013123, Morgan Kaufmann Publishers Inc., 1995.",
      "year": 1995
    },
    {
      "authors": [
        "J.R. Quinlan",
        "R.M. Cameron-Jones"
      ],
      "title": "FOIL: A midterm report",
      "venue": "Machine Learning: ECML-93, pp. 1\u201320, Springer Berlin Heidelberg, 1993.",
      "year": 1993
    }
  ],
  "sections": [
    {
      "text": "Index Terms\u2014interpretability, local-interpretability, k-optimal, association-rules\nI. INTRODUCTION Explainability of machine learning models is becoming ever more important; for example, the European General Data Protection Regulation from 2018 contains a right to explanation concept for any decision provided by predictive models. Recently, model-agnostic interpretability methods have been introduced that offer such explanations for predictions. These use simpler models fitted locally in the neighbourhood of an instance to the output of a more complex black-box model. The first work in this line that paved the way for others was the work of Ribeiro [1] that introduced Local Interpretable Modelagnostic Explanations (LIME). Here, instances are randomly perturbed in the neighbourhood of the instance to be explained and a linear model is fitted to the data in the generated neighbourhood. LIME has various limitations, e.g., it does not perform well when the features have a higher degree of interactions among features and non-linear relationships with the target variable. Consequently, Lundberg and Lee [2] introduced SHapley Additive exPlanation (SHAP) that overcomes many of the shortcomings of LIME by providing consistent additive explanations.\nRecently, many researchers have shifted from linear models as explainers to rule-based explanations, as they arguably provide more precise explanations to the end users [3] and are more interpretable [4] compared to others. A global rulebased explainer was introduced by Puri et al. [5]. Ribeiro et al. [3] proposed Anchor-LIME, where with the help of a bandit algorithm [6] a neighbourhood is selected. Then, rules are extracted from the neighbourhood while finding subsets of features that retain the same prediction when held constant, even though all other features are changed. Rules obtained that way are called anchors by those authors. A limitation of Anchor-LIME is that it does not provide counterfactual rules which are often important to reverse a decision. LOcal Rule-based Explanations (LORE) was introduced by Guidotti et al. [7]. In this algorithm a decision tree is built in the neighborhood of an instance to be explained, to acquire a single rule for the decision and set of counterfactual rules for the reverse decision.\nIn this paper, we propose a flexible framework for Local Rule-based Model Interpretability with k-optimal Associations (LoRMIkA). LoRMIkA leverages decades of research in association rule mining, and is therewith able to overcome a number of drawbacks of the existing algorithms. We argue that association rules are better suited to provide explanations than, e.g., linear models, decision trees, as they are local models both with respect to features and instances. Furthermore, we argue that the most predictive rules are not necessarily the rules that explain best. LoRMIkA uses an efficient search algorithm to find the k-optimal rules from a neighbourhood and is therewith able to produce modelagnostic explanations for a given black-box algorithm. We are able to search for the best rules with respect to strength, lift, leverage, coverage and support, which are measures developed by the association rule mining community [8] to measure both if rules are predictive and interesting. Furthermore, LoRMIkA generates multiple rules for the decision and to reverse the decision, tackles redundancy of features in rules and is able to generate simple rules.\nWe have tested and compared LoRMIkA with other stateof-the-art approaches on three different tabular classification datasets and conducted both qualitative and quantitative experiments to assess both interpretability and local accuracy, with\nar X\niv :1\n90 8.\n03 84\n0v 1\n[ cs\n.L G\n] 1\n1 A\nug 2\n01 9\ncompetitive results. The remainder of this paper is structured as follows. Section II revisits the most important results from the association rule mining community with respect to local explainers. Section III presents our approach. Section IV discusses the experimental setup and results, and Section V concludes the paper."
    },
    {
      "heading": "II. ASSOCIATION RULE MINING",
      "text": "In this section we revisit the major relevant findings in association rule mining research with respect to association rules being local models, predictive versus explanatory rules, and efficient ways for finding rules."
    },
    {
      "heading": "A. Notations and Definitions",
      "text": "Association rule mining is a rule-based machine learning approach to find interesting combinations of input and output variables of frequent patterns, correlations, associations, or causal structures in large databases. It was firstly introduced by Agrawal [9]. In the following, we define the concepts used in our work.\nDefinition 1. Association Rule: An Association rule is a rule in the form X \u21d2 Y , where X and Y are disjoint sets. X is called the antecedent (left-hand-side or LHS) and set Y is called the consequent (right-hand-side or RHS) of the rule. In our work, X is a set of particular feature values, and Y is the value of the target variable.\nDefinition 2. Support: Fraction of instances that fulfill both X and Y . This shows the relative frequency of a particular pattern of feature values in the dataset. Support(X) = Support count of (X)\nTotal number of instances in the dataset\nDefinition 3. Coverage : The support of the antecedent (lefthand-side or LHS) of an association rule. Coverage{X \u21d2 Y } = Support(X)\nDefinition 4. Strength or Precision : This measures relative frequency of examples that satisfy the RHS when they satis Strength{X \u21d2 Y } = Support(X,Y ) Coverage(X,Y )\nDefinition 5. Lift : Measures how often feature values in Y appear in instances that contain X , while controlling for the frequency for target value Y . This is a measure for how surprising or interesting a rule is, i.e., how much it differs from a random association. A lift equal to one implies that no associations can be found. A lift between zero and one means a negative correlation and a lift greater one means positive correlation. Lift{X \u21d2 Y } = Support(X,Y ) Coverage(X)\u00d7 Coverage(Y ) Definition 6. Leverage : When the feature values are statistically independent computing the difference between the probability of the rule and the expected probability is called the leverage. Leverage can vary between [\u22121, 1]. When the leverage is equal to zero, no associations can be found. When\nit is positive/negative, a positive/negative relationship of the RHS and LHS can be determined. Leverage(X \u21d2 Y ) = Support(X \u21d2 Y ) \u2212 (Coverage(X) \u00d7 Coverage(Y ))"
    },
    {
      "heading": "B. Association rules are local models",
      "text": "A typical Machine Learning algorithm for prediction will have to produce a single global model that is often the result of some form of model selection. In this process interesting findings about the dataset that may contain useful explanations may get lost and not be considered, as usually there will be not one single valid model, but different potentially equally valid ones. Webb [10] discusses the characteristics of association rules being local models, as they consider only certain features and only certain values of these features, thus only considering a subspace of the feature space. Association rule mining aims to discover all such local models. For example, if there are two rules which are equally predictive, our aim is to find both of these rules which help users when making decisions. Also, the model that is globally optimal may not be the optimal solution for a locally defined region on the subspace. Association rule mining can find the optimal models in any specified region, which will be more efficient than a global model [10]."
    },
    {
      "heading": "C. Rules that predict vs rules that explain",
      "text": "Predictability of a rule can be measured using the strength of the rule and the interestingness of a rule can be measured by the lift or the leverage. Furthermore, when the value of the strength is high, the rule is said to be a predictive rule and when the value of the lift or the leverage is high, the rule is said to be an interesting rule. Novak et al. [11] show the differences between interpretability and predictability, by discussions that the most predictive rules and the rules that explain best on a given dataset will be usually different. Using the example of a C4.5 decision tree for a predictive algorithm, they illustrate that redundant rules will be ignored, while in descriptive algorithms, redundant rules should be considered. On the other hand, highly predictive rules may result from spurious correlations in the training data, if they represent only a small number of examples. Such rules will be filtered out by an adequate descriptive algorithm accordingly, while a predictive algorithm may be forced to take such rules into account for the sake of completeness of the predictions. Thus, though rules may not be predictive, they may still be of interest to understand a dataset, and on the other hand even if rules are highly predictive they may not be useful for explanations."
    },
    {
      "heading": "D. Mining interesting rules efficiently",
      "text": "The traditional approach for association rule mining is the Apriori approach [9] whose fundamental step is to find the itemsets that occur most often, the so-called frequent itemsets. To select frequent itemsets, a minimum support needs to be given as a parameter. Association rules are then determined within these frequent itemsets. The frequent itemset association paradigm has a number of drawbacks, such as its inability to uncover higher order associations, as these are\ncomparatively infrequent. This is known as the so-called vodka and caviar problem [12]. Another limitation of the approach is that minimum support is not a reasonable threshold to regulate the number of associations, as it is impossible to select the number of associations in advance. So it boils down to a trial and error process, and therewith the minimum support constraint is not a faithful parameter to acquire interesting association rules [10].\nWebb [13] presents the Optimized Pruning for Unordered Search (OPUS) algorithm, that overcomes many of the shortcomings of other association rule mining techniques. It employs a statistically sound process of selecting the top k interesting rules, i.e., the rules with the highest support, coverage, strength, leverage, or lift. Furthermore, it rigorously controls the generation of spurious rules [10] and has the ability to enable filter modes to adjust the length of the rules to be discovered according to input parameters."
    },
    {
      "heading": "III. OUR APPROACH",
      "text": "The main goal of our approach LoRMIkA is to explain an instance locally, with k-optimal association rules. First, we select a neighbourhood of the instance to be explained with the aid of a distance measure. Fig. 1 summarizes how the local explainer works in our algorithm. Then, we generate new samples in the neighbourhood with interpolation and crossover, and perform association rule mining for the instances in the neighbourhood, using as their target values the outputs of the global black-box model. The resulting rules are then categorized into four categories based on the feature values and target value of the instance to be explained.\nOur approach is summarized in Algorithm 1 and the most important parts are discussed in the following.\nAlgorithm 1: Explain Black-box Input : Trx \u2212 training instances without target\nTry \u2212 target of training instances E \u2212 instances need to be explained M \u2212 global black-box model C \u2212 categorical features N \u2212 numerical features\nOutput: Excel Sheet for each element in E with rules in separate four tabs\n1 t\u2190 no of new instances 2 Trpx \u2190 PreProcessingInputData(Trx, E) 3 for e \u2208 E do 4 SelecIns\u2190 SelectInstFrmNeighbourhood(Trx, e) 5 for i\u2190 1 to t do 6 Ig \u2190 GenInstFrmNeighbourhood(SelecIns, C,N) 7 end 8 FullRecordSet\u2190 GetPredictFrmGlobalModel(SelecIns, Ig,M) 9 GenRules\u2190 MOGenRules(TxtNam, TxtData)\n10 return GenRules 11 end"
    },
    {
      "heading": "A. Preprocessing the input data",
      "text": "We preprocess the training data as follows. The categorical variables are converted with a one-hot encoding and numerical variables are Z-score normalized. This is done by the PreProcessingInputData(Trx, E) function in Algorithm 1."
    },
    {
      "heading": "B. Determine the instances in the neighbourhood",
      "text": "The process of instance selection within the given neighbourhood is outlined in Algorithm 2. In this step, the distance between each pre-processed instance in the training set (background set) and the instance that needs to be explained is calculated. We use Euclidean distance as the distance measure, and convert the distance to an exponential similarity score to make the distance more linear and to compare the similarity of the instances in the training set with the explained instance. The similarity is defined as follows:\nK(x, x\u2032) = exp ( \u2212 x\u2212 x \u20322\n2w2\n) . (1)\nIn (1), K(x, x\u2032) is the similarity between two instances x and x\u2032, and w is the kernel width (see also Algorithm 2), a tuning parameter. When w is high, K(x, x\u2032) will be close to 1 for any x, x\u2032. When w is low, K(x, x\u2032) will be close to 0. In our approach \u03c3 in Algorithm 2 is equal to the w in equation 1, which is equal to 0.75 times the number of features [1].\nAfter this we iterate through the sorted similarity vector, until we acquire the minimum number of instances from the class with least instances. The similarity of that point will be the cut point of the similarity score Sct, in Algorithm 2. Also, within the neighbourhood the majority classes\u2019 instances are\nAlgorithm 2: SelectInstFrmNeighbourhood(Trx, E) Input: Trpx \u2212 pre-processed data Output: Neighbours that are in the training set around\nthe instance that needs to be explained\n1 L\u2190 Minimum no of neighbours from each class 2 Sct \u2190 Cut point of the similarity score 3 \u03c3 \u2190 0.75 times square root of the number of features 4 result\u2190 true 5 DistTrSet\u2190 GetEuclidianDistance(Trpx, e) 6 SimTrSet\u2190 CnvrToSimilarityScore(DistTrSet, \u03c3) 7 while result == true do 8 SelecIns\u2190 SelectInstFrmNeighbourhood(Trx, e)\n/* iterate until no of neighbours for minimum class is less than L by adjusting Sct. Then undersample the majority classes until it becomes less than 5 times of the minority class. */\n9 end 10 return SelectIns\nrandomly under-sampled, until there are less than five times of the minority class in order to overcome the class imbalance drawback.\nC. Instance Generation\nThe instance generation procedure is outlined in Algorithm 3. After determining the instances in the neighbourhood, in this step we use the output of Algorithm 2 to generate more instances within the selected neighbourhood, using interpolation and cross-over. To generate a new instance, we randomly choose two parent instances. For the numerical variables new instances are generated as follows:\nNew instance1 = x+ (x \u2032 \u2212 x) \u2217 \u03b1 (2)\nNew instance2 = k + (y \u2212 z) \u2217 \u03c3 (3)\nIn (2), x and x\u2032 are the parent instances, and \u03b1 is a randomly generated number between 0 and 1. Similarly, in (3), k, y and z are the instances from the training set, and \u03c3 is a randomly generated number between 0.5 and 1. Using the aforementioned procedures, we generate a total of t new instances. This corresponds to the GenInstFrmNeighbourhood(SelecIns, C,N) function in Algorithm 1. Then, for categorical features, we use the value of the nearest selected instances in (2) and (3) to the explained instances as the categorical feature values in the newly generated child instance.\nThen, the target predictions of this newly generated dataset and the neighbours are obtained using the global black-box model, and the dataset is used as input for the rule mining algorithm in the next step.\nAlgorithm 3: GenInstFrmNeighbourhood(SelecIns, C,N) Input: SelecIns\u2212 Output of the Algorithm 2\nC \u2212 Categorical Features N \u2212 Numerical Features e\u2212 Instance to be explained\nOutput: Ig \u2212 Generated instances 1 \u03b1\u2190 uniform(0, 1) 2 \u00b5\u2190 uniform(0.5, 1) 3 x, x\u2032 \u2190 RandomSelecIns(SelecIns) 4 newIns1 \u2190 x+ (x\u2032 \u2212 x) \u2217 \u03b1 5 newIns2 \u2190 k + (y \u2212 z) \u2217 \u00b5 /* Get closest neighbours to the\nexplained instance in each newIns1 and newIns2 cases */\n6 closeIns1 \u2190 GetClosestInstance(e, [x, x\u2032]) 7 closeIns2 \u2190 GetClosestInstance(e, [k, y, z]) 8 foreach i \u2208 C do 9 newIns1(i)\u2190 closeIns1(i)\nnewIns2(i)\u2190 closeIns2(i) 10 end 11 return newIns1, newIns2"
    },
    {
      "heading": "D. Generate rules",
      "text": "This step corresponds to the MOGenRules function in Algorithm 1. Association rules are generated using OPUS search. Here, we use the OPUS algorithm for rule extraction rather than algorithms like CPAR [14], RIPPER [15], or FOIL [16], as these algorithms find minimal rule sets which lead to accurate predictions. As discussed in Section II-C the main drawback of focusing on the most predictive rules is the inability to uncover higher order associations, which are relatively infrequent. Here, we argue that a local explainer must provide good local explanations, not good local predictions, which is our central novelty.\nAs stated in Section II-A, in association rules, the LHS of the association rules are the feature values of the dataset and the RHS are the target values obtained from the blackbox model. The inputs to the rule generating algorithm are the instances generated within the neighbourhood and the instances in the neighbourhood of the instance that needs to be explained which were selected from the training set. LoRMIkA provides flexibility to search for the k-optimal rules with highest support, coverage, strength, lift, or leverage. This choice can be made by the user. In this way, both predictive and interesting rules can be generated. Also, as there is in general a risk of over-estimating the precision when the coverage is low, the OPUS algorithm provides a mechanism called the m-estimate to adjust the values of strength and lift. This feature helps to avoid discovering spurious highly predictive rules and overfitting.\nThe set of rules obtained this way as explainers for a particular instance can then be categorized into four types of rules as follows tt,tf,ft,ff :\n1) tt \u2192 The conditions of the LHS of the rule agree with the features of the instance to be explained AND the RHS of the rule agrees with the target value of the instance to be explained. 2) tf \u2192 The conditions of the LHS of the rule agree with the features of the instance to be explained AND the RHS of the rule disagrees with the target value of the instance to be explained. 3) ft \u2192 The conditions of the LHS of the rule disagree with the features of the instance to be explained AND the RHS of the rule agrees with the target value of the instance to be explained. 4) ff \u2192 The conditions of the LHS of the rule disagree with the features of the instance to be explained AND the RHS of the rule also disagrees with the target value of the instance to be explained.\nThe results of these four categories can be interpreted as follows. Let R be the whole set of rules taken from the neighbourhood of the instance to be explained which will be referred to as X . (T \u222a F ) \u2283 R. T and F are the set of rules related to the decision and to the reverse decision respectively, where T \u2229 F = \u2205. Let Tx \u2283 T and Fx \u2283 F . Tx and Fx are the set of rules which are specific to the instance X . Tx contributes to the true decision of the instance (tt rules) and Fx influences the opposed decision of the instance (tf rules) X . The set T \u2229 (T \u2229 Tx)\u2032 contains the rules that explain the further possibilities to retain the existing target of the instance X after making changes to the existing values of the features. This corresponds to the rules in the ft category. F \u2229 (F \u2229Fx)\u2032 contains the rules that will assist to change the current decision of the instance X by changing the existing feature values. The rules under the ff category are also known as counterfactuals. The above concept is summarized in Fig. 2. An example for these rules will be discussed in Section IV.\nIn this way, our approach is able to provide a complete picture of rules that explain the local neighbourhood of an instance and give the practitioner all the information for informed decision making."
    },
    {
      "heading": "IV. EXPERIMENTS",
      "text": "In this section, we compare LoRMIkA with other state-ofthe-art rule-based algorithms in both qualitative and quantitative aspects."
    },
    {
      "heading": "A. Overview of the datasets",
      "text": "We use the evaluation framework from Guidotti et al. [7] for our experiments, which employs three real-world tabular classification datasets Adult, Compas, German that have both categorical and continuous features. Continuous features are discretized in our approach. In all three datasets, each instance of a dataset represents a record that belongs to a single person.\nThe Adult dataset from the UCI Machine Learning Repository contains data about income levels in relation to demographic features. It contains 48,842 instances in total. The income, which is the target column of the dataset divides the whole dataset into two classes: \u201c\u2264 50K\u201d and \u201c\u2265 50K\u201d.\nThe Compas dataset from ProPublica includes the features used by the COMPAS algorithm to assess a criminal defendants likelihood to re-offend (Low, Medium and High). This dataset consists of over 10,000 records and we have divided it into the two classes \u201cMedium-Low\u201d and \u201cHigh\u201d risk.\nThe German dataset from the UCI Machine Learning Repository contains 1,000 records and classifies persons as \u201cgood\u201d or \u201cbad\u201d creditors.\nFor the experiments, we have considered five algorithms as the global black-box models. They are support vector machine (SVM), random forest with 100 trees (RF), logistic regression (LR), decision trees (DT) and multi-layer neural networks with \u2019LBFGS\u2019 solver (NN). Some of these models, e.g. DT, are interpretable globally however, this does not mean that we necessarily obtain good local interpretations. Therefore it is interesting to observe how these globally interpretable algorithms will be interpreted locally for a particular instance.\nMissing value imputations are done for both continuous and categorical variables using mean and mode respectively. Each dataset is randomly split into a 4:1 ratio to obtain a training and a test set, respectively. Moreover, the continuous attributes were discretized into three sub ranges, such that each case contains almost equal number of instances.\nThe parameters of our method are fairly robust and we use a common set of parameters in all three datasets as follows. From Algorithm 2, L = 40, \u03c3 = 0.75 times square root of the number of features. Moreover, the proportion of minority class instances to majority class instance is 1:5. Furthermore, all results are executed 10 times and averages are reported here, for stability of the results."
    },
    {
      "heading": "B. Qualitative analysis",
      "text": "Fig. 4 shows an instance-level sample output explanation of the LoRMIkA algorithm for an instance from the Compas dataset. Here, the real values of the instance are displayed in Fig. 3. According to the prediction given by the random forest classifier, there is 65% probability to classify this prisoner as having a \u201cHigh\u201d level of likelihood to re-offend.\nThe explanation of the output given by LoRMIkA as shown in Fig. 4 is summarized below.\n1) tt \u2192 Having 26\u2264 age \u226429.250 and is violent recid = 1 explains how the instance acquired 65% chance to be a \u201cHigh\u201d level defendant. Therefore, these features positively affect the given decision, which is \u201cHigh\u201d. Moreover, this rule is a highly predictive rule (precision = 0.93), and it is interesting (lift = 1.22). 2) tf \u2192 Having priors count \u2264 4.520 explains how the instance acquires 35% chance to be a \u201cMedium-Low\u201d level defendant. Moreover, this rule is quite interesting with a lift of 2.31. Further, this is not a highly predictive rule, since the precision is around 0.5. 3) ft\u2192 The rule explains that, if the prisoner\u2019s priors count \u2265 6, regardless of any other given features, there is a high chance to become a \u201cHigh\u201d level defendant. Moreover, it shows that if the defendant is younger than 27 years and priors count is around 5 or 6, still there is a high chance of being a \u201cHigh\u201d level defendant. This shows which are the other possibilities that help to increase the probability (increase 65% to 100%) towards the decision, which is \u201cHigh\u201d. 4) ff \u2192 The rule explains that, if the defendant doesn\u2019t increase the priors count when he is getting older, there is a chance to reverse the defendant to a \u201cMediumLow\u201d level defendant to re-offend. This rule is highly predictive and interesting since both the precision and lift are high. This is a counterfactual rule.\nWe compare our approach against the state-of-the-art rulebased approaches ANCHOR and LORE, which aim to find predictive rules, i.e., with high precision. As outlined earlier, high-precision rules are not always desirable for explainability, since there can be rules which are not highly predictive, but yet interesting. For example in Fig. 4 under the \u201ctf results\u201d we show rules with a high lift, as opposed to strength which\ndetermines how predictive a rule is. Moreover, this example illustrates that LoRMIKA provides four types of descriptive, simple rules with counteractions compared to the other rulebased explainers. The \u201ctt results\u201d present the rules which explain the current decision of the instance. The \u201ctf results\u201d explain the features which already contribute to the probability for reversing a decision of the current instance. The \u201cft results\u201d\nexplain the other steps that can be taken to increase the probability of the current decision of the instance. The \u201cff results\u201d show the counterfactual rules which help to reverse the decision by changing the current feature values. LoRMIkA is able to provide multiple rules in each category.\nThe explanations provided in Figures 4, 5 and 6 are related to an instance which has a \u201cHigh\u201d likelihood to be a reoffendant. In Fig. 4, the LoRMIkA algorithm has selected the features prior death count, age, and whether the prior murders are violent. These seem highly related and relevant to the prediction in question, but also brief and intuitive to understand. In contrast, Anchor (Fig. 5) provides a rather verbose rule pointing narrowly to the outcome of the particular decision, so it seems harder to interpret. The counterfactual output provided by the LORE algorithm, in Fig. 6, seems less guided towards whether the individual in question will become a highly re-offendant person. The \u201cage\u201d feature seems not enough to decide whether the prisoner is a \u201cHigh\u201d level defended to re-offend. This example illustrates the strengths of the LoRMIkA algorithm to provide rules with high interpretability and credibility."
    },
    {
      "heading": "C. Quantitative analysis",
      "text": "The quantitative analysis presented here is based on the coverage that measures the fraction of instances in the neighborhood which satisfy the LHS of the rule, the precision which measures the percentage of the instances which satisfy the RHS of the rule, out of the instances selected for the coverage, the lift which measures the interestingness of the rule and the fidelity to measure how well the explainer approximates the global blackbox model. Fidelity compares the predictions of the explainer model and the blackbox model on the neighbourhood.\nAccuracy aspect: Tables I, II, III and IV report mean and standard deviation of the coverage, precision, lift and fidelity for Anchor, LORE, and LoRMIkA algorithms. Table I, Table II and Table III illustrate that LoRMIkA maintains the highest coverage, precision and the lift in most of the instances while achieving a satisfactory fidelity in Table IV.\nBoth Anchor and LORE algorithms generate rules with low coverage and high precision. LoRMIkA in contrast has an adaptable optimization criterion that can be changed according to the task at hand. E.g., when evaluating coverage we can obtain rules with the highest coverage. This shows the flexibility of our algorithm that makes it possible to obtain interesting and predictive rules and doesn\u2019t limit us to rules with the highest predictive power as the state-of-the-art algorithms we compare against. Moreover, in contrast to LORE, LoRMIkA provides interesting rules with high lift. In Table IV we do not consider Anchor, as it changes the neighbourhood of the rules using a bandit algorithm until the neighbourhood satisfies most of the criteria in the LHS of the rule.\nFurthermore, we measure the stability of the three approaches by the Jaccard coefficient of features considering 50 instances over 10 iterations of the algorithm. The Jaccard coefficient calculates the similarity of the rules that explain the same instance in each iteration. Table V indicates the mean and the standard deviation of the Jaccard coefficient and it reveals that LoRMIkA outperforms all the other algorithms with maximum similarity and zero standard deviation here, indicating that our explanations are robust. When measuring the Jaccard coefficient, we consider rules generated for highest strength and rules which satisfy the instance (tt rules).\nInterpretability aspect: As the interpretability of a given method is inherently difficult to measure, as a proxy we look at simplicity of the generated explanations. We measure the total amount of features used in a given rule base of a local explainer. Table VI indicates the mean values of the number of features used to explain each instance in Anchor, LORE and LoRMIkA under three black-box algorithms. The results show that LoRMIkA uses on average less features to explain the output of the given black-box algorithm. This indicates that LoRMIkA develops more abstract and concise rules compared to the other algorithms. Furthermore, in LoRMIkA, the number of features can be set according to the user preference."
    },
    {
      "heading": "V. CONCLUSIONS",
      "text": "We have presented Local Rule-based Model Interpretability with k-optimal Associations (LoRMIkA), a model-agnostic framework for local explainability of classification algorithms. It employs association rule mining techniques in a local neighbourhood to explain a particular instance and is therewith able to extract models that are local both with respect to features and instances. It uses the efficient OPUS search algorithm to extract the top k-optimal rules with respect to measures such as support, coverage, precision, lift and leverage. This makes the framework flexible and allows us to extract simple rules that are not only predictive but also interesting and better suited to provide explanations. The experiments performed have shown that LoRMIkA is competitive and able to outperform stateof-the-art local explainers both in quantitative and qualitative aspects."
    }
  ],
  "title": "LoRMIkA: Local Rule-based Model Interpretability with k-optimal Associations",
  "year": 2019
}
