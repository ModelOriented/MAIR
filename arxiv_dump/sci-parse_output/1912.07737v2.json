{
  "abstractText": "DJORDJE SLIJEPCEVIC\u2217, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, Austria FABIAN HORST\u2217, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Germany BRIAN HORSAK, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, Austria SEBASTIAN LAPUSCHKIN, Department of Video Coding & Analytics, Fraunhofer Heinrich Hertz Institute, Germany ANNA-MARIA RABERGER, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, Austria WOJCIECH SAMEK,Department of Video Coding &Analytics, Fraunhofer Heinrich Hertz Institute, Germany CHRISTIAN BREITENEDER, Institute of Visual Computing and Human-Centered Technology, TU Wien, Austria WOLFGANG IMMANUEL SCH\u00d6LLHORN, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Germany MATTHIAS ZEPPELZAUER, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, Austria",
  "authors": [
    {
      "affiliations": [],
      "name": "DJORDJE SLIJEPCEVIC"
    },
    {
      "affiliations": [],
      "name": "BRIAN HORSAK"
    }
  ],
  "id": "SP:c8041421fb371795685a4fc0be02a9b354127ed8",
  "references": [
    {
      "authors": [
        "Amina Adadi",
        "Mohammed Berrada"
      ],
      "title": "Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)",
      "venue": "IEEE Access",
      "year": 2018
    },
    {
      "authors": [
        "Julius Adebayo",
        "Justin Gilmer",
        "Michael Muelly",
        "Ian Goodfellow",
        "Moritz Hardt",
        "Been Kim"
      ],
      "title": "Sanity Checks for Saliency Maps",
      "venue": "In Advances in Neural Information Processing Systems 31,",
      "year": 2018
    },
    {
      "authors": [
        "Murad Alaqtash",
        "Thompson Sarkodie-Gyan",
        "Huiying Yu",
        "Olac Fuentes",
        "Richard Brower",
        "Amr Abdelgawad"
      ],
      "title": "Automatic classification of pathological gait patterns using ground reaction forces and machine learning algorithms",
      "venue": "In 2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS). IEEE,",
      "year": 2011
    },
    {
      "authors": [
        "Vijay Arya",
        "Rachel KE Bellamy",
        "Pin-Yu Chen",
        "Amit Dhurandhar",
        "Michael Hind",
        "Samuel C Hoffman",
        "Stephanie Houde",
        "Q Vera Liao",
        "Ronny Luss",
        "Aleksandra Mojsilovi\u0107"
      ],
      "title": "One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques. arXiv:1909.03012 [Preprint",
      "year": 2019
    },
    {
      "authors": [
        "Sebastian Bach",
        "Alexander Binder",
        "Gr\u00e9goire Montavon",
        "Frederick Klauschen",
        "Klaus-Robert M\u00fcller",
        "Wojciech Samek"
      ],
      "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
      "venue": "PloS One 10,",
      "year": 2015
    },
    {
      "authors": [
        "David Baehrens",
        "Timon Schroeter",
        "Stefan Harmeling",
        "Motoaki Kawanabe",
        "Katja Hansen",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "How to Explain Individual Classification Decisions",
      "venue": "Journal of Machine Learning Research",
      "year": 2010
    },
    {
      "authors": [
        "Richard Baker"
      ],
      "title": "Measuring Walking: A Handbook of Clinical Gait Analysis",
      "year": 2013
    },
    {
      "authors": [
        "David Balduzzi",
        "Marcus Frean",
        "Lennox Leary",
        "J.P. Lewis",
        "Kurt Wan-Duo Ma",
        "Brian McWilliams"
      ],
      "title": "The Shattered Gradients Problem: If resnets are the answer, then what is the question",
      "venue": "In Proceedings of the 34th International Conference on Machine Learning",
      "year": 2017
    },
    {
      "authors": [
        "Lucia Bizovska",
        "Zdenek Svoboda",
        "Patrik Kutilek",
        "Miroslav Janura",
        "Ales Gaba",
        "Zuzana Kovacikova"
      ],
      "title": "Variability of centre of pressure movement during gait in young and middle-aged women",
      "venue": "Gait & Posture 40,",
      "year": 2014
    },
    {
      "authors": [
        "Brian G Booth",
        "No\u00ebl LW Keijsers",
        "Jan Sijbers",
        "Toon Huysmans"
      ],
      "title": "STAPP: spatiotemporal analysis of plantar pressure measurements using statistical parametric mapping",
      "venue": "Gait & Posture",
      "year": 2018
    },
    {
      "authors": [
        "Johannes Burdack",
        "Fabian Horst",
        "Sven Giesselbach",
        "Ibrahim Hassan",
        "Sabrina Daffner",
        "Wolfgang I. Sch\u00c3\u0171llhorn"
      ],
      "title": "Systematic Comparison of the Influence of Different Data Preprocessing Methods on the Performance of Gait Classifications Using Machine Learning",
      "venue": "Frontiers in Bioengineering and Biotechnology",
      "year": 2020
    },
    {
      "authors": [
        "Tom Chau"
      ],
      "title": "A review of analytical techniques for gait data. Part 1: fuzzy, statistical and fractal methods",
      "venue": "Gait & Posture 13,",
      "year": 2001
    },
    {
      "authors": [
        "Fran\u00e7ois Chollet"
      ],
      "title": "Deep Learning with Python. Manning Publications Company, Shelter Island (NY)",
      "year": 2017
    },
    {
      "authors": [
        "Andre Esteva",
        "Brett Kuprel",
        "Roberto A. Novoa",
        "Justin Ko",
        "SusanM. Swetter",
        "HelenM. Blau",
        "Sebastian Thrun"
      ],
      "title": "Dermatologist-level classification of skin cancer",
      "year": 2017
    },
    {
      "authors": [
        "Joana Figueiredo",
        "Cristina P. Santos",
        "Juan C. Moreno"
      ],
      "title": "Automatic recognition of gait patterns in human motor disorders using machine learning: A review",
      "venue": "Medical Engineering and Physics",
      "year": 2018
    },
    {
      "authors": [
        "Ruth C Fong",
        "Andrea Vedaldi"
      ],
      "title": "Interpretable explanations of black boxes by meaningful perturbation",
      "venue": "IEEE International Conference on Computer Vision (ICCV). IEEE,",
      "year": 2017
    },
    {
      "authors": [
        "Holger A Haenssle",
        "Christine Fink",
        "R Schneiderbauer",
        "Ferdinand Toberer",
        "Timo Buhl",
        "A Blum",
        "A Kalloo",
        "A Ben Hadj Hassen",
        "Luc Thomas",
        "A Enk"
      ],
      "title": "Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists",
      "venue": "Annals of Oncology 29,",
      "year": 2018
    },
    {
      "authors": [
        "Eni Halilaj",
        "Apoorva Rajagopal",
        "Madalina Fiterau",
        "Jennifer L Hicks",
        "Trevor J Hastie",
        "Scott L Delp"
      ],
      "title": "Machine learning in human movement biomechanics: best practices, common pitfalls, and new opportunities",
      "venue": "Journal of Biomechanics",
      "year": 2018
    },
    {
      "authors": [
        "Jianxing He",
        "Sally L. Baxter",
        "Jie Xu",
        "Jiming Xu",
        "Xingtao Zhou",
        "Kang Zhang"
      ],
      "title": "The practical implementation of artificial intelligence technologies in medicine",
      "venue": "Nature Medicine 25,",
      "year": 2019
    },
    {
      "authors": [
        "Lisa Anne Hendricks",
        "Zeynep Akata",
        "Marcus Rohrbach",
        "Jeff Donahue",
        "Bernt Schiele",
        "Trevor Darrell"
      ],
      "title": "Generating visual explanations",
      "venue": "In European Conference on Computer Vision (ECCV). Springer, 3\u201319",
      "year": 2016
    },
    {
      "authors": [
        "Andreas Holzinger",
        "Chris Biemann",
        "Constantinos S. Pattichis",
        "Douglas B. Kell"
      ],
      "title": "What do we need to build explainable AI systems for the medical domain? arXiv:1712.09923 [Preprint",
      "venue": "(Dec. 2017)",
      "year": 2017
    },
    {
      "authors": [
        "Andreas Holzinger",
        "Georg Langs",
        "Helmut Denk",
        "Kurt Zatloukal",
        "Heimo M\u00c3ijller"
      ],
      "title": "Causability and explainability of artificial intelligence in medicine",
      "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 9,",
      "year": 2019
    },
    {
      "authors": [
        "Brian Horsak",
        "Djordje Slijepcevic",
        "Anna-Maria Raberger",
        "Caterine Schwab",
        "MarianneWorisch",
        "andMatthias Zeppelzauer"
      ],
      "title": "GaitRec, a large-scale ground reaction force dataset of healthy and impaired gait",
      "venue": "Scientific Data 7,",
      "year": 2020
    },
    {
      "authors": [
        "Fabian Horst",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "Klaus-Robert M\u00fcller",
        "Wolfgang I Sch\u00f6llhorn"
      ],
      "title": "Explaining the unique nature of individual gait patterns with deep learning",
      "venue": "Scientific Reports 9,",
      "year": 2019
    },
    {
      "authors": [
        "Chih-Wei Hsu",
        "Chih-Chung Chang",
        "Chih-Jen Lin"
      ],
      "title": "A Practical Guide to Support Vector Classification",
      "venue": "Technical Report",
      "year": 2016
    },
    {
      "authors": [
        "Maximilian Kohlbrenner",
        "Alexander Bauer",
        "Shinichi Nakajima",
        "Alexander Binder",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "title": "Towards best practice in explaining neural network decisions with LRP. arXiv:1910.09840 [Preprint",
      "year": 2019
    },
    {
      "authors": [
        "Sebastian Lapuschkin",
        "Stephan W\u00e4ldchen",
        "Alexander Binder",
        "Gr\u00e9goire Montavon",
        "Wojciech Samek",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Unmasking Clever Hans Predictors and Assessing What Machines Really Learn",
      "venue": "Nature Communications",
      "year": 2019
    },
    {
      "authors": [
        "Hong-yin Lau",
        "Kai-yu Tong",
        "Hailong Zhu"
      ],
      "title": "Support vector machine for classification of walking conditions of persons after stroke with dropped foot",
      "venue": "Human Movement Science 28,",
      "year": 2009
    },
    {
      "authors": [
        "Yann LeCun",
        "L\u00e9on Bottou",
        "Genevieve B. Orr",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Efficient BackProp",
      "venue": "In Neural Networks: Tricks of the Trade - Second Edition. Springer,",
      "year": 2012
    },
    {
      "authors": [
        "Scott M. Lundberg",
        "Su-In Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "In Advances in Neural Information Processing Systems (NIPS). Curran Associates,",
      "year": 2017
    },
    {
      "authors": [
        "Laurens van der Maaten",
        "Geoffrey Hinton"
      ],
      "title": "Visualizing data using t-SNE",
      "venue": "Journal of Machine Learning Research 9,",
      "year": 2008
    },
    {
      "authors": [
        "Scott Mayer McKinney",
        "Marcin Sieniek",
        "Varun Godbole",
        "Jonathan Godwin",
        "Natasha Antropova",
        "Hutan Ashrafian",
        "Trevor Back",
        "Mary Chesus",
        "Greg C Corrado",
        "Ara Darzi"
      ],
      "title": "International evaluation of an AI system for breast cancer screening",
      "venue": "Nature 577,",
      "year": 2020
    },
    {
      "authors": [
        "Gr\u00e9goire Montavon",
        "Alexander Binder",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Layer-wise Relevance Propagation: An Overview. In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",
      "year": 2019
    },
    {
      "authors": [
        "Gr\u00e9goire Montavon",
        "Wojciech Samek",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Methods for interpreting and understanding deep neural networks",
      "venue": "Digital Signal Processing",
      "year": 2018
    },
    {
      "authors": [
        "Anh Nguyen",
        "Alexey Dosovitskiy",
        "Jason Yosinski",
        "Thomas Brox",
        "Jeff Clune"
      ],
      "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks",
      "venue": "In Advances in Neural Information Processing Systems. Curran Associates,",
      "year": 2016
    },
    {
      "authors": [
        "Angela Nieuwenhuys",
        "Eirini Papageorgiou",
        "Kaat Desloovere",
        "Guy Molenaers",
        "Tinne De Laet"
      ],
      "title": "Statistical parametric mapping to identify differences between consensus-based joint patterns during gait in children with cerebral palsy",
      "venue": "PLoS One",
      "year": 2017
    },
    {
      "authors": [
        "Corina N\u00c3ijesch",
        "Victor Valderrabano",
        "Cora Huber",
        "Vinzenz von Tscharner",
        "Geert Pagenstert"
      ],
      "title": "Gait patterns of asymmetric ankle osteoarthritis patients",
      "venue": "Clinical Biomechanics 27,",
      "year": 2012
    },
    {
      "authors": [
        "Todd C. Pataky"
      ],
      "title": "Generalized n-dimensional biomechanical field analysis using statistical parametric mapping",
      "venue": "Journal of Biomechanics 43,",
      "year": 2010
    },
    {
      "authors": [
        "Todd C. Pataky"
      ],
      "title": "One-dimensional statistical parametric mapping in Python",
      "venue": "Computer Methods in Biomechanics and Biomedical Engineering 15,",
      "year": 2012
    },
    {
      "authors": [
        "Angkoon Phinyomark",
        "Giovanni Petri",
        "Esther Ib\u00e1\u00f1ez-Marcelo",
        "Sean T. Osis",
        "Reed Ferber"
      ],
      "title": "Analysis of big data in gait biomechanics: Current trends and future directions",
      "venue": "Journal of Medical and Biological Engineering 38,",
      "year": 2018
    },
    {
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "title": "Model-agnostic interpretability of machine learning",
      "venue": "[Preprint]",
      "year": 2016
    },
    {
      "authors": [
        "Robert Rosenthal"
      ],
      "title": "Meta-Analytic Procedures for Social Science Research Sage Publications: Beverly",
      "venue": "pp. Educational Researcher 15,",
      "year": 1986
    },
    {
      "authors": [
        "Wojciech Samek",
        "Alexander Binder",
        "Gr\u00e9goire Montavon",
        "Sebastian Lapuschkin",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Evaluating the visualization of what a deep neural network has learned",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems 28,",
      "year": 2016
    },
    {
      "authors": [
        "Wojciech Samek",
        "Alexander Binder",
        "Gr\u00e9goire Montavon",
        "Sebastian Lapuschkin",
        "Klaus-Robert"
      ],
      "title": "Evaluating the Visualization of What a Deep Neural Network Has Learned",
      "venue": "MA\u0303ijller",
      "year": 2017
    },
    {
      "authors": [
        "Wojciech Samek",
        "Gr\u00e9goire Montavon",
        "Sebastian Lapuschkin",
        "Christopher J Anders",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Toward Interpretable Machine Learning: Transparent Deep Neural Networks and Beyond",
      "year": 2020
    },
    {
      "authors": [
        "Wojciech Samek",
        "Thomas Wiegand",
        "Klaus-Robert M\u00fcller"
      ],
      "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models",
      "venue": "ITU Journal: ICT Discoveries",
      "year": 2017
    },
    {
      "authors": [
        "Wolfgang I Sch\u00f6llhorn"
      ],
      "title": "Applications of artificial neural nets in clinical biomechanics",
      "venue": "Clinical Biomechanics 19,",
      "year": 2004
    },
    {
      "authors": [
        "Huijuan Shi",
        "Hongshi Huang",
        "Yuanyuan Yu",
        "Zixuan Liang",
        "Si Zhang",
        "Bing Yu",
        "Hui Liu",
        "Yingfang Ao"
      ],
      "title": "Effect of dual task on gait asymmetry in patients after anterior cruciate ligament reconstruction",
      "venue": "Scientific Reports",
      "year": 2018
    },
    {
      "authors": [
        "Avanti Shrikumar",
        "Peyton Greenside",
        "Anshul Kundaje"
      ],
      "title": "Learning important features through propagating activation differences",
      "venue": "In Proceedings of the 34th International Conference on Machine Learning",
      "year": 2017
    },
    {
      "authors": [
        "Karen Simonyan",
        "Andrea Vedaldi",
        "Andrew Zisserman"
      ],
      "title": "Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv:1312.6034 [Preprint",
      "year": 2013
    },
    {
      "authors": [
        "Djordje Slijepcevic",
        "Matthias Zeppelzauer",
        "Anna-Maria Gorgas",
        "Caterine Schwab",
        "Michael Sch\u00fcller",
        "Arnold Baca",
        "Christian Breiteneder",
        "Brian Horsak"
      ],
      "title": "Automatic classification of functional gait disorders",
      "venue": "IEEE Journal of Biomedical and Health Informatics 22,",
      "year": 2017
    },
    {
      "authors": [
        "Djordje Slijepcevic",
        "Matthias Zeppelzauer",
        "Caterine Schwab",
        "Anna-Maria Raberger",
        "Christian Breiteneder",
        "Brian Horsak"
      ],
      "title": "Input Representations and Classification Strategies for Automated Human Gait Analysis",
      "venue": "Gait & Posture (2019)",
      "year": 2019
    },
    {
      "authors": [
        "Djordje Slijepcevic",
        "Matthias Zeppelzauer",
        "Caterine Schwab",
        "Anna-Maria Raberger",
        "Bernhard Dumphart",
        "Arnold Baca",
        "Christian Breiteneder",
        "Brian Horsak"
      ],
      "title": "2018. P 011-Towards an optimal combination of input signals and derived representations for gait classification based on ground reaction force measurements",
      "venue": "Gait & Posture",
      "year": 2018
    },
    {
      "authors": [
        "Erik \u0160trumbelj",
        "Igor Kononenko"
      ],
      "title": "Explaining predictionmodels and individual predictions with feature contributions",
      "venue": "Knowledge and Information Systems 41,",
      "year": 2014
    },
    {
      "authors": [
        "Erico Tjoa",
        "Cuntai Guan"
      ],
      "title": "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI. arXiv:1907.07374 [Preprint",
      "year": 2019
    },
    {
      "authors": [
        "Eric J Topol"
      ],
      "title": "High-performance medicine: The convergence of human and artificial intelligence",
      "venue": "Nature Medicine 25,",
      "year": 2019
    },
    {
      "authors": [
        "Leen Van Gestel",
        "Tinne De Laet",
        "Enrico Di Lello",
        "Herman Bruyninckx",
        "Guy Molenaers",
        "Anja Van Campenhout",
        "Erwin Aertbeli\u00c3\u0144n",
        "Mike Schwartz",
        "Hans Wambacq",
        "Paul De Cock",
        "Kaat Desloovere"
      ],
      "title": "Probabilistic gait classification in children with cerebral palsy: A Bayesian approach",
      "venue": "Research in Developmental Disabilities",
      "year": 2011
    },
    {
      "authors": [
        "Markus Wagner",
        "Djordje Slijepcevic",
        "Brian Horsak",
        "Alexander Rind",
        "Matthias Zeppelzauer",
        "Wolfgang Aigner"
      ],
      "title": "KAVAGait: Knowledge-assisted visual analytics for clinical gait analysis",
      "venue": "IEEE Transactions on Visualization and Computer Graphics 25,",
      "year": 2018
    },
    {
      "authors": [
        "Ferdous Wahid",
        "Rezaul K Begg",
        "Chris J Hass",
        "Saman Halgamuge",
        "David C Ackland"
      ],
      "title": "Classification of Parkinson\u2019s disease gait using spatial-temporal gait features",
      "venue": "IEEE Journal of Biomedical and Health Informatics 19,",
      "year": 2015
    },
    {
      "authors": [
        "Nils Wilhelm",
        "Anna V\u00f6gele",
        "Rebeka Zsoldos",
        "Theresia Licka",
        "Bj\u00f6rn Kr\u00fcger",
        "J\u00fcrgen Bernard"
      ],
      "title": "Furyexplorer: Visual-interactive exploration of horse motion capture data",
      "venue": "In Visualization and Data Analysis 2015. International Society for Optics and Photonics,",
      "year": 2015
    },
    {
      "authors": [
        "Sebastian Wolf",
        "Tobias Loose",
        "Matthias Schablowski",
        "Leonhard D\u00f6derlein",
        "R\u00fcdiger Rupp",
        "Hans J\u00fcrgen Gerner",
        "Georg Bretthauer",
        "Ralf Mikut"
      ],
      "title": "Automated feature assessment in instrumented gait analysis",
      "venue": "Gait & Posture 23,",
      "year": 2006
    },
    {
      "authors": [
        "Luisa M Zintgraf",
        "Taco S Cohen",
        "Tameem Adel",
        "Max Welling"
      ],
      "title": "Visualizing deep neural network decisions: Prediction difference analysis",
      "venue": "[Preprint]",
      "year": 2017
    }
  ],
  "sections": [
    {
      "heading": "On the Explanation of Machine Learning Predictions in Clinical Gait Analysis",
      "text": "DJORDJE SLIJEPCEVIC\u2217, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, Austria FABIAN HORST\u2217, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Germany BRIAN HORSAK, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, Austria SEBASTIAN LAPUSCHKIN, Department of Video Coding & Analytics, Fraunhofer Heinrich Hertz Institute, Germany ANNA-MARIA RABERGER, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, Austria WOJCIECH SAMEK,Department of Video Coding &Analytics, Fraunhofer Heinrich Hertz Institute, Germany CHRISTIAN BREITENEDER, Institute of Visual Computing and Human-Centered Technology, TU Wien, Austria WOLFGANG IMMANUEL SCH\u00d6LLHORN, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Germany MATTHIAS ZEPPELZAUER, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, Austria\nMachine learning (ML) is increasingly used to support decision-making in the healthcare sector. While ML approaches provide promising results with regard to their classification performance, most share a central limitation, namely their black-box character. Motivated by the interest to understand the functioning of ML models, methods from the field of Explainable Artificial Intelligence (XAI) have recently become important. This article investigates the usefulness of XAI methods in clinical\n\u2217Both authors contributed equally to this research.\nAuthors\u2019 addresses: Djordje Slijepcevic, Djordje.Slijepcevic@fhstp.ac.at, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, St. P\u00f6lten, Austria; Fabian Horst, horst@uni-mainz.de, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Mainz, Germany; Brian Horsak, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, St. P\u00f6lten, Austria; Sebastian Lapuschkin, Department of Video Coding & Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Anna-Maria Raberger, Institute of Health Sciences, Department of Health Sciences, St. P\u00f6lten University of Applied Sciences, St. P\u00f6lten, Austria; Wojciech Samek, Department of Video Coding & Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Christian Breiteneder, Institute of Visual Computing and Human-Centered Technology, TU Wien, Vienna, Austria; Wolfgang Immanuel Sch\u00f6llhorn, Department of Training and Movement Science, Institute of Sport Science, Johannes Gutenberg-University Mainz, Mainz, Germany; Matthias Zeppelzauer, Institute of Creative Media Technologies, Department of Media & Digital Technologies, St. P\u00f6lten University of Applied Sciences, St. P\u00f6lten, Austria.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2020 Association for Computing Machinery. XXXX-XXXX/2020/8-ART $15.00 https://doi.org/10.1145/1122445.1122456\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nar X\niv :1\n91 2.\n07 73\n7v 2\n[ cs\n.L G\n] 1\n9 A\nug 2\n02 0\n2 \u2022 Slijepcevic and Horst, et al.\ngait classification. For this purpose, predictions of state-of-the-art classification methods are explained with an established XAI method, i.e., Layer-wise Relevance Propagation (LRP). We propose to evaluate the obtained explanations with two complementary approaches: a statistical analysis of the underlying data using Statistical Parametric Mapping and a qualitative evaluation by a clinical expert. A gait dataset comprising ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls is utilized. We investigate several gait classification tasks, employ multiple classification methods, and analyze the impact of data normalization and different signal components for classification performance and explanation quality. Our experiments show that explanations obtained by LRP exhibit promising statistical properties concerning inter-class discriminativity and are also in line with clinically relevant biomechanical gait characteristics.\nCCS Concepts: \u2022 Computing methodologies\u2192 Neural networks; \u2022 Applied computing\u2192Health care information systems.\nAdditional KeyWords and Phrases: clinical gait analysis, human gait classification, explainable artificial intelligence, layer-wise relevance propagation, statistical parametric mapping, ground reaction forces, convolutional neural networks"
    },
    {
      "heading": "ACM Reference Format:",
      "text": "Djordje Slijepcevic, Fabian Horst, Brian Horsak, Sebastian Lapuschkin, Anna-Maria Raberger, Wojciech Samek, Christian Breiteneder, Wolfgang Immanuel Sch\u00f6llhorn, and Matthias Zeppelzauer. 2020. On the Explanation of Machine Learning Predictions in Clinical Gait Analysis. 1, 1 (August 2020), 37 pages. https://doi.org/10.1145/1122445.1122456"
    },
    {
      "heading": "1 INTRODUCTION",
      "text": "Artificial Intelligence (AI) and machine learning (ML) techniques have become almost ubiquitous in our daily lives by supporting or guiding our decisions and providing recommendations. Impressively, there are certain medical tasks, such as the detection of skin or breast cancer, that ML approaches have already been able to solve more efficiently and effectively than humans [14, 18, 33]. Therefore, it is not surprising that ML approaches are currently becoming popular in the healthcare sector [57]. This trend has also been recognized in the field of clinical gait analysis (CGA) [16, 48]. CGA focuses on the quantitative description and analysis of human gait from a kinematic (i.e., joint angles), kinetic (i.e., ground reaction forces and joint moments), and muscular (i.e., electromyographic activity) point of view. Thereby, CGA produces a vast amount of data [19, 41], which are difficult to comprehend due to their multi-dimensional and multi-correlated nature [12, 62]. In the last years, ML methods have been successfully employed in CGA for the classification of patient groups [16, 48] such as stroke [29], Parkinson\u2019s disease [60], cerebral palsy [58], multiple sclerosis [3], osteoarthritis [38], and patients suffering from different functional gait disorders [52]. While ML approaches yield promising results regarding classification performance, most share a central limitation, which is their black-box character [1]. This means that even if the underlying mathematical principles in these methods are understood, it is often unclear why a particular prediction has been made and if meaningfully grounded patterns have led to this prediction. Additionally, the black-box character also hinders ML approaches to provide justifications of their predictions. This is, however, necessary for compliance with legislation such as the General Data Protection Regulation (GDPR, EU 2016/679) [1, 15, 20]. These factors currently limit the application of ML-based decision-support systems in medical practice [22, 47]. Due to the aforementioned reasons, the field of Explainable Artificial Intelligence (XAI) gained increasing attention in recent years. Different approaches have been proposed (see Section 2: Related work). In general, XAI methods intend to illustrate how complex and non-linear ML models operate and how they produced their predictions. However, explanation is understood in the sense of providing more differentiated insights into the behaviour of ML models in order to fathom the dependence of the results on input variables (without claiming to give causation). Even though research in XAI is still in an early stage, the application of such approaches in medicine has already raised attention [22, 56]. The motivation is to increase the traceability and trust of medical professionals in ML approaches [23]. However, application of XAI methods to the field of CGA remains to be\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 3\ninvestigated. A first step in that direction has recently been taken by Horst et al. [25] for explaining predictions in gait-based person recognition.\nThe primary aim of this article is to investigate to which extent XAI methods can help to explain ML predictions in the context of CGA. For this purpose, we compare the results of several classification models trained on different gait classification tasks and analyze the quality of explanations, which are derived from the trained models by an established XAI method, i.e., Layer-wise Relevance Propagation (LRP). The assessment of explanations\u2019 quality is, however, a challenge since no ground truth exists for automatically generated explanations. In contrast to images, which are more frequently subject to explainability studies [2, 17, 44, 46], the evaluation of explanations becomes particularly challenging when the input signals are more abstract and thus not straightforward to interpret, as often is the case with biomedical signals. Recently, it has been shown that XAI approaches do not necessarily refer to the actual prediction of the classification model and sometimes even build upon unrelated information [2]. Thus, a more comprehensive investigation of explanations obtained by XAI methods is necessary to verify whether they are meaningful and justified. To account for the above-mentioned challenges, we suggest a two-step approach for the evaluation of the obtained explanations. First, we analyze the discriminatory power of the obtained explanations from a statistical perspective. For this purpose, we leverage Statistical Parametric Mapping (SPM) [39] \u2013 a method building upon random field theory \u2013 to derive statistical measures along with the input signals and thereby investigate how statistically justified the obtained explanations are. Second, an experienced domain expert interprets the explainability results from a clinical perspective, to verify whether obtained explanations match characteristics from clinical practice. Our investigation focuses on two leading research questions: (1) Which input features or signal regions are most relevant for automatic gait classification? (2) To what extent are input features or signal regions identified as being relevant for a given gait classification task statistically justified and in line with clinical assessment? In addition to these two leading questions, we investigate several further aspects that may influence classification performance as well as explainability in more detail, including the influence of different classification methods, the impact of data normalization, and the role of different input signal components (i.e., the horizontal forces, measurements of the affected leg and measurements of the unaffected leg).\nWe perform our investigation on theGaitRec dataset [24], which contains ground reaction force measurements from clinical practice. We design prediction models for different gait classification tasks and derive possible explanations from the resulting models that are based on relevance scores. These relevance scores are directly related to specific regions in the input signal. Subsequently, we analyze the explanations from a statistical as well as a clinical perspective. The results show that explanations share promising statistical properties concerning class discriminativity and thus indicate that predictions are grounded on statistically justified information for the task. Further, we show that input features considered as relevant can also be interpreted as meaningful and clinically relevant biomechanical gait characteristics. Overall, our investigation demonstrates the usefulness of XAI in the domain of gait classification, exemplifies how to apply XAI methods to gait measurement data, and suggest approaches to evaluate their quality. The performed study suggests that XAI methods can be useful to better understand and interpret automatic predictions in clinical gait analysis."
    },
    {
      "heading": "2 RELATED WORK",
      "text": "Methods from XAI can be grouped according to the type of explanation they provide. We distinguish between XAI approaches for (i) data exploration, (ii) prediction explanation and (iii)model explanation based on an adaptation of the taxonomy introduced by Arya et al. [4]. In the following, we briefly introduce the three different types of approaches and their capabilities.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n4 \u2022 Slijepcevic and Horst, et al.\nData exploration includes methods from the fields of visual analytics, statistics and unsupervised machine learning. As such, the methods are not capable of explaining a model but rather the data on which the model is trained. These methods focus on projecting the data into a space where it is possible to find meaningful structures or clusters and thus understand the data in more detail. A popular approach for data exploration introduced by Maaten and Hinton [32] is T-distributed Stochastic Neighbor Embedding (t-SNE), which projects high-dimensional data into a lower-dimensional and visualizable space. The projection is performed in a way that the cluster structure in the original data space is optimally exposed. Thereby, an understanding of the data and the identification of typical patterns and clusters in the data is facilitated. Other approaches in this category are visual analytics approaches that employ advanced techniques for the interactive visualization of data to support data exploration, i.e., finding characteristic patterns or dependencies within data [59, 61]. Prediction explanation aims at explaining the local behavior of a model, i.e., the prediction for a given input instance. For a classification task, these methods can provide, for example, explanations about which part of the input influenced the classifier\u2019s prediction the most. For classification of gait data, the explanation should highlight all relevant signal regions and characteristic signal shapes in the input data, which are associated with a particular gait disorder. Two main categories can be distinguished for explaining the local behavior of a machine learning model: i) self-explaining models and ii) post-hoc methods. Self-explaining models integrate components that learn relationships between input data and predictions during training. Simultaneously, they learn how these relationships relate to terms from a predefined dictionary and consequently generate explanations from them. A self-explaining approach which does not visually highlight relevant regions in input data but generates textual explanations was proposed by Hendricks et al. [21]. This selfexplaining model combines a Convolutional Neural Network (CNN) and a Recurrent Neural Network (RNN). The CNN learns discriminative features to perform a classification task, while the RNN generates textual explanations of the prediction. This approach cannot be applied to a previously trained model in a post-hoc manner, which limits the practical applicability of such approaches.\nPost-hoc methods provide much greater applicability as they can be applied to already trained models. These methods can be further categorized into i) propagation-based, ii) perturbation-based, and iii) Shapley-value-based methods. Propagation-based methods determine the contributions of each input feature by (back-)propagating some quantity of interest from the model\u2019s output layer to the input layer. Sensitivity Analysis [64] has been introduced to Support Vector Machines (SVM) [6] and CNNs [51] in the form of saliency maps. Layer-wise Relevance Propagation (LRP) [5, 34] and Deep Learning Important FeaTures (DeepLIFT) [50] are methods that propagate importance scores from the output layer back to the input, thereby enabling the identification of positive and negative evidences for a specific prediction. Sensitivity Analysis and the therewith obtained explanations, in general, suffer from the effects of shattered gradients [8], especially so in more complex (deeper) networks. Modern approaches to CNN explainability, such as LRP or DeepLift, do not have this problem and work well for a wider range of network architectures and models in general [27, 35]. Perturbation-based methods, such as those introduced by Fong and Vedaldi [17] or Zintgraf et al. [63], treat the model as a black box and estimate the importance of input features by (partially) occluding the input and measuring the effect on the model output. While some methods produce explanations directly from a perturbation process, others employ a learning component \u2013 e.g., the Interpretable Model-agnostic Explanations (LIME) method [42] \u2013 to estimate locally interpretable surrogate models mimicking the prediction process of the black-box model. Perturbation-based methods can be considered to be model-agnostic, as they do not require access to internal model parameters or structures to operate. However, this model-agnosticism is bought at a considerable computational cost, compared to propagation-based approaches. Shapley-value-based methods attempt to approximate the Shapley values of a given prediction. For this purpose, the effect of omitting an input feature is examined, taking into account all possible combinations of other input features, that can be included or excluded [55]. Lundberg and Lee [31] proposed the SHapley Additive exPlanations (SHAP) method, which is a unified approach building upon the\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 5\ntheory of Shapley values and existing propagation-based and perturbation-based methods, e.g., LIME, DeepLIFT, and LRP. Model explanation provides an interpretation of what a trained model has learned, i.e., the most characteristic representations or prototypes for an entire class are visualized (e.g., a class of gait disorders in CGA). These methods can indicate which classes overlap and point out ambiguous input features. In addition to saliency maps, Simonyan et al. [51] proposed a method for generating a representative visualization for a specific class that was learned by a CNN. For this purpose, they applied activation maximization, i.e., starting with a blank image, each pixel is changed by utilizing backpropagation so that the activity of a neuron is increased. The resulting visualizations give a first impression about the patterns learned but are highly abstract and can only be interpreted to a limited extent. To generate visualizations that are easier to interpret, Nguyen et al. [36] proposed a method to constrain the optimization process by image priors that were learned automatically. Lapuschkin et al. [28] proposed the Spectral Relevance Analysis (SpRAy) which summarizes a model\u2019s learned strategies by analyzing similarities and dissimilarities over large quantities of input relevance maps computed with respect to a category of interest.\nFor gait classification, prediction explanation is desirable to provide clinical experts with detailed information about which patterns in the input signals are important for a specific prediction. Additionally, based on aggregations of these explanations, differences between patient groups can be assessed. In this context, post-hoc methods are preferable because they provide a classifier-agnostic approach (can be applied to any classification model) and do not require retraining or additional labels. We, therefore, choose a established post-hoc explainability method, i.e., LRP, in our experiments."
    },
    {
      "heading": "3 APPROACH AND METHODOLOGY",
      "text": "The general approach we followed in this study was to design and train classification models for automated gait classification tasks (see Figure 1B) based on three-dimensional ground reaction forces (GRFs) of both legs (see Figure 1A), to explain the predictions of these models based on relevance scores that are related to the input signal space by using LRP (see Figure 1C), and to evaluate these results from a statistical (see Figure 1D) and a clinical perspective (see Figure 1E).\n3.1 Gait Classification The main task in automated gait classification is to determine whether a person has a healthy or pathological gait pattern based on gait measurements. We employed three-dimensional GRFs of the affected and unaffected side as input signals and investigated the classification performance of several state-of-the-art classification methods. Furthermore, the input signals were fed directly into the classification models. This ensures that the results of the employed explainability method (LRP) can be directly mapped to the original signals. For easier interpretation of the XAI results, we refrained from using data reduction techniques such as e.g., Principal Component Analysis (PCA), which are a common practice in automated gait classification [11, 19, 54].\n3.2 Prediction Explanation We employed Layer-wise Relevance Propagation (LRP) for prediction explanation [5] as a post-hoc method that provides explanations in the input space, which is the space where the signals are usually interpreted by experts in clinical practice. LRP decomposes the prediction f (x) of a learned function f given an input vector x into time- and component-resolved input relevance values Ri for each individual input value xi . This enables to explain the prediction of an ML model as partial contributions of an individual input value. LRP indicates which information a model uses to predict in favor or against an output class. Thereby, it enables the interpretation of\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n6 \u2022 Slijepcevic and Horst, et al.\ninput relevance scores and their dynamics as representation for a certain class (i.e., healthy controls or functional disorders in ankle, knee or hip). For the explanation of predictions, we decomposed the input relevance scores of each gait trial with LRP. In order to analyse patterns learned for a specific class, we used LRP to decompose the ground truth label (and not the predicted value) of the trial. For the visualization of the explanations, we averaged the underlying GRF signals and the resulting input relevance scores over all trials of a class. Given that the models investigated in this study are comparatively shallow and are largely unaffected by detrimental effects such as gradient shattering [8, 34], we performed relevance decomposition according to LRP\u03b5 with \u03b5 = 10\u22125 in all layers across the different models (except for the CNN for which we employed the flat rule at the input layer) [27].\n3.3 Statistical Evaluation To evaluate the derived relevance scores of LRP, we employ Statistical Parametric Mapping (SPM) [39, 40] which recently received increased attention in the gait analysis community [10, 37]. While standard inference statistical approaches tend to reduce time-continuous signals to single time-discrete values for statistical testing, SPM allows to use the entire time-continuous signals to make probabilistic conclusions. It follows the same notion and logic as classical inference statistics. The main advantages of SPM are that the statistical results are presented in the original sampling space and that there is no need for a (potentially biasing) parameterization technique [39, 40]. In comparison to the XAI methods, SPM is completely data-centric. Therefore, SPM is suited for our investigation, as an model-independent method to assess the quality of derived explanations. Since the LRP explanations\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 7\nand the results of SPM reside in the same space (the input signal space), we can leverage SPM to verify the meaningfulness of LRP explanations from a statistical point of view. For the statistical evaluation we compute independent t-tests using the SPM1D1 package provided by Pataky [40] for Matlab and investigate differences between each GRF signal between two classes (for visualization purposes we concatenated the results obtained on each GRF component). To take into account the dependence of SPM results on the choice of a distinct alpha level, we performed experiments with three different alpha levels: 0.01, 0.05, and 0.1. The output of SPM provides t-values for each point of the investigated time series and the threshold corresponding to the chosen alpha level. The t-values exceeding this threshold indicate statistically significant differences in the corresponding sections of the time series. For a better visibility, we marked these significant sections as gray-shaded areas in Figures 4, 5, and 6. We used three different shades of gray for the three different alpha levels, i.e., dark gray for 0.01, gray for 0.05, and light gray for 0.1. Additionally, we computed the effect size by transforming the resulting t-values to Pearson\u2019s correlation coefficient r using the definition by Rosenthal [43]. The effect size provides an indicator for the discriminativeness of a given signal region independent of the alpha level.\n3.4 Clinical Evaluation To evaluate the derived relevance scores of LRP from a clinical perspective, a clinical expert with more than ten years\u2019 experience in human gait analysis analyzed the explainability results. The expert verified the extent to which regions with the highest input relevance scores correspond to GRF characteristics from clinical practice."
    },
    {
      "heading": "4 EXPERIMENTAL SETUP",
      "text": "4.1 Data Recording and Dataset For the gait classification task we utilized a subset of the large-scale GaitRec dataset [24]. This dataset is part of an existing clinical gait database maintained by a local Austrian rehabilitation center. Before conducting our experiments approval was obtained from the local Ethics Committee (#GS1-EK-4/299-2014). The employed dataset contains bilateral three-dimensional ground reaction force (GRF) recordings of patients and healthy controls walking unassisted at self-selected walking speed on an approximately 10 m walkway with two centrallyembedded force plates (Kistler, Type 9281B12, Winterthur, CH). Data were recorded at 2000 Hz, filtered with a zero-lag Butterworth filter of 2nd order with a cut-off frequency of 20 Hz, time-normalized to 101 points (100% stance phase), and amplitude-normalized to 100% body weight. During one session subjects walked barefoot or in socks until a minimum number of 5 valid recordings were available. Recordings were defined as valid by an experienced assessor.\nIn total, the dataset comprises GRF measurements from 132 patients with lower-body gait disorders (GD) and data from 62 healthy controls (HC), both of various physical composition and gender. The dataset includes three 1 SPM1D v.0.4, http://www.spm1d.org/\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n8 \u2022 Slijepcevic and Horst, et al.\nclasses of orthopaedic gait disorders associated with the hip (H , N=37), knee (K , N=52), and ankle (A, N=43). For class-specific demographic details of the data refer to Table 1. The dataset is balanced regarding the number of recorded sessions per person and the number of trials per person. Figure 2 shows an overview of all GRF measurements of the affected side (except for healthy controls where each step is visualized) per class and the associated mean and standard deviation. The GD classes (A, H , and K) include patients after joint replacement surgery, fractures, ligament ruptures, and related disorders associated with the above-mentioned anatomical areas. A well-experienced physical therapist with more than a decade of clinical experience manually labeled the dataset based on the available medical diagnosis of each patient.\n4.2 Input Data Preparation The input data for each classification task is a concatenated version of the three-dimensional GRF signals from both force plates (see Figure 1). The concatenation of all six GRF signals (three force components per force plate) results in a 1\u00d7606-dimensional input vector for each gait trial. The three-dimensional GRF signals are the medio-lateral horizontal force (GRFML), anterior-posterior horizontal force (GRFAP ), and vertical force (GRFV ). The dataset includes only unilateral gait disorders, i.e., disorders where the main physical limitation can be attributed to one leg (the affected leg/side in the following). The signal components of the affected leg (input features: 1 to 303) are concatenated first and are followed by the signal components of the unaffected leg (input features: 304 to 606) in the input vector. For the healthy controls there is no affected and unaffected side (both sides are unaffected). Thus, the order of the signals was randomly assigned, while ensuring an equal distribution, to avoid any bias regarding the side.\n4.3 Data Normalization Normalization of input vectors is applied to ensure an equal contribution of all six GRF signals to the classification models and thus avoids that signals with larger numeric ranges dominate those with smaller numeric ranges [13, 26]. To evaluate the robustness of our models\u2019 predictions and the derived relevance estimates concerning normalization, we firstly conducted experiments without normalization. In a second step, we conducted the same experiments applying min-max normalization to the input signals and thereby scaled each signal to the range [\u22121, 1]. The global minimum and maximum values were determined separately for each of the six GRF signals over all trials.\n4.4 Classification Tasks We investigate six different classification tasks on the dataset introduced above to provide a more comprehensive picture on the investigated problem and to enable the differentiation between task-specific and general observations. Classification tasks include:\n\u2022 binary classification between healthy controls and all gait disorders (HC/GD), \u2022 binary classification between healthy controls and each gait disorder separately (i.e., HC/H , HC/K , and HC/A), \u2022 multi-class classification between healthy controls and all gait disorders (HC/H/K/A), \u2022 and multi-class classification between all gait disorders (H/K/A).\n4.5 Classification Methods In our experiments, three representative machine learning approaches, i.e., (linear) Support Vector Machine (SVM), Multi-layer Perceptron (MLP), and Convolutional Neural Network (CNN) were compared in terms of prediction accuracy and learned input relevance patterns. The SVM models were trained using a standard quadratic optimization algorithm, with an error penalty parameter C = 0.1 and \u21132-constrained regularization of\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nthe learned weight vectorw . The MLP models comprised of three consecutive fully connected layers with ReLU non-linearities activating the hidden neurons and a final SoftMax activation in the output layer. The size of both hidden layers is 768 whereas the size of the output layer is c , where c is the number of target classes. The CNN models process the given data via three consecutive convolutional layers, with a <filter size>-<stride>-<output channel> configuration of 8-2-24, 8-2-24 and 6-3-48, and ReLUs for non-linear neuron activation. The resulting 48\u00d748 feature mapping is then unrolled into a 2304-dimensional vector, and fed into a fully-connected layer, which directly maps to the model output. This fully connected layer is topped with a SoftMax output activation,\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n10 \u2022 Slijepcevic and Horst, et al.\nwhich is acting as a multi-class predictor output towards the c target classes. Both, the MLP and CNN models, have been trained via standard error back-propagation using stochastic gradient descent [30] and a mean absolute (\u21131) loss function. The training procedure was executed for 3 \u00b7 104 iterations of mini batches of five randomly selected training samples and an initial learning rate of 5 \u00b7 10\u22123. The learning rate was gradually decreased after every 104-th training iteration to 10\u22123 by a factor of 0.2 and then to 5 \u00b7 10\u22124 by a factor of 0.5. Model weights were initialized with random values drawn from a normal distribution with \u00b5 = 0 and \u03c3 =m\u2212 12 , wherem is the number of inputs to each output neuron of the layer [30]. Since the CNN receives as input a 1\u00d7606-dimensional input vector, its convolution operations can be understood as 1D convolutions, moving over the time axis only. We used 1D convolutions to maintain comparability with the two other classification methods (MLP and SVM). Preliminary experiments demonstrated negligible differences between 1D and 2D CNNs.\n4.6 Performance Evaluation The prediction accuracies were reported over a stratified ten-fold cross-validation configuration, where eight partitions of the data are used for training, one partition is used as validation set and the remaining partition is reserved for testing. The samples from each class were distributed evenly while ensuring that all gait trials from an individual subject are placed in the same partition of the data to rule out subject-related information influencing the measured model performance during testing. All results are reported as mean with standard deviation (SD), unless otherwise stated. Additionally, we calculated the Zero Rule baseline (ZRB) for each classification task. The ZRB refers to the theoretical accuracy obtained by assigning class labels according to the prior probabilities of the classes, i.e., the target labels are always set to the class with the greatest cardinality in the training dataset.\n4.7 Implementation The implementation of the three ML methods and the LRP method was conducted within the software framework Python 3.7 (Python Software Foundation, USA). Data preprocessing, SPM, and the visualization of the results were performed in Matlab 2017b (MathWorks, USA)."
    },
    {
      "heading": "5 RESULTS",
      "text": "We first present the results obtained in our classification experiments as well as from the explainability analysis and then discuss them in detail in Section 6. We start with a presentation of the classification accuracies achieved for the different classification methods, tasks, and normalization methods (Section 5.1) and continue with a presentation of the explainability results obtained by LRP (Section 5.2).\n5.1 Classification Results The mean prediction accuracy showed a clear superiority over the ZRB for all three classification methods (CNN, SVM, and MLP) and all classification tasks (see Figure 3 and Supplementary Table S1). A 2\u00d72 repeated measures analysis of variance (ANOVA) (classification method: CNN, SVM, and MLP; normalization: min-max and non-normalized) conducted for each classification task only indicated a significant difference in classification accuracy between the three classifiers for taskHC/H/K/A (F2,18 = 5.251, p = 0.016, \u03b72p = 0.368). Additional pairwise and Bonferroni-corrected post-hoc tests revealed that the CNN resulted in a marginally (\u223c3%), but significantly (p = 0.029) lower accuracy than the SVM for task HC/H/K/A. No other significant differences were found for the classifiers\u00e2\u0102\u0179 performances. Regarding normalization, no significant differences were found. Only for task HC/H/K/A (F1,9 = 4.670, p = 0.059, \u03b72p = 0.342) the ANOVA slightly missed the alpha level. For the other tasks no significant effects and differences were found.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 11\n5.2 Explainability Results In the following, we present in detail the results for classification task HC/GD together with respective result visualizations. Results for the other five investigated classification tasks can be found in the supplementary material (see Supplementary Figures S1\u2013S24).\nFigure 4 shows an exemplary result for prediction explanation by LRP, i.e.,the averaged signals together with the color-coded averaged relevance values for each of the 606 input values for taskHC/GD with non-normalized GRF signals. The input relevance values point out which GRF characteristics were most relevant for (or contradictory to) the classification of a certain class (HC orGD). For visualization, input values neutral to the prediction (Ri \u2248 0)\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n12 \u2022 Slijepcevic and Horst, et al.\nare shown in black color, while warm hues indicate input values supporting the prediction (Ri \u226b 0) of the analyzed class and cool hues identify contradictory input values (Ri \u226a 0). For binary classification tasks (HC/GD, HC/H , HC/K , and HC/A), note that a high input relevance value for one class results in a contradictory input relevance value for the other class. Therefore, the total relevance, which is the absolute sum of the relevance scores of both classes is a good indicator for the overall relevance of an input value for a respective classification task. The higher the total relevance at a certain signal region, the more discriminative is this region for the two underlying classes.\nThe highest input relevance values were observed in GRFV of the affected side, as illustrated in Figure 4. In the same way, the mean GRF signals of both classes (see Figure 4A) as well as the SPM analysis (gray-shaded areas in Figure 4) highlighted statistically significant differences between both classes in the same regions of GRFV of the affected side. While LRP identified hardly any relevant regions in both horizontal forces (GRFAP\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 13\nand GRFML), it is noticeable that the SPM analysis highlighted a lot more regions within GRFAP and GRFML as statistically significantly different between the two classes. This shows that relevant regions identified by LRP mostly correlated with significant signal regions. However, not all significant regions are necessarily used by the classification model.\nWhen min-max normalization is applied to the input data of the classification task from above (HC/GD), the identified regions of high relevance in GRFV are similar to those obtained from non-normalized signals (see Figure 4). However, there are many additional regions of high relevance in both horizontal forces (see Figure 5). Note that the regions identified by SPM are the same since they are not affected by the normalization. The additionally identified regions of high relevance according to LRP agree to a large extent with the SPM results. The regions with the highest input relevance values for the prediction can be observed at approximately 20% and 80% of the stance phase in the affected and unaffected GRF signals. For theGRFML a relevant region can also be observed at 10% of the stance phase. In addition, high input relevance scores can be observed in theGRFV during the first and last \u223c5% of the stance phase of the affected and unaffected side, as well as during the middle of the stance phase of the affected side.\nFigure 6 shows the results of task HC/GD (with min-max normalized GRF signals as in Figure 5) for all three employed classification methods (CNN, SVM, and MLP). The relevance scores agree to a large extent. However, with respect to GRFV , the highest input relevance values can be observed in the peak regions for the CNN, while the highest input relevance values for SVM and MLP are present during the first and last \u223c5% of the stance phase (beginning and end of the GRFV signal). These results show that the investigated classification methods rely on the same regions in the input data with only small exceptions.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nFor the sake of brevity, only the results for the classification task HC/GD were presented. For results of the other classification tasks we refer the reader to the supplementary material (see Supplementary Figures S1\u2013S24). The discussion in the following will incorporate all six classification tasks."
    },
    {
      "heading": "6 DISCUSSION",
      "text": "The primary aim of this article is to investigate whether XAI methods can enhance explainability of ML predictions in clinical gait classification. In this section, the classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance-based explanations. These explanations are, furthermore, evaluated from a statistical and clinical viewpoint. Additionally, we discuss dependencies, influences and interesting observations with respect to different classificationmethods, tasks, normalizationmethods, and signal components (horizontal forces and affected/unaffected leg signals).\n6.1 Classification Results The results expressed in terms of classification accuracy (presented in Figure 3 and Supplementary Table S1) demonstrate a comparable level of performance between the three different machine learning methods (CNN, SVM, and MLP). The achieved performance level is not only interesting by itself but also important information for further explainability experiments. The reason is that an objective analysis of explainability by a post-hoc method like LRP is only meaningful if the classification model can robustly differentiate between the target classes, i.e., a certain model quality is necessary to draw meaningful conclusions from explainability results. An analysis of unreliable classification models bears the potential risk that unstable patterns, noise, and spurious correlations bias the explainability results. For this reason, we excluded the classification tasks HC/H/K/A and H/K/A from our further investigation, as the tasks could not be solved with sufficient accuracy (average classification accuracy above 80%). For the binary classification tasks this risk is much lower, because the higher classification accuracies (and deviations from ZRB) obtained suggest that robust features can be found in the input data.\nAnother aspect we assessed is the influence of normalization on the input data (see Figure 3). The normalization of the input data is important for machine learning since highly differing value ranges can have a negative influence on the classification model, i.e., input variables with a higher value range have a stronger influence on the predictions [13, 26]. The same appears to be the case for the gait data, where the normalization of the input\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 15\ndata strongly influences the classification models, as can be observed from the relevance scores of the horizontal forces (compare Figures 4 and 5). Surprisingly, however, min-max normalization does not significantly improve the classification results (see Figure 3) for the investigated classification tasks. This raises the question of whether the use of GRFV alone would already be sufficient to solve the classification tasks. We discuss this seemingly contradictory behavior in the following section.\n6.2 Explainability Results In the following, we discuss different related aspects with regard to our first leading research question: \u201cWhich input features or signal regions are most relevant for automatic gait classification?\u201d. The visualizations for all classification tasks and classification methods can be found in the supplementary material (see Supplementary Figures S1\u2013S24). Which input features and signal regions are most relevant for the automatic classification of functional gait disorders? For the classification of non-normalized GRF signals (e.g., Figure 4), the most relevant input values are mainly located in GRFV of the affected side, i.e., especially the two peaks and the valley in between are relevant for the tasks. This shows that the classification models learned that the HC class and the gait disorder classes (GD, H , K , and A) differ most in these three sections of the signals. These results were also confirmed in our earlier studies, e.g., where the peaks ofGRFV and the valley between them were most important for discriminating the classes [52]. Is the unaffected side important? Identified relevant regions are considerably less pronounced in GRFV of the unaffected side, but they correlate to a large extent with those of the affected side, except that only the rear part of the valley and not the entire valley is relevant (best recognized from the total relevance curve in e.g., Figure 4D). In earlier studies [53, 54], we showed that the omission of the unaffected side during classification negatively affected classification accuracy. The explainability results confirm this observation. The unaffected side seems to capture complementary information relevant to the classification task. Are the anterior-posterior and medio-lateral forces relevant for the task? A minimal degree of relevance can be observed in the peaks of the non-normalized affected and unaffected GRFAP signals. The absence of relevant regions from the horizontal forces (GRFAP and GRFML) does not confirm our results from previous studies using normalized GRF signals [53, 54], where we showed that adding horizontal forces indeed improved classification performance (leading even to peak performance). The question of whether or not horizontal forces are beneficial for the task cannot be answered conclusively. Interestingly, the statistical analysis via SPM highlights regions in the horizontal forces that differ significantly between the HC class and the gait disorder classes (GD, H , K , and A).\nWhat is the impact of normalization on explainability? The reason for the absence of relevant regions in the horizontal forces could be their small value range. The rather small range compared to the GRFV component may lead to a smaller influence on the training of the classification models. Explainability results for min-max normalized input data show that more relevant regions are identified by LRP in the horizontal forces of the affected and unaffected side (e.g., Figure 5). Normalization amplifies the relevance of values in the horizontal forces and thereby makes them similarly important as GRFV . Based on the LRP relevance scores, we conclude that normalization is important to obtain unbiased predictions (bias introduced by different signal amplitudes). Are all identified relevant regions necessary for the task? For all classification tasks and classification methods, with min-max normalized input data, many regions of the GRF signals are identified to be relevant for the classification of a particular class by LRP. The classification performance with and without normalization does, however, not vary significantly (see classification results in Section 5.1). This raises the question of whether all identified regions are necessary to achieve peak performance in classification or whether some of them are redundant (i.e., not yielding an increase in classification performance when combined). Note that the assumption\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n16 \u2022 Slijepcevic and Horst, et al.\nof redundancy is supported by the fact that the three GRF components represent individual dimensions of the same three-dimensional physical process. Thus, a strong correlation is a priori given in the data. To answer the question we occluded parts of the input vector in the classification experiment and evaluated the changes in classification performance. Occlusion is realized by replacing the horizontal forces (GRFAP and GRFML) of both sides (affected and unaffected) with zero values and retraining the classification model. Table 2 shows the classification results for the occluded input. To enable easier comparison with the previous results, the deviation from the mean classification accuracy of the non-occluded experiments (from Figure 3 and Supplementary Table S1) are displayed for all binary classification tasks (see Table 2). The results decrease on average when the horizontal forces are occluded, except for task HC/A with min-max normalized input data. Furthermore, the decrease is more pronounced for min-max normalized input data than for non-normalized input data. This further corroborates our assumption that normalization is important to take information from horizontal forces into account. However, the classification results of the binary classification tasks are not influenced by the occlusion of horizontal forces in a statistically significant way. This was confirmed by several dependent t-tests (p > 0.05) with Bonferroni correction. Our results indicate that the relevant regions identified by LRP may represent an over-complete set, which exhibits a certain degree of redundancy, as removing one section does not necessarily lead to reduced classification performance. However, redundancy is not necessarily a negative property. It may be an important property to achieve higher robustness to noise and possibly also to outliers and missing data [25].\nAre the anterior-posterior and medio-lateral forces relevant for the task (question revisited)? The effects of occluded horizontal forces are illustrated in Table 2. Especially for experiments with min-max normalized input data a decrease in mean performance can be observed (e.g., HC/H and HC/K). Thus, the relevant regions in the horizontal forces cannot be completely redundant to those in GRFV and, therefore, represent also complementary information. This is also in line with our previous quantitative performance evaluations [53, 54].\nDo different classifiers rely on different patterns? A condensed comparison of the three employed classification methods is depicted in Figure 6. The LRP relevance values are consistent for non-normalized and normalized input data. For the former (e.g., for task HC/GD see Supplementary Figures S1, S3, and S5), the relevant regions for SVM and MLP largely correspond across all binary classification tasks. The CNN matches the relevant regions of SVM and MLP in broad terms. The relevant regions in GRFV of the unaffected side for the CNN are considerably lower compared to SVM and MLP (compare Supplementary Figures S1, S3, and S5), e.g., for task HC/GD the valley inGRFV of the unaffected side is hardly relevant and the second peak inGRFV of the unaffected side is considerably less relevant compared to SVM and MLP. For min-max normalized data (see Figure 6), the relevant regions for SVM and MLP coincide also to a large extent. The relevant regions of CNN\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 17\ncorrespond to those of SVM and MLP with regard to their location, but are considerably more relevant (best visible in the total relevance curves in the right part of Figure 6). The most pronounced difference between the classification methods can be observed in the estimated relevance scores at the beginning and end of GRFV signals. While LRP indicates that those regions are relevant for SVM and MLP, the total relevance curve of the CNN does not show any correspondence in those regions. The remaining binary classification tasks, i.e., HC/H (see Supplementary Figures S7\u2013S12), HC/K (see Supplementary Figures S13\u2013S18) and HC/A (see Supplementary Figures S19\u2013S24) confirm these findings. A reason for the strong difference in relevance scores at the beginning and end of the stance phase might be the higher degree of inter- and intra-subject variability due to balance instabilities. Additionally, measurement noise may bias the rather small force values during these phases of stance [9]. In the absence of ground truth information for automatically generated explanations, it is difficult to assess whether regions considered as relevant for SVM and MLP are related to (biomechanically) meaningful gait characteristics. While LRP clearly shows where the prediction is grounded, it cannot explain why these patterns are important. However, it allows to identify and compare the learning strategies of different classification methods and, thus, points out potential degeneration effects, influences of noise, and spurious correlations.\n6.3 Statistical Verification of Relevance-based Explanations In the following, we investigate the statistical properties of the signal regions found to be relevant by LRP to answer the second leading research question: \u00c2\u0165\u00c2\u0165To what extent are input features or signal regions identified as being relevant for a given gait classification task statistically justified?\u201d. To answer this question, we leverage SPM, which provides significance estimates for each sample of the input signals. We compare the LRP regions with those considered as significantly different by SPM. Results show that in the vast majority of cases, the SPM analysis shows statistically significant differences in regions which are also highly relevant for classification according to LRP. Thus, for binary classification tasks, it seems that machine learning models base their predictions primarily on features that are also significantly different between the two classes. This can be observed, e.g., in the HC/GD classification for both, min-max normalized and non-normalized GRF signals in Figure 4D and Figure 5D. As the total relevance increases, the effect size usually also increases. We performed a cross-correlation to determine the relationship between the effect size and the total relevance. Both curves show highly correlated behavior for the normalized case (r = 0.73), whereas for the non-normalized case a moderate positive correlation (r = 0.61) could be observed. For the latter, the disagreement between SPM estimates and LRP results indicated the presence of bias in the analysis. This bias, which was introduced by different amplitude ranges in the input signals, prevented the classification models to learn relevant patterns in the horizontal forces. SPM clearly showed this bias, which underlines the role of SPM as a suitable statistical reference for our investigation.\nConcerning our second research question, we conclude that the relevance estimates are to the greatest extent statistically justified, when the data is correctly preprocessed (normalized). The second part of the research question regarding the validity of the explanations with respect to clinical assessment is investigated in the following section.\n6.4 Clinical Evaluation of Relevance-based Explanations \u201cTo what extent are input features or signal regions identified as being relevant for a given gait classification task in line with clinical assessment?\u201d This question is answered in the following by a clinical expert with more than ten years\u2019 experience in human gait analysis. To assist the reader in following the discussion and to facilitate the interpretation of the input signals, the domain-specific terms and gait cycle definitions are described in Figure 7 .\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n18 \u2022 Slijepcevic and Horst, et al.\nThe explainability results for min-max normalized input data illustrate clinically meaningful patterns. Across all classification tasks and models high LRP relevance scores occurred mainly during loading response and terminal stance phase in GRFAP and in loading response, mid stance, and terminal stance in GRFV . These phases are especially sensitive toward gait anomalies as loading response requires the absorption of body weight and terminal stance plays an essential role for forward propulsion. Both aspects are affected in case of gait impairments due to a diminished walking speed (requiring less absorption or push-off) as well as factors that go along with an injury, such as the presence of pain, a decreased range of motion and/or lessened muscle strength. When analyzing the explainability results in more detail, one can identify specific gait dynamics that can be traced back to an impairment at a certain joint level. For classification task HC/A (see Supplementary Figure S20) we can observe pronounced peaks in the total relevance curves of GRFAP , which may be caused by alterations in the pre-swing phase of the affected side and the consecutive breaking impulse during initial contact on the contralateral (unaffected) side. For classification task HC/K , the highest LRP relevance scores are present in GRFV , GRFAP , and GRFML (see Supplementary Figure S14). Changes in GRFV may result from lessened knee\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 19\nflexibility that hinders typical knee dynamics over the entire course of the stance phase. More precisely, healthy walking requires an almost fully extended knee joint during initial contact followed by a slight knee flexion thereafter, by definition called loading response. During the mid stance phase the walker\u2019s center of gravity is shifted forward and thus demands further knee extension. Highest LRP relevance values for the classification task HC/H are obtained during loading response and terminal stance inGRFV of the affected side (see Supplementary Figure S8). These results may be ascribed to lowered impact and weight-bearing in the early stance phase (due to a potentially more cautious walking strategy) to avoid excessive load on the affected hip joint. These observations further corroborate the idea that LRP explanations agree well with clinical assessment (given the input data is normalized). As the results presented above are based on min-max normalized data, the question arises whether similar observations can be derived from the experiments without normalization. The prediction explanations for nonnormalized data (see Figure 4 and Supplementary Figures S7, S13, S19) clearly show a different picture, even if classification results are comparable to those obtained with min-max normalized data. Relevant regions can only be found inGRFV . These observations highlight that normalization strongly affects the quality of classification models and, therefore, needs to be considered to derive clinically meaningful explanations.\n6.5 Limitations and Future Work A fundamental problem in evaluating the explainability results is the absence of a ground truth. A challenge in interpreting the explainability results is that alterations of the input signals can be caused not only by the influence of a pathology, but also by other independent parameters, e.g., a lower walking speed or an increased body mass. To minimize potential biases introduced by independent parameters on prediction explanations, future research should attempt to develop normalization procedures for input signals that compensate such influencing factors or develop classification models that inherently learn the relationship between influencing factors and input signals. A limitation regarding the applicability of the present work in a clinical setting is its sole use of GRF signals. Kinematic data would allow a more comprehensive view on the biomechanical processes during walking and therefore simplify the interpretation of explainability results. Besides visual explanations as presented in this paper, a translation into human understandable textual explanations would be desired for clinical application. An interesting direction for future research is the generation of textual explanations based on biomechanical parameters estimated from the input signals. This would enable approaches that exceed pure explainability and provide deeper interpretations for clinical experts in the form of, e.g., \"there is a high probability of a pathology in the knee due to a limited knee extension during the mid stance phase\"."
    },
    {
      "heading": "7 CONCLUSION",
      "text": "The present findings highlight that machine learning models base their predictions on meaningful features of GRF signals in clinical gait classification tasks that are in accordance with a statistical and clinical evaluation. Hence, XAI methods which provide explainability for predictions made by machine learning models, such as LRP, can be promising solutions to increase justification of automatic classification predictions in CGA and can help to make the prediction processes comprehensible to clinical and legal experts. Thereby, XAI may facilitate the application of ML-based decision-support systems in clinical practice. Within the scope of our analysis we were able to show that:\n\u2022 Highly relevant regions were identified in the signals of the affected and unaffected side. Thus, the unaffected side captures additional information which are relevant for automated gait classifications.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n20 \u2022 Slijepcevic and Horst, et al.\n\u2022 For time-series data such as GRF signals, SPM has shown to be a suitable statistical reference. Relevant regions in the input data (according to LRP) are in the most cases also significantly different and in line with clinical evaluation. \u2022 Input data normalization allows machine learning models to consider features from various input signals for their predictions (especially if the value ranges differ as much as for the three force components of the GRF). Without normalization, only relevant regions in the GRFV were identified which is not reasonable from a clinical point of view. Therefore, data normalization is highly recommended for ML-based gait classification. \u2022 For the investigated binary gait classification tasks, machine learning models seem to learn an overcomplete set of features that may contain redundant information. This might explain why the occlusion of horizontal forces in our experiments had negligible influence on the classification accuracies and also why the classification accuracies for the classification of normalized and non-normalized GRF signals were similar.\nThis paper can be considered as a first step towards explainability of ML approaches in clinical gait analysis. We will conduct further research to compare different explanation methods and rule-based approaches [27] for different classification tasks and datasets. In addition, we want to point out that quantitative and objective methods are necessary to assess the quality of prediction explanations [45] including datasets with respective ground truth explanations."
    },
    {
      "heading": "CONFLICT OF INTEREST STATEMENT",
      "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
    },
    {
      "heading": "AUTHOR CONTRIBUTIONS",
      "text": "DS, A-MR, MZ, BH prepared the dataset. FH, DS, SL, WS, WIS, BH conceived the presented idea. MZ, WS, WIS, BH raised the funding. FH, DS, SL, A-MR, MZ, WS, CB, WIS, BH participated in the data analysis. FH, DS, SL, A-MR, MZ, BH wrote the manuscript. FH, DS, SL, A-MR, MZ, WS, BH designed the figures. FH, DS, SL, A-MR, MZ, WS, CB, WIS, BH reviewed and approved the final manuscript."
    },
    {
      "heading": "FUNDING",
      "text": "This work was partly funded by the Austrian Research Promotion Agency (FFG) and the BMDWwithin the COINprogram (#866855 and #866880), the Lower Austrian Research and Education Company (NFB), the Provincial Government of Lower Austria (#FTI17-014). Further support was received from the GermanMinistry for Education and Research as BIFOLD (#01IS18025A and #01IS18037A) and TraMeExCo (#01IS18056A)."
    },
    {
      "heading": "ACKNOWLEDGMENTS",
      "text": "We want to thank Marianne Worisch, Szava Zolt\u00e1n, and Theresa Fischer for their great assistance in data preparation and their support in clinical and technical questions."
    },
    {
      "heading": "DATA AVAILABILITY STATEMENT",
      "text": "For our analyses, we used a subset of the GaitRec dataset [24]. The data and the experimental code will be made publicly available on GitHub after publication.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 21"
    },
    {
      "heading": "SUPPLEMENTARY TABLES AND FIGURES",
      "text": "The present Supplementary Material is intended to present additional results we generated for the paper \"On the Explanation of Machine Learning Predictions in Clinical Gait Analysis\". The primary aim of this article is to investigate to which degree Explainable Artificial Intelligence (XAI) methods can make predictions of machine learning (ML) approaches more explainable to clinical experts in clinical gait analysis.\nFor this purpose, we investigate different gait classification tasks, employ a representative set of classification methods \u2013 (linear) Support Vector Machine (SVM), Multi-layer Perceptron (MLP), and Convolutional Neural Network (CNN) \u2013, and a well-established XAI method \u00e2\u0102\u015e Layer-wise Relevance Propagation (LRP) \u00e2\u0102\u015e to explain predictions at the signal (input) level. Since there is no ground truth for automatically generated explanations in this context, we evaluate the explanations from a clinical point of view by a clinical expert. In addition, as a second reference, we propose the use of Statistical Parametric Mapping (SPM) to compare the obtained results from a statistical point of view. The dataset employed, comprises ground reaction force (GRF) measurements from 132 patients with gait disorders (GD) and data from 62 healthy controls (HC). The GD class is furthermore differentiated into three classes of gait disorders associated with the hip (H ), knee (K), and ankle (A). The classification tasks, which represent the basis of the XAI investigation, due to high classification accuracies obtained, include a binary classification between healthy controls and all gait disorders (HC/GD), and a binary classification between healthy controls and each gait disorder separately, i.e.\u201e HC/H , HC/K , and HC/A. The classification results obtained for the six classification tasks, are presented in Supplementary Table S1.\nThe following figures visualize the relevance-based explanations obtained with LRP. The input vector for the classifiers comprises concatenated affected and unaffected GRF signals. These GRF signals are time-normalized to 101 points (100% stance phase), thus the input vector contains 606 values. For each value LRP provides whether they are relevant or not for the classification. Sub-figure (A) shows mean GRF signals averaged over each class of the classification task. The shaded areas in all sub-figures highlight areas in the input signals where SPM resulted in a statistically significant difference between both classes. Sub-figure (B) shows mean GRF signals (including a band of one standard deviation) for the HC class. The input relevance indicates which GRF characteristics were most relevant for (or contradictory to) the classification of a certain class. For visualization, input values neutral to the prediction (Ri \u2248 0) are shown in black, while warm hues indicate input values supporting the prediction (Ri \u226b 0) of the analyzed class and cool hues identify contradictory input values (Ri \u226a 0). Sub-figure (C) depicts mean GRF signals averaged over a pathological class (H , K , or A) or all gait disorders (GD), in the same format as in sub-figure (B). Sub-figure (D) shows the effect size obtained from SPM and the total relevance, which is calculated as the sum of the absolute input relevance values of both classes. The total relevance indicates the common relevance of the input signal for the classification task.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 25"
    },
    {
      "heading": "CLASSIFICATION RESULTS",
      "text": "Table S1. Overview of the prediction accuracy obtained for the three employed classification methods (CNN, SVM and MLP) and all six classification tasks with min-max normalized and non-normalized input signals, reported in pairs of mean (standard deviation) over the ten-fold cross validation in percent. Note that the Zero-Rule Baseline (ZRB) is task-specific.\nTask Normalization ZRB SVM MLP CNN HC/GD no norm. 68.0 88.6 (4.9) 88.1 (4.8) 87.8 (4.5) HC/GD min-max 68.0 88.4 (5.3) 88.8 (5.0) 88.0 (5.0) HC/H no norm. 62.6 85.9 (8.4) 86.6 (7.9) 85.1 (8.2) HC/H min-max 62.6 87.1 (7.6) 86.7 (8.5) 85.5 (8.0) HC/K no norm. 54.4 85.7 (9.0) 86.1 (7.9) 84.8 (9.9) HC/K min-max 54.4 88.5 (7.2) 88.5 (7.6) 85.9 (9.3) HC/A no norm. 59.0 89.1 (5.9) 88.3 (6.3) 88.7 (5.5) HC/A min-max 59.0 87.6 (7.4) 86.5 (8.1) 86.7 (8.3) H/K/A no norm. 39.4 46.4 (9.5) 45.9 (11.0) 48.0 (10.1) H/K/A min-max 39.4 51.8 (9.6) 47.4 (10.9) 50.7 (9.8) HC/H/K/A no norm. 32.0 58.7 (7.5) 55.6 (7.6) 55.0 (8.7) HC/H/K/A min-max 32.0 59.5 (8.5) 59.2 (7.6) 57.5 (7.0)\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n26 \u2022 Slijepcevic and Horst, et al."
    },
    {
      "heading": "EXPLAINABILITY RESULTS",
      "text": "Classification Task: HC/GD | Classification method: CNN\nFig. S1. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on non-normalized GRF signals using a CNN as classifier.\nFig. S2. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on min-max normalized GRF signals using a CNN as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 27\nClassification Task: HC/GD | Classification method:MLP\nFig. S3. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on non-normalized GRF signals using an MLP as classifier.\nFig. S4. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on min-max normalized GRF signals using an MLP as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n28 \u2022 Slijepcevic and Horst, et al.\nClassification Task: HC/GD | Classification method: SVM\nFig. S5. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on non-normalized GRF signals using a SVM as classifier.\nFig. S6. Result overview for the classification of healthy controls and the aggregated class of all three gait disorders (HC/GD) based on min-max normalized GRF signals using a SVM as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 29\nClassification Task: HC/H | Classification method: CNN\nFig. S7. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on non-normalized GRF signals using a CNN as classifier.\nFig. S8. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on min-max normalized GRF signals using a CNN as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n30 \u2022 Slijepcevic and Horst, et al.\nClassification Task: HC/H | Classification method:MLP\nFig. S9. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on non-normalized GRF signals using an MLP as classifier.\nFig. S10. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on min-max normalized GRF signals using an MLP as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 31\nClassification Task: HC/H | Classification method: SVM\nFig. S11. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on non-normalized GRF signals using a SVM as classifier.\nFig. S12. Result overview for the classification of healthy controls (HC) and hip injury class (H ) based on min-max normalized GRF signals using a SVM as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n32 \u2022 Slijepcevic and Horst, et al.\nClassification Task: HC/K | Classification method: CNN\nFig. S13. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based on non-normalized GRF signals using a CNN as classifier.\nFig. S14. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based onmin-max normalized GRF signals using a CNN as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 33\nClassification Task: HC/K | Classification method:MLP\nFig. S15. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based on non-normalized GRF signals using an MLP as classifier.\nFig. S16. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based onmin-max normalized GRF signals using an MLP as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n34 \u2022 Slijepcevic and Horst, et al.\nClassification Task: HC/K | Classification method: SVM\nFig. S17. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based on non-normalized GRF signals using a SVM as classifier.\nFig. S18. Result overview for the classification of healthy controls (HC) and knee injury class (K ) based onmin-max normalized GRF signals using a SVM as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 35\nClassification Task: HC/A | Classification method: CNN\nFig. S19. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on non-normalized GRF signals using a CNN as classifier.\nFig. S20. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on min-max normalized GRF signals using a CNN as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\n36 \u2022 Slijepcevic and Horst, et al.\nClassification Task: HC/A | Classification method:MLP\nFig. S21. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on non-normalized GRF signals using an MLP as classifier.\nFig. S22. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on min-max normalized GRF signals using an MLP as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020.\nOn the Explanation of Machine Learning Predictions in Clinical Gait Analysis \u2022 37\nClassification Task: HC/A | Classification method: SVM\nFig. S23. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on non-normalized GRF signals using a SVM as classifier.\nFig. S24. Result overview for the classification of healthy controls (HC) and ankle injury class (A) based on min-max normalized GRF signals using a SVM as classifier.\n, Vol. 1, No. 1, Article . Publication date: August 2020."
    }
  ],
  "title": "On the Explanation of Machine Learning Predictions in Clinical Gait Analysis",
  "year": 2020
}
