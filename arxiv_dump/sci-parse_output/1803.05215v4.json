{
  "abstractText": "Demosaicking and denoising are among the most crucial steps of modern digital camera pipelines and their joint treatment is a highly ill-posed inverse problem where at-least two-thirds of the information are missing and the rest are corrupted by noise. This poses a great challenge in obtaining meaningful reconstructions and a special care for the efficient treatment of the problem is required. While there are several machine learning approaches that have been recently introduced to deal with joint image demosaicking-denoising, in this work we propose a novel deep learning architecture which is inspired by powerful classical image regularization methods and large-scale convex optimization techniques. Consequently, our derived network is more transparent and has a clear interpretation compared to alternative competitive deep learning approaches. Our extensive experiments demonstrate that our network outperforms any previous approaches on both noisy and noise-free data. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which also requires fewer trainable parameters than the current state-of-the-art deep network solution. Finally, we show that our network has the ability to generalize well even when it is trained on small datasets, while keeping the overall number of trainable parameters low.",
  "authors": [
    {
      "affiliations": [],
      "name": "Filippos Kokkinos"
    },
    {
      "affiliations": [],
      "name": "Stamatios Lefkimmiatis"
    }
  ],
  "id": "SP:edf2a8a2b7669656e2092291fbe305706a01b5b0",
  "references": [
    {
      "authors": [
        "Xin Li",
        "L.Z. Bahadir Gunturk"
      ],
      "title": "Image demosaicing: a systematic survey",
      "year": 2008
    },
    {
      "authors": [
        "L. Zhang",
        "X. Wu",
        "A. Buades",
        "X. Li"
      ],
      "title": "Color demosaicking by local directional interpolation and nonlocal adaptive thresholding",
      "venue": "Journal of Electronic imaging 20(2)",
      "year": 2011
    },
    {
      "authors": [
        "J. Duran",
        "A. Buades"
      ],
      "title": "Self-similarity and spectral correlation adaptive algorithm for color demosaicking",
      "venue": "IEEE transactions on image processing 23(9)",
      "year": 2014
    },
    {
      "authors": [
        "A. Buades",
        "B. Coll",
        "J.M. Morel",
        "C. Sbert"
      ],
      "title": "Self-similarity driven color demosaicking",
      "venue": "IEEE Transactions on Image Processing 18(6)",
      "year": 2009
    },
    {
      "authors": [
        "F. Heide",
        "M. Steinberger",
        "Y.T. Tsai",
        "M. Rouf",
        "D. Pajak",
        "D. Reddy",
        "O. Gallo",
        "J. Liu",
        "W. Heidrich",
        "K Egiazarian"
      ],
      "title": "Flexisp: A flexible camera image processing framework",
      "venue": "ACM Transactions on Graphics (TOG) 33(6)",
      "year": 2014
    },
    {
      "authors": [
        "K. Chang",
        "P.L.K. Ding",
        "B. Li"
      ],
      "title": "Color image demosaicking using inter-channel correlation and nonlocal self-similarity",
      "venue": "Signal Processing: Image Communication 39",
      "year": 2015
    },
    {
      "authors": [
        "K. Hirakawa",
        "T.W. Parks"
      ],
      "title": "Adaptive homogeneity-directed demosaicing algorithm",
      "venue": "IEEE Transactions on Image Processing 14(3)",
      "year": 2005
    },
    {
      "authors": [
        "D. Alleysson",
        "S. Susstrunk",
        "J. Herault"
      ],
      "title": "Linear demosaicing inspired by the human visual system",
      "venue": "IEEE Transactions on Image Processing 14(4)",
      "year": 2005
    },
    {
      "authors": [
        "E. Dubois"
      ],
      "title": "Frequency-domain methods for demosaicking of bayer-sampled color images",
      "venue": "IEEE Signal Processing Letters 12(12)",
      "year": 2005
    },
    {
      "authors": [
        "E. Dubois"
      ],
      "title": "Filter design for adaptive frequency-domain bayer demosaicking",
      "venue": "2006 International Conference on Image Processing.",
      "year": 2006
    },
    {
      "authors": [
        "E. Dubois"
      ],
      "title": "Color filter array sampling of color images: Frequency-domain analysis and associated demosaicking algorithms",
      "year": 2009
    },
    {
      "authors": [
        "J. Sun",
        "M.F. Tappen"
      ],
      "title": "Separable markov random field model and its applications in low level vision",
      "venue": "IEEE Transactions on Image Processing 22(1)",
      "year": 2013
    },
    {
      "authors": [
        "F.L. He",
        "Y.C.F. Wang",
        "K.L. Hua"
      ],
      "title": "Self-learning approach to color demosaicking via support vector regression",
      "venue": "Image Processing (ICIP), 2012 19th IEEE International Conference on, IEEE",
      "year": 2012
    },
    {
      "authors": [
        "D. Khashabi",
        "S. Nowozin",
        "J. Jancsary",
        "A.W. Fitzgibbon"
      ],
      "title": "Joint demosaicing and denoising via learned nonparametric random fields",
      "venue": "IEEE Transactions on Image Processing 23(12)",
      "year": 2014
    },
    {
      "authors": [
        "A. Foi",
        "M. Trimeche",
        "V. Katkovnik",
        "K. Egiazarian"
      ],
      "title": "Practical poissonian-gaussian noise modeling and fitting for single-image raw-data",
      "venue": "IEEE Transactions on Image Processing 17(10)",
      "year": 2008
    },
    {
      "authors": [
        "D. Menon",
        "G. Calvagno"
      ],
      "title": "Joint demosaicking and denoisingwith space-varying filters",
      "venue": "2009 16th IEEE International Conference on Image Processing (ICIP).",
      "year": 2009
    },
    {
      "authors": [
        "L. Zhang",
        "R. Lukac",
        "X. Wu",
        "D. Zhang"
      ],
      "title": "Pca-based spatially adaptive denoising of cfa images for single-sensor digital cameras",
      "venue": "IEEE Transactions on Image Processing 18(4)",
      "year": 2009
    },
    {
      "authors": [
        "T. Klatzer",
        "K. Hammernik",
        "P. Knobelreiter",
        "T. Pock"
      ],
      "title": "Learning joint demosaicing and denoising based on sequential energy minimization",
      "venue": "2016 IEEE International Conference on Computational Photography (ICCP).",
      "year": 2016
    },
    {
      "authors": [
        "M. Gharbi",
        "G. Chaurasia",
        "S. Paris",
        "F. Durand"
      ],
      "title": "Deep joint demosaicking and denoising",
      "venue": "ACM Trans. Graph. 35(6)",
      "year": 2016
    },
    {
      "authors": [
        "S. Boyd",
        "N. Parikh",
        "E. Chu",
        "B. Peleato",
        "J Eckstein"
      ],
      "title": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
      "venue": "Foundations and Trends R \u00a9 in Machine Learning 3(1)",
      "year": 2011
    },
    {
      "authors": [
        "T. Goldstein",
        "S. Osher"
      ],
      "title": "The split bregman method for l1-regularized problems",
      "venue": "SIAM journal on imaging sciences 2(2)",
      "year": 2009
    },
    {
      "authors": [
        "D.R. Hunter",
        "K. Lange"
      ],
      "title": "A tutorial on mm algorithms",
      "venue": "The American Statistician 58(1)",
      "year": 2004
    },
    {
      "authors": [
        "M.A. Figueiredo",
        "J.M. Bioucas-Dias",
        "R.D. Nowak"
      ],
      "title": "Majorization\u2013minimization algorithms for wavelet-based image restoration",
      "venue": "IEEE Transactions on Image processing 16(12)",
      "year": 2007
    },
    {
      "authors": [
        "Y. Romano",
        "M. Elad",
        "P. Milanfar"
      ],
      "title": "The little engine that could: Regularization by denoising (red)",
      "venue": "SIAM Journal on Imaging Sciences 10(4)",
      "year": 2017
    },
    {
      "authors": [
        "S.V. Venkatakrishnan",
        "C.A. Bouman",
        "B. Wohlberg"
      ],
      "title": "Plug-and-play priors for model based reconstruction",
      "venue": "2013 IEEE Global Conference on Signal and Information Processing.",
      "year": 2013
    },
    {
      "authors": [
        "K. Zhang",
        "W. Zuo",
        "Y. Chen",
        "D. Meng",
        "L. Zhang"
      ],
      "title": "Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising",
      "venue": "IEEE Transactions on Image Processing 26(7)",
      "year": 2017
    },
    {
      "authors": [
        "S. Lefkimmiatis"
      ],
      "title": "Universal denoising networks: A novel cnn architecture for image denoising",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
      "year": 2018
    },
    {
      "authors": [
        "K. Zhang",
        "W. Zuo",
        "S. Gu",
        "L. Zhang"
      ],
      "title": "Learning deep cnn denoiser prior for image restoration",
      "venue": "arXiv preprint",
      "year": 2017
    },
    {
      "authors": [
        "A. Foi"
      ],
      "title": "Clipped noisy images: Heteroskedastic modeling and practical denoising",
      "venue": "Signal Processing 89(12)",
      "year": 2009
    },
    {
      "authors": [
        "X. Liu",
        "M. Tanaka",
        "M. Okutomi"
      ],
      "title": "Single-image noise level estimation for blind denoising",
      "venue": "IEEE transactions on image processing 22(12)",
      "year": 2013
    },
    {
      "authors": [
        "K. He",
        "X. Zhang",
        "S. Ren",
        "J. Sun"
      ],
      "title": "Deep residual learning for image recognition",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition.",
      "year": 2016
    },
    {
      "authors": [
        "A. Beck",
        "M. Teboulle"
      ],
      "title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
      "venue": "SIAM Journal on Imaging Sciences 2(1)",
      "year": 2009
    },
    {
      "authors": [
        "Q. Lin",
        "L. Xiao"
      ],
      "title": "An adaptive accelerated proximal gradient method and its homotopy continuation for sparse optimization",
      "venue": "Computational Optimization and Applications 60(3)",
      "year": 2015
    },
    {
      "authors": [
        "A. Buades",
        "B. Coll",
        "J.M. Morel"
      ],
      "title": "A non-local algorithm for image denoising",
      "venue": "Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. Volume 2., IEEE",
      "year": 2005
    },
    {
      "authors": [
        "K. Dabov",
        "A. Foi",
        "V. Katkovnik",
        "K. Egiazarian"
      ],
      "title": "Image denoising by sparse 3-d transform-domain collaborative filtering",
      "venue": "IEEE Transactions on image processing 16(8)",
      "year": 2007
    },
    {
      "authors": [
        "D. Martin",
        "C. Fowlkes",
        "D. Tal",
        "J. Malik"
      ],
      "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics",
      "venue": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001. Volume 2.",
      "year": 2001
    },
    {
      "authors": [
        "K. He",
        "X. Zhang",
        "S. Ren",
        "J. Sun"
      ],
      "title": "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification",
      "venue": "Proceedings of the IEEE international conference on computer vision.",
      "year": 2015
    },
    {
      "authors": [
        "D.P. Kingma",
        "J. Ba"
      ],
      "title": "Adam: A method for stochastic optimization",
      "venue": "arXiv preprint arXiv:1412.6980",
      "year": 2014
    },
    {
      "authors": [
        "A.J. Robinson",
        "F. Fallside"
      ],
      "title": "The utility driven dynamic error propagation network",
      "venue": "Technical Report CUED/F-INFENG/TR.1, Engineering Department, Cambridge University, Cambridge, UK",
      "year": 1987
    },
    {
      "authors": [
        "P. Getreuer"
      ],
      "title": "Color demosaicing with contour stencils",
      "venue": "2011 17th International Conference on Digital Signal Processing (DSP).",
      "year": 2011
    },
    {
      "authors": [
        "S.A. Bigdeli",
        "M. Zwicker",
        "P. Favaro",
        "M. Jin"
      ],
      "title": "Deep mean-shift priors for image restoration",
      "venue": "Advances in Neural Information Processing Systems.",
      "year": 2017
    }
  ],
  "sections": [
    {
      "text": "Keywords: deep learning, denoising, demosaicking, proximal method, residual denoising"
    },
    {
      "heading": "1 Introduction",
      "text": "Modern digital cameras perform a certain number of processing steps in order to create high quality images from raw sensor data. The sequence of the required processing steps is known as the imaging pipeline and the first two and most crucial steps involve image denoising and demosaicking. Both of these problems belong to the category of ill-posed problems while their joint treatment is very challenging since two-thirds of the underlying data are missing and the rest are perturbed by noise. It is clear that reconstruction errors during this early stage of the camera pipeline will eventually lead to unsatisfying final results. Furthermore, due to the modular nature of the camera processing pipelines, demosaicking and denoising were traditionally dealt in the past in a sequential\nar X\niv :1\n80 3.\n05 21\n5v 4\n[ cs\n.C V\nmanner. In detail, demosaicking algorithms reconstruct the image from unreliable spatially-shifted sensor data which introduce non-linear pixel noise, casting denoising an even harder problem. Since, demosaicking is an essential step of the camera pipeline, it has been extensively studied. For a complete survey of recent approaches, we refer to [1]. One of the main drawbacks of several of the currently introduced methods that deal with the demosaicking problem, is that they assume a specific Bayer pattern[1,2,3,4,5,6]. This is a rather strong assumption and limits their applicability since there are many cameras available in the market that employ different Color filter Array (CFA) patterns. Therefore, demosaicking methods that are able to generalize to different CFA patterns are preferred.\nOne simple method that works for any CFA pattern is bilinear interpolation on the neighboring values for a given pixel for each channel. The problem with this approach is the produced zippering artifacts which occur along high frequency signal changes, e.g., edges. Therefore, many approaches involve edge-adaptive interpolation schemes which follow the direction of the gradient of strong edges [1]. However, the real challenges of demosaicking extend in the exploitation of both intra and inter-channel dependencies. The most common assumption is that color differences between color channels are constant, so that the end result leads to smooth images. Other approaches make use of the selfsimilarity and redundancy properties of natural images [4,2,3,6]. Moreover, in some cases a post-processing step is applied to remove certain type of artifacts [7]. Another successful class consists of methods that act upon the frequency domain. Any Bayer CFA can be represented as the combination of a luminance component at baseband and two modulated components [8]. Upon this interpretation, Dubois [9,10,11] created a successful set of filter-banks using a least-squares method that was able to generalize to arbitrary sensor patterns.\nFrom the perspective of learning based approaches, the bibliography is short. A common problem with the design of learning based demosaicking algorithms is the lack of ground-truth images. In many approaches such as those in [12,13] the authors used already processed images as references that are simulated mosaicked again, i.e. they apply a mosaick mask on the already demosaicked images, therefore obtaining non-realistic pairs for tuning trainable methods. In a recent work Khasabi et. al. [14] provided a way to produce a dataset with realistic reference images allowing for the design of machine learning demosaicking algorithms. We use the produced Microsoft Demosaicking dataset (MSR) [14] in order to train, evaluate and compare our system. The contained images have to be demosaicked in the linear RGB (linRGB) color space before being transformed via color transformation and gamma correction into standard RGB (sRGB) space. Furthermore, two common CFA patterns are contained into the dataset, namely Bayer and Fuji X Trans which enables the development and evaluation of methods that are able to deal with different CFA patterns.\nApart from the demosaicking problem, another problem that requires special attention is the elimination of noise arising from the sensor and which distorts the acquired raw data. Firstly, the sensor readings are corrupted with shot noise [15]\nwhich is the result of random variation of the detected photons. Second, electronic inefficiencies during reading and converting electrical charge into a digital count exhibit another type of noise, namely read noise. Under certain circumstances both noises can be approximated by noise following a heteroscedastic Gaussian pdf [15]. Prior work from Kalevo and Rantanen [16], analyzed whether denoising should occur before or after the demosaicking step. It was experimentally confirmed that denoising is preferably done before demosaicking. However, the case of joint denoising and demosaicking was not analyzed. In later work, many researchers [17,18,19] showed that joint denoising and demosaicking yields better results. Motivated by these works, we also pursue a joint approach for denoising and demosaicking of raw sensor data.\nIn a very recent work Gharbi et. al. [20] exploit the advantages in the field of deep learning to create a Convolutional Neural Network (CNN) that is able to jointly denoise and demosaick images. Apart from the design of the aforementioned network, a lot of effort was put by the authors to create a new large demosaicking dataset, namely the MIT Demosaicking Dataset which consists of 2.6 million patches of images. These patches were mined from a large collection of data following specific visual distortion metrics.\nOur main contribution is a novel deep neural network for solving the joint image demosaicking-denoising problem1. The network architecture is inspired by classical image regularization approaches and a powerful optimization strategy that has been successfully used in the past for dealing with general inverse imaging problems. We demonstrate through extensive experimentation that our approach leads to higher-quality reconstruction than other competing methods in both linear RGB (linRGB) and standard RGB (sRGB) color spaces. Moreover, we further show that our derived network not only outperforms the current CNN-based state-of-the art network [20], but it achieves this by using less trainable parameters and by being trained only on a small fraction of the training data."
    },
    {
      "heading": "2 Problem Formulation",
      "text": "To solve the joint demosaicking-denoising problem, one of the most frequently used approaches in the literature relies on the following linear observation model\ny = Mx + n, (1)\nwhich relates the observed sensor raw data, y \u2208 RN , and the underlying image x \u2208 RN that we aim to restore. Both x and y correspond to the vectorized forms of the images assuming that they have been raster scanned using a lexicographical order. Under this notation, M \u2208 RN\u00d7N is the degradation matrix that models the spatial response of the imaging device, and in particular the CFA pattern. According to this, M corresponds to a square diagonal binary matrix\n1 The code for both training and inference will be made available from the authors\u2019 website.\nwhere the zero elements in its diagonal indicate the spatial and channel locations in the image where color information is missing. Apart from the missing color values, the image measurements are also perturbed by noise which hereafter, we will assume that is an i.i.d Gaussian noise n \u223c N (0, \u03c32). Note, that this is a rather simplified assumption about the noise statistics distorting the measurements. However, this model only serves as our starting point based on which we will design our network architecture. In the sequel, our derived network will be trained and evaluated on images that are distorted by noise which follows statistics that better approximate real noisy conditions.\nRecovering x from the measurements y belongs to the broad class of linear inverse problems. For the problem under study, the operator M is clearly singular. This fact combined with the presence of noise perturbing the measurements leads to an ill-posed problem where a unique solution does not exist. One popular way to deal with this, is to adopt a Bayesian approach and seek for the Maximum A Posteriori (MAP) estimator\nx? = arg max x log(p(x|y)) = arg max x log(p(y|x)) + log(p(x)), (2)\nwhere log(p(y|x)) represents the log-likelihood of the observation y and log(p(x)) represents the log-prior of x. Problem (2) can be equivalently re-casted as the minimization problem\nx? = arg min x\n1\n2\u03c32 \u2016y \u2212Mx\u201622 + \u03c6(x) (3)\nwhere the first term corresponds to the negative log-likelihood (assuming i.i.d Gaussian noise of variance \u03c32) and the second term corresponds to the negative log-prior. According to the above, the restoration of the underlying image x, boils down to computing the minimizer of the objective function in Eq. (3), which consists of two terms. This problem formulation has also direct links to variational methods where the first term can be interpreted as the data-fidelity that quantifies the proximity of the solution to the observation and the second term can be seen as the regularizer, whose role is to promotes solutions that satisfy certain favorable image properties.\nIn general, the minimization of the objective function\nQ(x) = 1\n2\u03c32 \u2016y \u2212Mx\u201622 + \u03c6(x) (4)\nis far from a trivial task, especially when the function \u03c6(x) is not of a quadratic form, which implies that the solution cannot simply be obtained by solving a set of linear equations. From the above, it is clear that there are two important challenges that need to be dealt with before we are in position of deriving a satisfactory solution for our problem. The first one is to come up with an algorithm that can efficiently minimize Q (x), while the second one is to select an appropriate form for \u03c6 (x), which will constrain the set of admissible solutions by promoting only those that exhibit the desired properties.\nIn Section 3, we will focus on the first challenge, while in Section 4 we will discuss how it is possible to avoid making any explicit decisions for the regularizer (or equivalently the negative log-prior) by following a machine learning approach. Such an approach will allow us to infer the form of \u03c6 (x), in an indirect way, from training data."
    },
    {
      "heading": "3 Majorization-Minimization Framework",
      "text": "One of the main difficulties in the minimization of the objective function in Eq. (4) is the coupling that exists between the singular degradation operator, M, and the latent image x. To circumvent this difficulty there are several optimization strategies available that we could rely on, with potential candidates being splitting variables techniques such as the Alternating Direction Method of Multipliers [21] and the Split Bregman approach [22]. However, one difficulty that arises by using such methods is that they involve additional parameters that need to be tuned so that a satisfactory convergence speed to the solution is achieved. Unfortunately, there is not a simple and straightforward way to choose these parameters. For this reason, in this work we will instead pursue a majorization-minimization (MM) approach [23,24], which does not pose such a requirement. Under this framework, as we will describe in detail, instead of obtaining the solution by minimizing (4), we compute it iteratively via the successive minimization of surrogate functions. The surrogate functions provide an upper bound of the initial objective function [23] and they are simpler to deal with than the original objective function.\nSpecifically, in the majorization-minimization (MM) framework, an iterative algorithm for solving the minimization problem\nx\u2217 = arg min f Q (x) (5)\ntakes the form\nx(t+1) = arg min x Q\u0303(x;x(t)), (6)\nwhere Q\u0303(x;x(t)) is the majorizer of the function Q(x) at a fixed point x(t), satisfying the two conditions\nQ\u0303(x;x(t)) > Q(x),\u2200x 6= x(t) and Q\u0303(x(t);x(t)) = Q(x(t)). (7)\nHere, the underlying idea is that instead of minimizing the actual objective function Q(x), we fist upper-bound it by a suitable majorizer Q\u0303(x;x(t)), and then minimize this majorizing function to produce the next iterate x(t+1). Given the properties of the majorizer, iteratively minimizing Q\u0303(\u00b7;x(t)) also decreases the objective function Q(\u00b7). In fact, it is not even required that the surrogate function in each iteration is minimized, but it is sufficient to only find a x(t+1) that decreases it.\nTo derive a majorizer for Q (x) we opt for a majorizer of the data-fidelity term (negative log-likelihood). In particular, we consider the following majorizer\nd\u0303(x,x0) = 1\n2\u03c32 \u2016y \u2212Mx\u201622 + d(x,x0), (8)\nwhere d(x,x0) = 1 2\u03c32 (x\u2212 x0) T [\u03b1I\u2212MTM](x\u2212 x0) is a function that measures the distance between x and x0. Since M is a binary diagonal matrix, it is an idempotent matrix, that is MTM = M, and thus d(x,x0) = 1 2\u03c32 (x\u2212 x0)\nT [\u03b1I\u2212 M](x \u2212 x0). According to the conditions in (7), in order d\u0303(x,x0) to be a valid majorizer, we need to ensure that d(x,x0) \u2265 0,\u2200x with equality iff x = x0. This suggests that aI\u2212M must be a positive definite matrix, which only holds when \u03b1 > \u2016M\u20162 = 1, i.e \u03b1 is bigger than the maximum eigenvalue of M. Based on the above, the upper-bounded version of (4) is finally written as\nQ\u0303(x,x0) = 1\n2(\u03c3/ \u221a a)2 \u2016x\u2212 z\u201622 + \u03c6(x) + c, (9)\nwhere c is a constant and z = y + (I\u2212M)x0. Notice that following this approach, we have managed to completely decouple the degradation operator M from x and we now need to deal with a simpler problem. In fact, the resulting surrogate function in Eq. (9) can be interpreted as the objective function of a denoising problem, with z being the noisy measurements that are corrupted by noise whose variance is equal to \u03c32/a. This is a key observation that we will heavily rely on in order to design our deep network architecture. In particular, it is now possible instead of selecting the form of \u03c6 (x) and minimizing the surrogate function, to employ a denoising neural network that will compute the solution of the current iteration. Our idea is similar in nature to other recent image restoration approaches that have employed denoising networks as part of alternative iterative optimization strategies, such as RED [25] and P 3 [26]. This direction for solving the joint denoising-demosaicking problem is very appealing since by using training data we can implicitly learn the function \u03c6 (x) and also minimize the corresponding surrogate function using a feed-forward network. This way we can completely avoid making any explicit decision for the regularizer or relying on an iterative optimization strategy to minimize the function in Eq. (9)."
    },
    {
      "heading": "4 Residual Denoising Network (ResDNet)",
      "text": "Based on the discussion above, the most important part of our approach is the design of a denoising network that will play the role of the solver for the surrogate function in Eq. (9). The architecture of the proposed network is depicted in Fig. 1. This is a residual network similar to DnCNN [27], where the output of the network is subtracted from its input. Therefore, the network itself acts as a noise estimator and its task is to estimate the noise realization that distorts the input. Such network architectures have been shown to lead to better restoration results than alternative approaches [27,28]. One distinctive difference between\nour network and DnCNN, which also makes our network suitable to be used as a part of the MM-approach, is that it accepts two inputs, namely the distorted input and the variance of the noise. This way, as we will demonstrate in the sequel, we are able to learn a single set of parameters for our network and to employ the same network to inputs that are distorted by a wide range of noise levels. While the blind version of DnCNN can also work for different noise levels, as opposed to our network it features an internal mechanism to estimate the noise variance. However, when the noise statistics deviate significantly from the training conditions such a mechanism can fail and thus DnCNN can lead to poor denoising results [28]. In fact, due to this reason in [29], where more general restoration problems than denoising are studied, the authors of DnCNN use a non-blind variant of their network as a part of their proposed restoration approach. Nevertheless, the drawback of this approach is that it requires the training of a deep network for each noise level. This can be rather impractical, especially in cases where one would like to employ such networks on devices with limited storage capacities. In our case, inspired by the recent work in [28] we circumvent this limitation by explicitly providing as input to our network the noise variance, which is then used to assist the network so as to provide an accurate estimate of the noise distorting the input. Note that there are several techniques available in the literature that can provide an estimate of the noise variance, such as those described in [30,31], and thus this requirement does not pose any significant challenges in our approach.\nA ResDNet with depth D, consists of five fundamental blocks. The first block is a convolutional layer with 64 filters whose kernel size is 5\u00d75. The second one is a non-linear block that consists of a parametrized rectified linear unit activation function (PReLU), followed by a convolution with 64 filters of 3\u00d73 kernels. The PReLU function is defined as PReLU(x) = max(0,x) +\u03ba \u2217min(0,x) where \u03ba is a vector whose size is equal to the number of input channels. In our network we use D \u2217 2 distinct non-linear blocks which we connect via a shortcut connection every second block in a similar manner to [32] as shown in Fig. 1. Next, the output of the non-linear stage is processed by a transposed convolution layer which reduces the number of channels from 64 to 3 and has a kernel size of 5\u00d75. Then, it follows a projection layer [28] which accepts as an additional input the\nnoise variance and whose role is to normalize the noise realization estimate so that it will have the correct variance, before this is subtracted from the input of the network. Finally the result is clipped so that the intensities of the output lie in the range [0, 255]. This last layer enforces our prior knowledge about the expected range of valid pixel intensities.\nRegarding implementation details, before each convolution layer the input is padded to make sure that each feature map has the same spatial size as the input image. However, unlike the common approach followed in most of the deep learning systems for computer vision applications, we use reflexive padding than zero padding. Another important difference to other networks used for image restoration tasks [27,29] is that we don\u2019t use batch normalization after convolutions. Instead, we use the parametric convolution representation that has been proposed in [28] and which is motivated by image regularization related arguments. In particular, if v \u2208 RL represents the weights of a filter in a convolutional layer, these are parametrized as\nv = s (u\u2212 u\u0304) \u2016u\u2212 u\u0304\u20162 , (10)\nwhere s is a scalar trainable parameter, u \u2208 RL and u\u0304 denotes the mean value of u. In other words, we are learning zero-mean valued filters whose `2-norm is equal to s.\nFurthermore, the projection layer, which is used just before the subtraction operation with the network input, corresponds to the following `2 orthogonal projection\nPC (y) = \u03b5 y\nmax(\u2016y\u20162 , \u03b5) , (11)\nwhere \u03b5 = e\u03b3\u03b8, \u03b8 = \u03c3 \u221a N \u2212 1, N is the total number of pixels in the image (including the color channels), \u03c3 is the standard deviation of the noise distorting the input, and \u03b3 is a scalar trainable parameter. As we mentioned earlier, the goal of this layer is to normalize the noise realization estimate so that it has the desired variance before it is subtracted from the network input."
    },
    {
      "heading": "5 Demosaicking Network Architecture",
      "text": "The overall architecture of our approach is based upon the MM framework, presented in Section 3, and the proposed denoising network. As discussed, the MM is an iterative algorithm Eq. (6) where the minimization of the majorizer in Eq. (9) can be interpreted as a denoising problem. One way to design the demosaicking network would be to unroll the MM algorithm as K discrete steps and then for each step use a different denoising network to retrieve the solution of Eq. (9). However, this approach can have two distinct drawbacks which will hinder its performance. The first one, is that the usage of a different denoising neural network for each step like in [29], demands a high overall number of parameters, which is equal to K times the parameters of the employed denoiser,\nAlgorithm 1: The proposed demosaicking network described as an iterative process. The ResDnet parameters remain the same in every iteration.\nInput: M : CFA, y : input, K : iterations, w \u2208 RK : extrapolation weights, \u03c3 \u2208 RK : noise vector x0 = 0, x1 = y; for i\u2190 1 to K do\nu = x(i) +wi(x (i) \u2212 x(i\u22121));\nx(i+1) = ResDNet((I\u2212M)u + y,\u03c3i); end\nmaking the demosaicking network impractical for any real applications. To override this drawback, we opt to use our ResDNet denoiser, which can be applied to a wide range of noise levels, for all K steps of our demosaick network, using the same set of parameters. By sharing the parameters of our denoiser across all the K steps, the overall demosaicking approach maintains a low number of required parameters.\nThe second drawback of the MM framework as described in Section 3 is the slow convergence [33] that it can exhibit. Beck and Teboulle [33] introduced an accelerated version of this MM approach which combines the solutions of two consecutive steps with a certain extrapolation weight that is different for every step. In this work, we adopt a similar strategy which we describe in Algorithm 1. Furthermore, in our approach we go one step further and instead of using the values originally suggested in [33] for the weights w \u2208 RK , we treat them as trainable parameters and learn them directly from the data. These weights are initialized with wi = i\u22121 i+2 ,\u22001 \u2264 i \u2264 K.\nThe convergence of our framework can be further sped up by employing a continuation strategy [34] where the main idea is to solve the problem in Eq. (9) with a large value of \u03c3 and then gradually decrease it until the target value is reached. Our approach is able to make use of the continuation strategy due to the design of our ResDNet denoiser, which accepts as an additional argument the noise variance. In detail, we initialize the trainable vector \u03c3 \u2208 RK with values spaced evenly on a log scale from \u03c3max to \u03c3min and later on the vector \u03c3 is further finetuned on the training dataset by back-propagation training.\nIn summary, our overall demosaicking network is described in Algorithm 1 where the set of trainable parameters \u03b8 consists of the parameters of the ResDNet denoiser, the extrapolation weights w and the noise level \u03c3. All of the aforementioned parameters are initialized as described in the current section and Section 4 and are trained on specific demosaick datasets. In order to speed up the learning process, the employed ResDNet denoiser is pre-trained for a denoising task where multiple noise levels are considered.\nFinally, while our demosaick network shares a similar philosophy with methods such as RED [25], P 3 [26] and IRCNN [29], it exhibits some important and distinct differences. In particular, the aforementioned strategies make use of certain optimization schemes to decompose their original problem into subproblems\nthat are solvable by a denoiser. For example, the authors of P 3 [26] decompose the original problem Eq. (1) via ADMM [21] optimization algorithm and solve instead a linear system of equations and a denoising problem, where the authors of RED [25] go one step further and make use of the Lagrangian on par with a denoiser. Both approaches are similar to ours, however their formulation involves a tunable variable \u03bb that weights the participation of the regularizer on the overall optimization procedure. Thus, in order to obtain an accurate reconstruction in reasonable time, the user must manually tune the variable \u03bb which is not a trivial task. On the other hand, our method does not involve any tunable variables by the user. Furthermore, the approaches P 3, RED and IRCNN are based upon static denoisers like Non Local Means [35], BM3D [36] and DCNN [27], meanwhile we opt to use a universal denoiser, like ResDnet, that can be further trained on any available training data. Finally, our approach goes one step further and we use a trainable version of an iterative optimization strategy for the task of the joint denoising-demosaicking in the form of a feed-forward neural network."
    },
    {
      "heading": "6 Network Training",
      "text": ""
    },
    {
      "heading": "6.1 Image Denoising",
      "text": "The denoising network ResDnet that we use as part of our overall network is pre-trained on the Berkeley segmentation dataset (BSDS) [37], which consists of 500 color images. These images were split in two sets, 400 were used to form a train set and the rest 100 formed a validation set. All the images were randomly cropped into patches of size 180\u00d7 180 pixels. The patches were perturbed with noise \u03c3 \u2208 [0, 15] and the network was optimized to minimize the Mean Square Error. We set the network depth D = 5, all weights are initialized as in He et al. [38] and the optimization is carried out using ADAM [39] which is a stochastic gradient descent algorithm which adapts the learning rate per parameter. The training procedure starts with an initial learning rate equal to 10\u22122."
    },
    {
      "heading": "6.2 Joint Denoising and Demosaicking",
      "text": "Using the pre-trained denoiser 6.1, our novel framework is further trained in an end-to-end fashion to minimize the averaged L1 loss over a minibatch of size d,\nL(\u03b8) = 1\nN d\u2211 i=1 \u2016yi \u2212 f(xi)\u20161 , (12)\nwhere yi \u2208 RN and xi \u2208 RN are the rasterized groundtruth and input images, while f (\u00b7) is the output of our network. The minimization of the loss function is carried via the Backpropagation Through Time (BPTT) [40] algorithm since the weights of the network remain the same for all iterations.\nDuring all our experiments, we used a small batch size of d = 4 images, the total steps of the network were fixed to K=10 and we set for the initialization of\nvector \u03c3 the values \u03c3max = 15 and \u03c3min = 1 . The small batch size is mandatory during training because all intermediate results have to be stored for the BPTT, thus the memory consumption increases linearly to iteration steps and batch size. Furthermore, the optimization is carried again via Adam optimizer and the training starts from a learning rate of 10\u22122 which we decrease by a factor of 10 every 30 epochs. Finally, for all trainable parameters we apply `2 weight decay of 10\u22128. The full training procedure takes 3 hours for MSR Demosaicking Dataset and 5 days for a small subset of the MIT Demosaicking Dataset on a modern NVIDIA GTX 1080Ti GPU."
    },
    {
      "heading": "7 Experiments",
      "text": "Initially, we compare our system to other alternative techniques on the demosaickonly scenario. Our network is trained on the MSR Demosaick dataset [14] and it is evaluated on the McMaster [2], Kodak, Moire and VDP dataset [20], where all the results are reported in Table 1. The MSR Demosaick dataset consists of 200 train images which contain both the linearized 16-bit mosaicked input images and the corresponding linRGB groundtruths that we also augment with horizontal and vertical flipping. For all experiments, in order to quantify the quality of the reconstructions we report the Peak signal-to-noise-ratio (PSNR) metric.\nApart from the MSR dataset, we also train our system on a small subset of 40,000 images from MIT dataset due to the small batch size constraint. Clearly our system is capable of achieving equal and in many cases better performance\nthan the current the state-of-the art network [20] which was trained on the full MIT dataset, i.e. 2.6 million images. We believe that training our network on the complete MIT dataset, it will produce even better results for the noisefree scenario. Furthermore, the aforementioned dataset contains only noise-free samples, therefore we don\u2019t report any results in Table 2 and we mark the respective results by using N/A instead. We also note that in [20], the authors in order to use the MIT dataset to train their network for the joint demosaicking denoising scenario, pertubed the data by i.i.d Gaussian noise. As a result, their system\u2019s performance under the presence of more realistic noise was significantly reduced, which can be clearly seen from Table 2. The main reason for this is that their noise assumption does not account for the shot noise of the camera but only for the read noise.\nSimilarly with the noise free case, we train our system on 200 training images from the MSR dataset which are contaminated with simulated sensor noise [15]. The model was optimized in the linRGB space and the performance was evaluated on both linRGB and sRGB space, as proposed in [14]. It is clear that in the noise free scenario, training on million of images corresponds to improved performance, however this doesn\u2019t seem to be the case on the noisy scenario as presented in Table 2. Our approach, even though it is based on deep learning techniques, is capable of generalizing better than the state-of-the art system while being trained on a small dataset of 200 images. In detail, the proposed\nsystem has a total 380,356 trainable parameters which is considerably smaller than the current state-of-the art [20] with 559,776 trainable parameters.\nOur demosaicking network is also capable of handling non-Bayer patterns equally well, as shown in Table 3. In particular, we considered demosaicking using the Fuji X-Trans CFA pattern, which is a 6x6 grid with the green being the dominant sampled color. We trained from scratch our network on the same trainset of MSR Demosaick Dataset but now we applied the Fuji X-Trans mosaick. In comparison to other systems, we manage to surpass state of the art performance on both linRGB and sRGB space even when comparing with systems trained on million of images.\nOn a modern GPU (Nvidia GTX 1080Ti), the whole demosaicking network requires 0.05 sec for a color image of size 220 \u00d7 132 and it scales linearly to images of different sizes. Since our model solely consists of matrix operations, it could also be easily transfered to application specific integrated circuit (ASIC) in order to achieve a substantial execution time speedup and be integrated to cameras."
    },
    {
      "heading": "8 Conclusion",
      "text": "In this work, we presented a novel deep learning system that produces highquality images for the joint denoising and demosaicking problem. Our demosaick network yields superior results both quantitative and qualitative compared to the current state-of-the-art network. Meanwhile, our approach is able to generalize well even when trained on small datasets, while the number of parameters is kept low in comparison to other competing solutions. As an interesting future research direction, we plan to explore the applicability of our method on other image restoration problems like image deblurring, inpainting and superresolution where the degradation operator is unknown or varies from image to image."
    }
  ],
  "title": "Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks",
  "year": 2018
}
