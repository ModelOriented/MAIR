{
  "abstractText": "We propose a methodology for effectively modeling individual heterogeneity using deep learning while still retaining the interpretability and economic discipline of classical models. We pair a transparent, interpretable modeling structure with rich data environments and machine learning methods to estimate heterogeneous parameters based on potentially high dimensional or complex observable characteristics. Our framework is widely-applicable, covering numerous settings of economic interest. We recover, as special cases, well-known examples such as average treatment effects and parametric components of partially linear models. However, we also seamlessly deliver new results for diverse examples such as price elasticities, willingness-to-pay, and surplus measures in choice models, average marginal and partial effects of continuous treatment variables, fractional outcome models, count data, heterogeneous production function components, and more. Deep neural networks are particularly well-suited to structured modeling of heterogeneity in economics: we show how the network architecture can be easily designed to match the global structure of the economic model, giving novel methodology for deep learning as well as, more formally, improved rates of convergence. Our results on deep learning have consequences for other structured modeling environments and applications, such as for additive models or other varying coefficient models. Our inference results are based on an influence function we derive, which we show to be flexible enough to to encompass all settings with a single, unified calculation, removing any requirement for case-by-case derivations. The usefulness of the methodology in economics is shown in two empirical applications: we study the response of 410(k) participation rates to firm matching and the impact of prices on subscription choices for an online service. Extensions of the main ideas to instrumental variables and multinomial choices are shown.",
  "authors": [
    {
      "affiliations": [],
      "name": "Max H. Farrell"
    },
    {
      "affiliations": [],
      "name": "Tengyuan Liang"
    },
    {
      "affiliations": [],
      "name": "Sanjog Misra"
    }
  ],
  "id": "SP:aed5ce2a9980875a16bc9048859aa860ab298a5a",
  "references": [
    {
      "authors": [
        "den",
        "M. Wattenberg",
        "M. Wicke",
        "Y. Yu",
        "X. Zheng"
      ],
      "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems,\u201d Software available from tensorflow.org",
      "year": 2015
    },
    {
      "authors": [
        "S. Athey"
      ],
      "title": "Recursive partitioning for heterogeneous causal effects,",
      "venue": "Imbens",
      "year": 2016
    },
    {
      "authors": [
        "S. Athey",
        "G.W. Imbens",
        "S. Wager"
      ],
      "title": "Approximate residual balancing: De-biased inference of average treatment effects in high dimensions,",
      "venue": "Journal of the Royal Statistical Society, Series B,",
      "year": 2018
    },
    {
      "authors": [
        "S. Athey",
        "J. Tibshirani",
        "S. Wager"
      ],
      "title": "Generalized random forests,",
      "venue": "The Annals of Statistics,",
      "year": 2019
    },
    {
      "authors": [
        "F. Bach"
      ],
      "title": "Breaking the curse of dimensionality with convex neural networks,",
      "venue": "The Journal of Machine Learning Research,",
      "year": 2017
    },
    {
      "authors": [
        "P. Bajari",
        "D. Nekipelov",
        "S.P. Ryan",
        "M. Yang"
      ],
      "title": "Machine Learning Methods for Demand Estimation,",
      "venue": "American Economic Review,",
      "year": 2015
    },
    {
      "authors": [
        "B. Bauer",
        "M. Kohler"
      ],
      "title": "On deep learning as a remedy for the curse of dimensionality in nonparametric regression,",
      "venue": "Annals of Statistics,",
      "year": 2019
    },
    {
      "authors": [
        "A. Belloni",
        "V. Chernozhukov",
        "I. Fern\u00e1ndez-Val",
        "C. Hansen"
      ],
      "title": "Program Evaluation and Causal Inference With High-Dimensional Data,",
      "year": 2017
    },
    {
      "authors": [
        "A. Belloni",
        "V. Chernozhukov",
        "C. Hansen"
      ],
      "title": "Inference on Treatment Effects after Selection Amongst High-Dimensional Controls,",
      "venue": "Review of Economic Studies,",
      "year": 2014
    },
    {
      "authors": [
        "S.T. Berry"
      ],
      "title": "Estimating discrete-choice models of product differentiation,",
      "venue": "The RAND Journal of Economics,",
      "year": 1994
    },
    {
      "authors": [
        "J. Blanchet",
        "Y. Kang",
        "J.L.M. Olea",
        "V.A. Nguyen",
        "X. Zhang"
      ],
      "title": "Machine Learning\u2019s Dropout Training is Distributionally Robust Optimal,",
      "year": 2020
    },
    {
      "authors": [
        "M.D. Cattaneo"
      ],
      "title": "Semiparametric Estimation of Multi-valued Treatment Effects under Ignorability,",
      "venue": "Journal of Econometrics,",
      "year": 2010
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "R.K. Crump",
        "M.H. Farrell",
        "E. Schaumburg"
      ],
      "title": "Characteristic-Sorted Portfolios: Estimation and Inference,",
      "venue": "Review of Economics and Statistics,",
      "year": 2020
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "R.K. Crump",
        "M. Jansson"
      ],
      "title": "Generalized Jackknife Estimators of Weighted Average Derivatives,",
      "venue": "Journal of the American Statistical Association,",
      "year": 2013
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "M.H. Farrell"
      ],
      "title": "Efficient Estimation of the Dose Response Function under Ignorability using Subclassification on the Covariates,",
      "venue": "Advances in Econometrics: Missing Data Methods, ed. by D. Drukker, Emerald Group Publishing Limited,",
      "year": 2011
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "M.H. Farrell",
        "Y. Feng"
      ],
      "title": "2020b): \u201cLarge Sample Properties of Partitioning-based Series Estimators,",
      "venue": "Annals of Statistics,",
      "year": 2020
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "M. Jansson"
      ],
      "title": "Average Density Estimators: Efficiency and Bootstrap Consistency,",
      "year": 2019
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "M. Jansson",
        "X. Ma"
      ],
      "title": "Two-step Estimation and Inference with Possibly Many Included Covariates,",
      "venue": "Review of Economic Studies,",
      "year": 2019
    },
    {
      "authors": [
        "M.D. Cattaneo",
        "M. Jansson",
        "W.K. Newey"
      ],
      "title": "Inference in Linear Regression Models with Many Covariates and Heteroskedasticity,",
      "venue": "Journal of the American Statistical Association,",
      "year": 2018
    },
    {
      "authors": [
        "R. Chen",
        "R. Tsay"
      ],
      "title": "Functional-coefficient autoregressive models,",
      "venue": "Journal of the American Statistical Association,",
      "year": 1993
    },
    {
      "authors": [
        "X. Chen",
        "S. C"
      ],
      "title": "Land of addicts? an empirical investigation of habitbased asset pricing models,",
      "venue": "Ludvigson",
      "year": 2009
    },
    {
      "authors": [
        "V. Chernozhukov",
        "D. Chetverikov",
        "M. Demirer",
        "E. Duflo",
        "C. Hansen",
        "W. Newey",
        "J. Robins"
      ],
      "title": "Double/debiased machine learning for treatment and structural parameters,",
      "venue": "The Econometrics Journal,",
      "year": 2018
    },
    {
      "authors": [
        "V. Chernozhukov",
        "M. Demirer",
        "G. Lewis",
        "V. Syrgkanis"
      ],
      "title": "Semi-Parametric Efficient Policy Learning with Continuous Actions,",
      "venue": "Advances in Neural Information Processing Systems 32,",
      "year": 2019
    },
    {
      "authors": [
        "V. Chernozhukov",
        "W. Newey",
        "R. Singh"
      ],
      "title": "De-Biased Machine Learning of Global and Local Parameters Using Regularized Riesz Representers,",
      "year": 2020
    },
    {
      "authors": [
        "V. Chernozhukov",
        "W.K. Newey",
        "R. Singh"
      ],
      "title": "2020b): \u201cAutomatic Debiased Machine Learning of Causal and Structural Effects,",
      "year": 2020
    },
    {
      "authors": [
        "W.S. Cleveland",
        "E. Grosse",
        "W.M. Shyu"
      ],
      "title": "Local regression models,\u201d in Statistical models in S, ed",
      "venue": "Pacific Grove: Wadsworth and Brooks/Cole,",
      "year": 1991
    },
    {
      "authors": [
        "K. Colangelo",
        "Y.-Y"
      ],
      "title": "Double Debiased Machine Learning Nonparametric Inference with Continuous Treatments,",
      "year": 2020
    },
    {
      "authors": [
        "F.X. Diebold",
        "M. Shin"
      ],
      "title": "Machine learning for regularized survey forecast combination: Partially-egalitarian LASSO and its derivatives,",
      "venue": "International Journal of Forecasting,",
      "year": 2019
    },
    {
      "authors": [
        "Dube",
        "J.-P. H",
        "S. Misra"
      ],
      "title": "Personalized Pricing and Customer Welfare,",
      "venue": "Available at SSRN: https://ssrn.com/abstract=2992257",
      "year": 2019
    },
    {
      "authors": [
        "J. Fan",
        "W. Zhang"
      ],
      "title": "Statistical methods with varying coefficient models,",
      "venue": "Statistics and Its Interface,",
      "year": 2008
    },
    {
      "authors": [
        "M.H. Farrell"
      ],
      "title": "Robust Inference on Average Treatment Effects with Possibly More Covariates than Observations,",
      "venue": "Journal of Econometrics,",
      "year": 2015
    },
    {
      "authors": [
        "M.H. Farrell",
        "T. Liang",
        "S. Misra"
      ],
      "title": "Deep Neural Networks for Estimation and Inference,",
      "year": 2019
    },
    {
      "authors": [
        "M. Gentzkow",
        "B. Kelly"
      ],
      "title": "Taddy (2019a): \u201cText as data,",
      "venue": "Journal of Economic Literature,",
      "year": 2019
    },
    {
      "authors": [
        "M. Gentzkow",
        "J.M. Shapiro"
      ],
      "title": "Taddy (2019b): \u201cMeasuring group differences in high-dimensional choices: method and application to congressional speech,",
      "year": 2019
    },
    {
      "authors": [
        "B.S. Graham",
        "C.C. d. X. Pinto"
      ],
      "title": "Semiparametrically efficient estimation of the average linear regression function,",
      "venue": "Journal of Econometrics,",
      "year": 2018
    },
    {
      "authors": [
        "S. Gu",
        "B. Kelly",
        "D. Xiu"
      ],
      "title": "Empirical Asset Pricing via Machine Learning,",
      "venue": "The Review of Financial Studies,",
      "year": 2020
    },
    {
      "authors": [
        "J. Hahn"
      ],
      "title": "On the Role of the Propensity Score in Efficient Semiparametric Estimation of Average Treatment Effects,",
      "year": 1998
    },
    {
      "authors": [
        "B. Hanin"
      ],
      "title": "Universal function approximation by deep neural nets with bounded width and relu activations,",
      "venue": "arXiv preprint arXiv:1708.02691",
      "year": 2017
    },
    {
      "authors": [
        "T. Hastie",
        "R. Tibshirani"
      ],
      "title": "Varying-Coefficient Models,",
      "venue": "Journal of the Royal Statistical Society, Series B,",
      "year": 1993
    },
    {
      "authors": [
        "K. Hirano",
        "G. W"
      ],
      "title": "The Propensity Score with Continuous Treatments,",
      "venue": "Imbens",
      "year": 2004
    },
    {
      "authors": [
        "G.J. Hitsch",
        "S. Misra"
      ],
      "title": "Heterogeneous Treatment Effects and Optimal Targeting Policy Evaluation,",
      "venue": "SSRN preprint 3111957",
      "year": 2018
    },
    {
      "authors": [
        "J.Z. Huang",
        "H. Shen"
      ],
      "title": "Functional coefficient regression models for non-linear time series: a polynomial spline approach,",
      "venue": "Scandinavian Journal of Statistics,",
      "year": 2004
    },
    {
      "authors": [
        "H. Ichimura",
        "W. K"
      ],
      "title": "The influence function of semiparametric estimators,",
      "venue": "Newey",
      "year": 2015
    },
    {
      "authors": [
        "M. Igami"
      ],
      "title": "Artificial intelligence as structural estimation: Deep Blue, Bonanza, and AlphaGo,",
      "venue": "The Econometrics Journal,",
      "year": 2020
    },
    {
      "authors": [
        "A. Javanmard",
        "A. Montanari"
      ],
      "title": "Debiasing the lasso: Optimal sample size for gaussian designs,",
      "venue": "The Annals of Statistics,",
      "year": 2018
    },
    {
      "authors": [
        "T. Kaji",
        "E. Manresa",
        "G. Pouliot"
      ],
      "title": "An adversarial approach to structural estimation,",
      "venue": "arXiv preprint arXiv:2007.06169",
      "year": 2020
    },
    {
      "authors": [
        "N. Kallus"
      ],
      "title": "Deepmatch: Balancing deep covariate representations for causal inference using adversarial training,",
      "venue": "arXiv preprint arXiv:1802.05664",
      "year": 2018
    },
    {
      "authors": [
        "E.H. Kennedy",
        "Z. Ma",
        "M.D. McHugh",
        "D. S"
      ],
      "title": "Nonparametric methods for doubly robust estimation of continuous treatment effects,",
      "venue": "Small",
      "year": 2017
    },
    {
      "authors": [
        "M.R. Kosorok"
      ],
      "title": "Introduction to Empirical Processes and Semiparametric Inference, Springer-Verlag",
      "year": 2008
    },
    {
      "authors": [
        "D. Kozbur"
      ],
      "title": "Inference in additively separable models with a high-dimensional set of conditioning variables,",
      "venue": "Journal of Business & Economic Statistics,",
      "year": 2020
    },
    {
      "authors": [
        "H. Leeb",
        "B. M"
      ],
      "title": "Model Selection and Inference: Facts and Fiction,",
      "venue": "Po\u0308tscher",
      "year": 2005
    },
    {
      "authors": [
        "Q. Li",
        "C.J. Huang",
        "D. Li",
        "T.-T. Fu"
      ],
      "title": "Semiparametric smooth coefficient models,",
      "venue": "Journal of Business & Economic Statistics,",
      "year": 2002
    },
    {
      "authors": [
        "T. Liang"
      ],
      "title": "On How Well Generative Adversarial Networks Learn Densities: Nonparametric and Parametric Results,",
      "year": 2018
    },
    {
      "authors": [
        "T. Liang"
      ],
      "title": "Mehler\u2019s Formula, Branching Process, and Compositional Kernels of Deep Neural Networks,",
      "venue": "Tran-Bach",
      "year": 2020
    },
    {
      "authors": [
        "E. Mammen",
        "S. van de Geer"
      ],
      "title": "Penalized quasi-likelihod estimation in partially linear models,",
      "venue": "Annals of Statistics,",
      "year": 1997
    },
    {
      "authors": [
        "P. Manchanda",
        "P. Chintagunta"
      ],
      "title": "Responsiveness of Physician Prescription Behavior to Salesforce Effort: An Individual Level Analysis,",
      "venue": "Marketing Letters,",
      "year": 2004
    },
    {
      "authors": [
        "S. Mullainathan",
        "Z. Obermeyer"
      ],
      "title": "A Machine Learning Approach to Low-Value Health Care: Wasted Tests, Missed Heart Attacks and Mis-Predictions,",
      "venue": "NBER Working Paper 26168",
      "year": 2019
    },
    {
      "authors": [
        "S. Mullainathan",
        "J. Spiess"
      ],
      "title": "Machine Learning: An Applied Econometric Approach,",
      "venue": "Journal of Economic Perspectives,",
      "year": 2017
    },
    {
      "authors": [
        "A. Nevo"
      ],
      "title": "Measuring Market Power in the Ready-to-Eat Cereal Industry,",
      "year": 2001
    },
    {
      "authors": [
        "W.K. Newey"
      ],
      "title": "Semiparametric efficiency bounds,",
      "venue": "Journal of Applied Econometrics,",
      "year": 1990
    },
    {
      "authors": [
        "W.K. 47 Newey",
        "J.M. Robins"
      ],
      "title": "Cross-fitting and fast remainder rates for semiparametric estimation,",
      "venue": "arXiv preprint arXiv:1801.09138",
      "year": 2018
    },
    {
      "authors": [
        "A. O\u2019Hagan"
      ],
      "title": "Curve fitting and optimal design for prediction,",
      "venue": "Journal of the Royal Statistical Society: Series B,",
      "year": 1978
    },
    {
      "authors": [
        "R. Okui",
        "D.S. Small",
        "Z. Tan",
        "J.M. Robins"
      ],
      "title": "Doubly Robust Instrumental Variable Regression,",
      "venue": "Statistica Sinica,",
      "year": 2012
    },
    {
      "authors": [
        "L.E. Papke"
      ],
      "title": "Participation in and Contributions to 401(k) Pension Plans: Evidence from Plan Data,",
      "venue": "The Journal of Human Resources,",
      "year": 1995
    },
    {
      "authors": [
        "L.E. Papke",
        "J.M. Wooldridge"
      ],
      "title": "Econometric methods for fractional response variables with an application to 401 (k) plan participation rates,",
      "venue": "Journal of Applied Econometrics,",
      "year": 1996
    },
    {
      "authors": [
        "J.L. Powell",
        "J.H. Stock",
        "T.M. Stoker"
      ],
      "title": "Semiparametric Estimation of Index Coefficients,",
      "year": 1989
    },
    {
      "authors": [
        "J. Schmidt-Hieber"
      ],
      "title": "Nonparametric regression using deep neural networks with ReLU activation function,",
      "venue": "Annals of Statistics,",
      "year": 2019
    },
    {
      "authors": [
        "C.J. Stone",
        "M.H. Hansen",
        "C. Kooperberg",
        "Y.K. Truong"
      ],
      "title": "Polynomial splines and their tensor products in extended linear modeling: 1994 Wald memorial lecture,",
      "venue": "The Annals of Statistics,",
      "year": 1997
    },
    {
      "authors": [
        "Y. Wang"
      ],
      "title": "Ro\u010dkov\u00e1 (2020): \u201cUncertainty Quantification for Sparse Deep Learning,",
      "venue": "Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics",
      "year": 2020
    },
    {
      "authors": [
        "Y. Wei",
        "Z. Jiang"
      ],
      "title": "Estimating Parameters of Structural Models Using Neural Networks,",
      "year": 2019
    },
    {
      "authors": [
        "J.M. Wooldridge"
      ],
      "title": "Estimating average partial effects under conditional moment independence assumptions,\u201d cemmap working paper CWP03/04",
      "year": 2004
    },
    {
      "authors": [
        "D. Yarotsky"
      ],
      "title": "Error bounds for approximations with deep ReLU networks,",
      "venue": "Neural Networks,",
      "year": 2017
    },
    {
      "authors": [
        "A. Zeileis",
        "T. Hothorn",
        "K. Hornik"
      ],
      "title": "Model-based recursive partitioning,",
      "venue": "Journal of Computational and Graphical Statistics,",
      "year": 2008
    },
    {
      "authors": [
        "G nonlinear"
      ],
      "title": "\u03b2\u0303 be estimated from an independent sample of data. By the previous results, these converge at rate rn. Let tj denote the j th element of T , taken to be one if j = 0. One the second sample, \u03b1\u0303 and \u03b2\u0303 are known, nonrandom functions, and therefore estimation of \u03bb\u0303j,k := E[\u0120(\u03b1\u0303(X) + \u03b2\u0303(X)\u2032T )tjtk",
      "year": 2019
    }
  ],
  "sections": [
    {
      "text": "Keywords: Heterogeneity, Deep Learning, Doubly Robust, Semiparametric Inference, Varying Coefficient Model, Structural models.\n\u2217The authors would like to thank Matias Cattaneo, Chris Hansen, Whitney Newey, the participants and discussants at the Chamberlain seminar and 2020 QME conference, as well as those at the marketing seminar at NYU, UCBerkeley, and Columbia for useful discussions, comments, and suggestions.\nar X\niv :2\n01 0.\n14 69\n4v 1\n[ ec\non .E\nM ]\n2 8\nO ct\n2 02"
    },
    {
      "heading": "1 Introduction",
      "text": "One of the primary goals in applying machine learning methods in economics and other social sciences is capturing rich individual heterogeneity. The increasing availability of large, complex data sets and the development of novel machine learning methods mean that economic phenomena can be studied at levels of detail previously not possible. This has spurred a push to move beyond standard parametric econometric models, which can only crudely capture heterogeneity, if at all, and to deploy machine learning methods that are increasingly flexible and able to handle highdimensional, complex inputs.\nA central issue with using machine learning in the context of the social sciences is that the added flexibility often comes at the cost of interpretability. In contrast to typical machine learning models, parametric models encode structure that is grounded in economic principles and economic reasoning. These forces are brought to bear when doing the analysis. Mechanically, this structure is required when the data is small because the data cannot \u201cspeak for itself\u201d, but the structure also delivers interpretable results based on parameters with understandable and communicable meaning. With newly-available large, rich data it is now tempting to let the data speak for itself, usually via the application of some black box machine learning tool. The danger in doing this, and one critical reason classical models remain in favor, is that the output of these black boxes, i.e. the \u201cspeech\u201d, is often not economically meaningful. From this point of view, the rigidity of classical models with structural assumptions acts as a disciplining force, regularizing the data toward economic principles. In an ideal world a researcher would be able to exploit the flexibility of machine based approaches within the structure dictated by economic models. The goal of this paper is to provide a methodological framework for doing just this: effectively capturing individual heterogeneity using machine learning tools while still retaining the interpretability and economic discipline of classical models. We seek to move away from using machine learning tools as black box prediction methods, where they have been so successful and attained widespread popularity, and instead harness the power in the context of a transparent structured model of individual heterogeneity.\nOur methodological framework has three key components. The first is the articulation of the relationship of the outcome of interest to the important variables of study through a model where the coefficients are free to depend on the full set of individual information. This allows us to capture\nobserved heterogeneity in a flexible way. This modeling approach is not fully nonparametric, and intentionally so. The relationship between outcomes and the variables of interest are based on some predefined structure. This affords us the ability to retain the same interpretability as that of a structural parametric model. Enforcing the structure disciplines the data toward economic principles, and moreover, one can impose shape or other context specific constraints if desired.\nThe second element is the estimation of the individual heterogeneity. Here we advocate for deep learning in the form of multi-layer, feed-forward neural nets and we develop a novel, yet simple, architecture to learn the heterogeneity directly. Deep neural networks (DNNs) have a unique combination of strengths which makes them ideally suited to estimating individual heterogeneity within the context of an economic model. DNNs have had incredible empirical success, matching or setting the state of the art in a wide range of tasks. This has largely been in prediction problems, but we show that these gains are obtainable in economic contexts as well. We show how to design the network architecture so that the global structure of the economic model is baked in directly and the estimation targets are meaningful quantities, not predictions. This exploits the representation-learning format of DNNs, and we refer to the property as structural compatibility. This is not as transparent or tractable to do with local (Nadaraya-Watson kernel or matching type) methods. While classical series estimators are are also compatible with structure, through restrictions on the bases, they are not equipped to handle the complex heterogeneity that is the hallmark of modern applications. Our novel architecture delivers both practical/empirical gains and theoretical improvements. DNNs also handle discrete data seamlessly in practice (as well as in theory), in contrast to classical methods. Put together, DNNs with the architecture we demonstrate, are excellent for learning individual heterogeneity. We further stress that, perhaps contrary to common beliefs in the economics community, huge sample sizes are not required: our first application shows excellent results with only a few thousand individuals. We prove that deep neural networks converge at rates governed by the dimension of the heterogeneity, independent of the dimension of the variables of interest. These results may be of independent interest in additive models, varying coefficient models, and other such contexts.\nFinally, we address the difficulty of obtaining valid inference after machine learning. While the implementation of ML has exploded, thanks to data availability and access to affordable and scalable computing, valid statistical inference has lagged behind. We leverage recent developments\nto give inference results for any regular parameter that is a functional of the individual heterogeneity learned in the first stage. Recent work has provided tools for validating asymptotic inference, but assume that an influence function is available. We provide a single, unified influence function calculation that is flexible enough to cover any parameter within our framework. By design, our framework covers a broad set of interesting applications and models while also delivering methods that can be taken directly to the data. As special cases we recover the workhorse examples of average treatment effects and components in partially linear models. However, we also seamlessly deliver new results for diverse examples such as: price elasticities, willingness-to-pay, and surplus measures in choice models, average partial effects of continuous treatments, count models, heterogeneous production function components, and more. Importantly, all of these are covered without requiring additional derivations and without the need to customize the inference engine to the context.\nOur work contributes directly to several recent strands of literature. First is the recent application of machine learning in applied economics. A complete list is too numerous, but examples span fields such as healthcare (Mullainathan and Obermeyer, 2019), macroeconomic forecasting (Diebold and Shin, 2019), industrial organization and marketing (Bajari et al., 2015; Hitsch and Misra, 2018; Dube and Misra, 2019), empirical finance and asset pricing (Gu et al., 2020), and applied microeconomics more broadly (Mullainathan and Spiess, 2017; Gentzkow et al., 2019a,b). From a theoretical point of view, our results for deep learning build on the recent work by Farrell et al. (2019), who also provide a broader overview of the relevant literature. We rely on results in the recent literature on inference after machine learning, chiefly Chernozhukov et al. (2018) (see other references therein), and our influence function approach builds on the seminal works in the area, Newey (1994) in particular, to yield new and useful results.\nThe combination of the specification we adopt, the availability of computing infrastructure, and the theory presented above offer a perfect package for applied researchers. In Section 2 we introduce our methodological framework for capturing heterogeneity: we give details on the models and parameters and discuss their interpretation as well as the estimation of heterogeneity using deep learning. Section 3 gives asymptotic results, both for deep learning and subsequent inference based on our influence function. Two applications are given in Sections 4 and 5, studying 401(k) participation rates (a fractional outcome) and individual choice models. Other interesting economic settings where our framework applies are given in Section 6. Incorporating instrumental variables\nis briefly discussed in Section 7.1 and finally Section 8 concludes. Proofs are given in an appendix."
    },
    {
      "heading": "2 A Framework for Heterogeneity",
      "text": "In this section we lay out and discuss our framework for heterogeneity. We first state the model, then in subsequent subsections we discuss its interpretation and the use of deep learning to recover its elements. Theoretical results, and formal regularity conditions for identification, estimation, and inference, are deferred until Section 3. The starting point, encapsulating our first important idea, is the model relating the outcome Y to the variables of central interest, or treatments, T , and the characteristics X which capture the heterogeneity.1 For a known function G(u), u \u2208 R, and unknown functions \u03b1(\u00b7) and \u03b2(\u00b7), we assume that\nE[Y |X = x,T = t] = G ( \u03b1(x) + \u03b2(x)\u2032t ) . (2.1)\nThis model is natural when the dimension of T , denoted K, is fixed, as these are the important variables under study, and the functions \u03b1(x) and \u03b2(x) are nonparametric or the dimension of X, denoted d, is large: we aim to study specific relationships but allow for rich heterogeneity. In many applications there is only one treatment. The (link) function G(\u00b7) is chosen by the researcher to fit the application, such as a logistic function for a binary outcome. We advocate for deep learning to estimate the functions \u03b1(\u00b7) and \u03b2(\u00b7). Section 2.1 shows why deep learning is well suited for structured modeling, among modern ML methods, and thus is an important part of our proposed methodology. We emphasize that \u03b1(x) and \u03b2(x) are functions of observed covariates; this is not a random coefficient model. Note that \u03b2(\u00b7) can be vector valued reflecting the possibility of multiple treatment variables. Further, our framework does not require the treatments to be binary or even discrete and also, in some applications the outcome Y or treatments T will be transformations of the raw data, possibly using additional variables, without causing any issue. That is, without any theoretical overhead we can consider a model where, for an unknown vector valued function \u03be(x),\n1Notation. Vectors and matrixes will be written in boldface. Capital letters are used for random variables; lower case for realizations. The expectation operator, with respect to the true data generating process, is denoted E[\u00b7]. The L2 norm for a function g(x) is \u2016g\u2016L2(X) = E[g(X)] 1/2.\nknown functions gY and gT , and other observed variables P , we have\nE [ gY (Y,P )\u2212G ( \u03be(X)\u2032gT (T ,P ) )\u2223\u2223X = x,T = t,P = p] = 0. (2.2) For readability and its intuitive appeal, we will work with the model (2.1) rather than carry around the notation of (2.2), however we make use of such transformations in some of the examples in Section 6 below.\nThe heterogeneous coefficient functions \u03b1(\u00b7) and \u03b2(\u00b7) are the key inputs into the final parameter of inferential interest. For a known, real-valued function H, chosen by the researcher, we consider inference on\n\u03b80 = E [ H(X, \u03b1(X),\u03b2(X); t\u2217) ] , (2.3)\nwhere t\u2217 is some fixed value of interest.\nThe combination of the model (2.1) (or (2.2) more generally) and parameter (2.3), though simple to state, is intuitively appealing, economically interpretable, and contains a large number of economically interesting parameters via appropriate choices of the functions G and H and definitions of the variables Y and T . A simple, familiar example is H(X, \u03b1, \u03b2; t\u2217) = \u03b2, so that \u03b80 is the average partial effect when G is linear. Further, if T \u2208 {0, 1}, this is the average treatment effect. To appreciate the breadth of applicability, consider the empirical illustrations. In Section 4 we revisit the fractional outcome model of Papke and Wooldridge (1996), where Y \u2208 [0, 1] and G(u) is the logistic CDF, and we use \u03b2(x) to capture firm heterogeneity in the response to 401(k) matching rates. An interesting economic question is whether the returns are diminishing, that is if the second derivative of the regression function is negative. Thanks to the structure imposed by the model (2.1), we can write this as H(x, \u03b1, \u03b2; t\u2217) = \u03b2(x)2G\u2217(1\u2212G\u2217)(1\u22122G\u2217), where G\u2217 = G(\u03b1(x)+\u03b2(x)t\u2217). We then study a binary choice problem in Section 5, where the variable of interest is a price. There, setting H(x, \u03b1, \u03b2; t\u2217) = \u2212\u03b2(x)\u22121 log(1+exp(\u03b1(x)+\u03b2(x) \u00b7 t\u2217)) yields a measure of consumer welfare at a price t\u2217. Section 6 gives many other examples and Section 7 shows how to extend the main ideas to other settings.\nHidden layers Inputs Parameter layer Model layer"
    },
    {
      "heading": "2.1 Deep Thoughts",
      "text": "To allow for flexible, potentially complex heterogeneity or high dimensional observables, machine learning is an appealing choice. Here we argue that deep neural networks (DNNs) have a unique combination of strengths which makes them an excellent choice, among machine learning methods, for recovering individual heterogeneity. The most obvious is the incredible success DNNs have had in a wide variety of machine learning prediction problems, where they have been found to handle many different data types and tasks extremely well. In many applications the dimension of X is large enough, and the heterogeneity complex enough, that classical methods will not work, but deep learning still yields excellent predictions. The last several years have seen the development of stable, scalable computational tools, such as TensorFlow (Abadi et al., 2015), leading to the reliable numerical performance of deep nets.\nBut part of our goal is to take DNNs beyond prediction, to learn the (structural) coefficient functions \u03b1(x) and \u03b2(x). To do so, we design a new architecture, which combines the standard fully-connected feedforward networks (multi-layer perceptrons, MLPs) with the economic structure of model (2.1). This architecture is shown diagrammatically in Figure 1. We use MLPs to learn the functions \u03b1(x) and \u03b2(x) in a penultimate \u201cparameter layer\u201d. These are then combined according to the structure in the final, \u201cmodel layer\u201d of the network, which learns G(\u03b1(x) + \u03b2(x)\u2032t). The learning of \u03b1(x) and \u03b2(x) is jointly performed during optimization of the loss (discussed below). This is crucial because it forces the machine learning to be faithful to the economic structure.\nUsing this architecture, our DNN-based estimators \u03b1\u0302(x) and \u03b2\u0302(x) jointly minimize a loss function that matches model (2.1). We assume that the true \u03b1 and \u03b2 minimize a per-observation loss function ` which depends on G(u) through a known real-valued transformation g(\u00b7) and the vector W = (Y,X \u2032,T \u2032)\u2032, given as\n(\u03b1,\u03b2\u2032)\u2032 = arg min a,b\nE [ ` ( g(G(a(X) + b(X)\u2032T )),W )] , (2.4)\nwhere optimization is over an assumed function class. Our estimates are defined as solving the empirical analog of the loss:\n(\u03b1\u0302, \u03b2\u0302\u2032)\u2032 = arg min a,b\u2208FDNN\n1 n n\u2211 i=1 ` ( g(G(a(xi) + b(xi) \u2032ti)),wi ) , (2.5)\nwhere optimization is now over the relevant class of DNNs, which in particular is restricted to use the architecture we design. The transformation g is typically chosen, implicitly or explicitly, along with the link function G(u). Often g is the identity or the inverse. For example, in the logistic case, one has g(G) = log(G/(1\u2212G)) and the corresponding loss is `(g,w) = \u2212yg+log(1+eg). Regularity conditions sufficient for identification, estimation, and inference are spelled out in Section 3. These are mild enough to allow for all interesting examples of which we are aware, including more general likelihood-type problems, and including the examples in Sections 6 and 7.\nBy exploiting our structured architecture, we prove that only the dimension of X, the heterogeneity, affects the rates of convergence of our DNN estimators \u03b1\u0302(x) and \u03b2\u0302(x). Further, it will only be the number of continuously distributed variables, which affects the rate. An important practical advantage of DNNs is that discrete covariates are handled automatically. We do not need to restrict attention, in practice or in theory, to continuous X. In nonparametric theory there is often no penalty in the rate of convergence for discrete variables (under standard assumptions), but realizing these gains in practice can be difficult, as most nonparametric estimators are designed with continuous variables in mind (such as those built upon basis expansions or kernel approximations). DNNs require no customization: the inputs in Figure 1 can be any mix of continuous and discrete data. We show that if there are dC \u2264 d := dim(X) continuously distributed covariates,\nthen\n\u2016\u03b1\u0302\u2212 \u03b1\u2016L2(X) = O ( n \u2212 p p+dC log8(n) ) and \u2016\u03b2\u0302 \u2212 \u03b2\u2016L2(X) = O ( n \u2212 p p+dC log8(n) ) .\nSee Lemma 1 for a formal statement. This result may be of independent interest, given the popularity of additive models, varying coefficient models, and other similar structures. Coupling these rates with the Neyman orthogonal score we derive below, \u03c8(w, \u03b1,\u03b2,\u039b)\u2212 \u03b80, we prove (Theorem 2 below) that a valid 95% confidence interval for \u03b80 is obtained with\n\u03b8\u0302 \u2212 1.96 \u221a \u03a8\u0302/n , \u03b8\u0302 + 1.96 \u221a \u03a8\u0302/n,\nwhere the centering \u03b8\u0302 is given in (3.6) and the standard error estimators are defined in (3.7).\nOur deep learning theory builds on Farrell et al. (2019), who studied generic regression problems using MLPs, i.e. the straightforward prediction case. This result formalizes one major theoretical benefit of using our structured architecture: naively applying prediction focused machine learning, essentially estimating G(u\u0302(x, t)) for a completely unstructured, nonparametric u\u0302, would give a much slower rate, one dependent on dim(X) + dim(T ). Second, it is not clear that one can recover separate \u03b1\u0302(xi) and \u03b2\u0302(xi) from G(u\u0302(x, t)). In much the same way, it is important to clarify that our aim is explicitly not on adaptive estimation. The model structure of G(\u03b1(x) +\u03b2(x)\u2032t) is enforced, not recovered. Certain specialized types of DNNs may in fact adapt to such structures (Bach, 2017; Bauer and Kohler, 2019; Schmidt-Hieber, 2019), but this is not useful for our purposes.\nWe are able to easily and transparently make our estimator, through the architecture of Figure 1, mirror the global structure of the model (2.1) (or any other) because DNNs learn a basis-function style representation, and in this way are akin to a global smoother.2 More apt for the present purpose, we dub this property \u201cstructural compatibility\u201d. This makes the machine learning faithful to the economics, rather than allowing the reverse. Classical series methods are also structurally compatible, in this sense, via using a restricted set of basis functions, but these methods are ill-\n2The distinction between a global and local smoother is not universal or precise. Here, we use \u201cglobal\u201d to mean that the estimator imposes a global smoothing across the data, typified by a series estimator, whereas a \u201clocal\u201d estimator imposes only local smoothing structure, typified by Nadaraya-Watson kernel regression. However, this need not match the notion of using global versus local data in estimation: for example, although series estimators are generally regarded as global, those such as splines or partitioning, through their specific basis functions, use only local data when doing estimation and inference (Cattaneo and Farrell, 2013; Cattaneo et al., 2020b).\nequipted to handle complex, high-dimensional tasks. And while enforcing the structure of the model on the estimator is particularly transparent and tractable with DNNs, it is possible with \u201clocal\u201d methods as well, such as kernel-based regression (Fan and Zhang, 2008) or random forests (Athey et al., 2019). In sum, DNNs are not the only possible method to apply, nor do we claim any formal optimality, but from a practical point of view, they are ideal.\nExperience has shown, and our theory bears out, that imposing the structure of the model (2.1) improves estimation quality. That is, it is important to simultaneously and jointly estimate \u03b1(x) and \u03b2(x) and measure the (appropriate) loss in terms of yi and G(\u03b1\u0302(xi) + \u03b2\u0302(xi) \u2032ti). This can be contrasted with learning a generic conditional expectation function, E[Y | X,T ], and then only after estimation, using the structure to separate \u03b1(x) and \u03b2(x). Instead, the network learns the functions \u03b1(x) and \u03b2(x) jointly and simultaneously. This notion has been exploited, implicitly or explicitly, in work on average effects of a binary treatment, Example 1. Here, \u03b1(x) and \u03b2(x) relate to the conditional means of the two potential outcomes, under treatment and control, and these may be expected to share similar features. This has been used for trees by Zeileis et al. (2008) and Athey and Imbens (2016), where the treatment and control groups share a partition, and by Farrell et al. (2019) for DNNs, most similar to the present case. In this case, model (2.1) holds without loss of generality, and thus the theoretical gains are not evident.\nFinally, it is worth mentioning that other recent work has considered the combination of deep learning and structural modeling. Typically, the goal is estimation of a parametric structural model and deep learning methods are applied to learn the mapping of data to parameters (Wei and Jiang, 2019; Kaji et al., 2020; Igami, 2020). Our focus, using deep learning to estimate individual-level heterogeneity, is quite different, and further, we give theoretical results on deep neural network estimation and subsequent inference which are not available in prior work."
    },
    {
      "heading": "2.2 Motivation and Discussion",
      "text": "The setup in (2.1) strikes a neat balance between two opposing demands: being simultaneously quite flexible in modeling the heterogeneity construct versus retaining economic interpretability and respect for economic-theoretical restrictions. The key idea is to blend the economic structure of a classical parametric model while still being fully flexible where it is important, in the individual heterogeneity. To be clear, our specification in model (2.1) is not the only way to do so, and our\ncore idea can be applied in other contexts or structures equally well.\nFurther, it is only because of the structure imposed by the model (2.1) that it is possible to cover such a broad range of interesting parameters through the form (2.3), via different choices of the function H. Many economic quantities of interest can be cleanly and directly expressed as functions of the \u201cintercept\u201d and \u201cslope\u201d, whereas unrestricted nonparametric modeling of the conditional expectations would not allow for this.\nTo better understand the interpretability and flexibility of the model (2.1) it is useful to consider several extremes. To fix ideas we use a scalar treatment variable and consider the binary choice setting of Section 5. Here Y is binary, T = T is a scalar price, and X are individual-level characteristics. First, consider a classical parametric model, which is easy to interpret but completely rigid. The classical (and indeed structural) approach would be a logistic regression of choice on price, that is,\nE[Y | T = t] = G (\u03b1+ \u03b2 \u00b7 t) , (2.6)\nwhere G(u) = (1 + exp(\u2212u))\u22121. Here there is no possibility for capturing heterogeneity. However, the advantages of the structure are clear from an economic point of view. First, the parameters have a clear and direct interpretation. The price effect is captured by the slope \u03b2, for example. Second, economically meaningful, and policy-relevant, summary parameters are easily computed, such as the measure of consumer welfare given by\n\u2212 1 \u03b2\nlog ( 1 + exp(\u03b1+ \u03b2 \u00b7 t\u2217) ) .\nSections 3.1 shows how our theoretical results apply to this case and Section 5 takes this to data. We can just as easily compute a willingness-to-pay measure, \u03b2/\u03b1, or an elasticity, (1\u2212G (\u03b1+ \u03b2 \u00b7 t\u2217))\u03b2\u00b7t\u2217. Such measures are readily constructed once estimates of the parameters in the model are obtained. Third, we can bring economics to bear in the estimation. Economic theory tells us that the price coefficient, \u03b2, will be negative in the standard case. The structure of the model will mean that this is true empirically as well: loosely speaking, the model regularizes the data toward economically-valid estimates. Alternatively, one can easily and transparently impose negativity as a shape constraint in estimation.\nAt the other extreme of heterogeneity would be individual-specific effects. This may be, at heart, the intuition that many researchers have when discussing heterogeneity: the \u201ctreatment effect\u201d is possibly unique to each individual. This can be captured by having individual-specific coefficients, namely, assuming that for parameters \u03b1i, \u03b2i,\nE[Yi | T = t] = G(\u03b1i + \u03b2it).\nThis is still cleanly interpretable: \u03b2i is the price effect for person i and \u2212\u03b2\u22121i log(1+exp(\u03b1i+\u03b2i \u00b7t\u2217)) is person i\u2019s welfare at a price t\u2217. In this interpretation, \u03b1i and \u03b2i are fixed parameters, though individual specific. That is, the object of interest would be \u03b2i itself, capturing the heterogeneity, rather than assuming a random coefficients model, with \u03b2i = \u03b2(ui) for an observed realization ui \u223c U , where the goal would be to recover the distribution. Although intuitive, this individualspecific model cannot be taken to the data without further assumptions, long panels, or other additional information. Even in these cases, the individual specific coefficients may not conform nicely to economic theory. Finally, the conclusions from this model can be difficult to use for future decision making, as person i may not be seen again by the policy maker.\nOur approaches balances these two extremes, retaining advantages of both, by assuming that \u03b2(xi) approximates \u03b2i, but letting this approximation be fully flexible. This maintains the interpretation: \u03b2(xi) is the price effect and \u2212\u03b2(xi)\u22121 log(1 + exp(\u03b1(xi) +\u03b2(xi) \u00b7 t\u2217)) the surplus for person of \u201ctype\u201d xi, and we can conduct semiparametric inference on the average of these heterogeneous quantities. To the extent that \u03b2i and \u03b2(xi) differ, our approach captures the portion that can be used for future policy, i.e., for future individuals of \u201ctype\u201d xi.\nWe will maintain this approximation idea implicitly throughout, but it is possible to formalize. First, one can view the true \u03b2(xi) as the best approximation to \u03b2i that lies in an assumed function class, and then conduct all analyses on, and make conclusions about, the best approximation. This matches the intuitive understanding that capturing \u03b2i is not possible, so we \u201csettle\u201d for the best approximation we can get in the data, and further, the approximation that captures the portion of \u03b2i that is useful for future individuals similar to person i. Mathematically, on can place assumptions on the difference \u2223\u2223\u03b2i \u2212 \u03b2(xi)\u2223\u2223, (2.7)\nand similarly for \u03b1i. This will amount to conditions on the covariates xi and the assumed function class that contains \u03b2(x). We can use this idea to frame how different models approach heterogeneity. For example, the recent literature on high-dimensional sparse models often assumes, implicitly or explicitly, that |\u03b2i \u2212 \u03b2(xi)| \u2192 0 as dim(xi) \u2192 \u221e, but restricts \u03b2(x) to be a linear function with sparse parameters (see, e.g., the discussion in Farrell, 2015, \u00a74.2). The classical parametric model, in these terms, takes the extreme position that |\u03b2i \u2212 \u03b2| = 0: no covariates matter and the \u2018function\u201d \u03b2(x) is a constant. Perhaps more productively, we can compare to the prevalent practice of including covariates using linear interaction terms, by far the most common way to impose a parametric model for \u03b2(xi):\nE[Y |X = x, T = t] = G ( \u03b1+ \u03b2 \u00b7t+ \u03b2\u20321x\u00b7t+ \u03b3 \u2032x ) .\nThe parameters \u03b21 are then, if found to be statistically and economically different from zero, taken as evidence of heterogeneity. Such a model is often intuitive and shares some of the advantages of the classical approach: the parameters are cleanly interpretable and allow for simple, approximate ceterus perebus approximation. However, this method has several drawbacks, the most obvious of which is that it is inflexible when it comes to the heterogeneity, allowing neither nonlinear or unknown functional forms nor large dimensional data. In other words, assuming that |\u03b2i\u2212\u03b2\u20321xi| = 0 may not be realistic.\nIn general we will not know either the functional form of \u03b2(x) nor which covariates are important. This is one strong motivation for applying modern machine learning methods. In particular, deep learning is attractive given its success at handling a large number of variables in a flexible fashion. To put our DNN estimator \u03b2\u0302(xi) = \u03b2\u0302DNN(xi) into the context of this motivation, we can write \u2223\u2223\u2223\u03b2i \u2212 \u03b2\u0302DNN(xi)\u2223\u2223\u2223 \u2264 \u2223\u2223\u2223\u03b2i \u2212 \u03b2(xi)\u2223\u2223\u2223+ \u2223\u2223\u2223\u03b2(xi)\u2212 \u03b2\u0304DNN(xi)\u2223\u2223\u2223+ \u2223\u2223\u2223\u03b2\u0304DNN(xi)\u2212 \u03b2\u0302DNN(xi)\u2223\u2223\u2223. (2.8) The first term is exactly the approximation discussed above: this is rendered small by virtue of the complexity of the function \u03b2(x) and the large dimensionality of X. The second is a bias term: we rely on the fact DNNs are known to provide universal approximations (Yarotsky, 2017; Hanin,\n2017) and thus a sufficiently rich parameterized DNN \u03b2\u0304DNN(xi) that can recover the function \u03b2(x). Finally, the third term is a stochastic error, a variance term, which can also be controlled. A traditional nonparametric statistical analysis addresses the latter two terms. On this front, we build on the recent progress of Farrell et al. (2019) on the statistical properties of deep learning.\nRemark 1. Models of the form (2.1) have been studied in the statistics literature in the past, originating several times under different names. O\u2019Hagan (1978) is perhaps the earliest. Perhaps most commonly known, at least in cross-sectional applications, as the \u201cvarying coefficient\u201d model (Cleveland et al., 1991; Hastie and Tibshirani, 1993), it is also known as the \u201cfunctional coefficient\u201d model in the time series literature (Chen and Tsay, 1993) and the \u201csmooth coefficient\u201d model (Li et al., 2002), and falls into the class of \u201cextended linear models\u201d Stone et al. (1997). See Fan and Zhang (2008) for a review. Our results for deep learning (Lemma 1 below) show that DNNs are useful in these contexts more generally.\nIn all cases, the terminology reemphasizes that we are not using random coefficients. In economics, random coefficients are often studied and applied, but varying coefficient models are not frequently used (apart from linear interactions). Much of the literature restricts to the identity link, G(u) = u, and semiparametric inference, if considered at all, is restricted to the parametric component in a partially linear model, see Example 2 in Section 6. \u2663"
    },
    {
      "heading": "3 Asymptotic Theory",
      "text": "With the framework complete, we now turn to asymptotic theoretical guarantees for estimation and inference. Inference will be based on an influence function for the parameter \u03b80 of (2.3), under the restrictions of the model (2.1). We first derive this result. We then give deep learning results for estimating \u03b1(x) and \u03b2(x) and the additional nuisance parameter in the influence function. Finally, we briefly demonstrate inference validity."
    },
    {
      "heading": "3.1 Influence Function",
      "text": "Given the DNN-based estimates \u03b1\u0302(x) and \u03b2\u0302(x), it is tempting to form an empirical analog of \u03b80, the so-called \u201cplug-in\u201d estimator:\n\u03b8\u0302PI = 1\nn n\u2211 i=1 H ( xi, \u03b1\u0302(xi), \u03b2\u0302(xi); t \u2217 ) . (3.1)\nHowever, inference for this estimator will be valid under only strong conditions which are not realistic for many machine learning methods, including deep learning. Using an influence function based estimator is one way to weaken the required conditions.\nIntuitively, the influence function accounts for two sources of uncertainty when estimating \u03b80 using machine learning in the first stage to recover the heterogeneity. Uncertainty in frequentist statistics captures the change in the estimator when the data is perturbed. Consider \u03b8\u0302PI given above. If the data is perturbed, this has two impacts on the final estimator. First, the more typical one, that if xi changes then the value H(xi, \u03b1\u0302(xi), \u03b2\u0302(xi); t \u2217) changes directly. But there is another affect of a perturbation: the very form of functions \u03b1\u0302(xi) and \u03b2\u0302(xi) will also change. It is by ignoring this second uncertainty that causes inference based on \u03b8\u0302PI to fail.\nInfluence functions have a long history in econometrics. Newey (1994) remains the seminal treatment. But there has been a recent resurgence in interest precisely because they deliver valid inference under fairly weak conditions on the machine learning methods. By far the most commonly studied setting is a binary treatment whose effect on the outcome of interest varies with a vector of covariates (Example 1 below). Much work has focused on lasso-based learning for the heterogeneity (Belloni et al., 2014; Farrell, 2015; Belloni et al., 2017) in which the two sources of uncertainty are clear: if the data changes, the coefficient estimates in a linear model change, but also the set of active coefficients itself may change. Failing to account for model selection renders inference invalid (Leeb and Po\u0308tscher, 2005). There is a now large literature on post-ML inference for treatment effects, see the works cited above as well as Chernozhukov et al. (2018), Athey et al. (2018), Kallus (2018), Farrell et al. (2019), and further references cited in these works. Inference after classical nonparametric estimation was studied by Hahn (1998), who importantly derived the efficient influence function. That influence function provides the base upon which many post-ML inference results stand. Applications of this model have found their way into a variety of fields\nincluding economics, medicine, marketing, and political science.\nOur goal is to build on these ideas and apply them in our structured model for individual heterogeneity. The steps of our calculation are standard, it is the range of models and parameters covered, coupled with direct applicability, which represents an advance. That is, we combine existing techniques with our structure to deliver our final result. Further, we explicitly and intentionally depart from this recent literature in several key ways, leading to useful results.\nThis is because we use only the information from Equations (2.1) and (2.3) to derive the influence function. This means that our results are broadly applicable, covering with a single influence function numerous areas of applied economics, the scope of which is illustrated by the diversity of the examples below. Derivation of an influence function is an unreasonably high price to pay for real world use. Possibly for this reason, much of the theoretical and applied literature has focused on binary treatments or partially linear models, where influence functions are widely known. The only other results with such broad applicability of which we are aware is the automatic debiasing proposed by Chernozhukov et al. (2020a,b). These papers show that, also using only the information from (2.1) and (2.3), one can, loosely speaking, learn the influence function automatically from the data. It is not clear if deep learning, or other methods not explicitly discussed therein, can be used in this framework however.\nThis breadth and easy of applicability comes at the expense of minimal conditions on the first stage estimators. Our estimator will be Neyman orthogonal (Chernozhukov et al., 2018) but not doubly robust in general, unless the function H is linear in the nonparametric objects. Thus one piece standing between our estimator and the weakest possible requirements is the nonlinearity bias (as coined by Cattaneo et al. (2013)). The impact of these and other remainder terms may be ameliorated by computationally intensive procedures (Newey and Robins, 2018; Cattaneo et al., 2019b) but such methods may be a poor match for modern machine learning methods such as deep neural networks. Pursuing these gains may in fact have detrimental consequences in some aspects (Cattaneo and Jansson, 2019).\nWe rely on the following conditions, all of which are standard. One important consequence of these conditions, in our framework, is that \u03b1(x) and \u03b2(x) are identified (see Lemma C.1 below). It also provides enough regularity on the data generating process so that our influence function can be calculated and asymptotic normality is obtained by our estimator below. One conceptually\nimportant point is that in general these conditions are not sufficient for a causal interpretation, which will require some form of unconfoundedness or conditional exogeneity.\nAssumption 1. The distribution of W = (Y,X \u2032,T \u2032)\u2032 obeys Equation (2.1). Equation (2.3) holds and identifies \u03b80. H(X, \u03b1(X),\u03b2(X); t \u2217), T , and Y \u2212 G(\u03b1(X) + \u03b2(X)\u2032T ) possess q > 4 finite absolute moments and positive variance. Uniformly in x: (i) H is thrice continuously differentiable in \u03b1 and \u03b2; (ii) with u denoting its scalar argument, G(u) is continuously invertible and thrice continuously differentiable; (iii) for T\u0303 = (1,T \u2032)\u2032 and G\u0307 = [dG(u)/du]u=\u03b1(x)+\u03b2(x)\u2032t, the eigenvalues of E[T\u0303 T\u0303 \u2032 | X = x] are bounded and bounded away from zero and \u039b(x) = E[G\u0307T\u0303 T\u0303 \u2032 | X = x] is invertible with bounded inverse.\nThese are mostly mild, common conditions and match standard assumptions in the special cases recovered by our framework. If G is linear, the condition on \u039b(x) is redundant. In other cases it will often be implied by other conditions on the model. For example, if G is the logistic link and P[Y = 1 | X = x,T = t] is bounded away from zero and one (which in turn may be implied by conditions on X, T , and the functions \u03b1 and \u03b2, such as boundedness). Or, in the context of treatment effects we need the standard overlap condition. Some version of the condition of positive variance, or invertibility of \u039b(x), is quite standard in semiparametric problems. Notice that \u039b(x) has the dimension of T , which is generally small; that is, inverting a large matrix is not required no matter the complexity of X.\nWe can now state our influence function result, which comes in the standard form: one term as if \u03b1 and \u03b2 were known and a second term representing a correction in the form of a residual and Riesz representer. (Making precise a discussion from earlier, it is the Riesz representer which is learned automatically by Chernozhukov et al. (2020a,b)). In Appendix A we derive the following result using standard methods.\nTheorem 1. Let Assumption 1 hold. Recall that dim(T ) = K, t\u0303 = (1, t)\u2032, and \u039b(x) = E[G\u0307T\u0303 T\u0303 \u2032 | X = x]. Denote the kth entry of the K-vector \u03b2(x) as \u03b2k(x) and define the vector of partial derivatives\n\u2207H(x) = ( \u2202H\n\u2202\u03b1 , \u2202H \u2202\u03b21 , . . . , \u2202H \u2202\u03b2K\n)\u2032 .\nThen for \u03b80 of Equation (2.3), a valid and Neyman orthogonal score is \u03c8(w, \u03b1,\u03b2,\u039b) \u2212 \u03b80, where\nw = (y,x\u2032, t\u2032)\u2032 and\n\u03c8(w, \u03b1,\u03b2,\u039b) = H (x, \u03b1(x),\u03b2(x); t\u2217) + \u2207H(x)\u2032\u039b(x)\u22121t\u0303 ( y \u2212G ( \u03b1(x) + \u03b2(x)\u2032t )) . (3.2)\nAt this level of generality, this influence function is new to the literature. In certain special cases we recover existing results, such as the case of average treatment effects (Example 1 in Section 6) or partially linear models (Example 2). For average partial effects (Example 3) there is overlap with the results of Wooldridge (2004), Graham and Pinto (2018), and Chernozhukov et al. (2019). More generally, for some cases an influence function is previously available, even if it does not agree with our result (for example, in cases where we sacrifice efficiency). Most importantly, when the first stage regression under the squared loss, Newey (1994) gives the form of the correction factor for a broader set of moment conditions than (2.3) and this result is in many cases as simple and applicable as ours. For cases where the loss function in (2.4) is not the expected squared residual, our results are new.\nThe form of the influence function is standard. The matrix \u039b(x) is perhaps the most complex portion of the score and several comments are warranted. First, the presence of an inverse function is commonplace in semiparametric inference problems, and moreover, as here, such a term often enters the Riesz representers. One appealing aspect of our influence function is that we do not have a nonparametric density function in the Riesz representer. The matrix \u039b(x) consists only of regression-type objects: we must project (moments of) the treatment variables onto X. Further, notice that \u039b does not depend on the chosen function H, determining the parameter of interest. This is helpful when several parameters are of interest in one application.\nWe will maintain the standard assumptions that both \u039b(xi) and \u039b\u0302(xi) are uniformly invertible (the former in the population, as in Assumption 1 above, and the latter in the data, as in Theorem 2 below). Broadly, these assumptions must be verified for a particular model and a particular estimator, and their plausibility should be carefully evaluated, as is generally the case with semiparametric inference where such terms are commonplace. For two specific examples, our assumptions correspond the requirement in treatment effect models that the propensity score and its estimate be bounded away from zero and one, or in linear models more generally, we require positive definiteness of the conditional variance and its estimator.\nThese assumptions simplify in cases where one has prior knowledge that only a certain subset of the heterogeneity covariates, say X1 \u2282X, are relevant for T . An extreme case is randomization (Remark 3 below). Another example occurs with T being prices, which are known with certainty to be set by the firm according to only several characteristics of the market or consumer. Further, nonsingularity of \u039b will often be implied by other conditions, such as the more standard assumption of positive conditional variance of T given X, along with properties of the link function. This is true, for example, when G is the logistic link and the argument is bounded.\nFinally, here is a gap between applications with linear link functions G(u) and nonlinear cases that appears novel. When G(u) is linear, G\u0307 \u2261 1 and \u039b(x) is simply the covariance matrix of T , conditional on X. This can be estimated by standard ML methods as it is a matrix of standard prediction problems. However, in the nonlinear case, the moments are weighted by G\u0307, which depends on the unknown \u03b1 and \u03b2. When G(u) is nonlinear, we must first estimate G\u0307, as it depends on the unknown \u03b1 and \u03b2, and then estimate \u039b(x) separately. This introduces an extra splitting when, for example, performing cross fitting. Again these complications vanish in the common case of a randomized treatment, as in Remark 3.\nThere are two special cases in which \u03c8 simplifies, which are common enough in applications to\nbe worth spelling out here.\nRemark 2 (Univariate Treatments). If dim(T ) = K = 1, we can compute \u039b(x)\u22121 directly and state \u03c8 more explicitly, and in some cases, more familiarly. Define the K-vector \u03bb(x) as having kth entry \u03bbk(x) = E[G\u0307T k\u22121|X = x], so that \u039b(x) has {j, l} entry equal to \u03bbj+l\u22122(x). Denote \u2207H(x) = (H\u0307\u03b1(x), H\u0307\u03b2(x))\u2032. Then (3.2) becomes\n\u03c8(w, \u03b1, \u03b2,\u03bb) = H (x, \u03b1(x), \u03b2(x); t\u2217)\n+ H\u0307\u03b1(x) (\u03bb2(x)\u2212 \u03bb1(x)t) + H\u0307\u03b2(x) (\u03bb0(x)t\u2212 \u03bb1(x)) \u03bb2(x)\u03bb0(x)\u2212 \u03bb1(x)2 ( y \u2212G(\u03b1(x) + \u03b2(x)t) ) ,\n(3.3)\nWe note here that the treatment may be discrete or continuous, in either case the form of the influence function remains the same. \u2663\nRemark 3 (Randomized Treatments). If T is randomly assigned, or more generally is independent ofX, then obtaining \u039b(x) is simpler, though it remains a function of x in general. To fix ideas, consider the classical case of a randomized binary treatment. Here G(u) = u and T = {0, 1} so that, in the notation of Remark 2, \u03bb0(x) = 1 and \u03bb1(x) = \u03bb2(x) = P[T = 1]. The treatment probability may be known, but even if it is unknown, nonparametric estimation is no longer required. This message\ncarries over to the general case, where under independence \u039b(x) = \u222b G\u0307(\u03b1(x) + \u03b2(x)\u2032t)t\u0303t\u0303\u2032dFT (t). If the distribution, denoted FT (t), is known, this object can be computed numerically once the functions \u03b1(x) and \u03b2(x) are given (or if G(u) = u, these are not needed). These functions will be treated as fixed as we will employ three-fold sample splitting to estimate them for nonlinear link functions. This continues to apply under cases such as stratified randomization, where the relevant distribution will be known and depend on a very simple subset of the covariates. \u2663"
    },
    {
      "heading": "3.2 Convergence for Structured Deep Neural Networks",
      "text": "As is standard, the orthogonal score depends on the original nonparametric objects, \u03b1(x) and \u03b2(x), but also on a nuisance function, \u039b(x). The function \u039b(x) is a nuisance function in the truest sense: it is required only for valid inference because we take the influence function approach. One may estimate this object in any number of ways, and moreover, this estimation is not required for experiments (Remark 3). For valid inference, we can simply assume a high-level conditions for recovery of \u039b(x) (i.e. a better than n\u22121/4 rate) but we will spell out estimation results using DNNs.\nIt is useful to define some notation. Recall that W collects (Y,X \u2032,T \u2032)\u2032, as does wi, and\nthat \u03b2k(x) is the k th entry of \u03b2(x). Let \u03b2\u0302k(x) be the k th entry of \u03b2\u0302(x). In the same way, let \u03bbj,k(x) and \u03bb\u0302j,k be the (j, k) entries of \u039b(x) and \u039b\u0302(x), respectively. Note that \u03bbj,k(x) and \u03bb\u0302j,k are symmetric and to recover the one-subindex notation of Remark 2, when treatment is scalar, \u03bbj,k(x) 7\u2192 \u03bbj+k\u22122(x).\nEstimation of \u03bbj,k(x) is a prediction problem, but where the \u201coutcome\u201d is G\u0307(\u03b1(xi)+\u03b2(xi) \u2032ti)[t\u0303i]j [t\u0303i]k.\nFor linear models, when G(u) = u, G\u0307 \u2261 1 and may be dropped (and \u03bb1,1(x) \u2261 1). For nonlinear cases, we employ sample splitting: using one sample we obtain \u03b1\u0302(x) and \u03b2\u0302(x), and then we treat these as fixed functions when estimating \u03bbj,k(x) in the second sample. The loss function optimized in this estimation must be specific to the setting. Often this will be least squares, but not always, such as if T is discrete, where with the presence of G\u0307, a fractional outcome model may be warranted.\nWe will state two assumptions before giving the asymptotic results for estimation. Our first\nassumption concerns the loss function.\nAssumption 2. For constants c1, c2, and C` that are bounded and bounded away from zero, continuously invertible transformation g(\u00b7), and f\u2217 = g(G(\u03b1(x) + \u03b2(x)\u2032t)), `(g,w) given in (2.4) obeys, for f = g(G(a(x) + b(x)\u2032t)) for any a(x) and b(x),\n|`(f,w)\u2212 `(f \u2032,w)| \u2264 C`|f \u2212 f \u2032|,\nc1E [ (f \u2212 f\u2217)2 ] \u2264 E[`(f,W )]\u2212 E[`(f\u2217,W )] \u2264 c2E [ (f \u2212 f\u2217)2 ] .\n(3.4)\nThe same conditions hold for the loss function used to estimate \u039b(x), with \u03bbj,k(x) in place of G(\u03b1(x) + \u03b2(x)\u2032t) in all cases.\nThe first condition is a Lipschitz continuity requirement in the transformed conditional expectation and the second requires sufficient curvature at the true. Neither are restrictive. All of our examples, and other applications discussed in Farrell et al. (2019) and elsewhere, obey these requirements.\nWe next assume that \u03b1, \u03b2, and \u039b are appropriately smooth functions. Define the Ho\u0308lder ball\nWp,\u221e([\u22121, 1]q) of functions h : Rq \u2192 R with smoothness p \u2208 N+ as\nWp,\u221e([\u22121, 1]q) := { h : max\n\u03b1,|\u03b1|\u2264\u03b2 ess sup v\u2208[\u22121,1]q\n|D\u03b1h(v)| \u2264 1 } , (3.5)\nwhere \u03b1 = (\u03b11, . . . , \u03b1q), |\u03b1| = \u03b11 + . . .+ \u03b1q and D\u03b1h is the weak derivative.\nLet XC denote the continuously distributed elements of X, and define dC = dim(XC), and\ntake the rest to be binary random variables, without loss of generality.\nAssumption 3. Let Assumption 1 hold and further assume that (i) the elements of W are bounded random variables; (ii) XC has compact connected support, taken to be [\u22121, 1]dC ; (iii) As functions of xC , the continuously distributed components of X, \u03b1(x), \u03b2k(x), k = 1, . . . ,K, and \u03bbj,l(x), (j, l) \u2208 {0, . . . ,K}2, are members of Wp,\u221e([\u22121, 1]dC ); (iv) the loss and model are such that g/\u2016g\u2016\u221e and G/\u2016G\u2016\u221e belong to Wp,\u221e([\u22121, 1]).\nWe now state our results for deep learning. These consist of rates of convergence for \u03b1\u0302(x),\n\u03b2\u0302(x), and \u039b\u0302(x).\nLemma 1. Denote rn := n \u2212 p p+dC log8(n). Let wi, i = 1, . . . , n be a random sample that obeys Assumptions 2 and 3. Then for a DNN structured according to Section 2.1, of width H n(dC)/2(p+dC) log2 n and depth L log n, \u2016\u03b1\u0302 \u2212 \u03b1\u2016L2(X) = O(rn) and \u2016\u03b2\u0302k \u2212 \u03b2k\u2016L2(X) = O(rn), k = 1, . . . ,K. Further, for a generic network of the same size, \u2016\u03bb\u0302j,k \u2212 \u03bbj,k\u2016L2(X) = O(rn).\nNotice that here we have separate rates for the functions \u03b1(x) and \u03b2(x) (technically, though not stated, we obtain nonasymptotic bounds, not merely rates). This is required. The parameter of interest depends on these two separately, not on the conditional expectation E[Y |x, t] as a whole, which would be more typical of past work (unstructured) on inference after machine learning and also of results designed to adapt to the structure of the model. Neither will work here. What is important is that our results show that the \u03b1\u0302(x) and \u03b2\u0302(x) defined in Section 2.1, i.e. built using our architecture, converge at a rate which depends on the dimension of (the continuous component of) X. This is, intuitively, what should happen: the heterogeneity is where the model is flexible. Simply applying existing results would yield a bound depending on dC + K: the dimension of T would become a severe restriction. These results may be useful in other contexts where varying coefficient models are used. Further, with no additional theoretical work, our results will cover cases such as additive models. That is, if we assume E[Y | X = x] = G(\u03b1(x1) + \u03b2(x2)), for nonoverlapping subsets x1,x2 of x, we will obtain rates for \u03b1(x1) and \u03b2(x2) that depend on dim(x1) \u2228 dim(x2) (in addition to smoothness). We omit a full statement for brevity, but the architecture of Section 2.1 and the proofs in the appendix can be easily adapted to this case. Lastly, the wide and deep architectures used in this result can be replaced with others, though this will have consequences for the rates, as discussed by Farrell et al. (2019).\nFor other recent theoretical results on deep learning in other contexts, see Liang (2018), Polson and Roc\u030ckova\u0301 (2018), Wang and Roc\u030ckova\u0301 (2020), Liang and Tran-Bach (2020), and references therein. Our theory does not address regularization, neither the implicit regularization that may occur in the optimization nor explicit regularization of the network parameters themselves though norm penalties, weight decay, drop out, or other methods. In our applications we obtain excellent performance without using explicit regularization, though in low signal-to-noise scenarios adding explicit regularization to the implicit regularization may yield improvements. The role of regularization, and its properties, in deep learning is a major open question is the subject of both\nempirical (as reviewed in Goodfellow et al. (2016)) and theoretical study (Polson and Roc\u030ckova\u0301, 2018; Blanchet et al., 2020)."
    },
    {
      "heading": "3.3 Gaussian Inference",
      "text": "Turning to inference, we will apply the results from Chernozhukov et al. (2018) and as such we keep the discussion brief. Essentially, armed with our influence function and results for deep learning, we have everything we need to obtain asymptotic normality for an estimator of \u03b80. We will rely on sample splitting or cross fitting here, in order to obtain the desired theoretical result. From a theoretical point of view, sample splitting allows us to obtain a properly centered limiting distribution under weaker conditions on the first stage (deep neural network) estimates. However, this comes at a computational cost which can be large in some applications. Farrell et al. (2019) show that for some estimands sample splitting is not needed for inference after deep learning under reasonable assumptions. Following their argument it may be possible to remove the reliance on sample splitting for the results below as well.\nWe will be brief in describing the estimation procedure, leaving further discussion to Chernozhukov et al. (2018) and Newey and Robins (2018). First, the observations {1, . . . , n} are split into S subsets, denoted by Ss \u2282 {1, . . . , n}, s = 1, . . . , S. Let Scs be the complement of Ss. We then, for each s = 1, . . . , S, estimate the functions \u03b1(\u00b7), \u03b2(\u00b7), and \u039b(\u00b7) using Scs ; denote these by \u03b1\u0302s(\u00b7), \u03b2\u0302s(\u00b7), and \u039b\u0302s(\u00b7). When G(u) = u, \u03b1(x), \u03b2(x), and \u039b(x) may be estimated simultaneously using all of Scs . For nonlinear models, we split this set in two pieces, estimate \u03b1(x) and \u03b2(x) on the first and then, using these as fixed functions, obtaining \u039b\u0302(x) on the second. The final estimator of \u03b80 is then\n\u03b8\u0302 = 1\nS S\u2211 s=1 \u03b8\u0302s, \u03b8\u0302s = 1 |Ss| \u2211 i\u2208Ss \u03c8(wi, \u03b1\u0302s(xi), \u03b2\u0302s(xi), \u039b\u0302s(xi)), (3.6)\nwhere |Ss| is the cardinality of Ss and is assumed to be proportional to the sample size n. Along with the point estimator \u03b8\u0302 we will require an estimator of the asymptotic variance, which is given by \u03a8 = V[\u03c8(w, \u03b1,\u03b2,\u03bb)]. To estimate \u03a8 we use the variance analogue of (3.6):\n\u03a8\u0302 = 1\nS S\u2211 s=1 \u03a8\u0302s, \u03a8\u0302s = 1 |Ss| \u2211 i\u2208Ss ( \u03c8(wi, \u03b1\u0302s(xi), \u03b2\u0302s(xi), \u039b\u0302s(xi))\u2212 \u03b8\u0302 )2 . (3.7)\nFor \u03b8\u0302 and \u03a8\u0302 defined by this procedure, we have the following inference result, which establishes\nasymptotic normality and validity of standard errors.\nTheorem 2. Let wi, i = 1, . . . , n be a random sample that obeys Assumption 1. For all s, j, k, suppose \u2016\u03b1\u0302s \u2212 \u03b1\u2016L2(X), \u2016\u03b2\u0302k,s \u2212 \u03b2k\u2016L2(X), and \u2016\u03bb\u0302j,k,s \u2212 \u03bbj,k\u2016L2(X) are o(n\u22121/4) and that \u039b\u0302(xi) is uniformly invertible. Then\n\u221a n\u03a8\u0302\u22121/2(\u03b8\u0302 \u2212 \u03b8) = n\u2211 i=1 \u03a8\u22121/2\u03c8(wi, \u03b1(xi),\u03b2(xi),\u039b(xi))/ \u221a n+ op(1)\u2192d N (0, 1).\nThe novelty of this result lies in our framework, the model (2.1) and parameter (2.3), and the new influence function of Theorem 1. This result delivers valid inference on the broad class of problems we have discussed already and those discussed below. The proof itself appears in Appendix B and follows from Chernozhukov et al. (2018), once the influence function and DNN convergence rates are in place."
    },
    {
      "heading": "4 Application I: Fractional Outcomes and 401(k) Participation",
      "text": "To demonstrate the methods outlined above we use the context and data outlined in Papke and Wooldridge (1996). The crux of the empirical exercise is to ascertain the relation between employee participation rates and employer match rates in the context of 401(k) plans."
    },
    {
      "heading": "4.1 Context",
      "text": "401(k) plans allow employees to make pre-tax contributions and for employers to match part of such contributions. Participation is a choice on the part of the employee and can depend on the characteristics of the plan(s) offered by the employer. Papke and Wooldridge (1996), following Papke (1995) , examine the relation between participation rates (henceforth yi) and the matching rate (ti) (the proportion of the employee contribution that is matched by the employer). They use data from Form 5500 filings by the employers with the Internal Revenue Service, which contain participation rates and contribution behavior for each plan offered.\nSince participation rates naturally fall in [0, 1] the authors advocate the use of structure to\nensure that the outcome variable remain on the unit interval. In particular, they suggest using\nE[yi|ti] = G ( \u03b1+ \u03b2ti ) , (4.1)\nwhere 0 \u2264 G \u2264 1. They argue that this specification is valid even at the endpoints and is more practically relevant then transformations of the dependent variable. We take this structure as given and extend it to include heterogeneity. This gives us the following specification:\nE[yi|ti,xi] = G ( \u03b1(xi) + \u03b2(xi)ti ) , (4.2)\nwhere ti is the match rate, xi are firm and plan characteristics (number of employees (EMP), age of the plan (AGE), whether the plan is the sole plan offered (SOLE)) and yi is the participation rate. Apart from this specification related departure, we follow Papke and Wooldridge (1996) quite closely in setting up the empirical exercise. As in their paper, we restrict our attention to the case where ti \u2264 1 and adopt the quasi-likelihood approach (Binomial likelihood with a Logit link). For more details we refer readers to Papke and Wooldridge (1996)."
    },
    {
      "heading": "4.2 Quantities of Interest",
      "text": "The substantive quantity of interest in the application is the marginal effect (\nME (t) = \u2202G(t,x)\u2202t\n) of\nthe match rate on participation and the degree to which this marginal effect exhibits diminishing patterns. To investigate this Papke and Wooldridge (1996) evaluate the marginal effect (for x fixed) at t\u2217 \u2208 {0.0, 0.5, 1.0} and conclude that there exists evidence for diminishing marginal effects. We propose a more general approach by estimating the average marginal effect (AME),\nAME (t\u2217) = E [ \u2202G(t,X)\n\u2202t\n\u2223\u2223\u2223\u2223 t=t\u2217 ] ,\nas well as the average change in the marginal effect (ACME3),\nACME (t\u2217) = E [ \u22022E[Y | X, t]\n\u2202t2\n\u2223\u2223\u2223\u2223 t=t\u2217 ] .\n3We apologize for the acronym. Alternative suggestions for this effect are welcome.\nNote that in our specification G(u) = eu/ (1 + eu), and combined with the structure of the model, we obtain, for, G\u2217 = G (\u03b1(x) + \u03b2(x)t\u2217),\nAME (t\u2217) = E [HAME (\u03b1(X), \u03b2(X); t\u2217)] , where HAME (\u03b1, \u03b2; t\u2217) = \u03b2G\u2217 (1\u2212G\u2217) ,\nand\nACME (t\u2217) = E [HACME (\u03b1(X), \u03b2(X); t\u2217)] , where HACME (\u03b1, \u03b2; t\u2217) = \u03b22G\u2217 (1\u2212G\u2217) (1\u2212 2G\u2217) .\nSince this is a scalar treatment case the influence function for both parameters follows the form outlined in Remark 2. For both HAME and HACME the derivatives with respect to \u03b1 and \u03b2 are available in closed form. For example, for HAME we have\nH\u0307\u03b1(x) = \u03b2(x)G\u0308 and H\u0307\u03b2(x) = \u03b2 (x) G\u0308x+ G\u0307,\nwhere G\u0307 = G (1\u2212G) and G\u0308 = G\u0307 (1\u2212 2G). Similar calculations can be done for HACME. We omit those for brevity.4 Recall also that \u03bbk(x) = E[G\u0307T k|X = x] requires estimation. This can be done by projecting G\u0307T k for k \u2208 {0, 1, 2} on x using a deep neural net or via other nonparametric methods. Plugging in estimated values as appropriate in Equation (3.3), we obtain parameter estimates using Equation (3.6) and inference follows from Theorem 2.\nInference on average (first) derivatives more generally is a long-studied problem in econometrics, dating at least back to Powell et al. (1989), and while second derivatives are less common, they have been used in different contexts (Chen and Ludvigson, 2009). Our goal is to demonstrate that such such concepts can be straightforwardly examined using our proposed framework, and that the structure of the model can be an advantage."
    },
    {
      "heading": "4.3 Implementation",
      "text": "Our estimation routine was implemented in Tensorflow (Abadi et al., 2015). Given the low dimensional nature of x we chose a simple deep neural network with three hidden layers consisting of\n4Automatic differentiation or numerical methods offer a practical approach to obtaining these derivatives. We have had very positive experiences with both. For both our applications the results do not change if we use numerical or algorithmic methods to obtain the relevant derivatives.\ntwenty nodes in each. For the estimation of \u039b\u22121 we used similar (3 layer) deep network architectures with ten nodes each. Overall, this is a rather simple network with a total number of parameters around 1320. All activation functions were of the ReLU variety and we used the entire dataset for training and ran the training for 10000 epochs. Our experiments with different architectures provided qualitatively equivalent results. We discuss results from the described architecture below.\nOne important feature to note that DNNs share with other modern machine learning algorithm is that the results have randomness that is not present with other nonparametric methods. This is due to the randomness in the algorithm (starting points, batches, etc). Intuitively, this is similar to the randomness in cross-validated or bootstrapped estimators. A future topic for exploration is the best way to ensure replicability for machine learning."
    },
    {
      "heading": "4.4 Results and Discussion",
      "text": "We focus our attention on the two constructs discussed earlier \u2013 namely the average marginal effect (AME) and the average change in the marginal effect (ACME). We find that the marginal effects at all match rate values are positive and significant. Table 1 provides the AME estimates, along with 95% confidence intervals, while Figure 1 shows the entire distribution of the marginal effects at evaluated at a range of match rates (t\u2217 \u2208 {j/10}10j=0). These results coincide nicely with those found in Papke and Wooldridge (1996). In fact, their estimates of the marginal effects {0.2880, 0.197, 0.118} evaluated at the match rates t\u2217 \u2208 {0.0, 0.5, 1.0} are close to our estimates. Two of the estimates fall within the confidence intervals we estimate (i.e. for t\u2217 \u2208 {0.0, 0.5}) with the third (t\u2217 = 1.0) not very far off.\nOur results pertaining to the change in the marginal effects also provide strong evidence to the diminishing returns finding of Papke and Wooldridge (1996). Figure 2 shows the 95% CI for the ACME and a visual inspection as well as one-sided tests confirm that the effects are all negative. Unlike Papke and Wooldridge (1996), our curvature estimates are not at isolated points at specified x but rather interpretable statistics that are integrated over the distribution of x."
    },
    {
      "heading": "5 Application II: Estimating Consumer Surplus",
      "text": ""
    },
    {
      "heading": "5.1 Empirical Context",
      "text": "In a recent paper Dube and Misra (2019) use data from a series of experiments to construct optimal pricing schemes for an online startup. We use the data from their paper to construct and estimate of the mean consumer surplus. Their specification mirrors our own with the key difference being that they use a Lasso implementation to account for heterogeneity and a (weighted) Bayesian bootstrap to account for specification uncertainty.\nThe model in Dube and Misra (2019) is straightforward with\nE [Y |X = x,T = t] = G(\u03b1(x) + \u03b2(x)t).\nwhere the link function is the Logit with G(u) = (1 + exp(\u2212u))\u22121. In this context the treatment variable takes on ten different price values ranging from $19 to $399 and the outcome is a binary conversion indicator. For more details we refer the reader to the aforementioned paper.\nThe construct we are interested in is the expected consumer welfare function, evaluated at the\nnew price (t\u2217 = $249). This measure can be described as\n\u03b80 = E [ H(X, \u03b1(X),\u03b2(X); t\u2217) ] = E [ \u2212 1 \u03b2(X) log(1 + exp(\u03b1(X) + \u03b2(X) \u00b7 t\u2217)) ] .\nAs in the earlier application, this is a scalar treatment and the influence function for this statistic is relative straightforward to construct using the same format given in Remark 2. In this case straightforward calculations reveal that\nH\u0307\u03b1 = \u2212 G\n\u03b2 , and H\u0307\u03b2 = \u2212\nGt\u2217 +H\n\u03b2 .\nwhere the functionals G and H are evaluated at {x, t\u2217}. In this application the \u03bbk(x) = E[G\u0307T k|X = x] are trivial to compute since the density of T is uniform over the experimental price vector. Estimation and inference again follows by plugging first stage estimates into the influence function (3.3) and following Equation (3.6) and Theorem 2."
    },
    {
      "heading": "5.2 Implementation",
      "text": "As in the Papke and Wooldridge (1996) application, our estimation routine was implemented in Tensorflow (Abadi et al., 2015). In this case, since the dimensionality of x was significantly larger we used a deep neural network with three hidden layers with, respectively 100, 60, and 30 nodes. In total, the architecture involved 20252 parameters. As part of the regularization scheme we used a weight decay parameter of 0.02 and dropout percentages of [0.3, 0.2, 0.1] for the three layers. Finally, all activation functions were of the ReLU variety.\nWe initialized all weights using Xavier uniform initializer, while bias terms are all initialized to zero. The dataset was split on the validation and training set, where the validation set was chosen to be a random set representing 10% of the original dataset. We verified that the distribution of prices and conversions was preserved in both sets. During the training, the entirety of the training set was used (i.e. all 7071 instances since there is no need for mini-batching). The training was stopped when there were no improvements on the validation set loss for 30 epochs or if the maximum number of epochs was reached (=20000)."
    },
    {
      "heading": "5.3 Results",
      "text": "Our estimates reveal that \u03b8 = 51.02 with a 95% confidence interval of (41.86, 60.17). In other words, at a uniform price of $249 there is an average surplus of about $51 that remains with the consumer. This is more or less consistent with the findings in Dube and Misra (2019) who find that the optimal uniform price should be close to $327.\nIn figure (4) we plot the kernel density of H shifted by the mean of the influence function. Without accounting for the influence function adjustment the mean consumer surplus would be 35.57 (dotted line). The solid line represents the adjusted mean and the band at the bottom the 95% CI for the parameter. The difference of 15.44 is significant (and lies outside the 95% CI for \u03b8) and suggests that not correcting for the specification uncertainty would have created a substantial bias in the estimate. We note here that the procedure adopted by Dube and Misra (2019) also accounted for this uncertainty via a Bayesian bootstrap. Although these procedures are not directly comparable the similarity of the results suggest that accounting for the uncertainty induced by machine learning methods is important.\nThe purpose of our analysis was to demonstrate the value of our framework for applied work. Inference of constructs such as derivatives and consumer welfare are straightforward applications of the influence function we provide. In both applications the deep learning framework allowed for the incorporation of heterogeneity and for a more nuanced understanding of the phenomenon under investigation. An advantage of our setup is that the changes in the H can be done in the code and inference is obtained in an automatic manner. While not reported here, we leveraged this feature and explored a number of economically relevant statistics such as elasticities and the average profitability (at optimal prices).\nAnother noteworthy feature of the applications is that neither one boasts very large sample sizes. We deliberately chose these to demonstrate that deep learning can be used and useful even in small datasets as long as the complexity of the network is kept at reasonable levels. For a more involved application with larger N , in the context of customer targeting, we refer the reader to Farrell et al. (2019). We now discuss a variety of other contexts where our methods may be used."
    },
    {
      "heading": "6 Examples",
      "text": "The examples below illustrate the breadth of applicability of our framework, the model (2.1) and parameter (2.3). We show that our framework recovers past works as special cases as well as yields new results. We emphasize that our results cover all the examples below simultaneously, without any additional derivations required. This set is of course not exhaustive. We begin with some simple cases where we recover existing results.\nExample 1 (Average Effect of a Binary Treatment). Average treatment effects are a canonical semiparametric problem and the standard case in the recent literature on inference after machine learning (see references in Section 3.1). Here G is linear and T = {0, 1} is a scalar treatment indicator. Letting Y (t) be the potential outcome under treatment T = t, we find that E[Y (0) | X = x] = \u03b1(x) and E[Y (1) | X = x] = \u03b1(x) + \u03b2(x), so that \u03b2(x) represents the heterogeneous treatment effects.\nIf we set H(x, \u03b1, \u03b2, t) = \u03b2 in (2.3), then \u03b80 is the familiar average treatment effect. In this case, the model (2.1) is without loss of generality beyond unconfoundedness, and hence we recover the familiar efficient influence function (Hahn, 1998) in this case.5 In this example, assuming the propensity score is bounded away from zero and one ensures that \u039b(x)\u22121 exists; note the denominator in (3.3) is P[T = 1|X = x](1\u2212 P[T = 1|X = x]).\nIt is straightforward to extend this example to cover average treatment effects for specific treatment groups as well as multi-valued treatments and dose response functions. See Cattaneo (2010) and Cattaneo and Farrell (2011) for inference using classical nonparametrics (series) and Farrell (2015) for machine learning (group lasso) results. \u2663\n5To see this, referring to the simplified form of the influence function in (3.3), we have H\u0307\u03b1 = 0, H\u0307\u03b2 = 1, \u03bb0 = 1, and \u03bb1(x) = \u03bb2(x) = P[T = 1|X = x], the propensity score. Then\n(t\u2212 \u03bb1(x)) (y \u2212 \u03b1(x)\u2212 \u03b2(x)t) = ((1\u2212 \u03bb1(x))t\u2212 \u03bb1(x)(1\u2212 t)) (y \u2212 \u03b1(x)\u2212 \u03b2(x)t)) = (1\u2212 \u03bb1(x))t (y \u2212 \u03b1(x)\u2212 \u03b2(x))\u2212 \u03bb1(x)(1\u2212 t) (y \u2212 \u03b1(x)) = (1\u2212 \u03bb1(x))t (y(1)\u2212 E[Y (1) |X = x])\u2212 \u03bb1(x)(1\u2212 t) (y(0)\u2212 E[Y (0) |X = x]) ,\nwhere the first equality adds and subtracts \u03bb1(x)t, the second equality uses each term is multiplied by the treatment status, either t or (1 \u2212 t), and that (1 \u2212 t)t = 0, and the third equality applies definitions. Inserting this into (3.3), and canceling factors in the denominator, yields the result.\nExample 2 (Partially Linear Models). A widely studied semiparametric problem is the partially linear model, wherein \u03b2(x) is assumed constant, and for simplicity and comparability to past results, we focus on a single scalar treatment variable. Restricting to a constant or homogeneous treatment effect is a strong assumption and should be viewed with caution, but we can still apply our results to this case. Most studies use a linear model, but there are results for nonlinear G(u); our framework accommodates both simultaneously. Typically, the parameter of interest is \u03b2, in which case (3.3) immediately yields that \u03c8(y,x, t)\u2212 \u03b2 is\n[ \u03bb2(x)\u2212 \u03bb1(x) 2\n\u03bb0(x)\n]\u22121( t\u2212 \u03bb1(x)\n\u03bb0(x)\n)( y \u2212G(\u03b1(x) + \u03b2t) ) .\nOur choice to use only the information of model (2.1) and parameter (2.3) in the derivation of our influence function, in order to use only a single derivation for all cases, means that we will not obtain efficiency in general. Crucial to obtaining efficiency is using all the information provided by the generalized linear model form, in particular using the fact that generalized linear models correspond to exponential families and thus provide information on second moments. The above display is formatted to make this clear. The first factor is not the inverse of the efficient information, which in this model would be\nE [( T \u2212 \u03bb1(x)\n\u03bb0(x)\n)2 G\u0307 ] = E [ \u03bb2(x)\u2212 \u03bb1(x) 2\n\u03bb0(x)\n] .\nWe can therefore see that capturing further information is needed for efficiency. In the linear case, our estimator will be efficiency under homoskedasticity.\nWe can also see that, for each application, we must have that \u03bb2(x)\u03bb0(x) 6= \u03bb1(x)2. This is a restriction again on the conditional moments, but here weighted by G\u0307 for nonlinear models. In some cases the nonsingularity will follow from other regularity conditions, such as for the logistic link, where G\u0307 = G(1\u2212G) and the Hessian is invertible under bounded covariates.\nPartially linear models have received a great deal of attention in the theoretical literature, most often with a linear link function. Explicitly treating inference following machine learning, the pioneering work of Belloni et al. (2014) proved valid inference after lasso selection, which, as here, is efficient in the homoskedastic case. Chernozhukov et al. (2018) use this model as the\nleading example of their generic results. Cattaneo et al. (2018) give novel results for series-based inference with many terms; they also give numerous references that use classical nonparametrics. For the case of nonlinear link function, Mammen and van de Geer (1997) study inference on \u03b2 using penalized quasi-likelihood and obtain efficiency under appropriate assumptions (see Kosorok, 2008, for further discussion).\nThe literature has almost entirely focused on inference on \u03b2, but our framework allows for a much richer set of possibilities. For example, in both empirical finance and applied microeconomics the function \u03b1(x) is of interest, see Cattaneo et al. (2020a) and Cattaneo et al. (2019a) respectively.\n\u2663\nExample 3 (Continuous Treatments and Average Partial Effects). Moving beyond discrete treatments or homogeneous effects, our framework gives a simple way to assess the heterogeneous effect of a continuous treatment T or set of treatments T by recovering average partial effects. Here, model (2.1) imposes nontrivial structure. The specification of linearity in the treatment is a restriction, but yields a tractable and interpretable model. The average of the heterogeneous partial effect of one of the treatment variables is E[\u03b2k(X)] which, thanks to the model, can be extrapolated to any treatment level [t\u2217]k by taking \u03b80 = E[\u03b2k(X)[t\u2217k]]. Wooldridge (2004) and Graham and Pinto (2018) are perhaps the closest to our work in this context and also give conditions for a causal interpretation of E[\u03b2(X)]. Hirshberg and Wager (2019) use a very different approach to recover the average effect, but briefly discuss double robustness. Chernozhukov et al. (2019) use a similar model with the goal of policy targeting.\nA simple extension to the scalar case that is useful in applied settings to enriching our under-\nstanding is to use a more flexible parametric model with heterogeneous coefficients, for example\nE[Y |X = x,T = t] = \u03b1(x) + \u03b21(x)\u2032t+ \u03b22(x)\u2032t2.\nThis is a special case of (2.1) wherein T = (T, T 2)\u2032 and averages of linear combinations of \u03b21 and \u03b22 will provide simple, interpretable quantities that be easily used in policy making. The nonsingularity of \u039b(x) is again a restriction on the conditional moments of T given X, thanks to the linearity of G(u), essentially requiring linear independence through the fourth conditional\nmoment.\nWe also note that, unlike the papers aforecited, we can easily recover E[\u03b2k(X)] in nonlinear\nmodels, an object is of general interest in many applications.\nOur approach here contrasts with the typical econometric literature on continuous treatments, which has favored nonseparable models as opposed to structural modeling. This may increase the generality of the results but can make inference and interpretation more difficult. Hirano and Imbens (2004) did early work in this area and Kennedy et al. (2017) and Colangelo and Lee (2020) study inference using doubly robust estimators; see also other references therein. \u2663\nExample 4 (Interaction Effects). A simple but useful extension to Examples 1 and (3) is a heterogeneous interaction effect. Often one or two covariates are of specific interest and we may wish to capture an interaction of the treatment with this covariate, or a specific subgroup effect. If Z is the covariate of interest, model (2.1) takes the form E[Y |T = t, Z = z,X = x] = \u03b1(x, z) + \u03b21(x)t+ \u03b22(x)\u00b7t\u00b7z. The parameter of interest may be averages of \u03b22(x) or linear combinations such as E[\u03b21(X) + \u03b22(X)z\u2217] for fixed z\u2217. \u2663\nThe example of average partial effects, when combined with transformations of the outcome and the treatment, recovers many other useful settings, even restricting to linear link functions. This illustrates the usefulness of our framework covering many contexts with one calculation. The conditions for invertibility of \u039b(x) in each case is the same as the above.\nExample 5 (Heterogeneous Berry Logit). The so-called Berry logit, pioneered by Berry (1994) is a popular model for demand models where the outcome of interest is the market share distribution across firms. In most applications the researcher has access to outcomes {Yjm} which represent a collection of j = 0 . . . J market shares across m = 1 . . .M markets. The objective is then to model these as a function of firm (marketing) decisions tjm (see e.g. Nevo (2001)). We can introduce heterogeneity across markets by allowing for the marketing effects to be moderated by consumer characteristics xm, so that we can write a collection of (J \u2212 1) equations as follows\nE [ log\nYjm Y0m\n|X = xm,Tjm = tjm ] = \u03b1j(xm) + \u03b2(xm) \u2032(tjm \u2212 t0m).\nStacking these equations and the corresponding data allows us to construct an estimator for \u03b1j(xm) and \u03b2(xm). We note here that our framework can be extended to include instruments along the lines of Okui et al. (2012). We leave this to future work. \u2663\nExample 6 (Production Models). The Cobb-Douglas specification for production functions is denoted by Y = CK\u03b1(x)L\u03b2(x). With T = (K,L)\u2032, by taking logs we can write it in the form consistent with our requirements, that is,\nE [log Y |X = x,K = k, L = l] = logC + \u03b1(x) \u00b7 log k + \u03b2(x) \u00b7 log l.\nGiven estimates we may be interested in understanding if the technology exhibits increasing, constant, or decreasing returns to scale. This can be ascertained by computing \u03b8 = E[\u03b1(x) +\u03b2(x)] and noting that \u03b8 < 1, \u03b8 = 1, \u03b8 > 1 imply decreasing, constant, and increasing returns to scale. The Cobb-Douglas specification has also been used in demand settings and marketing mix models and the framework described above would be readily applicable there as well. \u2663\nMany of the examples above restrict to a linear model (after appropriate transformation). Our methods and results for deep learning are novel even for the linear case. But, as discussed in Section 3.2, Newey (1994) also gives a simple recipe for obtaining an influence function. The seamless accommodation of nonlinear models is one strength of our methodogolical framework, and we give a few examples to illustrate. Both empirical applications also use nonlinear models.\nExample 7 (Binary choice model). Section 5 studies a binary choice model, one of the workhorse models in applied economics. Here G(u) = (1 + exp(\u2212u))\u22121, the logistic link, and the treatment variable T is often, but not always, the price of the good after normalizing the price of the outside option.\nRecall that \u039b(x) does not depend on the parameter function H(\u00b7 \u00b7 \u00b7 ), and must be computed\nonly once per model. In this case, for u = \u03b1(x) + \u03b2(x)t, G\u0307(u) = G(u)[1\u2212G(u)], and so\n\u039b(x) = E [ G(u)[1\u2212G(u)] ( 1 T\nT T 2\n)\u2223\u2223\u2223\u2223\u2223X = x ] ,\nwhich will be invertible under standard economic assumptions.\nThere are many interesting parameters of interest in choice models and to show the utility of our framework we give the influence function for two more, beyond the consumer surplus discussed in Section 5, which we can allow to be fully heterogeneous in X. Importantly, without our structural assumption of model (2.1) it would not be easy to characterize or interpret these parameters.\n(a) A measure of willingness-to-pay is obtained by setting H(x, \u03b1(x), \u03b2(x); t\u2217) = \u03b2(x)/\u03b1(x), and\nwe find dH(x) = (\u03b2\u22121,\u2212\u03b1\u03b2\u22122)\u2032.\n(b) The price elasticity at a price t\u2217 takes H = (1 \u2212 P[Y = 1|x, t\u2217)\u03b2(x)t\u2217, implying \u2207H(x) =\n(\u2212G\u0307\u03b2(x)t\u2217,\u2212G\u0307\u03b2(x)t\u22172 + (1\u2212G)t\u2217)\u2032.\nIn both cases, inserting these functions and partial derivations into (3.3) yields the influence function immediately. \u2663\nExample 8 (Count Models). Another set of models that can be trivially put into our modeling framework deals with count model. As an illustration consider the framework proposed by Manchanda and Chintagunta (2004) who seek to model the number of prescriptions (Yjm) written by physician j at time m as a function of the number of detailing calls made to the doctor tjm. The authors assume that the outcome follows a Poisson distribution with mean\n\u03bbjm = exp ( \u03b1j + \u03b21jtjm + \u03b22jt 2 jm ) .\nWhile they use parametric assumptions and a Bayesian estimator to deal with heterogeneity we can appropriately modify the heterogeneous parameters and write\nE [log Yjm |X = xj , Tjm = tjm] = \u03b1j(xj) + \u03b2(xj)tjm + \u03b22(xj)t2jm,\nwhich allows us to use our estimator and inference procedure. Note that the actual model continues to be Possion, we have simply re-expressed the mean. We can replace the underlying distribution (with, say a Negative Binomial) or extend it to incorporate some other structural elements as long as it permits the expression of the mean outcome in additive separable form with known link (G) and transform (gY ) functions. \u2663"
    },
    {
      "heading": "7 Extensions",
      "text": "Our main ideas for capturing individual heterogeneity can be used in many other contexts. Below, we explore several, important concrete examples: linear instrumental variable models, multinomial choices, and high-dimensional treatment variables. However, beyond these, the framework of Section 2 can be extended to many other economic contexts.\nThe class of parameters, \u03b80 of (2.3), can be expanded in useful ways. While any t \u2217 that is a closed-form function of \u03b1(X) and \u03b2(X) is automatically included, via redefinition of H, more interesting would be implicitly defined t\u2217. A leading example would be the optimal price in choice models, such as Section 5 or Example 7. Here t\u2217 solves a known function of \u03b1(x) and \u03b2(x). Provided numerical derivatives, other other key pieces, can be found, this extension can be easily accommodated.\nMore broadly, the heterogeneity structure (2.1) can be imposed on most M or Z estimation problems. One interesting setting to explore would be modeling heterogeneity in quantile regression models, compared to the mean restriction of (2.1). Such extensions will require some degree of situation-specific derivations, potentially undermining our goal of broad applicability. The next two subsections explore fruitful extensions, which fall outside the scope of our previous results, but need only manageable derivations. The final extension takes us further afield."
    },
    {
      "heading": "7.1 Instrumental Variables",
      "text": "We now relax the exogeneity of the variables of interest. Consider for simplicity the case with a single, but endogenous, treatment variable, and an instrument Z. It is natural in our setting to allow fully flexible observed heterogeneity in the effects of the instrument. We therefore arrive at the two-equation model\nY = \u03b1(X) + \u03b2(X)T + V, (7.1)\nT = \u03b60(X) + \u03b61(X)Z + U, (7.2)\nwhere E[V | X, Z] = E[U | X, Z] = 0. For estimation, and moreover, derivation of influence function, we simply plug (7.2) into (7.1) to obtain the reduced form equation\nY = \u03b1\u0303(X) + \u03b2\u0303(X)Z + V\u0303 ,\n\u03b1\u0303 = \u03b1(x) + \u03b2(x)\u03b60(x), \u03b2\u0303(x) = \u03b2(x)\u03b61(x), V\u0303 = U + V.\n(7.3)\nUsing the instruments in this way directly generalizes the standard two stage least squares approach to handle high-dimensional, complex observed heterogeneity. Deep learning is again well-suited to estimating the coefficient functions in (7.2) and (7.3), exactly following Section 2.1.\nWith this notation, we aim to recover a parameter that is a function of the coefficient functions\nof (7.2) and (7.3), given by\n\u03b80 = E [ H ( X, \u03b1\u0303, \u03b2\u0303, \u03b60, \u03b61; t \u2217 )] . (7.4)\nThe leading case is the average partial effect of the endogenous variable T : \u03b80 = E[\u03b2(X)] = E[\u03b2\u0303(X)/\u03b61(X)].\nAll our theoretical results are extensible to this model of endogeneity. Here we state the analog of Theorem 1, as the influence function result is the most interesting. Theorem 2 and Lemma 1 easily extend to cover this model, so we omit statements for brevity.\nProposition 1. Let Assumption 1 hold for (7.3) and (7.2), with W replaced by (Y,X \u2032, Z)\u2032 and (T,X \u2032, Z)\u2032, respectively, and \u039bZ(x) = E[Z\u0303Z\u0303 \u2032 |X = x] in place of \u039b(x), where Z\u0303 = (1, Z)\u2032. Then for \u03b80 of Equation (7.4), \u03c8iv(z, \u03b1,\u03b2,\u03bb)\u2212 \u03b80 is a valid and Neyman orthogonal score, where\n\u03c8IV(y, t, z,x, \u03b1\u0303, \u03b2\u0303, \u03b60, \u03b61,\u039bZ) = H ( x, \u03b1\u0303, \u03b2\u0303, \u03b60, \u03b61; t \u2217 )\n+ \u2207H(x)\u2032 \u039bZ(x)\u22121z\u0303 (y \u2212G (\u03b1(x) + \u03b2(x)\u2032t)) \u039bZ(x) \u22121z\u0303 (t\u2212 \u03b60(X) + \u03b61(X)Z)  . (7.5)\nThis result has the same structure as Theorem 1, as discussed there. Here there is an extra correction term, which accounts for the estimation of \u03b60 and \u03b61 in the first stage. This approach is far from the only option in instrumental variable models. Indeed, for the special case of homogeneous effects in a partially linear IV model, Chernozhukov et al. (2018) study two different scores, Equations (4.7) and (4.8) therein, and also mention in footnote 8 that their method for constructing\northogonal scores would yield a third option. Different scores sometimes require different functions be estimated in the first step. Our approach here aims for ease of use: (7.2) and (7.3) can be directly estimated using the deep learning architectures of Section 2.1. Extending to the case of multiple endogenous regressors or instruments is straightforward."
    },
    {
      "heading": "7.2 Multinomial Choice",
      "text": "Our main focus has been on scalar outcomes Y . The linear IV model, in some sense, shows how our framework extends to a vector-valued outcomes, with an equation per outcome. The multinomial choice model is another leading case of multiple outcomes and equations, this time with nonlinear link function. Here we state results for McFadden\u2019s multinomial choice model, which is the go-to structure across a variety of disciplines. Again, additional derivations and notation are required, but may be worth the cost given the ubiquity of this model. In Appendix D we give the full details, some of which are omitted here to save notation. There we also discuss other multinomial models.\nWe extend Example 7 and Section 5 by allowing for J > 1 alternative options, in addition to the default, or outside, option. The logistic structure is maintained. The outcome is the unit vector Y = (Y1, Y2, . . . , YJ) \u2032, where each Yj is binary and is assumed to obey\nE[Yj |X = x,T = t] = Gj (u1, u2, . . . , uJ) , with Gj = exp{uj} 1 + \u2211J m=1 exp{um} , (7.6)\nfor utility functions uj = uj(x, t), with u0 normalized to zero. The structure assumed in our main model, Equation (2.1), is then imposed on the uj , with different assumptions giving rise to different models. The leading case is McFadden\u2019s logit, which assumes\nuj(x, tj) = \u03b1j(x) + \u03b2(x) \u2032tj , (7.7)\nwhere the tj are option-specific characteristics, such as prices. The key restriction is that the coefficients \u03b2(x) are common to all options. Unrestricted, but still economically-structured, multinomial logit would set uj(x, t) = \u03b1j(x) + \u03b2j(x) \u2032t. Just as in prior cases, naively applying a machine classifier leaves uj(x, t) as unrestricted, nonparametric functions, and does not allow for the economic interpretability or the recovery of useful parameters.\nIt is important for both estimation and inference that the model structure be respected: both the DNN estimation and the influence function need to account for the common \u03b2 coefficients. For DNN estimation, the architecture discussed in Section 2.1 can be easily modified to this case. We replace the loss function in (2.4) with the usual multinomial loss for McFadden\u2019s logit and we jointly estimate the \u03b1 := (\u03b11, \u03b12, . . . , \u03b1J) \u2032 and \u03b2 functions. Here again the model structure, and in particular the commonality of \u03b2, is imposed in the estimation by creating enriched parameter and model layers, expanding on Figure 1. All the advantages of DNN estimation carry through to this setting.\nThe influence function calculation also has to be redone, and will be different for different restrictions on the choice-specific utilities. The influence function itself is notationally cumbersome, but conceptually is the natural generalization of Theorem 1 beyond binary choices. We defer a full, precise statement to Appendix D. Briefly, for a parameter\n\u03b80 = E[H(X,\u03b1(X),\u03b2(X); t\u22171, . . . , t\u2217J)],\nthe influence function will be \u03c8 \u2212 \u03b80,\n\u03c8(w,\u03b1,\u03b2, t\u22171, . . . , t \u2217 J) = H + \u2207HJ(x)\u2032\u039bJ(x)\u22121CJ(y,w,x)\nwith w = (y,x, t1, . . . , tJ) \u2032, H = H(x,\u03b1(x),\u03b2(x); t\u22171, . . . , t \u2217 J), and, as before, \u2207HJ is the appropriate vector of derivatives of H, \u039bJ is the conditional variance, and CJ are the residuals. All of these are given in Appendix D, and depend on the number of choices and the specific structure."
    },
    {
      "heading": "7.3 High Dimensional Treatments",
      "text": "In some applications it may be interesting to consider the case when the number of variables of interest is large, that is, when dim(T ) = K \u2192\u221e. Our results do not cover this case without either further restrictions or new methods, but a formal extension may be possible. A central problem is that, in the core structure of the model, namely \u03b1(x) + \u03b2(x)\u2032t, we allow for a distinct and fully flexible heterogeneous effect of each treatment variable, \u03b2k(x), k = 1, . . . ,K. When T is high dimensional, estimation of these functions will not be possible, at least not with sufficient precision\nto allow for inference. There is thus a natural tradeoff between the dimensionality of the treatment variables and the complexity of the heterogeneity. If a researcher can a priori restrict the form of the heterogeneity such that the functions \u03b2k(x) are simple, or in the extreme case, constant, then useful results can be obtained.\nIn this case, our results connect with the literature on debiasing in high dimensional regression. To see this, consider the linear model with constant effects, i.e., \u03b1(x) \u2261 0 and \u03b2(x) = \u03b2, so that E[Y | X = x,T = t] = \u03b2\u2032t. For this model, Javanmard and Montanari (2018) seek a Gaussian limit for \u221a n(\u03b2\u0302 \u2212 \u03b2) where\n\u03b2\u0302 = \u03b2\u0302lasso + 1\nn MTn\n( Yn \u2212 Tn\u03b2\u0302lasso ) ,\nwhere Yn = (y1, . . . , yn), Tn = (t \u2032 1, . . . , t \u2032 n) \u2032, \u03b2\u0302lasso is the lasso estimator and M is an estimator of \u039b = E[TT \u2032], which is not a function of X in this restricted model. The above display is in perfect analogy with our Theorem 1, and the second term serves essentially the same function in both cases. One may check that perturbations to \u03b2 do not have a first order effect in expectation, as required for Neyman orthogonality. Similar to our Theorem 2, they require that \u03b2\u0302lasso and M are \u201cgood enough\u201d first-stage estimators of \u03b2 and \u039b, respectively, which they prove for sparse regression under conditions on the design Tn. (To avoid a lengthy treatment, we defer precise details to them.)\nThe linear model above rules out all heterogeneity, and is therefore less interesting for our present purpose. An open question is how much flexible heterogeneity can be accommodated which still obtaining useful results. Kozbur (2020) allows for flexible \u03b1(x), so that E[Y | X = x,T = t] = \u03b1(x) + \u03b2\u2032t, and studies inference on functionals. Our ideas can be adapted to this model. The architecture we proposed in Section 2.1, shown in Figure 1, will need adjustment. Instead of learning the function \u03b2(x) in the parameter layer, the model layer will learn weights for edge between t and the outcome. Some form of regularization will be needed in this layer, and thus the end result will be a combination of deep learning and regularized high dimensional regression. A formal exploration of this combination is a promising direction for future research."
    },
    {
      "heading": "8 Conclusion",
      "text": "We have provided a complete methodological framework for using machine learning in economic models to exploit rich, complex data on individual heterogeneity. We showed that deep learning is ideally suited to this task among modern machine learning methods and we detailed a new network architecture that is designed to estimate economically meaningful objects, moving past pure prediction and towards structural modeling. We gave results for the estimation of heterogeneity using deep learning, showing how our architecture delivers improved rates of convergence. Subsequent inference is proven valid building on a newly calculated influence function.\nOur framework covers a wide variety of interesting contexts. The combination of the specification we adopt, the availability of computing infrastructure, and the theory presented above offer a perfect package for applied researchers."
    },
    {
      "heading": "9 References",
      "text": "Abadi, M., A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane\u0301, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vie\u0301gas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng (2015): \u201cTensorFlow: Large-Scale Machine Learning on Heterogeneous Systems,\u201d Software available from tensorflow.org.\nAthey, S. and G. Imbens (2016): \u201cRecursive partitioning for heterogeneous causal effects,\u201d Proceedings of the National Academy of Sciences, 113, 7353\u20137360.\nAthey, S., G. W. Imbens, and S. Wager (2018): \u201cApproximate residual balancing: De-biased inference of average treatment effects in high dimensions,\u201d Journal of the Royal Statistical Society, Series B, 80, 597\u2013623.\nAthey, S., J. Tibshirani, and S. Wager (2019): \u201cGeneralized random forests,\u201d The Annals of Statistics, 47, 1148\u20131178.\nBach, F. (2017): \u201cBreaking the curse of dimensionality with convex neural networks,\u201d The Journal of Machine Learning Research, 18, 629\u2013681.\nBajari, P., D. Nekipelov, S. P. Ryan, and M. Yang (2015): \u201cMachine Learning Methods for Demand Estimation,\u201d American Economic Review, 105, 481\u201385.\nBauer, B. and M. Kohler (2019): \u201cOn deep learning as a remedy for the curse of dimensionality in nonparametric regression,\u201d Annals of Statistics, 47, 2261\u20132285.\nBelloni, A., V. Chernozhukov, I. Ferna\u0301ndez-Val, and C. Hansen (2017): \u201cProgram Evaluation and Causal Inference With High-Dimensional Data,\u201d Econometrica, 85, 233\u2013298.\nBelloni, A., V. Chernozhukov, and C. Hansen (2014): \u201cInference on Treatment Effects after Selection Amongst High-Dimensional Controls,\u201d Review of Economic Studies, 81, 608\u2013650.\nBerry, S. T. (1994): \u201cEstimating discrete-choice models of product differentiation,\u201d The RAND Journal of Economics, 25, 242\u2013262.\nBlanchet, J., Y. Kang, J. L. M. Olea, V. A. Nguyen, and X. Zhang (2020): \u201cMachine Learning\u2019s Dropout Training is Distributionally Robust Optimal,\u201d arXiv:2009.06111.\nCattaneo, M. D. (2010): \u201cEfficient Semiparametric Estimation of Multi-valued Treatment Effects under Ignorability,\u201d Journal of Econometrics, 155, 138\u2013154.\nCattaneo, M. D., R. K. Crump, M. H. Farrell, and Y. Feng (2019a): \u201cOn Binscatter,\u201d arXiv:1902.09608.\nCattaneo, M. D., R. K. Crump, M. H. Farrell, and E. Schaumburg (2020a): \u201cCharacteristic-Sorted Portfolios: Estimation and Inference,\u201d Review of Economics and Statistics, 101, 531\u2013551.\nCattaneo, M. D., R. K. Crump, and M. Jansson (2013): \u201cGeneralized Jackknife Estimators of Weighted Average Derivatives,\u201d Journal of the American Statistical Association, 108, 1243\u20131256. Cattaneo, M. D. and M. H. Farrell (2011): \u201cEfficient Estimation of the Dose Response Function under Ignorability using Subclassification on the Covariates,\u201d in Advances in Econometrics: Missing Data Methods, ed. by D. Drukker, Emerald Group Publishing Limited, vol. 27A, 93\u2013127. \u2014\u2014\u2014 (2013): \u201cOptimal Convergence Rates, Bahadur Representation, and Asymptotic Normality of Partitioning Estimators,\u201d Journal of Econometrics, 174, 127\u2013143. Cattaneo, M. D., M. H. Farrell, and Y. Feng (2020b): \u201cLarge Sample Properties of Partitioning-based Series Estimators,\u201d Annals of Statistics, 48, 1718\u20131741. Cattaneo, M. D. and M. Jansson (2019): \u201cAverage Density Estimators: Efficiency and Bootstrap Consistency,\u201d arXiv:1904.09372. Cattaneo, M. D., M. Jansson, and X. Ma (2019b): \u201cTwo-step Estimation and Inference with Possibly Many Included Covariates,\u201d Review of Economic Studies, 86, 1095\u20131122. Cattaneo, M. D., M. Jansson, and W. K. Newey (2018): \u201cInference in Linear Regression Models with Many Covariates and Heteroskedasticity,\u201d Journal of the American Statistical Association, 113, 1350\u20131361. Chen, R. and R. Tsay (1993): \u201cFunctional-coefficient autoregressive models,\u201d Journal of the American Statistical Association, 88, 298\u2013308. Chen, X. and S. C. Ludvigson (2009): \u201cLand of addicts? an empirical investigation of habitbased asset pricing models,\u201d Journal of Applied Econometrics, 24, 1057\u20131093. Chernozhukov, V., D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, W. Newey, and J. Robins (2018): \u201cDouble/debiased machine learning for treatment and structural parameters,\u201d The Econometrics Journal, 21, C1\u2013C68. Chernozhukov, V., M. Demirer, G. Lewis, and V. Syrgkanis (2019): \u201cSemi-Parametric Efficient Policy Learning with Continuous Actions,\u201d in Advances in Neural Information Processing Systems 32, ed. by H. Wallach, H. Larochelle, A. Beygelzimer, F. d\u2019Alche\u0301 Buc, E. Fox, and R. Garnett, 15065\u201315075. Chernozhukov, V., W. Newey, and R. Singh (2020a): \u201cDe-Biased Machine Learning of Global and Local Parameters Using Regularized Riesz Representers,\u201d arXiv:1802.08667. Chernozhukov, V., W. K. Newey, and R. Singh (2020b): \u201cAutomatic Debiased Machine Learning of Causal and Structural Effects,\u201d arXiv:1809.05224. Cleveland, W. S., E. Grosse, and W. M. Shyu (1991): \u201cLocal regression models,\u201d in Statistical models in S, ed. by J. M. Chambers and T. Hastie, Pacific Grove: Wadsworth and Brooks/Cole, 309\u2013376. Colangelo, K. and Y.-Y. Lee (2020): \u201cDouble Debiased Machine Learning Nonparametric Inference with Continuous Treatments,\u201d arXiv:2004.03036. Diebold, F. X. and M. Shin (2019): \u201cMachine learning for regularized survey forecast combination: Partially-egalitarian LASSO and its derivatives,\u201d International Journal of Forecasting, 35, 1679\u20131691.\nDube, J.-P. H. and S. Misra (2019): \u201cPersonalized Pricing and Customer Welfare,\u201d Available at SSRN: https://ssrn.com/abstract=2992257. Fan, J. and W. Zhang (2008): \u201cStatistical methods with varying coefficient models,\u201d Statistics and Its Interface, 1, 179\u2013195. Farrell, M. H. (2015): \u201cRobust Inference on Average Treatment Effects with Possibly More Covariates than Observations,\u201d arXiv:1309.4686, Journal of Econometrics, 189, 1\u201323. Farrell, M. H., T. Liang, and S. Misra (2019): \u201cDeep Neural Networks for Estimation and Inference,\u201d arXiv:1809.09953, Econometrica, forthcoming. Gentzkow, M., B. Kelly, and M. Taddy (2019a): \u201cText as data,\u201d Journal of Economic Literature, 57, 535\u201374. Gentzkow, M., J. M. Shapiro, and M. Taddy (2019b): \u201cMeasuring group differences in high-dimensional choices: method and application to congressional speech,\u201d Econometrica, 87, 1307\u20131340. Goodfellow, I., Y. Bengio, and A. Courville (2016): Deep learning, Cambridge: MIT Press. Graham, B. S. and C. C. d. X. Pinto (2018): \u201cSemiparametrically efficient estimation of the average linear regression function,\u201d Journal of Econometrics, forthcoming. Gu, S., B. Kelly, and D. Xiu (2020): \u201cEmpirical Asset Pricing via Machine Learning,\u201d The Review of Financial Studies, 33, 2223\u20132273. Hahn, J. (1998): \u201cOn the Role of the Propensity Score in Efficient Semiparametric Estimation of Average Treatment Effects,\u201d Econometrica, 66, 315\u2013331. Hanin, B. (2017): \u201cUniversal function approximation by deep neural nets with bounded width and relu activations,\u201d arXiv preprint arXiv:1708.02691. Hastie, T. and R. Tibshirani (1993): \u201cVarying-Coefficient Models,\u201d Journal of the Royal Statistical Society, Series B, 55, 757\u2013796. Hirano, K. and G. W. Imbens (2004): \u201cThe Propensity Score with Continuous Treatments,\u201d in Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives, ed. by G. A. and X.-L. Meng, New York: Wiley, 73\u201384. Hirshberg, D. A. and S. Wager (2019): \u201cAugmented Minimax Linear Estimation,\u201d arXiv:1712.00038. Hitsch, G. J. and S. Misra (2018): \u201cHeterogeneous Treatment Effects and Optimal Targeting Policy Evaluation,\u201d SSRN preprint 3111957. Huang, J. Z. and H. Shen (2004): \u201cFunctional coefficient regression models for non-linear time series: a polynomial spline approach,\u201d Scandinavian Journal of Statistics, 31, 515\u2013534. Ichimura, H. and W. K. Newey (2015): \u201cThe influence function of semiparametric estimators,\u201d arXiv preprint arXiv:1508.01378. Igami, M. (2020): \u201cArtificial intelligence as structural estimation: Deep Blue, Bonanza, and AlphaGo,\u201d The Econometrics Journal, forthcoming.\nJavanmard, A. and A. Montanari (2018): \u201cDebiasing the lasso: Optimal sample size for gaussian designs,\u201d The Annals of Statistics, 46, 2593\u20132622.\nKaji, T., E. Manresa, and G. Pouliot (2020): \u201cAn adversarial approach to structural estimation,\u201d arXiv preprint arXiv:2007.06169.\nKallus, N. (2018): \u201cDeepmatch: Balancing deep covariate representations for causal inference using adversarial training,\u201d arXiv preprint arXiv:1802.05664.\nKennedy, E. H., Z. Ma, M. D. McHugh, and D. S. Small (2017): \u201cNonparametric methods for doubly robust estimation of continuous treatment effects,\u201d Journal of the Royal Statistical Society. Series B, Statistical Methodology, 79, 1229.\nKosorok, M. R. (2008): Introduction to Empirical Processes and Semiparametric Inference, Springer-Verlag.\nKozbur, D. (2020): \u201cInference in additively separable models with a high-dimensional set of conditioning variables,\u201d Journal of Business & Economic Statistics, forthcoming.\nLeeb, H. and B. M. Po\u0308tscher (2005): \u201cModel Selection and Inference: Facts and Fiction,\u201d Econometric Theory, 21, 21\u201359.\nLi, Q., C. J. Huang, D. Li, and T.-T. Fu (2002): \u201cSemiparametric smooth coefficient models,\u201d Journal of Business & Economic Statistics, 20, 412\u2013422.\nLiang, T. (2018): \u201cOn How Well Generative Adversarial Networks Learn Densities: Nonparametric and Parametric Results,\u201d arXiv:1811.03179.\nLiang, T. and H. Tran-Bach (2020): \u201cMehler\u2019s Formula, Branching Process, and Compositional Kernels of Deep Neural Networks,\u201d arXiv preprint arXiv:2004.04767.\nMammen, E. and S. van de Geer (1997): \u201cPenalized quasi-likelihod estimation in partially linear models,\u201d Annals of Statistics, 25, 1014\u20131035.\nManchanda, P. and P. Chintagunta (2004): \u201cResponsiveness of Physician Prescription Behavior to Salesforce Effort: An Individual Level Analysis,\u201d Marketing Letters, 129\u2013145.\nMullainathan, S. and Z. Obermeyer (2019): \u201cA Machine Learning Approach to Low-Value Health Care: Wasted Tests, Missed Heart Attacks and Mis-Predictions,\u201d NBER Working Paper 26168.\nMullainathan, S. and J. Spiess (2017): \u201cMachine Learning: An Applied Econometric Approach,\u201d Journal of Economic Perspectives, 31, 87\u2013106.\nNevo, A. (2001): \u201cMeasuring Market Power in the Ready-to-Eat Cereal Industry,\u201d Econometrica, 69, 307\u2013342.\nNewey, W. K. (1990): \u201cSemiparametric efficiency bounds,\u201d Journal of Applied Econometrics, 5, 99\u2013135.\n\u2014\u2014\u2014 (1994): \u201cThe Asymptotic Variance of Semiparametric Estimators,\u201d Econometrica, 62, 1349\u2013 1382.\nNewey, W. K. and J. M. Robins (2018): \u201cCross-fitting and fast remainder rates for semiparametric estimation,\u201d arXiv preprint arXiv:1801.09138.\nO\u2019Hagan, A. (1978): \u201cCurve fitting and optimal design for prediction,\u201d Journal of the Royal Statistical Society: Series B, 40, 1\u201324.\nOkui, R., D. S. Small, Z. Tan, and J. M. Robins (2012): \u201cDoubly Robust Instrumental Variable Regression,\u201d Statistica Sinica, 22, 173\u2013205.\nPapke, L. E. (1995): \u201cParticipation in and Contributions to 401(k) Pension Plans: Evidence from Plan Data,\u201d The Journal of Human Resources, 30, 311\u2013325.\nPapke, L. E. and J. M. Wooldridge (1996): \u201cEconometric methods for fractional response variables with an application to 401 (k) plan participation rates,\u201d Journal of Applied Econometrics, 11, 619\u2013632.\nPolson, N. G. and V. Roc\u030ckova\u0301 (2018): \u201cPosterior concentration for sparse deep learning,\u201d in Advances in Neural Information Processing Systems, 930\u2013941.\nPowell, J. L., J. H. Stock, and T. M. Stoker (1989): \u201cSemiparametric Estimation of Index Coefficients,\u201d Econometrica, 57, 1403\u20131430.\nSchmidt-Hieber, J. (2019): \u201cNonparametric regression using deep neural networks with ReLU activation function,\u201d arXiv:1708.06633, Annals of Statistics, forthcoming.\nStone, C. J., M. H. Hansen, C. Kooperberg, and Y. K. Truong (1997): \u201cPolynomial splines and their tensor products in extended linear modeling: 1994 Wald memorial lecture,\u201d The Annals of Statistics, 25, 1371\u20131470.\nWang, Y. and V. Roc\u030ckova\u0301 (2020): \u201cUncertainty Quantification for Sparse Deep Learning,\u201d in Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics.\nWei, Y. and Z. Jiang (2019): \u201cEstimating Parameters of Structural Models Using Neural Networks,\u201d SSRN 3496098.\nWooldridge, J. M. (2004): \u201cEstimating average partial effects under conditional moment independence assumptions,\u201d cemmap working paper CWP03/04.\nYarotsky, D. (2017): \u201cError bounds for approximations with deep ReLU networks,\u201d Neural Networks, 94, 103\u2013114.\nZeileis, A., T. Hothorn, and K. Hornik (2008): \u201cModel-based recursive partitioning,\u201d Journal of Computational and Graphical Statistics, 17, 492\u2013514."
    },
    {
      "heading": "A Proof of Theorem 1: Influence Function Derivation and Ney-",
      "text": "man Orthogonality\nHere we prove Theorem 1. We first derive the novel influence function and then below we show Neyman orthogonality.\nA.1 Influence Function Derivation\nOur aim here is to show the main steps of the influence function calculation and the novel innovation is in the application; our interest is not in reviewing the details of semiparametric theory. For in-depth treatments, including discussion of regularity conditions, efficiency bounds, and other concerns, see Newey (1990), Newey (1994), and Ichimura and Newey (2015). Note that here our purpose is to derive the estimator itself, not to find the efficiency bound. Our derivation follows the pathwise derivative method as described by Newey (1994) (to whom we defer for precise regularity conditions, such as for interchanging differentiation and integration, rather than copying them down here).\nThe starting point is a parametric submodel which we shall index by \u03b7, so that the data distribution is F\u03b7 and the true distribution is F\u03b7|\u03b7=0. Along this submodel the true parameter is \u03b8(\u03b7) = \u222b H (x, \u03b1(x; \u03b7),\u03b2(x; \u03b7); t\u2217) f(x; \u03b7)dx, where f(\u00b7) is the density of x and \u03b1(x; \u03b7) and \u03b2(x; \u03b7) are the true functions for a given \u03b7. As a matter of notation, we often omit the dependence on \u03b7 when evaluating at \u03b7 = 0, so that, for example, \u03b2(x; 0) is written as \u03b2(x).\nFor the (true) score S(y,x, t; \u03b7 = 0) = S(y,x, t) of the parametric submodel we must find a\nfunction \u03c8(y,x, t) such that\n\u2202\u03b8(\u03b7)\n\u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 = E[\u03c8(y,X,T )S(y,X,T )]. (A.1)\nRecall that \u03b1(x) is a scalar and \u03b2(x) is the K-vector (\u03b21(x), \u03b22(x), . . . , \u03b2K(x)) \u2032. Indexing each\nof these, and the density, by \u03b7, and then applying the chain rule we have\n\u2202\u03b8(\u03b7)\n\u2202\u03b7 =\n\u2202\n\u2202\u03b7\n\u222b H (x, \u03b1(x; \u03b7),\u03b2(x; \u03b7); t\u2217) f(x; \u03b7)dx\n= \u222b H (x, \u03b1(x),\u03b2(x); t\u2217) \u2202f(x; \u03b7)\n\u2202\u03b7 dx+\n\u222b ( \u2207H \u2032(\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)\u2032 ) f(x; 0)dx, (A.2)\nwhere\n\u03b1\u0307 = \u2202\u03b1(x; \u03b7)\n\u2202\u03b7\n\u2223\u2223\u2223\u2223 \u03b7=0 , \u03b2\u0307k = \u2202\u03b2k(x; \u03b7) \u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 , k = 1, . . . ,K, \u2207H = ( \u2202H \u2202\u03b1 , \u2202H \u2202\u03b21 , . . . , \u2202H \u2202\u03b2K )\u2032 .\nWe will show that both terms of Equation (A.2) above can be written as expectations of products\nwith the full score S(y,x, t), as required by (A.1). We will use the standard fact that\nS(y,x, t) = S(y, t | x) + S(x). (A.3)\nThe first term of Equation (A.2) is\u222b H (x, \u03b1(x),\u03b2(x); t\u2217) \u2202f(x; \u03b7)\n\u2202\u03b7 dx = E [H (X, \u03b1(X),\u03b2(X); t\u2217)S(X)]\n= E [H (X, \u03b1(X),\u03b2(X); t\u2217)S(Y,X,T )] (A.4)\nwhere the first equality holds because the marginal score S(x)f(x) = \u2202f(x; \u03b7)/\u2202\u03b7|\u03b7=0 and the second equality follows from the usual mean zero property of scores and (A.3):\nE [H(\u03b1(X), \u03b2(X))S(Y,T |X)] = E [ H(\u03b1(X), \u03b2(X))E [S(Y,T |X) |X] ] = 0.\nThis first term is then the standard \u201cplug-in\u201d portion of the influence function, that is, the term that would appear if \u03b1(x) and \u03b2(x) were known functions. The second term of Equation (A.2) will give rise to the correction factor that accounts for the nonparametric estimation.\nFor the second term of Equation (A.2), because the function H(\u00b7) is known, the partial derivatives of H with respect to \u03b1 and \u03b2 are known; that is, \u03b7 does not appear in \u2207H. Thus we must find (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K), then evaluate the result at \u03b7 = 0, and finally, upon substituting these into the second term of (A.2), write the result in the required form.\nTo find (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K) we use the fact that the relevant first order condition holds as an identity in \u03b7, because for any submodel we may apply maximum likelihood. This step leverages the GLM structure. It will be convenient define t\u0303 = (1, t\u2032)\u2032. As an identity in \u03b7,\nE\u03b7 [( Y \u2212G ( \u03b1(X; \u03b7) + \u03b2(X; \u03b7)\u2032T )) T\u0303 \u2032 \u2223\u2223\u2223X] \u2261 0.\nThe expectation is also indexed by \u03b7 in the submodel, as the density depends on \u03b7. Making this explicit gives the form\u222b ( y \u2212G ( \u03b1(x; \u03b7) + \u03b2(x; \u03b7)\u2032t )) t\u0303\u2032f(y, t; \u03b7 | x)dydt \u2261 0.\nDifferentiating this identity and evaluating at \u03b7 = 0 we obtain\nE [( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303 \u2032S(Y,T |X) \u2223\u2223\u2223X]\u2212 E[ \u2202G \u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 T\u0303 \u2032 \u2223\u2223\u2223\u2223\u2223X ] = 0, (A.5)\nwhere S(Y,T |X) is the conditional score. Let G\u0307 denote the derivative of G(u) with respect to its scalar argument. Applying the chain rule, pulling out the common G\u0307, and collecting the derivatives\ninto a vector, we have\n\u2202G \u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 = G\u0307\u03b1\u0307+ G\u0307\u03b2\u03071z1 + \u00b7 \u00b7 \u00b7+ G\u0307\u03b2\u0307KzK = G\u0307 \u00b7 (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)t\u0303\nSubstituting this into the second term of the prior display we find that\nE\n[ \u2202G\n\u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 T\u0303 \u2032 \u2223\u2223\u2223\u2223\u2223X ] = E [ G\u0307 \u00b7 (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)T\u0303 T\u0303 \u2032 \u2223\u2223\u2223X] = (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)E [G\u0307T\u0303 T\u0303 \u2032\u2223\u2223\u2223X] , where the second equality holds because \u03b1(x) and \u03b2(x) are not functions of t and G\u0307 is a scalar.\nDefine \u039b(x) = E [ G\u0307T\u0303 T\u0303 \u2032 \u2223\u2223\u2223X = x], the final factor in this result. Then Equation (A.5) becomes E [( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303 \u2032S(Y,T |X)\n\u2223\u2223\u2223X]\u2212 (\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)\u039b(X) = 0. Therefore, assuming \u039b(x)\u22121 exists,\n(\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K) \u2032 = \u039b(x)\u22121E [( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303S(Y,T |X) \u2223\u2223\u2223X] . Thus we can re-write the second term of Equation (A.2) by substituting this form\u222b (\n\u2207H \u2032(\u03b1\u0307, \u03b2\u03071, . . . , \u03b2\u0307K)\u2032 ) f(x; 0)dx\n= E [ E [ \u2207H \u2032\u039b(X)\u22121 ( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303S(Y,T |X) \u2223\u2223\u2223X]] = E [ \u2207H \u2032\u039b(X)\u22121 ( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303S(Y,T |X)\n] = E [ \u2207H \u2032\u039b(X)\u22121 ( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303S(Y,X,T ) ] , (A.6)\nwhere the last line follows by the conditional mean zero property of the residual Y\u2212G (\u03b1(X) + \u03b2(X)\u2032T ), and therefore, using (A.3)\nE [ \u2207H \u2032\u039b(x)\u22121 ( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303 \u2032S(X) ] = E [ \u2207H \u2032\u039b(x)\u22121E [( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) |X ] T\u0303S(X) ] = 0.\nThus, combining Equations (A.4) and (A.6) with (A.2), we find that\n\u2202\u03b8(\u03b7)\n\u2202\u03b7 \u2223\u2223\u2223\u2223 \u03b7=0 = E [H (X, \u03b1(X),\u03b2(X); t\u2217)S(Y,X,T )]\n+ E [ \u2207H \u2032\u039b(X)\u22121 ( Y \u2212G ( \u03b1(X) + \u03b2(X)\u2032T )) T\u0303S(Y,X,T ) ] , (A.7)\nverifying Equation (A.1) with\n\u03c8(y,x, t) = H (x, \u03b1(x),\u03b2(x); t\u2217) + \u2207H(x)\u2032\u039b(x)\u22121t\u0303 ( y \u2212G ( \u03b1(x) + \u03b2(x)\u2032t )) . (A.8)\nwhere we have made the dependence of \u2207H(x) on x explicit and, to repeat, \u039b(x) = E [ G\u0307T\u0303 T\u0303 \u2032 \u2223\u2223\u2223X = x]. This is not an influence function as it lacks the appropriate centering, but of course E[\u03b80S(Y,X,T )] = \u03b80E[S(Y,X,T )] = 0, and thus we can freely center this \u03c8(t) and still obey (A.1).\nA.2 Neyman Orthogonality\nIt remains to verify Neyman orthogonality. This in fact must hold as a result of the influence function calculation, which explicitly calculates the linear remainder term that would arise from the plug in estimator. However, as it may be instructive, we verify the required property here for the scalar case, where dim(T ) = K = 1 as in Remark 2, so that\n\u03c8(w, \u03b1, \u03b2,\u03bb) = H (x, \u03b1(x), \u03b2(x); t\u2217)\n+ H\u0307\u03b1(x) (\u03bb2(x)\u2212 \u03bb1(x)t) + H\u0307\u03b2(x) (\u03bb0(x)t\u2212 \u03bb1(x)) \u03bb2(x)\u03bb0(x)\u2212 \u03bb1(x)2 ( y \u2212G(\u03b1(x) + \u03b2(x)t) ) .\nFor complete discussion and notation, we refer the reader to Chernozhukov et al. (2018) and their Definition 2.1. For any \u03b1\u0303 let \u2206\u03b1 = (\u03b1 \u2212 \u03b1\u0303) represent the deviation from the true \u03b1(x). Similarly define \u2206\u03b2 and \u2206\u03bbk for k = 0, 1, 2, and collect the latter as \u03bb + r\u2206\u03bb. We then evaluate \u2202rE[\u03c8(w, \u03b1 + r\u2206\u03b1, \u03b2 + r\u2206\u03b2,\u03bb + r\u2206\u03bb)] and show that at r = 0 this derivative vanishes. We omit arguments when this causes no confusion and unless stated otherwise, functions are evaluated at r = 0. Define H\u0308\u03b1,\u03b1 = \u2202H\u0307\u03b1/\u2202\u03b1 and H\u0308\u03b1,\u03b2 = \u2202H\u0307\u03b1/\u2202\u03b2 and similarly for H\u0308\u03b2,\u03b1 and H\u0308\u03b2,\u03b2 . Assumption 1 provides sufficient regularity for differentiation inside expectations. We the find \u2202r\u03c8(w, \u03b1+r\u2206\u03b1, \u03b2+ r\u2206\u03b2,\u03bb+ r\u2206\u03bb) is equal to:\nH\u0307\u03b1\u2206\u03b1 + H\u0307\u03b2\u2206\u03b2 + 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{( H\u0308\u03b1,\u03b1\u2206\u03b1 + H\u0308\u03b1,\u03b2\u2206\u03b2 ) (\u03bb2 \u2212 \u03bb1t) (y \u2212G)\n\u2212 H\u0307\u03b1 (\u03bb2 \u2212 \u03bb1t) G\u0307(\u2206\u03b1 + \u2206\u03b2t) + H\u0307\u03b1 (\u2206\u03bb2 \u2212\u2206\u03bb1t) (y \u2212G)\n+ ( H\u0308\u03b2,\u03b1\u2206\u03b1 + H\u0308\u03b2,\u03b2\u2206\u03b2 ) (\u03bb0t\u2212 \u03bb1) (y \u2212G) \u2212 H\u0307\u03b2 (\u03bb0t\u2212 \u03bb1) G\u0307(\u2206\u03b1 + \u2206\u03b2t)\n+ H\u0307\u03b1 (\u2206\u03bb0t\u2212\u2206\u03bb1) (y \u2212G) }\n\u2212 (\n1\n\u03bb2\u03bb0 \u2212 \u03bb21\n)2 (\u2206\u03bb2\u03bb0 + \u03bb2\u2206\u03bb0 \u2212 2\u03bb1\u2206\u03bb1) [ H\u0307\u03b1 (\u03bb2 \u2212 \u03bb1t) + H\u0307\u03b2 (\u03bb0t\u2212 \u03bb1) ] (y \u2212G).\nAll terms containing the residual (y \u2212G) are mean zero by assumption. We therefore have \u2202rE [\u03c8(w, \u03b1+ r\u2206\u03b1, \u03b2 + r\u2206\u03b2,\u03bb+ r\u2206\u03bb)] \u2223\u2223\u2223 r=0\n= E [ H\u0307\u03b1\u2206\u03b1 + H\u0307\u03b2\u2206\u03b2 ] \u2212 E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1 (\u03bb2 \u2212 \u03bb1t) G\u0307(\u2206\u03b1 + \u2206\u03b2t) + H\u0307\u03b2 (\u03bb0t\u2212 \u03bb1) G\u0307(\u2206\u03b1 + \u2206\u03b2t) }] . (A.9)\nMultiplying out, the second term on the right hand side is\nE [\n1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2G\u0307\u2206\u03b1 + H\u0307\u03b1\u03bb2G\u0307\u2206\u03b2t\u2212 H\u0307\u03b1\u03bb1tG\u0307\u2206\u03b1 \u2212 H\u0307\u03b1\u03bb1t2G\u0307\u2206\u03b2 }] + E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b2\u03bb0tG\u0307\u2206\u03b1 + H\u0307\u03b2\u03bb0t 2G\u0307\u2206\u03b2 \u2212 H\u0307\u03b2\u03bb1G\u0307\u2206\u03b1 \u2212 H\u0307\u03b2\u03bb1G\u0307\u2206\u03b2t }] .\n(A.10)\nWe next apply iterated expectations (conditioning on X) to each of these terms and use the definition of \u03bbk = \u03bbk(x) = E[G\u0307T k |X = x]. For example, the first term above is\nE [\n1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2G\u0307\u2206\u03b1 }] = E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2E[G\u0307 |X]\u2206\u03b1 }] = E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2\u03bb0\u2206\u03b1 }] .\nApplying this to all the terms, we find that Equation (A.10) is equal to\nE [\n1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2\u03bb0\u2206\u03b1 + H\u0307\u03b1\u03bb2\u03bb1\u2206\u03b2 \u2212 H\u0307\u03b1\u03bb21\u2206\u03b1 \u2212 H\u0307\u03b1\u03bb1\u03bb2\u2206\u03b2 }] + E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b2\u03bb0\u03bb1\u2206\u03b1 + H\u0307\u03b2\u03bb0\u03bb2\u2206\u03b2 \u2212 H\u0307\u03b2\u03bb1\u03bb0\u2206\u03b1 \u2212 H\u0307\u03b2\u03bb21\u2206\u03b2 }] .\nCanceling the second and fourth terms in the first line and the first and third terms in the second line, and then collecting the remaining terms, we find that this is equal to\nE [\n1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u03bb2\u03bb0\u2206\u03b1 \u2212 H\u0307\u03b1\u03bb21\u2206\u03b1 }] + E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ +H\u0307\u03b2\u03bb0\u03bb2\u2206\u03b2 \u2212 H\u0307\u03b2\u03bb21\u2206\u03b2 }] = E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b1\u2206\u03b1 ( \u03bb2\u03bb0 \u2212 \u03bb21 )}] + E [ 1\n\u03bb2\u03bb0 \u2212 \u03bb21\n{ H\u0307\u03b2\u2206\u03b2 ( \u03bb2\u03bb0 \u2212 \u03bb21 )}] = E [ H\u0307\u03b1\u2206\u03b1 ] + E [ H\u0307\u03b2\u2206\u03b2 ] .\nThis is the final form of the second term on the right of Equation (A.9), where it enters negatively and cancels with the first term, yielding the desired zero derivative condition."
    },
    {
      "heading": "B Proof of Theorem 2: Asymptotic Normality",
      "text": "The result follows from Theorems 3.1 and 3.2 of Chernozhukov et al. (2018) upon verifying Assumptions 3.1 and 3.2 therein. Assumption 3.1(a) holds by construction for \u03c8 given in Theorem 1:\nthe first term of \u03c8 has mean \u03b80 by (2.3) while the second is (conditionally) mean zero as assumed by the model (2.1) and with \u039b(x)\u22121 is bounded. Assumption 3.1(b), linearity, holds by definition of (2.3). Assumption 3.1(c) holds by Assumption 1, in particular the assumed smoothness on H and G and the nonsingularity of \u039b(x). Assumption 3.1(d), Neyman orthogonality, is verified as part of Theorem 1. Assumption 3.1(e) holds trivially as the matrix J0 therein is the number one.\nAssumption 3.2, parts (b) and (d) follow directly from the moment conditions imposed in Assumption 1. Conditions (a) and (c) follow from Equations (3.7) and (3.8) of Chernozhukov et al. (2018) and the assumed convergence of the first stage estimates."
    },
    {
      "heading": "C Results for Deep Learning",
      "text": "We now prove results stated in the main text for \u03b1(x), \u03b2(x), and \u039b(x). We begin with identification of the former two and then establish the rates of Lemma 1.\nLemma C.1. Under Assumption 1, the functions \u03b1(x) and \u03b2(x) are identified. Proof. Denote \u03be(x) = (\u03b1(x),\u03b2(x)\u2032)\u2032 (as in Equation (2.2)). Since G is invertible and conditional expectations are always identified, the quantity G\u22121(E[Y |X = x,T = t]) is identified. Suppose that \u03be(x) is not identified. Then there exists \u03be1(x) and \u03be2(x) such that G\n\u22121 (E[Y |X = x,T = t]) = \u03be1(x) \u2032t\u0303 = \u03be2(x) \u2032t\u0303 a.e. or equivalently that for \u03be\u2217(x) = \u03be1(x)\u2212 \u03be2(x), G\u22121 (E[Y |X = x,T = t]) = \u03be\u2217(x) \u2032t\u0303 = 0. But \u03be\u2217(x) \u2032 1t = 0 a.e. implies that\n0 = E [( \u03be\u2217(x) \u2032t )2 | x] = \u03be\u2217(x)\u2032E[T\u0303 T\u0303 \u2032|X]\u03be\u2217(x),\nbut because the middle matrix is positive definite, this means that \u03be\u2217(x) is zero. For linear G, this argument is given in Huang and Shen (2004) among others.\nProof of Lemma 1 for \u03b1(x) and \u03b2(x). We start with the bound given in Farrell et al. (2019, Theorem 2), which is generic both in terms of the complexity and the approximation bias. We will use this to obtain the rate at which g(G(\u03b1\u0302(x) + \u03b2\u0302(x)\u2032t)) converges to g(G(\u03b1(x) +\u03b2(x)\u2032t)). Since g(u) and G(u) are known and smooth, we then obtain the same rate for \u03b1\u0302(x) + \u03b2\u0302(x)\u2032t. The assumed form of the model, Equation (2.1), and its equivalent in the architecture, Section 2.1, is exploited to ensure that the rates do not depend on the dimension of T , only X.\nConsider the approximation first. It follows from Yarotsky (2017) that there are (separate) DNNs which approximate \u03b1(x) and \u03b2k(x), k = 1, . . . ,K. The depth and width to obtain a given approximation error may be read off from Yarotsky (2017) or the concise restatement in Farrell et al. (2019, Lemma 7). Importantly, only dC matters here: the dimensionality of the approximation problem is only in terms of x, not t. That is, the results guarantee approximation for any smooth function, and therefore we can form DNNs \u03b1\u0304n(x) and \u03b2\u0304k,n(x) such that \u2016\u03b1\u0304n\u2212\u03b1\u2016\u221e \u2264 and maxk \u2016\u03b2\u0304k,n \u2212 \u03b2n\u2016\u221e \u2264 , where each DNN has L( ) \u2264 C \u00b7 (log(1/ ) + 1) and W ( ), U( ) \u2264 C \u00b7 \u2212 dC p (log(1/ ) + 1), and the constants C only depend on dC and p. Then, because the linear\nindex form of g(G(\u03b1(x) +\u03b2(x)\u2032t)) is known these approximating DNNs can be combined following the architecture of Section 2.1, as in Figure 1, to form g(G(\u03b1\u0304n(x) + \u03b2\u0304n(x) \u2032t)), for which \u2225\u2225g(G(\u03b1\u0304n(x) + \u03b2\u0304n(x)\u2032t))\u2212 g(G(\u03b1(x) + \u03b2(x)\u2032t))\u2225\u2225\u221e \u2264 , (C.1) with the same bounds on the parameters, up to the fact that, at worst, the network will be dim(T )+1 times wider, but this is a constant. A similar argument shows that the discrete covariates both do not affect the rate and can be handled seamlessly. Suppose xd is binary. Then, for example, \u03b1(x) = xd\u03b11(x1, . . . , xd\u22121) + (1 \u2212 xd)\u03b10(x1, . . . , xd\u22121) for smooth d \u2212 1-dimensional functions \u03b11 and \u03b10. Adding a single node to each hidden layer allows the network to pass forward the input xd and multiply it with two separate learned functions, giving exactly \u03b1\u0304(x) = xd\u03b1\u03041(x1, . . . , xd\u22121) + (1\u2212xd)\u03b1\u03040(x1, . . . , xd\u22121). The same argument can be applied to every category of the discrete data and to each function to be learned. The estimator matches this structure exactly.\nLet rn := n \u2212 p p+dC log8(n). With the above approximation, Farrell et al. (2019, Theorem 2) then\nimmediately gives that with probability at least 1\u2212 e\u2212\u03b3 , for n large enough,\nEX,T [{ g ( G ( \u03b1\u0302(X) + \u03b2\u0302(X)\u2032T )) \u2212 g ( G ( \u03b1(X) + \u03b2(X)\u2032T ))}2] = O ( WL logW\nn log n+\nlog log n+ \u03b3\nn + 2 ) = O (rn) , (C.2)\nupon choosing the width and depth as stated in the lemma.\nLet \u03b4(x) = E[T | X = x]. Taking the expectation over a new draw of W , expanding the square, wherein the cross term is mean zero, and using the positivity of E[T\u0303 T\u0303 \u2032 |X], we have\nEX,T [( \u03b1\u0302(X) + \u03b2\u0302(X)\u2032T \u2212 \u03b1(X)\u2212 \u03b2(X)\u2032T )2] = EX,T [( \u03b1\u0302(X) + \u03b2\u0302(X)\u2032\u03b4(x)\u2212 \u03b1(X)\u2212 \u03b2(X)\u2032\u03b4(X) + ( \u03b2\u0302(X)\u2212 \u03b2(X) )\u2032 (T \u2212 \u03b4(X)) )2]\n= EX,T [( \u03b1\u0302(X) + \u03b2\u0302(X)\u2032\u03b4(x)\u2212 \u03b1(X)\u2212 \u03b2(X)\u2032\u03b4(X) )2] + EX,T [(( \u03b2\u0302(X)\u2212 \u03b2(X) )\u2032 (T \u2212 \u03b4(X)) )2]\n\u2265 EX,T [(( \u03b2\u0302(X)\u2212 \u03b2(x) )\u2032 (T \u2212 \u03b4(X)) )2]\n\u2265 CEX [( \u03b2\u0302(X)\u2212 \u03b2(X) )\u2032 ( \u03b2\u0302(X)\u2212 \u03b2(X) )] .\nFrom Equation (C.2), the starting point of this chain of bounds is O(r2n), and therefore we obtain\nthe required L2 convergence for each \u03b2\u0302k. Next,\n\u2016\u03b1\u0302\u2212 \u03b1\u2016L2(X) = \u2016\u03b1\u0302+ \u03b2\u0302 \u2032\u03b4 \u2212 \u03b1\u2212 \u03b2\u2032\u03b4 + \u03b2\u2032\u03b4 \u2212 \u03b2\u0302\u2032\u03b4\u2016L2(X)\n\u2264 \u2016\u03b1\u0302+ \u03b2\u0302\u2032\u03b4 \u2212 \u03b1\u2212 \u03b2\u2032\u03b4\u2016L2(X) + \u2016(\u03b2\u0302 \u2212 \u03b2) \u2032\u03b4\u2016L2(X) = O(rn) +O(rn) = O(rn),\nwhere the first term again applies (C.2) and the second applies the above finding for \u03b2\u0302 and boundedness of \u03b4(x) which is implied by the assumptions on \u039b(x).\nProof of Lemma 1 for \u039b(x). If G(u) = u, the result follows directly from Farrell et al. (2019). For nonlinear G, we apply sample splitting. Let \u03b1\u0303 and \u03b2\u0303 be estimated from an independent sample of data. By the previous results, these converge at rate rn. Let tj denote the j th element of T , taken to be one if j = 0. One the second sample, \u03b1\u0303 and \u03b2\u0303 are known, nonrandom functions, and therefore estimation of \u03bb\u0303j,k := E[G\u0307(\u03b1\u0303(X) + \u03b2\u0303(X)\u2032T )tjtk |X = x] again follows from Farrell et al. (2019). By a Taylor approximation, for a midpoint u\u0304 = u\u0304(X,T ), E [ G\u0307(\u03b1\u0303(X) + \u03b2\u0303(X)\u2032T )tjtk\n\u2223\u2223X = x] = E [G\u0307(\u03b1(X) + \u03b2(X)\u2032T )tjtk\u2223\u2223X = x] + E [( \u03b1\u0303(X) + \u03b2\u0303(X)\u2032T \u2212 \u03b1(X)\u2212 \u03b2(X)\u2032T ) G\u0308(u\u0304)tjtk\n\u2223\u2223X = x] . The second term is O(rn) by the Cauchy-Schwarz inequality, since G\u0308(u\u0304)tjtk is bounded and the first stage estimates are L2 consistent at rate rn by the above."
    },
    {
      "heading": "D Derivations for Multinomial Choice Models",
      "text": "In the plain multinomial logistic model, the different choices do not share any parameters, and thus each choice of j > 0 versus j = 0 can be thought of as an individual binary logistic regression with log odds \u03b1j(x)+\u03b2j(x) \u2032t. Here K = dim(\u03b2j) = dim(t) and the same t appear in all equations. The parameter of interest is\n\u03b8 = E[H(X, \u03b11(X), . . . , \u03b1J(X),\u03b21(X), . . . ,\u03b2K(X); t\u2217)]. (D.1)\nIn the case of the conditional, or McFadden, logit, we instead have \u03b1j(x)+\u03b2(x) \u2032tj and therefore\n\u03b8 = E[H(X, \u03b11(X), . . . , \u03b1J(X),\u03b2(X); t\u22171, . . . , t\u2217J)]. (D.2)\nThe derivation of the orthogonal score for both models follows the same steps as above. Equation (A.1) must be verified, though with a vector outcome Y . The chain-rule result of (A.2) is still the starting point, and the first term of the influence function will still be the \u201cplug-in\u201d portion of the influence function as if all the \u03b1j(x) and \u03b2j(x) were known. When deriving the correction factor the difference between the multinomial and conditional logit models will become important; the structure, via the first order conditions, determines the form of the correction factor.\nTo save notation, let Gj = Gj(u0, u1, . . . , uJ) and let H0(x) stand in for the full H function and its arguments from either (D.1) or (D.2), where the true \u03b1j(x) and \u03b2j(x) are used, or in the conditional logit case, the one vector \u03b2(x). Further, redefine \u2207H to be the gradient with respect to all the \u03b1j(x) and \u03b2j(x) that are present (or the alternative-invariant \u03b2(x) in the McFadden case) and let \u2206 be the vector that collects all the derivatives of the unknown \u03b1j(x) and \u03b2j(x) with respect to \u03b7, evaluated at \u03b7 = 0. To be explicit, in the case of the conditional or McFadden logit\n\u2206 = ( \u03b1\u03071, \u03b1\u03072, . . . , \u03b1\u0307J , \u03b2\u03071, \u03b2\u03072, . . . , \u03b2\u0307K )\u2032 , \u2207H = ( \u2202H\n\u2202\u03b11 , . . . ,\n\u2202H \u2202\u03b1J , \u2202H \u2202\u03b21 , . . . , \u2202H \u2202\u03b2K\n)\u2032 ,\nwhere \u03b2(X) = (\u03b21(X), . . . , \u03b2K(X)) \u2032, while for the multinomial logistic\n\u2206 = ( \u03b1\u03071, \u03b2\u0307 \u2032 1, \u03b1\u03072, \u03b2\u0307 \u2032 2, . . . , \u03b1\u0307J , \u03b2\u0307 \u2032 J , )\u2032 , \u2207H = ( \u2207H1(x)\u2032,\u2207H2(x)\u2032, . . . ,\u2207HJ(x)\u2032 )\u2032 ,\n\u03b2\u0307j = (\u03b2\u0307j,1, \u03b2\u0307j,2, . . . , \u03b2\u0307j,K) \u2032 \u2207Hj =\n( \u2202H\n\u2202\u03b1j , \u2202H \u2202\u03b2j,1 , . . . , \u2202H \u2202\u03b2j,K\n)\u2032 .\nNotice that in this case the \u03b1\u0307j and \u03b2\u0307j alternate within \u2206, as opposed to the \u03b2\u0307j being collected at the end.\nWith this notation, the analogue of Equation (A.2) is\n\u2202\u03b8(\u03b7)\n\u2202\u03b7 = E[H0(X)S(X)] + E\n[ \u2207H \u2032\u2206 ] , (D.3)\nwhere we\u2019ve applied Equation (A.3) to the first term and therefore it is already in the same form as Equation (A.4). For the multinomial logistic case the inner product in the second term is\n\u2207H \u2032\u2206 = J\u2211 j=1\n{ \u2202H\n\u2202\u03b1j\n\u2202\u03b1j(x; \u03b7)\n\u2202\u03b7 + K\u2211 k=1 \u2202H \u2202\u03b2j,k \u2202\u03b2j,k(x; \u03b7) \u2202\u03b7\n} ,\nwhile in the case of the conditional logit, where \u2207H and \u2206 are lower dimensional due to the restriction that all the \u03b2j are equal,\n\u2207H \u2032\u2206 = J\u2211 j=1 { \u2202H \u2202\u03b1j \u2202\u03b1j(x; \u03b7) \u2202\u03b7 } + K\u2211 k=1 { \u2202H \u2202\u03b2k \u2202\u03b2k(x; \u03b7) \u2202\u03b7 } .\nThe derivation proceeds by rewriting E [\u2207H \u2032\u2206] into a form analogous to Equation (A.6) by solving for (the elements of) \u2206 by exploiting the same first order condition method as in (A.5). Here the derivation deviates from the prior section, and also, the two multinomial models must be treated separately because they have different first order conditions. In particular, for the multinomial logistic model we have J +JK first order conditions, one for each \u03b1j and \u03b2j,k whereas for the restricted case, we have only J +K first order conditions. However, the form of all these is analogous to (A.5).\nTo see this, we start with the likelihood and obtain the relevant first order conditions. All of these steps are textbook multinomial/conditional logit likelihood manipulations. To start, by assumption,\nP[Y = j |X = x,T = t] = Gj (u1, u2, . . . , uJ) .\nThe likelihood, with yj = 1{y = j} and Gj = Gj(u0, u1, . . . , uJ), is\nJ\u220f j=0 G yj j = G0 J\u220f j=1 ( Gj G0 )yj ,\nwhere the second form exploits that y0 + y1 + \u00b7 \u00b7 \u00b7 + yJ = 1. Because we assume that Gj = exp{uj}\nexp{u0}+ \u2211J m=1 exp{um} , with u0 = 0, the log-likelihood is\nL = log(G0) + J\u2211 j=1 yjuj .\nHere the two cases diverge, because for the multinomial logistic model uj(x, t) = \u03b1j(x) + \u03b2j(x) \u2032t whereas for the conditional logit we assume uj(x, tj) = \u03b1j(x) + \u03b2(x) \u2032tj . It will be useful that, for j = 1, . . . , J , \u2202Gm \u2202\u00b5j = (1j,m \u2212Gj)Gm, 1j,m = 1{j = m}. (D.4)\nD.1 Conditional Logit\nFrom the above, for the conditional logit we obtain, for m = 1, . . . , J and ` = 1, . . . ,K,\n\u2202L \u2202\u03b1m = \u2202 log(G0) \u2202\u00b5m \u2202\u00b5m \u2202\u03b1m + J\u2211 j=1 yj \u2202uj \u2202\u03b1m = \u2212Gm + ym\n\u2202L \u2202\u03b2`\n= J\u2211\nm=1\n\u2202 log(G0)\n\u2202\u00b5m \u2202\u00b5m \u2202\u03b2`\n+ J\u2211\nm=1\nym \u2202um \u2202\u03b2`\n= J\u2211\nm=1\n(ym \u2212Gm)xm,`,\nwhere tm = (xm,1, . . . , xm,K) \u2032.\nLet Gj(\u03b7) = Gj(u0(x, t; \u03b7), u1(x, t; \u03b7), . . . , uJ(x, t; \u03b7)), with uj(x, t; \u03b7) = \u03b1j(x; \u03b7) + \u03b2(x; \u03b7) \u2032tj ,\nand Gj = Gj(0). Let\n\u03b1\u0307m = \u2202\u03b1m(x; \u03b7)\n\u2202\u03b7\n\u2223\u2223\u2223\u2223 \u03b7=0 , \u03b2\u0307 = \u2207\u03b7\u03b2(x; \u03b7) \u2223\u2223\u2223 \u03b7=0 .\nThe first order condition for \u03b1j , j = 1, . . . , J , identically in \u03b7, is\n0 \u2261 E\u03b7 [(Yj \u2212Gj) |X] ,\nand the first order condition for \u03b2`, ` = 1, . . . ,K, is\n0 \u2261 E\u03b7\n[ J\u2211\nm=1\n(Ym \u2212Gm)Xm,` \u2223\u2223\u2223X] .\nDifferentiating the \u03b1j first order condition, we obtain\n0 = E [(Yj \u2212Gj)S(Y,T |X) |X]\u2212 E\n[ J\u2211\nm=1\n\u2202Gj \u2202um \u2202um \u2202\u03b7 \u2223\u2223\u2223X] . Rearranging, and using Equation (D.4), then expanding the inner product into a summation,\nE [(Yj \u2212Gj)S(Y,T |X) |X]\n= E\n[ J\u2211\nm=1\n\u2202Gj \u2202um \u2202um \u2202\u03b7\n\u2223\u2223\u2223X]\n= E\n[ J\u2211\nm=1\n(1j,m \u2212Gj)Gm ( \u03b1\u0307m + \u03b2\u0307 \u2032tm ) \u2223\u2223\u2223X]\n= J\u2211 m=1 { \u03b1\u0307mE [ (1j,m \u2212Gj)Gm \u2223\u2223\u2223X]}+ \u03b2\u0307\u2032E[ J\u2211 m=1 (1j,m \u2212Gj)GmTm \u2223\u2223\u2223X]\n= J\u2211 m=1 { \u03b1\u0307mE [ (1j,m \u2212Gj)Gm \u2223\u2223\u2223X]+ \u03b2\u0307\u2032E [(1j,m \u2212Gj)GmTm\u2223\u2223\u2223X]} =\nJ\u2211 m=1 \u03b1\u0307mE [ (1j,m \u2212Gj)Gm \u2223\u2223\u2223X]+ K\u2211 k=1 \u03b2\u0307kE\n[ J\u2211\nm=1\n(1j,m \u2212Gj)GmXm,k \u2223\u2223\u2223X] (D.5)\nDoing the same for the \u03b2` first order condition yields\nE\n[ J\u2211\nm=1\n(Ym \u2212Gm)S(Y,T |X) |X\n]\n= E  J\u2211 m=1 Xm,` J\u2211 j=1 \u2202Gm \u2202uj \u2202uj \u2202\u03b7 \u2223\u2223\u2223X \n= E  J\u2211 m=1 Xm,` J\u2211 j=1 (1j,m \u2212Gj)Gm ( \u03b1\u0307j + \u03b2\u0307 \u2032tj ) \u2223\u2223\u2223X \n= J\u2211 j=1 \u03b1\u0307jE\n[ J\u2211\nm=1\nXm,`(1j,m \u2212Gj)Gm \u2223\u2223\u2223X]\n+ K\u2211 k=1 \u03b2\u0307kE  J\u2211 j=1 J\u2211 m=1 (1j,m \u2212Gj)GmXm,`Xj,k \u2223\u2223\u2223X  (D.6)\nWe will solve for the derivatives \u2206 by collecting Equation (D.5) over j = 1, . . . , J and (D.6) over ` = 1, . . . ,K, creating a system of equations and inverting a second-moment matrix, just as in the scalar-outcome case. To make the process clear, it is helpful to set additional notation. First, define the following scalars:\naj,m(x) = E [(1j,m \u2212Gj)Gm | x]\nbj,k(x) = E\n[ J\u2211\nm=1\nXm,k(1j,m \u2212Gj)Gm \u2223\u2223\u2223x]\nb\u0303`,k(x) = E  J\u2211 j=1 J\u2211 m=1 Xj,`Xm,k(1j,m \u2212Gj)Gm \u2223\u2223\u2223x \ncj(y,x, t) = yj \u2212Gj c\u0303`(y,x, t) = J\u2211 j=1 (yj \u2212Gj)xj,`.\nNotice that aj,m and b\u0303`,k are symmetric in their subscript arguments, aj,m = am,j and b\u0303`,k = b\u0303k,`, but bj,k is not. Now collect them into these the (J +K) vectors\nBj(x) = (aj,1, aj,2, . . . , aj,J , bj,1, bj,2, . . . , bj,K) \u2032 B\u0303`(x) = (b1,`, b2,`, . . . , bJ,`, b\u0303`,1, b\u0303`,2, . . . , b\u0303`,K) \u2032\nC(y,x, t) = (c1, c2, . . . , cJ , c\u03031, c\u03032, . . . , c\u0303K) \u2032 .\nFinally, create the (J +K) square matrix \u039b(x) (dropping the argument x for simplicity)\n\u039b(x) =  B\u20321 ... B\u2032J B\u0303\u20321 ...\nB\u0303\u2032K\n =  a1,1 a1,2 . . . a1,J b1,1 b1,2 . . . b1,K ... aJ,1 aJ,2 . . . aJ,J bJ,1 bJ,2 . . . bJ,K b1,1 b2,1 . . . bJ,1 b\u03031,1 b\u03031,2 . . . b\u03031,K ...\nb1,K b2,K . . . bJ,K b\u0303K,1 b\u0303K,2 . . . b\u0303K,K\n .\nThe matrix \u039b inherits the symmetry of the aj,m and b\u0303k,`, but is not itself a symmetric matrix.\nLastly, recall\n\u2206 = ( \u03b1\u03071, \u03b1\u03072, . . . , \u03b1\u0307J , \u03b2\u03071, \u03b2\u03072, . . . , \u03b2\u0307K )\u2032 ,\nWe then write Equations (D.5) and (D.6) as\n\u2206(x)\u2032\u039b(x) = E [ C(Y,X,T )\u2032S(Y,T |X) \u2223\u2223X = x] . If \u039b(x) is invertible, \u2206(x) = \u039b(x)\u22121E [ C(Y,X,T )S(Y,T |X) \u2223\u2223X = x] and therefore Equation\n(D.3) is\n\u2202\u03b8(\u03b7)\n\u2202\u03b7 = E[H0(X)S(X)] + E\n[ \u2207H \u2032\u039b(X)\u22121E [ C(Y,X,T )S(Y,T |X) \u2223\u2223X]] , analogous to Equation (A.7), giving the final formula.\nD.2 Multinomial Logit\nThe derivation in this case is similar, but each \u03b2j has an individual first order condition and for each j = 1, . . . , J , all the \u03b1m and \u03b2m appear in the j first order condition. Notice also that T is not j-specific. Just as the multinomial logistic model is equivalent to pairwise binary logistic regressions, we get the analogue of Equation (A.5) for each j. Following the same argument as given there,\nE [ (Yj \u2212GJ)T\u0303 \u2032 |X ] = J\u2211 m=1 ( \u03b1\u0307m, \u03b2\u0307 \u2032 m )\u2032 E [ (1j,m \u2212Gj)GmT\u0303 T\u0303 \u2032 |X ] ,\nwhere as before T\u0303 = (1,T \u2032)\u2032.\nWe will rearrange and stack these as before. In this case, define the (K + 1) square matrixes,\nbj,m(x) = E [ (1j,m \u2212Gj)GmT\u0303 T\u0303 \u2032 | x ] Note that these are symmetric in their subscript arguments: bj,m = bm,j . Now collect these into a J(K + 1)\u00d7 J matrix\nBj =  bj,1(x) bj,2(x) ...\nbj,J(x)\n .\nFinally, collect these into the J(K + 1) square matrix \u039b(x):\n\u039b(x) = ( B1, \u00b7 \u00b7 \u00b7 ,BJ ) .\nA useful alternative expression for \u039b(x) is \u039b(x) = E [ E [M | T ,x]\u2297 T\u0303 T\u0303 \u2032 \u2223\u2223x], where \u2297 is the kronecker product and M is the J \u00d7 J Hessian with (j,m) entry (1j,m \u2212Gj)Gm. Next, define the (K + 1) vectors.\ncj(y,x, t) = (yj \u2212Gj)t\u0303\nand collect them into the J(K + 1) vector\nC(y,x, t) = ( c\u20321, c \u2032 2, . . . , c \u2032 J )\u2032 .\nRecall that in this case\n\u2206 = ( \u03b1\u03071, \u03b2\u0307 \u2032 1, \u03b1\u03072, \u03b2\u0307 \u2032 2, . . . , \u03b1\u0307J , \u03b2\u0307 \u2032 J , )\u2032 , \u2207H = ( \u2207H1(x)\u2032,\u2207H2(x)\u2032, . . . ,\u2207HJ(x)\u2032 )\u2032 ,\n\u03b2\u0307\u2032j = (\u03b2\u0307j,1, \u03b2\u0307j,2, . . . , \u03b2\u0307j,K) \u2032 \u2207Hj =\n( \u2202H\n\u2202\u03b1j , \u2202H \u2202\u03b2j,1 , . . . , \u2202H \u2202\u03b2j,K\n)\u2032 .\nNotice that in this case the \u03b1\u0307j and \u03b2\u0307j alternate within \u2206, as opposed to the \u03b2\u0307j being collected at the end.\nWith all this notation, we then obtain the final formula, which is of the same form as for the\nconditional logit, but with each object suitably redefined."
    }
  ],
  "title": "Deep Learning for Individual Heterogeneity\u2217",
  "year": 2020
}
