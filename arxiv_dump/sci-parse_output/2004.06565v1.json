{
  "abstractText": "Equity research analysts at financial institutions play a pivotal role in capital markets; they provide an efficient conduit between investors and companies\u2019 management and facilitate the efficient flow of information from companies, promoting functional and liquid markets. However, previous research in the academic finance and behavioral economics communities has found that analysts\u2019 estimates of future company earnings and other financial quantities can be affected by a number of behavioral, incentive-based and discriminatory biases and systematic errors, which can detrimentally affect both investors and public companies. We propose a Bayesian latent variable model for analysts\u2019 systematic errors and biases which we use to generate a robust bias-adjusted consensus estimate of company earnings. Experiments using historical earnings estimates data show that our model is more accurate than the consensus average of estimates and other related approaches.",
  "authors": [
    {
      "affiliations": [],
      "name": "Chirag Nagpal"
    },
    {
      "affiliations": [],
      "name": "Robert E. Tillman"
    },
    {
      "affiliations": [],
      "name": "Prashant P. Reddy"
    },
    {
      "affiliations": [],
      "name": "Manuela M. Veloso"
    }
  ],
  "id": "SP:cbe00b13af2b157a04dc814502836577b369fdf2",
  "references": [
    {
      "authors": [
        "David Blei",
        "Alp Kucukelbir",
        "Jon McAuliffe"
      ],
      "title": "Variational inference: A review for statisticians",
      "venue": "Journal of the American Statistical Association,",
      "year": 2017
    },
    {
      "authors": [
        "Mark Thomas Bradshaw"
      ],
      "title": "Analysts\u2019 forecasts: What do we know after decades of work",
      "venue": "SSRN Electronic Journal,",
      "year": 2011
    },
    {
      "authors": [
        "Lawrence D. Brown"
      ],
      "title": "Analyst forecasting errors: Additional evidence",
      "venue": "Financial Analysts Journal,",
      "year": 1997
    },
    {
      "authors": [
        "Lawrence D. Brown",
        "Michael S. Rozeff"
      ],
      "title": "The superiority of analyst forecasts as measures of expectations: Evidence from earnings",
      "venue": "Journal of Finance,",
      "year": 1978
    },
    {
      "authors": [
        "Lawrence D. Brown",
        "Robert L. Hagerman",
        "Paul A. Griffin",
        "Mark E. Zmijewski"
      ],
      "title": "Security analyst superiority relative to univariate time-series models in forecasting quarterly earnings",
      "venue": "Journal of Accounting and Economics,",
      "year": 1987
    },
    {
      "authors": [
        "Edilberto Cepeda",
        "Dani Gamerman"
      ],
      "title": "Bayesian modeling of variance heterogeneity in normal regression models",
      "venue": "Brazilian Journal of Probability and Statistics,",
      "year": 2000
    },
    {
      "authors": [
        "Edilberto Cepeda",
        "Dani Gamerman"
      ],
      "title": "Bayesian methodology for modeling parameters in the two parameter exponential family",
      "venue": "Revista Estadi\u0301stica,",
      "year": 2005
    },
    {
      "authors": [
        "Stephen J. Ciccone"
      ],
      "title": "Trends in analyst earnings forecast properties",
      "venue": "International Review of Financial Analysis,",
      "year": 2005
    },
    {
      "authors": [
        "Werner F.M. De Bondt",
        "Richard H. Thaler"
      ],
      "title": "Do security analysts overreact",
      "venue": "The American Economic Review,",
      "year": 1990
    },
    {
      "authors": [
        "Michael J. Eames",
        "Steven M. Glover"
      ],
      "title": "Earnings predictability and the direction of analysts",
      "venue": "earnings forecast errors. The Accounting Review,",
      "year": 2003
    },
    {
      "authors": [
        "John C. Easterwood",
        "Stacey R. Nutt"
      ],
      "title": "Inefficiency in analysts\u2019 earnings forecasts: Systematic misreaction or systematic optimism",
      "venue": "The Journal of Finance,",
      "year": 1999
    },
    {
      "authors": [
        "John A. Elliott",
        "Donna R. Philbrick",
        "Cristine I. Wiedman"
      ],
      "title": "Evidence from archival data on the relation between security analysts\u2019 forecast errors and prior forecast revisions",
      "venue": "Contemporary Accounting Research,",
      "year": 2010
    },
    {
      "authors": [
        "Jennifer Francis",
        "Donna Philbrick"
      ],
      "title": "Analysts\u2019 decisions as products of a multi-task environment",
      "venue": "The Journal of Accounting Research,",
      "year": 1993
    },
    {
      "authors": [
        "Dov Fried",
        "Dan Givoly"
      ],
      "title": "Financial analysts\u2019 forecasts of earnings: a better surrogate for market expectations",
      "venue": "Journal of Accounting and Economics,",
      "year": 1982
    },
    {
      "authors": [
        "Harrison Hong",
        "Jeffrey D. Kubik"
      ],
      "title": "Analyzing the analysts: Career concerns and biased earnings forecasts",
      "venue": "The Journal of Finance,",
      "year": 2003
    },
    {
      "authors": [
        "Harrison Hong",
        "Jeffrey D. Kubik",
        "Amit Solomon"
      ],
      "title": "Security analysts\u2019 careeer concerns and herding of earnings forecasts",
      "venue": "RAND Journal of Economics,",
      "year": 2000
    },
    {
      "authors": [
        "Sima Jannati",
        "Alok Kumar",
        "Alexandra Niessen-Ruenzi",
        "Justin Wolfers"
      ],
      "title": "In-group bias in financial markets",
      "venue": "SSRN Electronic Journal,",
      "year": 2019
    },
    {
      "authors": [
        "Vinesh Jha",
        "Haim Mozes"
      ],
      "title": "Creating and profiting from more accurate earnings estimates with starmine professional",
      "venue": "StarMine white paper,",
      "year": 2001
    },
    {
      "authors": [
        "Diederik Kingma",
        "Jimmy Ba"
      ],
      "title": "Adam: A method for stochastic optimization",
      "venue": "Proceedings of the 3rd International Conference on Learning Representations,",
      "year": 2015
    },
    {
      "authors": [
        "Roger K. Loh",
        "G. Mujtaba Mianc"
      ],
      "title": "Do accurate earnings forecasts facilitate superior investment recommendations",
      "venue": "Journal of Financial Economics,",
      "year": 2006
    },
    {
      "authors": [
        "Roni Michaely",
        "Kent L. Womack"
      ],
      "title": "Conflict of interest and the credibility of underwriter analyst recommendations",
      "venue": "The Review of Financial Studies,",
      "year": 1999
    },
    {
      "authors": [
        "Roni Michaely",
        "Kent L. Womack"
      ],
      "title": "Market efficiency and biases in brokerage recommendations",
      "venue": "Advances in Behavioral Finance,",
      "year": 2005
    },
    {
      "authors": [
        "Roni Michaely",
        "Amir Rubin",
        "Dan Segal",
        "Alexander Vedrashko"
      ],
      "title": "Lured by the consensus: The implications of treating all analysts as equal",
      "venue": "SSRN Electronic Journal,",
      "year": 2018
    },
    {
      "authors": [
        "Michael B. Mikhail",
        "Beverly R. Walther",
        "Richard H. Willis"
      ],
      "title": "Does forecast accuracy matter to security analysts",
      "venue": "The Accounting Review,",
      "year": 1999
    },
    {
      "authors": [
        "Patricia C. O\u2019 Brien",
        "Maureen F. McNichols",
        "Hsiou-Wei Lin"
      ],
      "title": "Analyst impartiality and investment banking relationships",
      "venue": "The Journal of Accounting Research,",
      "year": 2005
    },
    {
      "authors": [
        "Michele O\u2019Neill",
        "Minsup Song",
        "Judith Swisher"
      ],
      "title": "How does prior information affect analyst forecast herding? Academy of Accounting and Financial Studies",
      "venue": "Journal, 15:105\u2013128,",
      "year": 2011
    },
    {
      "authors": [
        "Jana Smith Raedy",
        "Philip Shane",
        "Yanhua Yang"
      ],
      "title": "Horizon-dependent underreaction in financial analysts",
      "venue": "earnings forecasts. Contemporary Accounting Research,",
      "year": 2006
    },
    {
      "authors": [
        "Scott A. Richardson",
        "Siew Hong Teoh",
        "Peter D. Wysocki"
      ],
      "title": "Tracking analysts\u2019 forecasts over the annual earnings horizon: Are analysts\u2019 forecasts optimistic or pessimistic",
      "venue": "SSRN Electronic Journal,",
      "year": 1999
    }
  ],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": "Equity research analysts at financial institutions play a pivotal role in capital markets. Both large institutions and small investors alike lack the time and resources to analyze thousands of companies and meet with their management. Such activity would similarly overwhelm even the largest public companies. Analysts provide a necessary conduit between the companies\u2019 management and investors. In addition, regulators have a strong interest in the efficient flow of information from companies to ensure functional, liquid markets; analysts significantly contribute to this process [Bradshaw, 2011].\nOne important function of analysts is forecasting companies\u2019 future earnings and other financial quantities, e.g. revenue and cash flow. Investors use these quantities to understand the financial health of companies and the value of their stock. There are hundreds of academic studies which have analyzed these forecasts and their accuracy. Analysts\u2019 estimates of upcoming earning have been shown to be more accurate than those produced by a range of time-series models of actual reported earnings [Brown and Rozeff, 1978, Fried and Givoly, 1982]. Brown et al. [1987] finds that this is due to both a timing and information advantage. Accordingly, there is a strong relationship between analysts\u2019 revisions to their estimates and changes in stock prices [Michaely and Womack, 2005].\nDespite the value in these estimates, the academic finance and behavioral economics communities have found significant empirical evidence of various types of analyst biases and systematic errors. Much of this literature focuses on over-optimism in analysts\u2019 earnings forecasts [De Bondt and Thaler, 1990, Hong and Kubik, 2003, Elliott et al., 2010]. Common explanations for this optimism include incentives for analysts to maintain good relations with companies\u2019 management [Francis and Philbrick, 1993, Richardson et al., 1999] and possible conflicts of interest with companies who are also investment banking clients [Michaely and Womack, 1999, O\u2019 Brien et al., 2005]. Other literature, however, has highlighted that analysts are actually pessimistic or conservative in their estimates\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nar X\niv :2\n00 4.\n06 56\n5v 1\n[ q-\nfi n.\nST ]\n1 4\nA pr\nat shorter horizons and overly optimistic at longer-term horizons [Richardson et al., 1999, Brown, 1997, Eames and Glover, 2003, Elliott et al., 2010]. This literature explains this asymmetry similarly in terms analysts incentives to maintain good relations with companies\u2019 management: pessimistic projections for an upcoming quarter will result in a company beating expectations and a subsequent positive stock price reaction, whereas unrealistically optimistic projections will ultimately result in a company missing expectations and a negative stock price reaction.\nMany papers have investigated more specific behavioral biases [De Bondt and Thaler, 1990] and asymmetries [Easterwood and Nutt, 1999] in analysts\u2019 earnings estimates. Elliott et al. [2010] finds that analysts systematically underweight new information and underreact to their own previous revisions. Easterwood and Nutt [1999] finds that analysts underreact to negative information and overreact to positive information. Ciccone [2005] shows that forecast errors are different for profitmaking companies than loss-making companies. Raedy et al. [2006] provides evidence that analysts are less likely to make revisions in the opposite direction of previous revisions as they incur a greater reputational cost for acknowledging they \u201covershot\u201d in previous estimates. There is also evidence analysts engage in \u201cherding behavior\u201d [O\u2019Neill et al., 2011], or are unlikely to deviate too much from other analysts. Hong et al. [2000] finds that analysts are more likely to engage in herding in their revisions when their outstanding estimates deviate significantly from other analysts.\nFurthermore, there is evidence that biases and systematic errors are stronger in some analysts than others. Michaely and Womack [1999] finds that analysts with more experience have lower forecast error. Hong et al. [2000] finds that experienced analysts are also more likely to revise their estimates earlier and their estimates show more dispersion, indicating stronger conviction and willingness to issue bold forecasts that go against the trend. Mikhail et al. [1999] finds that earnings estimate accuracy is negatively correlated with analyst turnover. Finally, recent research has highlighted evidence of racial, gender and political biases towards out of group company CEOs [Jannati et al., 2019].\nMany investors use the consensus earnings estimate, or the simple average of estimates from analysts at major institutions, as a reliable forecast of a company\u2019s upcoming earnings. However, research has shown that inversely weighting these individual analysts\u2019 estimates based on their historical forecasting errors results in a more accurate \u201cadjusted\u201d consensus estimate [Jha and Mozes, 2001, Michaely et al., 2018]. While this is consistent with the finding that some analysts are more accurate than others, only considering the total forecasting error does not disentangle the systematic bias component of forecasting error from the unsystematic (or unpredictable) general error and does account for different types of biases and asymmetries in forecast errors. We hypothesize that a model which accounts for the systematic and asymmetric components of analyst estimate error will produce more robust adjusted consensus earnings estimates."
    },
    {
      "heading": "1.1 Primary contribution",
      "text": "We propose a Bayesian latent variable model for analysts\u2019 earnings estimate forecasting error and show how it can be used to infer a robust adjusted consensus earnings estimate. In our model, we assume there are latent subgroups of analysts such that analysts within each group demonstrate similar systematic forecasting errors. We use historical analyst estimates of company earnings and actual reported earnings to learn the parameters of this model. We then describe a procedure for inverse inference to generate a robust consensus estimate of future earnings from individual analysts\u2019 estimates. We believe robust earnings estimates benefit both investors, who require accurate forecasts of company financials, and public companies, whose stock prices may be undervalued as a result of some analysts\u2019 incentive biases, conflicts of interest or for discriminatory reasons.\nIn the following sections, we describe the proposed Bayesian latent variable model and inverse inference procedure to generate robust company earnings estimates. We compare the resulting robust estimates to actual reported company earnings. We find that this approach produces estimates which are more accurate than the consensus estimate and other adjusted consensus baselines."
    },
    {
      "heading": "2 Proposed Model for Robust Earnings Estimates",
      "text": "The specific financial quantity we focus on modeling the forecast error of is Earnings per Share (EPS), as this most widely considered quantity when assessing the value of a public company. EPS\nis the ratio between company\u2019s net income during a particular reporting period after subtracting preferred dividends and the number of outstanding common shares of that company\u2019s stock.\nWe assume that there exists a latent subgrouping of analysts such that within each group, we observe similar EPS forecasting errors. We hypothesize that analysts\u2019 estimates for changes in EPS (the difference between the EPS forecast for the next period and the company\u2019s reported EPS from the previous period) are normally distributed around a linear function of the actual resulting change in EPS with some heteroscedastic variance. Both the variance and the parameters of the linear function are conditioned on the latent subgroup an analyst belongs to. In this setting, the distribution of the forwards model, or the observed forecasting error process, can be written in closed form and parameter learning can be carried out with a gradient-based method."
    },
    {
      "heading": "2.1 The Forwards Model",
      "text": "For a particular reporting period, we use Xi to represent the actual change in reported EPS from the previous period, where i is an index over the set of companies, S, and \u03bei is an indicator of whether the change in EPS is positive or negative.\nNow, for each analyst indexed by j in the set of analysts, A, we draw a categorical variable zj conditioned on the parameters \u03b8j that determines which one of the K latent subgroups analyst j belongs to. Finally we draw a set of parameters wj conditioned on the analyst subgroup that interact with the true change in EPS Xi and \u03bei. We show the model in plate notation in Figure 1 and give the explicit steps in the process below:\n1. For all j \u2208 A, Draw zj |\u03b8j as,\nzj |\u03b8j \u223c Discrete(SOFT-MAX(\u03b8j))\n2. For all i \u2208 S, Draw \u03bei|Xi as,\n\u03bei = 1{Xi > 0}\n3. For all i \u2208 S and j \u2208 A , Draw X\u0302ij |Xi, {zj}Aj=1{\u03c9k}Kk=1 as\nX\u0302ij |\u00b7 \u223c N (\u03b1zj\u00b7Xi + \u03b2zj , \u03c32zj ) (1)"
    },
    {
      "heading": "2.2 Parameter Learning",
      "text": "To learn the parameters \u0398 of the model from observed analyst estimates and actual reported EPS data D, we want to maximize the likelihood, P (D|\u0398), which we can write as follows:\nP (D|\u0398) = P ({{X\u0302ij}|A|j=1} |S| i=1, {Xi, \u03bei} |S| i=1|{\u03b8j} |A| j=1, {\u03b1k, \u03b2k, \u03c3k} K k=1)\n= |S|\u220f i=1 |A|\u220f j=1 K\u2211 k=1 Pk(X\u0302ij |Xi, \u03bei, zj)P (zj |\u03b8j) (Here, Pk is as in Eq. 1)\nlogP (D|\u0398) = |S|\u2211 i=1 |A|\u2211 j=1 log K\u2211 k=1 Pk(X\u0302ij |Xi, \u03bei, zj)P (zj |\u03b8j)\nlogP (D|\u0398) = |S|\u2211 i=1 |A|\u2211 j=1 logEzj |\u03b8j [ Pk(X\u0302ij |Xi, \u03bei, zj) ] \u2265 |S|\u2211 i=1 |A|\u2211 j=1 Ezj |\u03b8j [ logPk(X\u0302ij |Xi, \u03bei, zj) ] (From Jensen\u2019s Inequality)\n, ELBO(\u0398;D)\nHere, ELBO(\u0398;D) is the Evidence Lower Bound, which is commonly used when carrying out Variational Inference with Graphical Models [Blei et al., 2017]. In the vernacular of Variational Inference, our approximating distribution, q(Z) of the True Posterior is the posterior distribution of Z given \u03b8, p(Zi|\u03b8i)."
    },
    {
      "heading": "2.3 Optimization",
      "text": "For parameter learning we utilize the popular First Order optimizer Adam [Kingma and Ba, 2015], which has a learning rate of 1\u00d7 10\u22124. We do not perform any minibatching and stop optimization as soon as we overfit the validation set.\nThe ELBO as defined in the previous section is explicitly optimized in the following form:\nELBO(\u03b8;D) = \u2212 |S|\u2211 i=1 |A|\u2211 j=1 K\u2211 k=1 SOFT-MAX(k)(\u03b8j) \u00b7 ( ||(\u03b1(\u03bei)k \u00b7 X\u0302ij + \u03b2 (\u03bei) k )\u2212Xi||22 \u03c3k )"
    },
    {
      "heading": "2.4 Identification",
      "text": "For purposes of identification and to ensure convergence to a good local minimum, we fix the hyper parameters corresponding to the latent group K = 1 as \u03b1 = 1 and \u03b2 = 0. Thus, the semantic interpretation of this latent group is that estimates from this group are accurate and unbiased."
    },
    {
      "heading": "2.5 Parameter Initialization",
      "text": "For all subgroups K 6= 1, we initialize \u03b1k and \u03b2k using the coefficient of Ridge regression estimates by regressing the estimates {{X\u0302ij}|A|j=1}Ni=1 on the corresponding set of changes in actual EPS {Xi}Ni=1. We further set the initial variance of each latent group \u03c32k to 1.0. We observe that in practice using these initial values leads to better convergence."
    },
    {
      "heading": "3 Inverse Inference for Generating Robust Estimates",
      "text": "At test time, we want to infer a robust estimate for change in EPS from the analysts\u2019 estimatesXij and the learned model parameters \u0398. For a company i, this is equivalent of inferring P (xi|{x\u0302ij}|A|j=1,\u0398). In our formulation, inference at test time is harder than parameter learning. This is primarily because the posterior over the latent variables is intractable. We can, however, express the conditional distributions of each variable in closed form, which allows us to use Gibbs Sampling, a Markov Chain Monte Carlo technique that allows inference by sampling from the conditional distributions, to overcome this challenge. Sampling from the full conditionals is easy for all of the variables except the changes in EPS actuals Xi. Proposition 1 gives the posterior distribution of Xi given the analyst estimates, {X\u0302ij}|A|j=1, and model parameters, {\u03b1k, \u03b2k, \u03c3k}Kk=1, in closed form to allow sampling.\nProposition 1 Under the DAG model assumptions in Figure 1, the Posterior Distribution of Xi conditioned on its Markov Blanket, or set of variable such that Xi is conditionally independent of all other variables in the model, is given as\nXi|[\u0303X], {zj}|A|j=1 \u223c Multivariate-Normal ( [\u00b5] , [\u03a3] )\nwhere, [\u03a3] = ( \u03c30 + [\u03b1] >[\u03b1] )\u22121 , [\u00b5] = [\u03a3]([\u03b1]> [\u0303X])\nand, [\u0303X] =  X\u0302i0\u2212\u03b2z0 X\u0302i1\u2212\u03b2z1\n... X\u0302i|A|\u2212\u03b2z|A|  , [\u03b1] =  \u03b1z0\u03b1z1... \u03b1z|A|  , [\u03c32] =  \u03c32z0 \u03c32z1 . . . \u03c32z|A|  Proof Sketch.\nThe Proof of the following proposition, involves adding a weak conjugate prior on Xi \u223c N (0, \u03c30). Now,\nX\u0302ij |Xi, zj \u223c N (\u03b1zj\u00b7Xi + \u03b2zj , \u03c32zj )\nX\u0302ij \u2212 \u03b2zj |Xi, zj \u223c N (\u03b1zj\u00b7Xi , \u03c32zj )\n{X\u0302ij \u2212 \u03b2zj} |A| j=1|Xi, {zj} |A| j=1 \u223c |A|\u220f j=1 N (\u03b1zj\u00b7Xi , \u03c32zj )\nRewriting in matrix form, we get\n[\u0303X]|Xi, {zj}|A|j=1 \u223c Multivariate-Normal ( X>i [\u03b1] , [\u03c3 2] ) (2)\nNow, from Equation 2 and the result in Cepeda and Gamerman [2000, 2005] pertaining to Bayesian Linear Regressions under Heteroscedasticity, we arrive at the posterior.\nAlgorithm 1 provides the steps in the Gibbs sampling procedure for inverse inference of Xi by sampling from the full posterior conditionals.\nAlgorithm 1: Gibb\u2019s Sampler for P ({Xi, \u03bei}|S|i=1|\u00b7) Input: {{X\u0302ij}|S|i=1} |A| j=1, {\u03b1k, \u03b2k, \u03c3k}Kk=1, {\u03b8j} |A| j=1 Initialize: for i\u2190 1 to |S| do\nX (0) i = 1 |A| \u2211 j X\u0302ij ; (Consensus Estimate) \u03be (0) i = 1{X (0) i > 0};\nend for n\u2190 1 to N do\nfor j \u2190 1 to A do z (n) j \u223c Discrete(SOFT-MAX(\u03b8j)); end for i\u2190 1 to S do\nX (n) i \u223c Pposterior(X (n) i |{z (n) j } |A| j=1, \u03be (n) i , {\u03b1k, \u03b2k, \u03c3k}Kk=1); (As in Prop. 1) \u03be (n) i = 1{X (n) i > 0};\nend end Output: {X(0)i , X (1) i , \u00b7 \u00b7 \u00b7 , X (1) i }\nWe evaluate this procedure using historical EPS estimates and actuals in the next section."
    },
    {
      "heading": "4 Experiments",
      "text": "We evaluate the ability of our model and inverse inference procedure to generate robust consensus estimates by first learning parameters from historical EPS estimates and actuals and then carrying out inverse inference to predict changes in EPS actuals Xi from test data estimates Xij . We compare these estimates using our approach, which we refer to as Latent Bayesian Averaging (LBA), to the simple consensus estimates and other reference baselines, which we describe below."
    },
    {
      "heading": "4.1 Reference Baselines",
      "text": "We consider the following reference baselines to benchmark our approach:\nNo Adjustment (NA): The estimate of Xi is the simple consensus estimate, or average of all of the analysts\u2019 estimates {X\u0302ij}|A|j=1.\nX\u0302i = 1\n|A| |A|\u2211 j=1 X\u0302ij\nWeighted Adjustment (WA): Instead of averaging over the estimates, {X\u0302ij}|A|j=1 naively, we perform a weighted averaging such that wj \u221d 1errorj , i.e. the weight given to an analyst\u2019s estimate is inversely proportional to the analyst\u2019s historical forecast accuracy.\nX\u0302i = 1\n|A| |A|\u2211 j=1 wj \u00b7 X\u0302ij\nRegression Adjustment (RA): We regress the set of true values, {X}Ni=1 against the corresponding estimates, {X\u0302}|A|a=1. At test time, we perform the learnt regression on {X\u0302} |A| a=1 to get adjusted estimates for X . The final estimate is the average of the adjusted estimates.\nWe consider two different regression functions, a parametric ridge regression RA-Ridge and a non-parametric regression consisting of an Random Forest of Decision Trees RA-Ensemble.\nX\u0302i = 1\n|A| |A|\u2211 j=1 f(X\u0302ij , \u03b8)\nwhere f(.) is the learnt regression function.\nBayesian Regression Adjustment (BA) : Instead of regressing the actual Xi on the estimates, {X\u0302ij}|A|j=1. We first learn a regression of {X\u0302ij} |A| j=1 on the actuals Xi with a linear link function f(\u03b2>Xi). At test time we condition on \u03b2 and place a weak conjugate prior on Xi. The final adjusted estimate ofXi is then recovered as the expectation ofXi under the posterior conditioned on {X\u0302ij}|A|j=1 and \u03b2.\nX\u0302i = EXi\u223cp(.|{X\u0302ij}|A|j=1,\u03b2)[Xi]\nNote that Bayesian Regression Adjustment is equivalent to our model when the number of latent groups K = 1."
    },
    {
      "heading": "4.2 Dataset",
      "text": "We use the Thompson Reuters\u2019 Institutional Brokers Estimate System (I/B/E/S) Dataset which records estimated earnings forecasts of different analysts for different companies and upcoming periods across multiple time horizons. For our experiments we look at a smaller subset of the I/B/E/S data consisting of the top 200 companies followed by the most analysts over a 19 year period from\nJanuary 1st, 2000 to January 1st, 2019. We consider forecasts at the horizons of the next Fiscal Year (FY1) and Second Fiscal Year (FY2). Some analysts have multiple revisions during this period. We only consider a revision if it was recorded at least 6 months (or 12 months) before the forecast period end date for the next Fiscal Year (Second Fiscal Year). We use the data from January 1st, 2000 to January 1st, 2012 for training, data from January 1st, 2012 to January 1st, 2014 for validation and data from January 1st, 2014 to January 1st, 2019 for testing."
    },
    {
      "heading": "5 Results",
      "text": "We consider the difference between the actual reported change in EPS and forecasted change using our method and each of the reference baselines. We report the micro averaged Root Mean Squared Error (RMSE), the Mean absolute Error (MAE) and the Coefficient of Determination (R2) across all companies for Fiscal Year 1 in Table 1 and Fiscal Year 2 in Table 2. We also report the 95%-CI which we generate by bootstrapping the inferred results for the test data points 1000 times. For completeness, we also report the RMSE and MAE values Macro Averaged over the individual companies.\nFrom the results in Tables 1 and 2, it is evident that analysts are reasonably accurate in their predictions of future earnings, as evidenced by the low RMSE for the unadjusted consensus estimates (NA). However, as expected, we see that analysts tend to err more as the forecast horizon is increased, as is evident from the higher FY2 errors. Although Weighted Averaging (WA) reduces errors in the FY2 consensus estimates, this benefit is not significant given the large confidence intervals around the results. Interestingly, we observed that Regression Adjustment (RA) reduced the consensus error by a large margin on the training dataset, but had worse performance on the test set. This was true for both Parametric Ridge Regression and Non-Parametric Random Forest Regression, suggesting that these models have a large tendency to overfit. Furthermore, amongst all the proposed baselines, Bayesian Adjustment BA has the highest errors (we do not report the R2 for BA for this reason). We hypothesize that this is because Bayesian Adjustment does not allow for the flexibility of discovering analysts who are unbiased. In contrast, our proposed Latent Bayesian Adjustment (LBA) reduces forecast error across all reported metrics for both FY1 and FY2 and the reductions are significant in each case, demonstrating its effectiveness as an improved consensus model."
    },
    {
      "heading": "6 Discussion and Future Work",
      "text": "Biases and systematic errors in earnings forecasts can negatively impact both investors and public companies. Accurate, unbiased consensus earnings are important to investors to understand the financial health of companies and value of their stock so they can make well-informed investment decisions. Similarly, if analysts\u2019 estimates are affected by behavioral, incentive-based or discriminatory biases, this may result in companies\u2019 stocks being undervalued. We proposed a Bayesian latent variable model and inverse inference procedure that we demonstrated produces estimates which are more robust than consensus estimates as well as other adjusted baselines.\nThere are a number of possible directions to pursue to further improve the model. Research has shown that analysts whose buy and sell recommendations are more profitable also produce more accurate estimates [Loh and Mianc, 2006]. Adding analysts\u2019 recommendations to the model might result in more robust identification of latent subgroups and more accurate estimates. Additionally, while our model incorporates the asymmetry in systematic errors for profit-making and loss-making companies, it does not incorporate other specific biases and asymmetries that have been identified, such as effects for different types of companies, investment banking relationships and discriminatory out of group effects. Additional data identifying some of these attributes for individual analysts and companies could further improve the model and make it more robust to these types of forecasting errors. Furthermore, the model we proposed is linear. Given the observed asymmetries in analysts\u2019 systematic forecasting errors, a nonlinear model might further improve the estimation procedure.\nWhile the focus of this paper is generating robust consensus earnings estimates, we note that the proposed model is applicable to any other problem where we have a quantity that is measured by multiple instruments or individuals, which may be subject to machine error or human subjectivity. There are many other close applications in finance and economics, such as GDP and unemployment forecasting, where this model may prove to be more robust than existing approaches. It might also prove useful in more distant applications like elections forecasting or combining sensor readings.\nDisclaimer\nThis paper was prepared for information purposes by the AI Research Group of JPMorgan Chase & Co and its affiliates (\u201cJ.P. Morgan\u201d), and is not a product of the Research Department of J.P. Morgan. J.P. Morgan makes no explicit or implied representation and warranty and accepts no liability, for the completeness, accuracy or reliability of information, or the legal, compliance, financial, tax or accounting effects of matters contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction."
    }
  ],
  "title": "Latent Bayesian Inference for Robust Earnings Estimates",
  "year": 2020
}
