{
  "abstractText": "We summarize our recent findings Ghauch et al. (2017), where we proposed a framework for learning a Kolmogorov model, for a collection of binary random variables. More specifically, we derive conditions that link outcomes of specific random variables, and extract valuable relations from the data. We also propose an algorithm for computing the model and show its first-order optimality, despite the combinatorial nature of the learning problem. We apply the proposed algorithm to recommendation systems, although it is applicable to other scenarios. We believe that the work is a significant step toward interpretable machine learning.",
  "authors": [
    {
      "affiliations": [],
      "name": "Hadi Ghauch"
    },
    {
      "affiliations": [],
      "name": "Mikael Skoglund"
    },
    {
      "affiliations": [],
      "name": "Hossein Shokri-Ghadikolaei"
    },
    {
      "affiliations": [],
      "name": "Carlo Fischione"
    },
    {
      "affiliations": [],
      "name": "Ali Sayed"
    }
  ],
  "id": "SP:e35c9e0f7247ca00265ac516fb89494a346d43cf",
  "references": [
    {
      "authors": [
        "Bishop",
        "Christopher M"
      ],
      "title": "Pattern Recognition and Machine Learning",
      "venue": "Springer-Verlag, Secaucus, NJ, USA,",
      "year": 2006
    },
    {
      "authors": [
        "Cai",
        "Jian-Feng",
        "Cands",
        "Emmanuel J",
        "Shen",
        "Zuowei"
      ],
      "title": "A singular value thresholding algorithm for matrix completion",
      "venue": "SIAM Journal on Optimization,",
      "year": 2010
    },
    {
      "authors": [
        "Davenport",
        "Mark",
        "Romberg",
        "Justin"
      ],
      "title": "An overview of low-rank matrix recovery from incomplete observations",
      "venue": "IEEE Journal of Selected Topics in Signal Processing,",
      "year": 2016
    },
    {
      "authors": [
        "Doshi-Velez",
        "Finale",
        "Kim",
        "Been"
      ],
      "title": "Towards a rigorous science of interpretable machine learning",
      "year": 2017
    },
    {
      "authors": [
        "Frank",
        "Marguerite",
        "Wolfe",
        "Philip"
      ],
      "title": "An algorithm for quadratic programming",
      "venue": "Naval Research Logistics Quarterly,",
      "year": 1956
    },
    {
      "authors": [
        "Gantner",
        "Zeno",
        "Rendle",
        "Steffen",
        "Freudenthaler",
        "Christoph",
        "Schmidt-Thieme",
        "Lars"
      ],
      "title": "Mymedialite: A free recommender system library",
      "venue": "In Proceedings of the Fifth ACM Conference on Recommender Systems,",
      "year": 2011
    },
    {
      "authors": [
        "Ghauch",
        "Hadi",
        "Skoglund",
        "Mikael",
        "Shokri-Ghadikolaei",
        "Hossein",
        "Fischione",
        "Carlo",
        "Sayed",
        "Ali"
      ],
      "title": "Learning elementary representations of random variables",
      "venue": "Journal of Machine Learning Research (submitted),",
      "year": 2017
    },
    {
      "authors": [
        "Gray",
        "Robert M"
      ],
      "title": "Probability, Random Processes, and Ergodic Properties",
      "year": 2009
    },
    {
      "authors": [
        "Jaggi",
        "Martin"
      ],
      "title": "Revisiting Frank-Wolfe: Projection-free sparse convex optimization",
      "venue": "In Proceedings of the 30th International Conference on Machine Learning,",
      "year": 2013
    },
    {
      "authors": [
        "Y. Koren",
        "Bell",
        "Robert",
        "Volinsky",
        "Chris"
      ],
      "title": "Matrix factorization techniques for recommender systems",
      "year": 2009
    },
    {
      "authors": [
        "Koren",
        "Yehuda"
      ],
      "title": "Factorization meets the neighborhood: A multifaceted collaborative filtering model",
      "venue": "In Proceedings of the 14th ACM International Conference on Knowledge Discovery and Data Mining,",
      "year": 2008
    },
    {
      "authors": [
        "Lee",
        "Daniel",
        "Seung",
        "Sebastian"
      ],
      "title": "Algorithms for nonnegative matrix factorization",
      "venue": "In Advances in Neural Information Processing Systems (NIPS),",
      "year": 2001
    },
    {
      "authors": [
        "Lipton",
        "Zachary Chase"
      ],
      "title": "The mythos of model interpretability",
      "venue": "CoRR, abs/1606.03490,",
      "year": 2016
    },
    {
      "authors": [
        "Lloyd",
        "Stuart"
      ],
      "title": "Least squares quantization in PCM",
      "venue": "IEEE Trans. Inf. Theor.,",
      "year": 2006
    },
    {
      "authors": [
        "Luo",
        "Zhi-Quan",
        "Ma",
        "Wing-Kin",
        "So",
        "A.M.-C",
        "Ye",
        "Yinyu",
        "Zhang",
        "Shuzhong"
      ],
      "title": "Semidefinite relaxation of quadratic optimization problems",
      "venue": "IEEE Signal Processing Magazine,,",
      "year": 2010
    },
    {
      "authors": [
        "Marr",
        "Bill"
      ],
      "title": "The top 10 AI and machine learning use cases everyone should know about",
      "year": 2016
    },
    {
      "authors": [
        "Slawski",
        "Martin",
        "Hein",
        "Matthias",
        "Lutsik",
        "Pavlo"
      ],
      "title": "Matrix factorization with binary components",
      "venue": "In Advances in Neural Information Processing Systems (NIPS),",
      "year": 2013
    },
    {
      "authors": [
        "Stark",
        "Cyril J"
      ],
      "title": "Expressive recommender systems through normalized nonnegative models",
      "venue": "CoRR, abs/1511.04775,",
      "year": 2015
    },
    {
      "authors": [
        "Stark",
        "Cyril J"
      ],
      "title": "Expressive recommender systems through normalized nonnegative models",
      "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,",
      "year": 2016
    },
    {
      "authors": [
        "Stark",
        "Cyril J"
      ],
      "title": "Recommender systems inspired by the structure of quantum theory",
      "venue": "CoRR, abs/1601.06035,",
      "year": 2016
    },
    {
      "authors": [
        "Tan",
        "Peng Hui",
        "L.K. Rasmussen"
      ],
      "title": "The application of semidefinite programming for detection in CDMA",
      "venue": "IEEE Journal on Selected Areas in Communications,",
      "year": 2001
    },
    {
      "authors": [
        "Whang",
        "Joyce Jiyoung",
        "Dhillon",
        "Inderjit S",
        "Gleich",
        "David F"
      ],
      "title": "Non-exhaustive, overlapping k-means",
      "venue": "In Proceedings of the 2015 SIAM International Conference on Data Mining, pp",
      "year": 2015
    }
  ],
  "sections": [
    {
      "heading": "1. Introduction",
      "text": "Machine learning and artificial intelligence tools have permeated a large number of areas (Marr, Sept 2016). These tools are based on machine learning models, which consist of learning an input-output mapping for a given dataset. Despite the plethora of models (e.g., matrix factorization (Koren et al., 2009), SVD-based models (Koren, 2008), neural networks (LeCun et al., 2015), and models inspired from physics (Stark, 2016b)), they lack interpretability: not offering insight about the data, nor the underlying process.\nThe work follows recent attempts at interpretable machine learning (Doshi-Velez & Kim, 2017), where the lack of interpretablity may have serious consequences in missioncritical systems, ethics, and validation of computer-aided diagnosis (Doshi-Velez & Kim, 2017). While there is no consensus around the definition of interpretability, causality (Lipton, 2016) is a vital component: it refers to associations within the data and information about the underlying data-generating process. We adopt the latter as our \u2018defi-\n1School of Electrical Engineering, Royal Institute of Technology, KTH, Stockholm 2School of Electrical, Ecole Polytechnique Federale de Lausanne . Correspondence to: Hadi Ghauch <ghauch@kth.se>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nnition\u2019 of interpretable model, as one where data-to-data relations are accurately discovered.\nWe propose learning a so-called Kolmogorov Model (KM) associated with a set of binary Random Variables (RVs). In addition to prediction, the interpretability of the model (as defined above) enables learning association rules (Agrawal et al., 1993): We derive a sufficient conditions under which the realization of one RV\u2019s outcome (deterministically) implies the outcome of the other. In the context of recommendation systems, association rules identify groups of items, for which a user liking one item implies that he/she likes all other items in the group. In cancer detection, the same rules identify groups of samples, for which the presence of DNA methylation in the group, implies its presence in all other samples. Additionally, these rules may provide insight into the physical mechanisms underlying user preferences, and DNA methylation.\nWe formulate the resulting problem as a coupled combinatorial problem, decompose it into two subproblems using the Block-Coordinate Descent (BCD) method, and we obtain provably optimal solutions for both. For the first one, we exploit the structure of linear programs on the unit simplex, to propose a low-complexity (yet optimal) Frank-Wolfe algorithm (Frank & Wolfe, 1956). To bypass the inherent complexity of the second subproblem (combinatorial and NP-hard), we propose a semidefinite relaxation, and show its quasi-optimality in recovering the optimal solution of the combinatorial subproblem. Finally, we show the convergence of our algorithm to a stationary point of the original problem. We refer the reader to Ghauch et al. (2017) for all the derivations/discussions."
    },
    {
      "heading": "2. System Model",
      "text": "Notation: We use bold upper-case letters to denote matrices, bold lower-case letters to denote vectors, and calligraphic letters to denote sets. For a given matrixA, [A]i,j denotes element (i, j), tr(A) denotes its trace, \u2016A\u2016F its Frobenius norm, and AT its transpose. For a vector a, [a]i denotes element i, [a]i:j elements i to j, and supp(a) its support. The inequality x \u2264 y holds element-wise. In denotes the n\u00d7n identity matrix, 1 and 0 the all-one and all-zero vectors (of appropriate dimension). en is the nth elementary basis vector, P = {p \u2208 RD+ | 1Tp = 1} the unit probability\nar X\niv :1\n80 6.\n02 32\n2v 1\n[ cs\n.L G\n] 6\nJ un\n2 01\n8\nsimplex, and {n} = {1, \u00b7 \u00b7 \u00b7 , n}."
    },
    {
      "heading": "2.1. Problem Formulation",
      "text": "Consider a double-indexed set of binary Random Variables (RVs), Xu,i \u2208 A = {1, 2}, with indexes from D = {(u, i) | u \u2208 U , i \u2208 I}. The RVs are defined on a sample space \u2126, consisting of elementary events \u2126 = {\u03c9d | 1 \u2264 d \u2264 D}. We denote by P[Xu,i = z], z \u2208 A, the probability that RV Xu,i takes the value z \u2208 A. Using that A = {1, 2}, we write P[Xu,i = 1] = \u03b8Tu\u03c8i,1 and P[Xu,i = 2] = \u03b8 T u\u03c8i,2, (1)\nwhere \u03c8i,1 +\u03c8i,2 = 1. \u03b8u is a Probability Mass Function (PMF) vector on the unit simplex, P , and {\u03c8i,1,\u03c8i,2} \u2208 BD are binary indicator vectors representing the support of its probability measure. The model follows from established results in classical probability (Gray, 2009).Since Xu,i is binary, it is fully characterized by considering one outcome,\nP[Xu,i = 1] = \u03b8Tu\u03c8i, (2) (1) and (2) are equivalent, and will be used interchangeably (dropping the z subscript of \u03c8i without any loss in generality). Thus, each RV Xu,i is associated with (determined by) a PMF vector \u03b8u, u \u2208 U , and an indicator vector \u03c8i, i \u2208 I. Notice that the model in (2) can approximate with arbitrarily small accuracy the measure corresponding to P[], given a large enough D.\nProblem 1 (Problem Statement) Let pu,i denote the empirical values of P[Xu,i = 1]. We assume that {pu,i} are known for elements of a training set K \u2286 D, where K = {(u, i) | (u, i) \u2208 U \u00d7 I}. 1 Given samples coming from the model in (2), we wish to deduce the parameters of underlying probability distribution: find parameters of the KM, i.e., {\u03c8i,\u03b8u} that best describe {pu,i | (u, i) \u2208 K}. The resulting problem is a fully parametric statistical inference task. For tractability, we address it using the minimum mean-squared error as a point estimator, which in turn results in minimizing\n\u2211 (u,i)\u2208K(P[Xu,i = 1] \u2212 pu,i)2 =\u2211\n(u,i)\u2208K(\u03b8 T u\u03c8i\u2212pu,i)2. Once computed, the optimal KM parameters can be used for prediction on a different set, and extracting statistical relations (among the RVs in K). The resulting optimization problem is\n(Q)  min {\u03c8i},{\u03b8u} \u2211 (u,i)\u2208K ( \u03b8Tu\u03c8i \u2212 pu,i )2 , E\ns.t. \u03b8u \u2208 P , \u03c8i \u2208 BD, \u2200(u, i) \u2208 K . (3)\nOur solution to this non-convex combinatorial problem is detailed in Section 3.\n1Note that acquiring (estimates of) the empirical probabilities can be done via training, and the specific method is applicationdependent (see Appendix A.2)."
    },
    {
      "heading": "2.2. Toy Example: Recommendation Systems",
      "text": "In this context, Xu,i models the preference of user u for item i, (u, i) \u2208 K. Thus, P[Xu,i = 1] (resp. P[Xu,i = 2]) models the probability that user u likes (resp. dislikes) item i. Moreover, \u03b8u determines the profile/taste of user u, \u03c8i is related to item i (depending on genre, price, etc.), and the elementary events denote movie genres (e.g., \u03c91 = \u201cAction\u201d, \u03c92 = \u201cSciFi\u201d, etc.). 2 Then, the corresponding empirical probability (i.e., training set) is obtained as pu,i , [R]u,i/Rmax where [R]u,i \u2208 N denotes the rating that user u has provided for item i, and Rmax the maximum rating (Stark, 2015).\nConsider a 10-star \u201crecommendation system\u201d, having 2 users and 2 items. We then find the D-dimensional (D = 3) KM factorization to obtain , {\u03c8i}2i=1 and {\u03b8u}2u=1.3 To showcase the model\u2019s intuition, note that p1,1, the probability that user 1 likes movie 1, is represented as \u03c8T1 \u03b81. It is thus expressed as convex/stochastic mixture of movie genres, since elementary events are movie genres in this scenario. More generally, a KM represents a set of observed outcomes for RVs, as mixtures of elementary events. After finding the empirical probabilities from the rated entries (as above), (Q) is solved to learn {\u03c8i}2i=1 and {\u03b8u}2u=1, and an example result is shown below: [ 0.3 0.5\n0.1 0.2 ] \ufe38 \ufe37\ufe37 \ufe38 {pu,i} =\n[ \u03b8T1 { 0.2 0.3 0.5\n\u03b8T2 { 0.1 0.1 0.8 ] 0 1 }Action 1 1 }SciFi 0\ufe38\ufe37\ufe37\ufe38 \u03c81 0\ufe38\ufe37\ufe37\ufe38 \u03c82 }Drama "
    },
    {
      "heading": "2.3. Related Work",
      "text": "Our proposal to model binary RVs as elementary events on a Kolmogorov space (Section 2.1) is based on established results from classical probability theory. To our best knowledge, this specific formulation is novel. Because this model is rooted in probability theory, (2) defines the outcome of a RV in the strict Kolmogorov sense (see definition in Section 2.1), and the resulting association rules (Section 4) also hold analytically. This is the reason behind the versatility of the approach. We will also show that the combinatorial aspects of (Q) are not a limitation.\nThe inner product in (2) is reminiscent of factorization methods such as, Matrix Factorization (MF) (Koren et al., 2009), Nonnegative Matrix Factorization (NMF) (Lee & Seung, 2001), SVD (Cai et al., 2010), and physics-inspired techniques (e.g., Nonnegative Models (NNMs) (Stark, 2016a)).\n2The model is generic since interpreting the elementary events in context-dependent. For a coin toss, \u2126 = {\u03c91, \u03c92}, the elementary events denote heads and tails, respectively.\n3D is the size of the Kolmogorov space \u2126, the number of elementary events, and the dimension of the factorization (selected via cross-validation to minimize the test error).\nHowever, the inner product in these methods do not model RVs, in an analytical sense (Section 2.1). Our method also generalizes K-means and some of its variants. Detailed discussions of the relation between our proposed method and these prior works is in Appendix A.1."
    },
    {
      "heading": "3. Proposed Algorithm",
      "text": "We use the well-known Block-Coordinate Descent (BCD) framework to handle coupling in the cost function of (Q) in (3). The method essentially splits (Q) into two subproblems. We derive different methods for each subproblem, with provable accuracy, and show convergence of the algorithm. Given {\u03c8(n)i } at iteration n, we first refine the current PMF estimate \u03b8u, as (Q1) : \u03b8 (n+1) u \u2208 argmin\n\u03b8u\u2208P f(\u03b8u) , \u03b8\nT uQ (n) u \u03b8u \u2212 2\u03b8 T ur (n) u ,\nwhere Q(n)u , \u2211 i\u2208IK \u03c8 (n) i \u03c8 (n)T i , r (n) u , \u2211 i\u2208IK \u03c8 (n) i pu,i. (e.1) We then refine the current indicator vector estimate, \u03c8i as (Q2) : {\u03c8(n+1)i } \u2208 argmin \u03c8i\u2208BD g(\u03c8i) , \u03c8 T i S (n+1) i \u03c8i \u2212 2\u03c8 T i v (n+1) i where S\n(n+1) i , \u2211 u\u2208UK \u03b8 (n+1) u \u03b8 (n+1)T u ,v (n+1) i , \u2211 u\u2208UK \u03b8 (n+1) u pu,i (e.2)\nMoreover, UK and IK are defined as K = {(u, i) | u \u2208 UK \u2282 U , i \u2208 IK \u2282 I}. Next we describe the solution approach to each problem."
    },
    {
      "heading": "3.1. Refine PMF Estimate",
      "text": "(Q1) is a convex quadratic problem that can be solved by a variety of tools. However, we exploit its structure to greatly reduce the computational complexity: The FrankWolfe (FW) algorithm (Frank & Wolfe, 1956) solves (Q1) as a succession of Linear Programs (LPs) over the unit simplex. While LP solvers generally have similar complexity as quadratic program solvers, solving an LP reduces to searching for the minimum index, when the LP is over the unit simplex. We formalize the algorithm, focusing on the original FW (detailed in Jaggi (2013)[Algorithm 1]).\nWhile \u03b8u should have two superscripts, n for the BCD iteration and k for the FW iteration, we only use \u03b8(k)u . We first determine the descent direction:\nd(k)u \u2208 argmins ( \u2207f(\u03b8(k)u ) )T s s.t. s \u2208 P . (4)\nThe constraint s \u2208 P greatly simplifies the above LP, i.e., d(k)u = ej? , j ? \u2208 argmin1\u2264j\u2264D [\u2207f(\u03b8 (k) u )]j . (5) The solution follows from LPs over the unit probability simplex (Proposition 2). Thus, finding the descent direction reduces to searching over the D-dimensional vector \u2207f(\u03b8(k)u ) (done in O(D)). Then, \u03b8 (k) u is updated using a\nsimple step size, \u03b1(k)u = k/(k + 1) (Jaggi, 2013). Table 1 summarizes the FW procedure, and Proposition 3 shows its convergence,"
    },
    {
      "heading": "3.2. Refine Indicator Estimate",
      "text": "The NP-hard nature of (Q2) implies that relaxations are the only choice for a scalable solution. We thus propose a solution based on Semi-Definite Relaxation (SDR) and randomization, and establish its quasi-optimality for (Q2). We use the results of Ma et al. (2002)[Sec IV-C]) and a series of reformulations to rewrite (Q2) in its equivalent form (Ghauch et al., 2017):\nX?i \u2208 argminXi tr(S\u0303iXi)s.t.Xi 0, [Xi]k,k = 1,\u2200k , rank(Xi) = 1 where Xi = xixTi , S\u0303i = [ (1/4)Si \u2212t\u0303i/2\n\u2212t\u0303Ti /2 0 ] , xi =[\nzi\nwi\n] , zi = 2\u03c8i \u2212 1, wi \u2208 {\u22121,+1} is an auxiliary\nvariable, and t\u0303i , (vi \u2212 (1/2)Si1). The above problem is then relaxed into a convex SDP,\nX (SDR)i \u2208 argminXi tr(S\u0303iXi) .s.t.Xi 0, [Xi]k,k = 1,\u2200k (6) X (SDR)i may be solved using generic SDP solvers. Then, a randomization procedure (Ma et al., 2002) extracts an approximate (binary) solution \u03c8\u0302i of (Q2); see Table 2. This evidently raises the issue of the suboptimality gap for SDR. We show in Proposition 4 that SDR is optimal (asymptotically in D) in recovering the binary solution of (Q2). Note that the performance bound in Proposition 4 compares the quality of the approximate binary solution offered by SDR, against the optimal solution of (Q2) (rather than just comparing the resulting cost functions)."
    },
    {
      "heading": "3.3. Algorithm Description",
      "text": "The BCD-based algorithm alternates between refining the indicator and PMF vectors (using the methods of Sec. 3.2 and Sec. 3.1; see Algorithm 1. Its convergence to a sta-\ntionary point of (Q) is shown Lemma 1. Figure 1 shows the convergence behavior of Algorithm 1 for the ML100K dataset. The numerical setup and further results are provided in Appendix A.7 (due to the lack of space)."
    },
    {
      "heading": "4. Interpretability via Association Rules",
      "text": "Once a KM is found, we derive association rules that emerge from (1) and (2)."
    },
    {
      "heading": "4.1. Association Rules",
      "text": "Proposition 1 (Inclusion of Support Set) Consider two random variables Xu,i and Xu,j (belonging to the training set), whose KM are given by (1). If supp(\u03c8j) \u2286 supp(\u03c8i), then the following association rules hold:\nXu,i = 1 implies Xu,j = 1 (7) Xu,j = 2 implies Xu,i = 2 . (8)\nFor the toy example of Section 2.2, note that supp(\u03c81) \u2286 supp(\u03c82). Then, Proposition 1 yields: if user 1 (or user 2) likes movie 2 implies he/she also likes movie 1. Propo-\nAlgorithm 1 Iterative computation of KMs (IKM)\n// Randomly Initialize {\u03b8(1)u \u2208 P} for n = 1, 2, ... do\nCompute S(n)i and t (n) i from (e.2) Update \u03c8\u0302 (n)\ni = SDR-wR(S (n) i , t (n) i ,Mrnd ), \u2200i \u2208 IK\nComputeQ(n)u and r (n) u from (e.1) // Initialize FWA with {\u03b8(n\u22121)u }, from prev iter Update \u03b8(n) ?\nu = FWA(Q (n) u , r (n) u , ), for all u \u2208 UK\nend for\nsition 1 motivates us to look for cases where the support set condition trivially holds: when \u03c8i = 1, then supp(\u03c8i) = {D}, and supp(\u03c8j) \u2286 supp(\u03c8i) holds, for any choice of \u03c8j\u2200 j \u2208 IK , where IK defined in Section 3.\nCorollary 1 (Maximally Influential RVs) Let {\u03c8i, \u03b8u}(u,i)\u2208K denote the KM associated with the outcome 1 for Xu,i, i.e., {Xu,i = 1}(u,i)\u2208K. We define M = {i | \u03c8i = 1} as the set of RV outcomes with maximum support. Then, the condition supp(\u03c8j) \u2286 supp(\u03c8i) (Proposition 1) holds trivially \u2200 j \u2208 IK . It follows that the association rules in (7) hold, for each i \u2208 M.\nFor maximally influential RVs, the realization of one outcome, Xu,i = 1, determines that of all RVs of the set {Xu,j = 1 | \u2200j \u2208 IK}. It is illustrated in Figure A.1. For a recommendation system, maximally influential RVs are items for which a user liking an item implies that he/she like all other items, in the training set. We underline that, unlike other probabilistic association rules, our approach provides deterministic rules. In Appendix A.3, we have provided efficient algorithmic approach to automatically mine these rules based on the adjacency matrix and influence score. Simulation results confirm the usefulness of our association rules ; see Appendix A.7."
    },
    {
      "heading": "5. Conclusion",
      "text": "We have proposed a framework for learning a Kolmogorov model, associated with a collection of binary RVs. Interpretability of the model (as defined by causality) was harnessed by deriving association rules, i.e., by finding sufficient conditions that bind outcomes of certain random variables. We also proposed an algorithm for computing a Kolmogorov model, a combinatorial non-convex problem, and showed its convergence to a stationary point of the problem, using block-coordinate descent. The combinatorial nature of the problem was addressed using a semi-definite relaxation, where we showed that it yields asymptomatically optimal solutions. Our results suggest that increased interpretability and improved prediction, do not cause a significant increase in complexity."
    },
    {
      "heading": "A. Supplementary Material for Learning Kolmogorov Models for Binary",
      "text": "Random Variables"
    },
    {
      "heading": "A.1. Related Work",
      "text": "We position our work against other approaches (focusing on recommendation systems).\nFactorization Methods: Note that, (Q) can be re-written as a low-rank matrix factorization problem, over the set of binary and stochastic matrices (Ghauch et al., 2017)[Sec. 9.2]. Thus, the proposed approach is connected to factorization methods: Matrix Factorization (MF) (Koren et al., 2009), Nonnegative Matrix Factorization (NMF) (Lee & Seung, 2001), SVD (Cai et al., 2010) (and their many variants/extensions) have gained widespread applicability, covering areas in sound processing, (medical) image reconstruction, recommendation systems and prediction problems (Davenport & Romberg, 2016). These techniques assume that each element in K is the inner product of two arbitrary vectors. Thus, the model in (2) does not represent a RV (in a mathematical sense), when viewed in the context of the proposed model (Section 2.1). Consequently, the analytical guarantees of Section 4, that yield the association rules, do not hold for general factorization methods: Though association rules may still be extracted, they are not as rooted in Kolmogorov probability theory, and lead to different statistical relations. Naturally, we wish the explore the association rules that arise from the proposed model.\nExact Factorization: Ideally, it is desirable to solve (Q) exactly, i.e., find \u03b8u,\u03c8i satisfying pu,i = \u03b8 T u\u03c8i, \u2200(u, i) \u2208 K, over the training set K. While we are unaware of such results, we highlight a related variant where the factorization is solved exactly over the entire dataset D, i.e, pu,i = \u03b8 T u\u03c8i, \u2200(u, i) \u2208 D, using binary MF (Slawski et al., 2013): It is not applicable when factorizing a subset of D, e.g., the training set K. Consequently, binary MF is unfit for prediction tasks.\nKMs as a generalization of K-Means: Consider a special case of (Q), where \u03c8i is constrained to have one non-zero element. The resulting problem becomes the well-knownKmeans clustering (Lloyd, 2006). The K-means algorithms (and its variants K-medoids, fuzzy K-means and K-SVD), have become pervasive in an abundance of applications such as clustering, classification, image segmentation, DNA analysis, online dictionary learning, source coding, etc. Our approach generalizes K-means, by allowing for overlapping clusters. While a similar generalization of the classical Kmeans algorithm was considered in (Whang et al., 2015), the number of points per cluster is determined explicitly. In our approach however, the number of points per cluster is optimized within the algorithm.\nNonnegative Models: Non-Negative Models (NNMs) (Stark, 2016a) are recent attempts at interpretable models. For reasons of computational tractability (Stark, 2016a), NNMs are defined by relaxing \u03c8i in (2), to the unit hypercube. However, this relaxation impairs the highly interpretable nature of the original model in (2), making association rules less accurate. Moreover, the relaxation implies that (2) no longer models the outcome of a random variable, thus limiting its applicability to (many) problems where KMs are applicable."
    },
    {
      "heading": "A.2. Applications",
      "text": "We briefly mention other applications.\nOutage Prediction in Wireless Communication: Consider a network with several transmitters and receivers. In this setting, Xu,i represents the state of the communication link, between transmitter u and receiver i (link (u, i)), and P[Xu,i = 1] (resp. P[Xu,i = 2]) denotes the probability that it is \u201cgood\u201d (resp. in outage). Then the corresponding KM, computed from K, can be used to predict the state of other links, in a different set. Moreover, the association rules in Section 4 identify links in the network, where link (u, i) good (resp. in outage) implies that link (u, j) good (resp. in outage). Thus the interpretability of KM provides valuable information on the network.\nDNA methylation for Cancer Detection: Recent investigations have suggested that DNA methylation, chemical changes in the DNA structure, may act as a cancer detection mechanism (Houseman et al., 2012). In this context, pu,i denotes the measured methylation level for location i on the DNA, and sample u. DNA methylation expresses pu,i = \u03c8 T i \u03b8u, where \u03c8i is a binary vector indicating the presence or absence of DNA methylation at location i, and \u03b8u is a PMF vector modeling the weight assigned to each location (Slawski et al., 2013). From the perspective of KMs, \u03c8Ti \u03b8u is the probability that location i and sample u is methylated. Moreover, the association rules can identify groups of DNA locations for which the presence (resp. absence) of methylation in one location, implies its presence (or absence) for all other locations in the group. Note that, the above insights are not possible using conventional methylation analysis.\nA.3. Interpretable Aspects\nHere we detail additional aspects of KMs, related to interpretability (via association rules).\nAdjacency Matrix and Influence Score: The association rules of Proposition 1 can be modeled using the so-called\nadjacency matrix A \u2208 B|IK |\u00d7|IK |, define as\n[A]i,j = ai,j =\n{ 1, if supp(\u03c8j) \u2286 supp(\u03c8i)\n0, otherwise . (A.1)\n[A]i,j = 1 denotes the inclusion of Xu,j in Xu,i. In this case, the first outcome ofXu,i implies the same outcome for Xu,j , and the second outcome for Xu,j implies the second one for Xu,i (as stated in Proposition 1), thereby implying coupling and mutual influence among them (since Xu,i influencesXu,j and vice-versa). This raises the natural question of quantifying this coupling. We define an influence score essentially counting (and normalizing) the number of pairs Xu,i and Xu,j , satisfying the support set condition,\n\u03b2i = 1 |IK | \u2211 j\u2208IK j 6=i ai,j . (A.2)\nThus, we provide the following method for automatically mining these rules (presented in the context of recommendation systems).\n\u2022 Check the support set condition, via a pairwise search to check for pairs \u03c8i and \u03c8j satisfying supp(\u03c8j) \u2286 supp(\u03c8i), \u2200(i, j) \u2208 IK \u00d7 IK , i 6= j. \u2022 Build the adjacency matrixA, in (A.1) , and compute the influence score \u03b2i \u2022 Find all pairs (i, j) such that ai,j = 1: for each of these pairs the following holds (from Proposition 1),{\n[u likes i] implies [u likes j]\n[u dislikes j] implies [u dislikes i] (A.3)\n\u2022 Identify, if possible, maximally influential RVs (Corollary 1), having the all-one indicator vector, i.e.,M = {i | \u03c8i = 1}. For each of them, the relations in (A.3) hold for all other items in the collection\nPractical Issues Regarding Interpretability We recall that the proposed SDR method was shown to be quasioptimal in providing approximate binary solutions to (Q2). Thus, the relaxation does not affect the interpretability, in the sense that Proposition 1 and Corollary 1 still hold. However, another remark is in order. While the derivations pertaining to association rules (Section 4) assume globally optimal solutions to (Q) - an NP-hard problem, Algorithm 1 guarantees locally optimal ones. Thus, a bound on the gap between these solutions is needed. We highlight this issue as an interesting topic for further investigation.\nA.4. Variations and Special Cases\nLearning RVs with Common Support: We underline some interesting special case of the proposed approach, namely, when all the RVs have the same support, i.e., \u03c81 = \u00b7 \u00b7 \u00b7 = \u03c8D , \u03c8. This reduces to learning KMs, for RVs having common support.\nLearning a sequence of RVs: Consider a special case of Sec. 2.1, where we learn a KM for a sequence of binary RVs, {Xu | u \u2208 U}, from observing samples from the training set, {pu | u \u2208 UK}. The KM in (2) reduces to P[Xu = 1] = \u03b8Tu\u03c8, and resulting optimization becomes: min{\u03b8u},\u03c8 \u2211 u\u2208UK (\u03b8 T u\u03c8 \u2212 pu)2\ns.t. \u03b8u \u2208 P , \u2200u \u2208 UK , \u03c8 \u2208 BD (A.4)\nThe BCD-based solution approach is still applicable in this case, though many simplifications are possible."
    },
    {
      "heading": "A.5. Practical Aspects",
      "text": "Including Regularization Parameters: Regularization parameters for \u03b8u and \u03c8i, are needed for prediction to avoid over-fitting (Bishop, 2006)[Sec. 1.1]. They can be included without any changes to the solution method. An `2\u2212regularization can be included in (Q1): f(\u03b8u) = \u03b8 T u (Qu + \u03bbuID)\u03b8u \u2212 2\u03b8 T uru + \u03b3u , (A.5) where the regularizer \u03bbu \u2265 0 is absorbed into a \u201cnew\u201d matrix (Qu + \u03bbuID). While desirable, an `1\u2212regularization for \u03b8u would not work, since \u03b8u \u2208 P . Similarly, an `1- regularization for (Q2) is, g(\u03c8i) = \u03c8 T i Si\u03c8i \u2212 2(vi \u2212 (\u00b5i/2)1)T\u03c8i + \u03b3i , (A.6)\nwhere the regularizer \u00b5i is absorbed into the linear term, since \u00b5i\u2016\u03c8i\u20161 = \u00b5i1T\u03c8i, for \u03c8i binary.\nComputational Complexity: The computational complexity of Algorithm 1 is dominated by the SDP solution in (6), \u2248 O(D4.5) for medium accuracy solutions (keeping in mind the negligible cost of the FW method). Thus, the total cost (per iteration) of Algorithm 1 is CKM \u2248 O(D4.5). The added complexity compared to MF, NMF, NNM and SVD++ (\u2248 O(D3)) is not significant, keeping in mind that D min(|IK | , |UK |). Moreover, complexity reduction techniques (for the SDP solution) can be investigated. Finally, proposed method yields problems that decouple , thereby significantly speeding up the computation due to parallelization.\nNon-stationary distributions: The proposed method assumes that distributions of the RVs (in the training set) are stationary: Indeed, scenarios with time-varying distributions are a limitation (and interesting future directions). However, in learning it is quite common to assume that the data-generating distribution is stationary."
    },
    {
      "heading": "A.6. Main Results",
      "text": "Below, we summarized the results used in the paper; see Ghauch et al. (2017) for the proofs.\nLPs over the Unit Probability Simplex: We use following known result to find the descent direction for the FW method (the proof is known).\nProposition 2 Consider the following Linear Program (LP),\n(PPS) x ? = argmin x\u2208Rn cTx, s.t. 1Tx = 1, x \u2265 0"
    },
    {
      "heading": "Its optimal solution is given by",
      "text": "x? = ej? ,where j? = argmin1\u2264j\u2264n c Tej\nThus, the solution reduces to searching over the vector c.\nConvergence of FW algorithm: We show the convergence of the FW algorithm (Table 1).\nProposition 3 Let \u03b8?u be the optimal solution to (Q1). Then the sequence of iterates {\u03b8(k)u } satisfies (Jaggi, 2013)[Theorem 1],\n\u2016f(\u03b8(k+1)u )\u2212 f(\u03b8 ? u)\u20162 \u2264 O(1/k), k = 1, 2, \u00b7 \u00b7 \u00b7\nProof: The linear convergence rate for all FW variants, was proved in Jaggi (2013)[Theorem 1].\nQuasi-optimality of SDR: The question was studied extensively in the context of binary detection for multi-antenna communication (Tan & Rasmussen, 2001). Interestingly, (Q2) can be recast as a noiseless binary detection problem, where SDR has been to be optimal. The results is formalized below.\nProposition 4 Let g(\u03c8?i ) and g(\u03c8\u0302i) denote the optimal solutions to the binary QP in (Q2), and its SDR after randomization (Table 2), respectively. The approximation quality is defined as (Luo et al., 2010),\n\u03b7 \u2264 g(\u03c8?i )/g(\u03c8\u0302i) \u2264 1. (A.7) It holds that \u03b7 = 1, with probability 1\u2212 exp\u2212O(D), asymptotically in D. Thus, the relaxation is quasi-optimal.\nProof: See (Ghauch et al., 2017)."
    },
    {
      "heading": "Convergence of IKM:",
      "text": "Lemma 1 Let tn , E({\u03c8(n)i }, {\u03b8 (n) u }), n = 1, 2, ... be the sequence of iterates, resulting from the updates in IKM. Then, {tn} is non-increasing in n, and converges to a stationary point of (Q) in (3), almost surely.\nProof: The convergence is shown in (Ghauch et al., 2017)."
    },
    {
      "heading": "A.7. Numerical Results",
      "text": "Experimental Setup: The training set K, is chosen as the MovieLens 100K (ML100K), with U = 943 users and I = 1682 items, split into 80% for training and 20% for testing. Let {\u03c8\u0302i}, {\u03b8\u0302u} the output of Algorithm 1, after 5 iterations (used to predict pu,i over the test set). For benchmarking, we factorize the rating matrix using MF (Koren et al., 2009), NMF (Lee & Seung, 2001), SVD++(Koren, 2008) (ensuring the dimension of the factorization, k, is close to D). The implementation and results use the MyMediaLite package (Gantner et al., 2011), and the corresponding performance results are available http://www.mymedialite.net/examples/ datasets.html. We also benchmark against the NNM algorithm in Stark (2015), and the classical K-means (K-M) algorithm.\nTraining Performance: We first evaluate the performance of Algorithm 1 on artificial training data, i.e., pu,i \u2208 K = {U = 20}\u00d7{I = 40} where {pu,i} are i.i.d. and uniformly chosen on the unit interval. We benchmark against a variant on Algorithm 1, where the SDR solution for Q2 is replaced by an exhaustive search. As the data is artificial, the resulting matrix does not have any missing entries: we also include the binary matrix factorization (BMF) in Slawski et al. (2013)[Algorithm 2]. Table (3) is a numerical vali-\ndation of Proposition 4 where we computed the error rate of SDR (compared to the exhaustive search), aggregated over all iterations. We observe that the approximation error decreases, with increasing D (following Proposition 4).\nFollowing the same setup and benchmarks, Fig A.2 shows the resulting normalized training RMSE training error, RMSE = ( \u2211 (u,i)\u2208K |pu,i \u2212 \u03b8\u0302 T\nu \u03c8\u0302i|2/|K|)1/2, for several values of D. We observe that the monotone convergence in Lemma 1 is validated numerically, and that the training error decays with increasing model size, D. While the performance of IKM (first-order optimality guarantee) is indistinguishable from its exhaustive search variant, there is large gap compared to BMF (globally optimal). Unfortunately, BMF does not work with missing data, and is inapplicable to prediction (Slawski et al., 2013). The same conclusions hold when testing Algorithm 1 on the ML100K (Fig. 1).\nInterpretability of KMs: We numerically evaluate the method for finding association rules (Section A.3), on the ML100K dataset, with the resulting influence scores shown in Fig. A.3. We first iden-\nBCD Iterations\nFigure A.2. Training error vs number of iterations (U = 20, I = 40)\ntify the set of maximally influential items, M = {119, 814, 1188, 1190, 1290, 1393, 1462, 1486, 1494, 1530, 1590, 1638}. For each of these items, a user liking one given item, implies he/she likes all other items in the training set. Interestingly, these results remain the same when D = 24, thereby suggesting that procedure for mining association rules is quite stable.\nPrediction Performance: Since the range of the predicted variable is different for MF/NMF/SVD++, and KM/NNM, we use the normalized test RMSE, i.e., NRMSE = \u03b7( \u2211 (u,i)\u2208K\u0304 |[R](u,i) \u2212 R\u0302u,i|2/|K\u0304|)1/2 where K\u0304 is the test set, and \u03b7 = (Rmax \u2212 Rmin)\u22121 = 1/4 is the normalization for MF/NMF/SVD++. For KMs/NNMs the same metric reduces to NRMSE =(\u2211\n(u,i)\u2208K\u0304 |[R](u,i)/Rmax \u2212 \u03b8\u0302 T u \u03c8\u0302i|2/|K\u0304| )1/2\n. The best values for \u03bbu and \u00b5i, were picked from a coarse twodimensional grid by cross-validation, using a held-out validation set. The Normalized RMSE results are shown in Table 4. We observe a significant gap between KMs, and well known collaborative filtering methods, especially as D increases. Moreover, the drop in performance for NNMs for increasing D may be due to over-fitting."
    }
  ],
  "title": "Learning Kolmogorov Models for Binary Random Variables ",
  "year": 2018
}
