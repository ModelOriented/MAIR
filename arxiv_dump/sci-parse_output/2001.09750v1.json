{"abstractText": "La inteligencia artificial (IA) es una de las tecnolog\u00edas m\u00e1s discutidas en la actualidad. Existen muchas aplicaciones innovadoras como el diagn\u00f3stico y tratamiento del c\u00e1ncer, la experiencia del cliente, los nuevos negocios, la educaci\u00f3n, la propagaci\u00f3n de enfermedades contagiosas y la optimizaci\u00f3n de la gesti\u00f3n de cat\u00e1strofes humanitarias. Sin embargo, con todas esas oportunidades tambi\u00e9n viene una gran responsabilidad para garantizar una buena pr\u00e1ctica justa de AI. El objetivo de este documento es identificar los principales desaf\u00edos sociales y \u00e9ticos implicados por una aceptaci\u00f3n masiva de la IA. Hemos examinado la literatura para los desaf\u00edos m\u00e1s comunes y los Richard Benjamins Idoia salazar Garc\u00eda \u2014 88 \u2014 hemos clasificado en siete grupos: 1) Efectos no deseados, 2) Responsabilidad, 3) Consecuencias desconocidas, 4) Relaciones personas-robots, 5) Concentraci\u00f3n de poder y riqueza, 6) Mal uso intencional, y 7) IA para armas y guerra. Los desaf\u00edos deben ser tratados de diferentes maneras dependiendo de su origen; algunos tienen soluciones tecnol\u00f3gicas, mientras que otros requieren respuestas \u00e9ticas, sociales o pol\u00edticas. Dependiendo del origen, diferentes actores podr\u00edan necesitar actuar. Cualquiera que sea la parte interesada identificada, el no tratar esos problemas dar\u00e1 lugar a incertidumbres y consecuencias imprevistas con un impacto social negativo potencialmente grande, afectando especialmente a los grupos m\u00e1s vulnerables de las sociedades. La tecnolog\u00eda est\u00e1 ayudando a tomar mejores decisiones, y AI est\u00e1 promoviendo decisiones basadas en datos, adem\u00e1s de discusiones basadas en la experiencia y la intuici\u00f3n, con muchas mejoras en marcha. Sin embargo, los efectos secundarios negativos de esta tecnolog\u00eda deben entenderse bien y actuar antes de lanzarlos masivamente al mundo. Palabras clave: Inteligencia Artificial, \u00e9tica, robots, tecnolog\u00eda.", "authors": [{"affiliations": [], "name": "Richard BenJaMins"}, {"affiliations": [], "name": "Idoia salazar Garc\u00eda"}], "id": "SP:65936b35e9aa5cce9a75ea4e994e4949a104ae5f", "references": [{"authors": ["M Burgess"], "title": "Just like humans, artificial intelligence can be sexist and racist", "venue": "Wired Magazine. [Disponible en: https://www.wired.co.uk/article/machine-learning-biasprejudice] [Consultado", "year": 2017}, {"authors": ["K Dautenhahn"], "title": "Methodology & Themes of Human-Robot Interaction: International Journal of Advanced Robotic Systems. [Disponible en: http://journals.sagepub.com/ doi/full/10.5772/5702] [Consultado el 04/10/2018", "year": 2017}, {"authors": ["Le Gouvernement"], "title": "Republique Fran\u00e7aise (2017): Rapport de synth\u00e8se France Inteligence Artificielle. [Disponible en: https://www.economie.gouv.fr/files/files/PDF/2017/ Rapport_synthese_France_IA_.pdf] [Consultado el 10/08/2018", "year": 2018}, {"authors": ["M Pollack"], "title": "Intelligent Technology for an Aging Population: The Use of AI to Assist Elders with Cognitive Impairment", "venue": "[Disponible en: https://www.aaai.org/ojs/index", "year": 2005}], "sections": [{"text": "\u2014 87 \u2014\nLa inteligencia artificial (IA) es una de las tecnolog\u00edas m\u00e1s discutidas en la actualidad. Existen muchas aplicaciones innovadoras como el diagn\u00f3stico y tratamiento del c\u00e1ncer, la experiencia del cliente, los nuevos negocios, la educaci\u00f3n, la propagaci\u00f3n de enfermedades contagiosas y la optimizaci\u00f3n de la gesti\u00f3n de cat\u00e1strofes humanitarias. Sin embargo, con todas esas oportunidades tambi\u00e9n viene una gran responsabilidad para garantizar una buena pr\u00e1ctica justa de AI. El objetivo de este documento es identificar los principales desaf\u00edos sociales y \u00e9ticos implicados por una aceptaci\u00f3n masiva de la IA. Hemos examinado la literatura para los desaf\u00edos m\u00e1s comunes y los\n\u2014 88 \u2014\nhemos clasificado en siete grupos: 1) Efectos no deseados, 2) Responsabilidad, 3) Consecuencias desconocidas, 4) Relaciones personas-robots, 5) Concentraci\u00f3n de poder y riqueza, 6) Mal uso intencional, y 7) IA para armas y guerra. Los desaf\u00edos deben ser tratados de diferentes maneras dependiendo de su origen; algunos tienen soluciones tecnol\u00f3gicas, mientras que otros requieren respuestas \u00e9ticas, sociales o pol\u00edticas. Dependiendo del origen, diferentes actores podr\u00edan necesitar actuar. Cualquiera que sea la parte interesada identificada, el no tratar esos problemas dar\u00e1 lugar a incertidumbres y consecuencias imprevistas con un impacto social negativo potencialmente grande, afectando especialmente a los grupos m\u00e1s vulnerables de las sociedades. La tecnolog\u00eda est\u00e1 ayudando a tomar mejores decisiones, y AI est\u00e1 promoviendo decisiones basadas en datos, adem\u00e1s de discusiones basadas en la experiencia y la intuici\u00f3n, con muchas mejoras en marcha. Sin embargo, los efectos secundarios negativos de esta tecnolog\u00eda deben entenderse bien y actuar antes de lanzarlos masivamente al mundo.\nPalabras clave: Inteligencia Artificial, \u00e9tica, robots, tecnolog\u00eda."}, {"heading": "1. INTRODUCTION", "text": "Artificial Intelligence (AI) is on the rise. There are so many innovative applications of AI that everybody is speaking about it. It improves the diagnosis and treatment of cancer, improves customer experience, creates new business, improves education, predicts how contagious diseases propagate and optimizes the management of humanitarian catastrophes, to name just a few.\nArtificial Intelligence already exists since the mid-fifties when John McCarthy first coined the term. Marvin Minsky\u2019s definition of AI was: \u201cThe science of making machines do things that would require intelligence if done by humans\u201d (Dennis, 2016). AI has had its ups and downs previously (e.g. AI Winters). In a white paper published earlier by author of this paper Richard Benjamins (LUCA-Telef\u00f3nica, 2016), was explained basic concepts of AI to provide some background information to better understand the many articles about AI appearing in the press and Internet. AI\u2019s current popularity is mostly due to the enormous progress in one of AI\u2019s subfields: Machine Learning (ML). There are three main reasons for this progress:\n\u2022 The abundance of data. ML analyses data, and today there is so much more data available than decades ago.\n\u2022 Increase in computational power. Moore\u2019s Law is still valid, and machines can process orders of magnitude faster and more than before.\n\u2022 Deep Learning. An extended version of Neural Networks that, thanks to the two previous points, has increased enormously the performance of all kinds of classification and prediction tasks.\n\u2014 89 \u2014\nHowever, with all those opportunities also comes great responsibility to ensure good and fair practice of AI. We identified seven societal and ethical challenges for Artificial Intelligence that should be dealt with before AI is massively applied. Not treating those issues will lead to uncertainty and unforeseen consequences with potentially large negative societal impact. It is therefore no surprise that many governments currently have set up national initiatives to discuss many of those issues (e.g. in the UK (Committee on AI, 2018) and France (Le Gouvernement Republique Fran\u00e7aise, 2017)."}, {"heading": "2. OBJECTIVES", "text": "The study and understanding of the societal and ethical aspects of Artificial Intelligence is a new, yet fast-growing area, where not much scientific literature exists. However, many informal articles and publications discuss the topic on the Internet, in the press and as outcomes of closed workshops with experts. The objective of this paper is to help shape the area by proposing a framework to classify the different types of societal and ethical challenges such that each can be properly studied and addressed through research and experiments.\nSpecific objectives:\n1. Analyse the social impact that the development of Artificial Intelligence is having, through the study of current real cases.\n2. Identify the advantages and disadvantages of the massive implementation of this technology.\n3. Identify old ethical dilemmas and compare them with the current ones derived from the implementation of these technologies.\n4. Offer a theoretical frame of reference for further studies related to the social impact of Artificial Intelligence.\n5. Determine future prospects, in the medium term, of this technology, once the seven major challenges are analysed."}, {"heading": "3. METHODOLOGY", "text": "The study and understanding of the societal and ethical aspects of Artificial Intelligence is a new, yet fast-growing, area, where not much scientific literature\n\u2014 90 \u2014\nexists. However, many white papers from different governments and organizations discuss the topic, knowing its relevance and high impact in the next future. In this paper we have analyse several white papers, defining white paper as: authoritative report or guide, made up by high qualified experts, that informs readers concisely about a complex issue and presents the issuing body\u2019s philosophy on the matter (Gordon and Graham, 2003). We also analyse different reports published in some of the most worldwide prestigious magazines specialized in technology as Wired.\nWe also have consulted some scientific articles from databases accessible through the Internet, as Scopus bibliographic database which supports the quality of these publications (De Granda-Orive et al., 2013). This is the largest database of abstracts and literature reviewed by peers and has intelligent tools that allow to control, analyse and visualize academic research. Given its wide coverage, both geographical and thematic, it is considered ideal to be used for bibliographic reviews (Codina, 2018). The main search criteria have been delimited by keywords including Boolean inclusion (AND) or exclusion (NOT) operators. Date range filters have also been used. Likewise, these same search criteria have been applied in the database Web of Science, where the references of the main scientific publications of any discipline of knowledge, both scientific and technological, humanistic and sociological since 1945 are detailed.\nIn addition, it has been of great help for the acquisition of the necessary knowledge for this research, the collaboration of the authors of this article in the online forum International Ethically Aligned Design (EAD), in which professionals of international relevance expose their point of view on how to create the best ethical code of Artificial Intelligence, taking into account the social impact of this technology. As well as in the discussion forums of the European AI Alliance, a body dependent on the European Commission, of which the authors are also a member.\nAlso, the knowledge of the authors necessary for the realization of this paper derives from several investigations related to other areas of the social impact of Artificial Intelligence, acquired as researchers of the SIMPAIR group (Social Impact of Artificial Intelligence and Robotics)."}, {"heading": "4. ANALYSIS AND RESULTS OF THE INVESTIGATION", "text": ""}, {"heading": "4.1. Seven societal and ethical challenges for Data and AI", "text": "The challenges that AI, and therefore Data as well, face include non-desired side effects, liability questions, yet unknown consequences, the relation humanrobots, increasing concentration of power and wealth, intentional bad uses, and AI for weapons and warfare. Below, we explain each of them.\n\u2014 91 \u2014\n1. Non-desired side effects\na) While Machine Learning is able to solve complex tasks with high performance, it might use information that from a society or humanity perspective is undesired. For example, deciding whether to provide a loan to people based on race or religion is not something our societies accept. While it is possible to remove those \u201cundesired\u201d attributes from data sets, there are other less obvious attributes that highly correlate with those \u201cundesired\u201d attributes whose removal is less straightforward. Machine Learning is objective and finds whatever relation there is in the data regardless of specific norms and values.\nb) A related issue is so-called bias of data sets. Machine Learning bases its conclusions on data. However, the data itself might be biased by not being representative for the group of people to which the results are applied. For instance, finding trends on school performance using mostly white schools will not provide insights applicable to all schools. Research has shown that ML takes over any bias from humans (Burgess, 2017). What we need is so-called \u201cFair\u201d Machine Learning, addressing the issues in point a) and b). (World Economic Forum, 2018).\nc) Apart from bias in the training data, bias can also come from the algorithm. A Machine Learning algorithm tries to be as accurate as possible when fitting the model to the training data. Accuracy can be defined in terms of so-called \u201cfalse positives\u201d and \u201cfalse negatives\u201d, often through a so-called confusion matrix. But the definition of this \u201caccuracy\u201d measure, whether it tries to optimize only false positives or only false negatives, or both, has an important impact on the outcome of the algorithm, and therefore on the groups of people affected by the AI program. In safety-critical domains such as health, justice, and transport defining \u201caccuracy\u201d is not a technical decision, but a domain or even a political decision.\nd) Deep learning algorithms can be highly successful but have a hard time to explain why they have come to a decision. For some applications, the explanation of decisions is an essential part of the decision itself, and lack of that makes the decision unacceptable. For example, a \u201crobo-judge\u201d deciding on a dispute between a customer and a health insurer is unacceptable without the explanation of the decision. This is referred to as the \u201cInterpretability\u201d problem. The book \u201cWeapons of math destruction\u201d gives many interesting examples of this.\ne) Data privacy, transparency and control. All data and AI system exploit data, and many times this is personal data. Using all this personal\n\u2014 92 \u2014\ndata has as side effect that privacy may be compromised, even if it is unintentionally. The recent scandal of Cambridge Analytica / Facebook shows that this is a bigger issue than we might have thought.\nTo avoid those effects, people sometimes refer to the need for FATE AI (Fair, Accountable, Transparent and Explainable Artificial Intelligence).\n2. Liability. When systems become autonomous and self-learning, accountability of behaviour and actions of those systems becomes less obvious. In the pre-AI world, incorrect usage of a device is the accountability of the user, while device failure is accountability of the manufacturer. When systems become autonomous and learn over time, some behaviour might not be foreseen by the manufacturer. It is therefore unclear who would be liable in case something goes wrong. A clear example of this are driverless cars. Discussions are ongoing whether a new legal person needs to be introduced for self-learning, autonomous systems, such as a legal status for robots, but it is generating some controversy.\n3. Unknown consequences of AI. The positive aspects of AI may have some consequences of which we don\u2019t know yet how they will work out.\na) AI can take over many boring, repetitive or dangerous tasks. But if this happens at a massive scale, maybe many jobs might disappear, and unemployment will skyrocket?\nb) If less and less people work, then the government will receive less income tax, while costs of social benefits will increase due to increased unemployment. How can this be made sustainable? Should there be a \u201crobot tax\u201d? How to be able to pay pensions when increasingly less people work?\nc) Is there a need for a universal basic income (UBI) for everybody? If AI takes most of the current jobs, what do all unemployed people then live from?\n4. How should people relate to robots? If Robots become more autonomous and learn during their \u201clifetime\u201d, then what should be the (allowed) relationship between robots and people? Could one\u2019s boss be a robot, or AI system? In Asia, robots are already taking care of elderly people, accompanying them in their loneliness. And, could people get married to a robot?\nAn initial overview of possible interactions between humans and robots includes (Dautenhahn, 2017):\na) Long-term interactions: in which robots cohabitate with humans in their homes, and work places.\nb) Robots in therapy, rehabilitation and supporting the elderly: Assistive robotics is a growing application domain for service robots. It involves\n\u2014 93 \u2014\ncritical safety and ethical issues, for example when robots take the role of assisting vulnerable people or people with special needs. It is a fact that today, approximately 10 percent of the world\u2019s population is over 60 years old and by 2050 this proportion will have more than doubled. We need to incorporate artificial intelligence techniques to support older adults and help them cope with the changes of aging, in particular with cognitive decline (Pollack, 2005)\nc) Multimodal interactions, expressiveness, and conversational skills in interactions: Research aiming at providing robots with human-like features and qualities is expanding. We are trying to create robots with a similar appearance to us. And not only this. We are also trying to provide \u201ctheir faces\u201d with natural expressions that normally would only correspond to humans.\nd) Social learning and skill acquisition via teaching and imitation: This theme involves research on robots that can adapt to changing environments and requirements, that can \u2018grow\u2019 with increasing levels of skills and knowledge they acquire, and that can be programmed indirectly by demonstrating tasks. Once acquired, the robot could also transfer the newly learnt skills to other robots. If this turns out a real possibility, it could lead to an ethical problem.\ne) Cooperation and collaboration in human-robot teams: Robots and humans will not only live side by side, but they also need to work hand in hand, each one of them performing specific tasks, but helping each other. This interaction, mostly at the beginning, might be quite difficult taking into account the concept of \u2018machine\u2019, and all its implications, that humanity has nowadays.\nf) Detecting and understanding human activity: This will be also a problem in the near future for this interaction. Many times, humans do things for reasons that could be out of logic for a machine.\nThese are just some of the possible interactions in the relationship between human and robots. Each one of them will probably need further study to get to relevant conclusions.\n5. Concentration of power and wealth in a few very large companies. Currently, AI is dominated by a few large digital companies, including GAFAM (Google, Amazon, Facebook, Apple, Microsoft) and some Chinese mega companies (BAT - Baidu, Alibaba and Tencent). This is mostly due to those companies having access to massive amounts of propriety data. This might lead to an oligopoly. Apart from the lack of competition, there is a danger that those companies\n\u2014 94 \u2014\nkeep AI as proprietary knowledge, not sharing anything with the larger society other than for the highest price possible. Another concern of this concentration is that those companies can offer high-quality AI as a service, based on their data and propriety algorithms (black box). When those AI services are used for public services, the fact that it is a black box (bias, undesired attributes, performance, etc.), raises serious concerns, like when the LA Police Department announced that it uses Amazon\u2019s face recognition solution (Rekognition) for policing. The Open Data Institute in London has started an interesting debate on whether AI algorithms and Data should be closed, shared or open.\n6. Intentional bad uses. All the points mentioned above are issues because AI and Data are applied with the intention to improve or optimize our lives. However, like any technology, AI and Data can also be used with bad intentions1. Think of AIbased cyberattacks2, terrorism, influencing important events with fake news3, etc.\n7. The last challenge is related to the application of AI for warfare and weapons, especially for lethal autonomous weapons systems (LAWS). This usually implies an explicit, political decision, that some will consider \u201cgood use\u201d, while other might call it bad use of AI. Some organizations are working on an international treaty to ban \u201ckiller robots\u201d. The issue recently attracted attention due to Google employees sending a letter to their CEO questioning Google\u2019s participation in defence projects."}, {"heading": "4.2. Stakeholders and potential actions", "text": "While there is ample debate ongoing about many of those issues (e.g. AI and the future of work), today it is unclear what solutions there will be for some of the challenges. What we can define, however, are relevant actions to work on as an approach for dealing with those challenges. Each of the actions might involve different stakeholders. While executing the approach, because of the uncertainty involved, adaptions need to be made in a learning by doing process.\n\u2022 Governments and institutions need to think about strategies and approaches to identify the issues along with their solution directions. The GDPR is a small, but important step into that direction. Several national governments\n1 (2018, 02). The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation. Open Data Institute. 05, 2018, https://img1.wsimg.com/blobby/go/3d82daa4-97fe4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf\n2 (2018, 02). Artificial intelligence poses risks of misuse by hackers, researchers say. Reuters. 05, 2018, https://www.reuters.com/article/us-cyber-tech/artificial-intelligence-posesrisks-of-misuse-by-hackers-researchers-say-idUSKCN1G503V\n3 (2018, 04). Artificial intelligence is making fake news worse. Business Insiders. 05, 2018, http://uk.businessinsider.com/artificial-intelligence-is-making-fake-news-worse-2018-4\n\u2014 95 \u2014\nare already working on this through multidisciplinary committees of experts (Committee on AI, 2018, Le Gouvernement Republique Fran\u00e7aise, 2017). Maybe governments should ensure the availability of rich and sufficiently varied open datasets to minimize unfair bias.\n\u2022 Private enterprises need to start thinking about self-regulation and about where they stand. They should be clear on how responsible they want to act and become.\n\u2022 Probably a one-size-fits-all approach will not work, as some AI and Big Data applications have less potential negative side effect than others. E.g., decisions in marketing have probably less negative side effects than decisions about insurance premiums or medical diagnosis. Decisions made for so-called \u201csafety-critical\u201d systems may need to be validated and verified by formal mathematical procedures to ensure their correct functioning under all possible circumstances.\n\u2022 GDPR (Europe\u2019s General Data Protection Regulation) is a step forward regarding protection of personal data. A clear distinction needs to be made between Data & AI applications using personal data versus those using aggregated, anonymized data. Applications using personal data will need an explicit and transparent user consent (as provisioned in the GDPR). This is not needed when aggregated, anonymized data is used, but, as a matter of transparency, one might argue for the \u201cright to be informed\u201d when users\u2019 (aggregated, anonymized) data is used for applications.\n\u2022 AI and Data should not only be used for commercial opportunities, but also for social opportunities, such as Data for Good and AI for Good, initiatives whose aims are to support achieving the United Nations Sustainable Development Goals (SDGs).\n\u2022 The Open Data approach should be extended to Open Algorithms, to enable the benefits of private data, while not increasing the privacy and commercial risks of private enterprises. In this approach, algorithms are sent to the data, so data remains in its original premises, rather than the usual other way around, where data is stored centrally and then algorithms are run on the data.\n\u2022 Code of conducts should be in place for all professional families that contribute to Data and AI applications. This should reduce the likelihood of bad uses and unintended negative side effects.\n\u2022 International, multidisciplinary committees should be put in place to oversee and monitor the uses of Data and AI across the world and raise alerts when needed. Something like the Civil Aviation Authority for airplane crashes.\n\u2014 96 \u2014\nT he\nfo llo\nw in\ng ta\nbl e\nre la\nte s\nth e\nid en\nti fi\ned c\non ce\nrn s\nw it\nh po\nte nt\nia l a\nct io\nns o\nf r el\nev an\nt s ta\nke ho\nld er\ns.\nCh al\nle n\nge c\nat eg\nor y\nCo n\nce rn\nSt ak\neh ol\nd er\nto a\nct T\nyp e\nof a\nct io\nn P\not en\nti al\na ct\nio n\nN on\n-d es\nir ed\nsi\nd e\nef fe\nct s\nN on\n-d es\nir ed\ns id\ne ef\nfe ct\ns Co\nm pa\nni es\na nd\nor\nga ni\nza ti\non s\nPo lic\ny Co\nde o\nf co\nnd uc\nts t\no ra\nis e\naw ar\nen es\ns of\nn on\n-d es\nir ed\nco\nns eq\nue nc\nes to\nd es\nig ne\nrs , d\nev el\nop er\ns an\nd us\ner s\nof A I U n d es ir ed a tt ri b u te s Co m pa ni es a nd or ga ni za ti on s Te ch ni ca l Fi nd c or re la ti on s be tw ee n se ns it iv e da ta a nd o th er va ri ab le s\nB ia\ns Co\nm pa\nni es\na nd\nor\nga ni\nza ti\non s\nTe ch\nni ca\nl D\nev el\nop o\nr us\ne to\nol t\nha t\nch ec\nks b\nia s\nof d\nat a\nse t\nw .r. t. ta rg et g ro\nup G ov er nm en ts Po lic y Pu bl is h bi as\n-f re\ne O\npe n\nD at\na se\nts\nIn te\nrp re\nta b\nil it\ny Co\nm pa\nni es\na nd\nor\nga ni\nza ti\non s\nTe ch\nni ca\nl Pe\nrf or\nm a\nnd u\nse r\nes ea\nrc h\non e\nxp la\nin ab\nle a\nlg or\nit hm\ns\nG ov\ner nm\nen ts\nEt hi\nca l\nD is\ncu ss\nio ns\no n\nin w\nha t a\nre as\nA I n\nee ds\nto b\ne ex\npl ai\nna bl\ne\nP ri\nva cy\nCo m\npa ni\nes a\nnd\nor ga\nni za\nti on\ns Po\nlic y\nPr iv\nac y\nby d\nes ig\nn, a\nnd tr\nan sp\nar en\nt p ri\nva cy\np ol\nic ie\ns\nCo m\npa ni\nes a\nnd\nor ga\nni za\nti on\ns Te\nch ni\nca l\nSe nd\na lg\nor it\nhm s\nto d\nat a\nra th\ner t\nha n\ntr an\nsf er\nri ng\nd at a ou t o f o rg an iz at io ns in cr ea si ng d at a br ea ch r is k\nLi ab\nil it\ny Li\nab il\nit y\nG ov\ner nm\nen ts\nPo lic\ny D\nis cu\nss io\nn on\nl ia\nbi lit\ny of\ns el\nfle\nar ni\nng ,\nau to\nno m\nou s\nsy st\nem s\nU n\nk n\now n\nco\nn se\nq u\nen ce\ns of\nA I\nW or\nk a\nn d\njo b\ns\nCo m\npa ni\nes a\nnd\nor ga\nni za\nti on\ns Po\nlic y\nTr ai\nni ng\na nd\nu p-\nsk ill\nin g\nof e\nm pl\noy ee\ns to\nt he\nd ig\nit al\nw\nor ld\nG ov\ner nm\nen ts\nPo lic\ny A\nda pt\ne du\nca ti\non al\ns ys\nte m\nfo r\nA I f\nut ur e. G ov er nm en ts a nd in st it ut io ns Po lic y Ev al ua te im pa ct of U ni ve rs al B as ic\nIn co\nm e\nan d\nsu st\nai na\nbi lit\ny of\nw el\nfa re\ns ys\nte m\nR el\nat io\nn\np eo\np le\n-r ob\not s\nR el\nat io\nn p\neo p\nle -r\nob ot\ns G\nov er\nnm en\nts Et\nhi ca\nl St\nud y\nth e\npo ss\nib le\nw ay\ns in\nw hi\nch p\neo pl\ne ca\nn re\nla te\nt o\nro bo\nts ,\nfr om\nc ol\nla bo\nra ti\non t\no m\ned ic\nal a\nss is\nta nc\ne to\nm\nar ri\nag e\nD at\na &\nw ea\nlt h\nco\nn ce\nn tr\nat io\nn D\nat a\nco n\nce n\ntr at\nio n\nG ov\ner nm\nen ts\nPo lic\ny Ev\nal ua\nte w\nha t\nca n\nbe d\non e\nto r\ned uc\ne de\npe nd\nen cy\no n a fe w t ec hn ol og ic al g ia nt s w it h di sp ro po rt io na l a m ou nt of d at\na In te n ti on al b ad u se s In te n ti on al b ad u se s G ov er nm en ts Po lic y St re\nng th\nen\ncy be\nrs ec\nur it\ny un\nit s\nw it\nh A\nI an\nd da\nta\nex pe\nrt is e A I a n d w ar fa re A I a n d w ar fa re G ov er nm en ts Et hi ca l D is cu ss e\nxp lic\nit ly\nh ow\nfa r\nw e\nsh ou\nld g\no w\nit h\nso -c\nal le d \u201ck ill er r ob ot s\u201d\nG en\ner al\nw or\nld -w\nid e\nim p\nac t o\nf A I\nG en\ner al\nw or\nld -w\nid e\nim p\nac t\nof A\nI\nG ov\ner nm\nen ts\nPo lic\ny Cr\nea te\nin te\nrn at\nio na\nl o rg\nan iz\nat io\nns w\nit h\nau th\nor it\ny ov\ner\nim po\nrt an\nt A I d\nev el\nop m\nen ts\na nd\np ro\nje ct\ns in\nth e\nw or ld Co m pa ni es , o rg an iz at io ns an d G ov er nm en ts Te ch ni ca l U se A I fo r so ci al p ur po se s to h el p ac hi ev e th e U\nN \u2019s\nSu\nst ai\nna bl\ne D\nev el\nop m\nen t G\noa ls\n.\nSo ur\nce :\nPr ep\nar ed\nb y\nth e\nau th\nor s\n\u2014 97 \u2014"}, {"heading": "5. CONCLUSIONS", "text": "With AI become increasingly more widespread, it is important that we are prepared to ensure that our societies and economies continue to function well with the expected massive uptake of Data & AI applications. In this paper, we have identified seven types of challenges to be dealt with before massively using AI and Big Data in our societies. We then looked at what type of actions are required by the different stakeholders to maximize the likelihood of the issues to be tackled. While some of the required actions are already in progress, several others are only starting. In general, we expect that significant debate is needed to take final decisions and there is no guarantee that different nations in the world will come to the same conclusions.\nHowever, while much work still needs to be done, we should neither forget that today, without massive uptake of AI, we don\u2019t live, and have never lived, in an ideal world. Think of the large number of humans that have taken, are taking and will take extremely wrong decisions, with hugely negative consequences for humanity. People are \u201chuman\u201d and therefore decisions inevitably are biased by personal experiences and opinions. And many decision makers have taken \u2013with good intent\u2013 important measures that have had serious negative side effects. So, while there are risks associated with the massive uptake of AI & Data, there is probably more to win than to lose with those technologies. Moreover, humanity has ample experience in how to manage or recover from negative consequences of (wrong) decisions.\nIf there is a final deadline before we would need to have solved the seven challenges, it will probably be the Singularity, the point in time when Artificial Intelligence will lead to machines that are smarter than human beings. However, even if this point may never arrive, it is good that societies start discussing the issues now, through a common vocabulary and framework, rather than waiting until it is (too) late."}], "title": "Towards a framework for understanding societal and ethical implications of Artificial Intelligence Hacia un marco para comprender las implicaciones sociales y e\u0301ticas de la Inteligencia Artificia"}