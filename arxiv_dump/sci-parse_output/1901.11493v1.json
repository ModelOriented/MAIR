{"abstractText": "A linear multi-factor model is one of the most important tools in equity portfolio management. The linear multi-factor models are widely used because they can be easily interpreted. However, financial markets are not linear and their accuracy is limited. Recently, deep learning methods were proposed to predict stock return in terms of the multi-factor model. Although these methods perform quite well, they have significant disadvantages such as a lack of transparency and limitations in the interpretability of the prediction. It is thus difficult for institutional investors to use black-box-type machine learning techniques in actual investment practice because they should show accountability to their customers. Consequently, the solution we propose is based on LSTM with LRP. Specifically, we extend the linear multi-factor model to be non-linear and time-varying with LSTM. Then, we approximate and linearize the learned LSTM models by LRP. We call this LSTM+LRP model a deep recurrent factor model. Finally, we perform an empirical analysis of the Japanese stock market and show that our recurrent model has better predictive capability than the traditional linear model and fully-connected deep learning methods.", "authors": [{"affiliations": [], "name": "Kei Nakagawa"}, {"affiliations": [], "name": "Tomoki Ito"}, {"affiliations": [], "name": "Masaya Abe"}, {"affiliations": [], "name": "Kiyoshi Izumi"}], "id": "SP:007b0091460a07e2472ce25211dfdde935a2d497", "references": [{"authors": ["M. Abe", "H. Nakayama"], "title": "Deep learning for forecasting stock returns in the cross-section", "venue": "Pacific-Asia Conference on Knowledge Discovery and Data Mining.", "year": 2018}, {"authors": ["Y. Amihud"], "title": "Illiquidity and stock returns: crosssection and time-series effects", "venue": "Journal of financial markets 5(1):31\u201356.", "year": 2002}, {"authors": ["A. Ang", "R.J. Hodrick", "Y. Xing", "X. Zhang"], "title": "The cross-section of volatility and expected returns", "venue": "The Journal of Finance 61(1):259\u2013299.", "year": 2006}, {"authors": ["L. Arras", "G. Montavon", "K.-R. M\u00fcller", "W. Samek"], "title": "Explaining recurrent neural network predictions in sentiment analysis", "venue": "EMNLP 2017 159.", "year": 2017}, {"authors": ["S. Bach", "A. Binder", "G. Montavon", "F. Klauschen", "K.-R. M\u00fcller", "W. Samek"], "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation", "venue": "PloS one 10(7):e0130140.", "year": 2015}, {"authors": ["S. Basu"], "title": "Investment performance of common stocks in relation to their price-earnings ratios: A test", "year": 1977}, {"authors": ["B. Boyer", "T. Mitton", "K. Vorkink"], "title": "Expected idiosyncratic skewness", "venue": "The Review of Financial Studies 23(1):169\u2013202.", "year": 2009}, {"authors": ["L. Breiman"], "title": "Random forests", "venue": "Machine learning 45(1):5\u201332.", "year": 2001}, {"authors": ["R.C. Cavalcante", "R.C. Brasileiro", "V.L. Souza", "J.P. Nobrega", "A.L. Oliveira"], "title": "Computational intelligence and financial markets: A survey and future directions", "venue": "Expert Systems with Applications 55:194\u2013211.", "year": 2016}, {"authors": ["H. Drucker", "C.J. Burges", "L. Kaufman", "A.J. Smola", "V. Vapnik"], "title": "Support vector regression machines", "venue": "Advances in neural information processing systems, 155\u2013161.", "year": 1997}, {"authors": ["E.F. Fama", "K.R. French"], "title": "The cross-section of expected stock returns", "venue": "the Journal of Finance 47(2):427\u2013 465.", "year": 1992}, {"authors": ["E.F. Fama", "K.R. French"], "title": "Common risk factors in the returns on stocks and bonds", "venue": "Journal of financial economics 33(1):3\u201356.", "year": 1993}, {"authors": ["E.F. Fama", "K.R. French"], "title": "Size, value, and momentum in international stock returns", "venue": "Journal of financial economics 105(3):457\u2013472.", "year": 2012}, {"authors": ["F.A. Gers", "J. Schmidhuber"], "title": "Recurrent nets that time and count", "venue": "Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium, volume 3, 189\u2013194. IEEE.", "year": 2000}, {"authors": ["C.R. Harvey", "Y. Liu", "H. Zhu"], "title": "and the crosssection of expected returns", "venue": "The Review of Financial Studies 29(1):5\u201368.", "year": 2016}, {"authors": ["S. Hochreiter", "J. Schmidhuber"], "title": "Long short-term memory", "venue": "Neural computation 9(8):1735\u20131780.", "year": 1997}, {"authors": ["K. Hou", "G.A. Karolyi", "B.-C. Kho"], "title": "What factors drive global stock returns? The Review of Financial Studies 24(8):2527\u20132574", "year": 2011}, {"authors": ["N. Jegadeesh", "S. Titman"], "title": "Returns to buying winners and selling losers: Implications for stock market efficiency", "venue": "The Journal of finance 48(1):65\u201391.", "year": 1993}, {"authors": ["N. Jegadeesh", "S. Titman"], "title": "Profitability of momentum strategies: An evaluation of alternative explanations", "venue": "The Journal of finance 56(2):699\u2013720.", "year": 2001}, {"authors": ["E. Jurczenko"], "title": "Risk-Based and Factor Investing", "venue": "Elsevier.", "year": 2015}, {"authors": ["D. Kinga", "J.B. Adam"], "title": "A method for stochastic optimization", "venue": "International Conference on Learning Representations (ICLR), volume 5.", "year": 2015}, {"authors": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "title": "Deep learning", "venue": "nature 521(7553):436.", "year": 2015}, {"authors": ["A.E. Levin"], "title": "Stock selection via nonlinear multi-factor models", "venue": "Advances in Neural Information Processing Systems, 966\u2013972.", "year": 1996}, {"authors": ["B.B. Mandelbrot"], "title": "The variation of certain speculative prices", "venue": "Fractals and scaling in finance. Springer. 371\u2013 418.", "year": 1997}, {"authors": ["K. Nakagawa", "T. Uchida", "T. Aoshima"], "title": "Deep factor model", "venue": "InMIDAS @ECML-PKDD 2018 - 3rd Workshop on MIning DAta for financial applicationS.", "year": 2018}, {"authors": ["R. Novy-Marx"], "title": "The other side of value: The gross profitability premium", "venue": "Journal of Financial Economics 108(1):1\u201328.", "year": 2013}, {"authors": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V Dubourg"], "title": "Scikit-learn: Machine learning in python. Journal of machine learning research 12(Oct):2825\u20132830", "year": 2011}, {"authors": ["S.A. Ross"], "title": "The arbitrage theory of capital asset pricing", "venue": "HANDBOOK OF THE FUNDAMENTALS OF FINANCIAL DECISION MAKING: Part I. World Scientific. 11\u201330.", "year": 2013}, {"authors": ["W.F. Sharpe"], "title": "Capital asset prices: A theory of market equilibrium under conditions of risk", "venue": "The journal of finance 19(3):425\u2013442.", "year": 1964}, {"authors": ["M.T. Soliman"], "title": "The use of dupont analysis by market participants", "venue": "The Accounting Review 83(3):823\u2013853.", "year": 2008}, {"authors": ["M. Suzuki"], "title": "Psran efficient stock-selection tool", "venue": "International Journal of Forecasting", "year": 1998}, {"authors": ["S. Tokui", "K. Oono", "S. Hido", "J. Clayton"], "title": "Chainer: a next-generation open source framework for deep learning", "venue": "Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS), volume 5, 1\u20136.", "year": 2015}], "sections": [{"text": "Consequently, the solution we propose is based on LSTM with LRP. Specifically, we extend the linear multi-factor model to be non-linear and time-varying with LSTM. Then, we approximate and linearize the learned LSTM models by LRP. We call this LSTM+LRP model a deep recurrent factor model. Finally, we perform an empirical analysis of the Japanese stock market and show that our recurrent model has better predictive capability than the traditional linear model and fully-connected deep learning methods."}, {"heading": "Introduction", "text": "Stock return has predictability been an important research theme, both academically and practically. In empirical finance, the typical method to predict stock returns is crosssection (regression) analysis using cross-sectional data of corporate attributes. The attribute that explains the stock return as revealed by the cross-section analysis is called a factor. A model that explains stock returns using multiple factors is called multi-factor model. A representative multi-factor model is the Fama\u2013French three-factor model (Fama and French 1992; 1993), which proposed that the cross-sectional structure of the stock return can be explained by three factors: beta (market portfolio), size (market capitalization), value (PBR). Since then, many other factors were identified. Specifically, Harvey, Liu, and Zhu (2016) reported over 300 identified factors by 2012.\nAlmost all these multi-factor models, including the FamaFrench three-factor model, are linear regression models and\nCopyright c\ufffd 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nuntil now, linear multi-factor models are one of the most important tools in equity portfolio management. Institutional investors are accountable to those whose money they invest. Linear multi-factor models are so widely used because they can be easily interpreted. There are two ways to use a linear multi-factor model: as a return or risk model, where the return model is used for predicting stock returns and the risk model for describing the factor attribution of the predicted stock return. However, it is well-known that financial markets are not linear (Mandelbrot 1997).\nRecently, deep learning methods were proposed to predict stock returns in terms of multi-factor models (Levin 1996; Abe and Nakayama 2018). Deep learning has been proven to be a powerful machine learning technique with various applications (LeCun, Bengio, and Hinton 2015), and can take the nonlinearity of factors into consideration. However, it has not yet made possible the consideration of time-varying factors. Therefore, we propose implementing a non-linear time-varying multi-factor model with long short-term memory (LSTM), which is a representative model to express a time-varying non-linear relationship. Although LSTM performs well in many sequential prediction problems, it has significant disadvantages, such as a lack of transparency and limitations in the interpretability of the prediction. As it is difficult for institutional investors to use black-box-type machine learning technique such as LSTM in actual investment practice because they need to be accountable to their customers, we present the application of layer-wise relevance propagation (LRP) (Bach et al. 2015) to linearize the proposed LSTM model. We consider this LSTM+LRP model a deep recurrent factor model. We can model non-linear and time-varying factors as a return model and comprehend which factor contributes to the prediction as a risk model.\nThe remainder of this paper is organized as follows. We formulate our deep recurrent factor model in the next section. Then, we empirically analyze the Japanese stock market and show that our model has a better predictive capability than the traditional linear model and fully-connected deep learning methods. Finally, we review related works and conclude."}, {"heading": "Deep Recurrent Factor Model with LSTM-LRP Non-Linear and Time-Varying Multi-Factor Model", "text": "Here, we formulate the deep recurrent factor model. The traditional linear multi-factor model assumes that stock return ri can be described as follows:\nri = \u03b1i +Xi1F1 + \u00b7 \u00b7 \u00b7+XiNFN + \u03b5i, (1)\nwhere Fn are a set of factor returns, Xin denotes the i-th stock\u2019s exposure to factor n, \u03b1i is an intercept term assumed to be equal to a risk-free rate of return under the arbitrage pricing theory framework (Ross 2013). \u03b5i is a random term with mean 0 and assumed to be uncorrelated across other random terms. Usually, factor exposure Xin is defined by the linearity of several descriptors.\nWhile linear multi-factor models are effective tools for equity portfolio management, the assumption of a linear relationship is rather restrictive. Specifically, linear models assume that each factor affects the stock return independently, but ignore the possible interactions between factors and the time-dependency of factor exposures and returns as shown in Table 1.\nWe extend equation (1) to the non-linear time-dependent model:\nri(t) = f\u0303(Xi1(t)F1(t) +Xi1(t\u2212 1)F1(t\u2212 1) +\n\u00b7 \u00b7 \u00b7 +XiN (t)FN (t) + \u00b7 \u00b7 \u00b7) + \u03b5i(t), (2)\nwhere ri(t), \u03b5i(t), Fn(t), Xin(t) are respectively i\u2019s stock return, random term, n-th factor return, and factor exposure\nat time t. Here, f\u0303 is a non-linear function that does not satisfy either or both of the following conditions:\nf(x+ y) = f(x) + f(y), (3)\nf(\u03b1x) = \u03b1f(x). (4)\nPrediction with the non-linear time-varying model (2) is more complex than that with the linear one since it requires\nboth factor returns and unknown function f\u0303 . Similar to a previous study (Levin 1996), we assume factor returns are constants F\u0304n. This assumption is also used in a linear multifactor model. The prediction task can thus be simplified, since the factor returns are no longer variables.\nTime-dependent model (2) can be transformed as follows:\nri(t) = f\u0303(Xi1(t)F1(t) +Xi1(t\u2212 1)F1(t\u2212 1) +\n\u00b7 \u00b7 \u00b7 +XiN (t)FN (t) + \u00b7 \u00b7 \u00b7) + \u03b5i(t)\n= f(Xi1(t), Xi1(t\u2212 1), . . . , XiN (t), . . .) + \u03b5i(t),(5)\nTo estimate the unknown non-linear function f , we use LSTM model."}, {"heading": "Implementation with LSTM-LRP", "text": "We use the LSTM model (Hochreiter and Schmidhuber 1997; Gers and Schmidhuber 2000) as a representation of equation (14):\nit = \u03c3(Wiht\u22121 + Uixt + bi) (6)\nft = \u03c3(Wfht\u22121 + Ufxt + bf ) (7)\not = \u03c3(Woht\u22121 + Uoxt + bo) (8)\ngt = tanh(Wght\u22121 + Ugxt + bg) (9)\nct = ft \ufffd ct\u22121 + it \ufffd gt (10)\nht = ot \ufffd tanh(ct), (11)\nwhere \u03c3 is the sigmoid function and i, f, o, c are, respectively, the input, forget, output gate, and cell memory values in response to input vector at time t. Here, the initial values are c0 = 0 and h0 = 0. Above, the activation functions \u03c3 and tanh are applied element-wise. Moreover, operator \ufffd denotes the Hadamard product(element-wise product).\nNext, from the viewpoint of the risk model, we calculate the decomposition of the predicted return by LRP. LRP is a method used to explain the output of the neural network based on input values. Specifically, LRP distributes the output to the input through relevance score R. The relevance score is propagated from the output to the input layer in a form close to a chain rule.\nTwo types of relevance calculation methods, weighted and multiplicative connections, are proposed to calculate the LRP of the LSTM network (Arras et al. 2017).\nWeighted connections Assume we know relevance scores Rj of neurons zj and want to compute scoresRi of lowerlayer neurons zi. Values zj are computed during forwardpass as follows:\nzj = \ufffd\ni\n(wij \u00d7 zi + bj). (12)\nThen, relevance scores Ri\u2190j are calculated as:\nRi\u2190j = wij \u00d7 zi +\n\u03b5\u00d7sign(zj+bj) N\nzj + \u03b5\u00d7 sign(zj) \u00d7Rj , (13)\nwhere N is the number of lower-layer neurons to which zj is connected and \u03b5 is a small positive real number to ensure non-negativity.\nMultiplicative connections To apply LRP to LSTM layers, we have to consider the gating mechanism. Let zj of the upper-layer be calculated as zj = zg \u00d7 zs by lower layers zg and zs. Here, zg is the gate, whose activation is between 0 and 1, and zs is the source that carries the information from the lower layer or previous layers. Then, the backpropagation rule is simply Rg = 0 and Rs = Rj .\nIt may seem that the values of zg and zs are disregarded; however, they were already considered in Rj , which depends on zj .\nWe linearize the LSTM models by LRP and rewrite the relevance score Rj corresponding to input Xin(t) with \u03b2in(t):\nri(t) = f(Xi1(t), Xi1(t\u2212 1), . . . , XiN (t), . . .) + \u03b5i(t)\n\u2248 \u03b2i1(t)Xi1(t) + . . .+ \u03b2iNXiN (t), . . .+ \u03b5i(t).(14)\nHere, \u03b2i1(t) can be interpreted as a factor return linearized by LRP. The factor return of the traditional linear multi-factor model is calculated for the investment universe, whereas the factor return linearized by LRP is calculated for each stocks in the investment universe. We can model the non-linearity and time-dependency of factors as the return model and identify which factor contributes to the prediction as a risk model. Figure 1 shows the outline of the deep recurrent factor model."}, {"heading": "Experiment on Japanese Stock Markets", "text": ""}, {"heading": "Data", "text": "We prepare a dataset of TOPIX500 index constituents. TOPIX500 is a well-accepted stock market index for the Tokyo Stock Exchange (TSE) in Japan and comprises the large and mid-cap segments of the Japanese market. The index is also often used as a benchmark for overseas institutional investors investing in Japanese stocks.\nWe use the five factors and 16 factor descriptors listed in Table 1. These are used relatively often in practice and are studied most widely in academia (Jurczenko 2015).\nIn calculating these factors, we acquire the necessary data from the Nikkei Portfolio Master (NPM) and Bloomberg. Factor descriptors are calculated on a monthly basis (at the end of month) from December 1990 to March 2015 as input data and stock returns with dividends are acquired on a monthly basis (at the end of month) as output data."}, {"heading": "Models", "text": "Our problem is identifying prediction model f(x) of an output Y , for the next month\u2019s stock returns given an input X and various descriptors. One set of training data is shown in Table 2. In addition to the proposed deep recurrent factor model, we use a linear regression model as baseline, support vector regression (SVR(Drucker et al. 1997)), random forest(Breiman 2001), and fully-connected deep learning (deep factor model) as comparison methods. The deep factor model and deep recurrent factor model are implemented with Chainer (Tokui et al. 2015) and the comparison methods with scikit-learn (Pedregosa et al. 2011). Table 3 lists the details of each model.\nWe train all models by using the latest 60 sets of training data from the past five years. We decided the hyper parameters of deep factor and deep recurrent factor models using 1/60 of each training dataset as the validation dataset. The models are updated by sliding one month ahead and carrying out a monthly forecast. The prediction period is from April 2007 to March 2015. To verify the effectiveness of each method, we compare the prediction accuracies of these models and the profitability of the quintile portfolio. We also construct a long/short portfolio strategy for a net-zero investment to buy top stocks and sell bottom stocks with equal weights in quintile portfolios. For quintile portfolio performance, we calculate the annualized average return, volatility, and Sharpe ratio(= return/volatility). Additionally, we calculate the average mean absolute error (MAE) and root mean squared error (RMSE) for the prediction period as prediction accuracy."}, {"heading": "Results", "text": "Table 4 lists the average MAEs and RMSEs of all years, along with the annualized return, volatility, and Sharpe ratio for each method. The best values appears in bold on each row.\nThe LSTM model has the best prediction accuracy in terms of MAE and RMSE. On the other hand, the LSTM+LRP model is the most profitable in terms of the Sharpe ratio. In any case, we find that the LSTM and DNN models exceed the linear model in terms of accuracy and profitability. This implies that the relationship between stock returns on the financial market and the factor is non-linear. We also find that the LSTM model exceeds the DNN model and the LSTM+LRP model exceeds the DNN+LRP model in terms of accuracy and profitability. These facts imply that the relationship between stock returns on the financial market and the factor is time-varying. Although the accuracy decreased slightly because of the linearization by LRP, the deep recurrent factor model, which can capture such a nonlinear and time-varying relationship, is thought to be superior."}, {"heading": "Interpretation", "text": "Here, we confirm that the effect of the LRP approximation on performance is high in terms of the return model. We interpret the top quintile portfolio based on the factor using the linear, deep factor, and deep recurrent factor models as of March 2015.\nThe contributions of each descriptor calculated by LRP are summed up for each factor and displayed as percentiles. We can thus identify which factor contributes to the prediction as a risk model compared to linear model, as shown in Figure 2.\nAlthough the values of the contributions are different in each model, the order is almost the same. Value, size, quality, risk, and momentum factors contribute to the prediction in this order. As described above, the contribution is similar to the linear model, but prediction performance is better than the linear model, as shown in Table 4. We can observe that the size and value factors account for more than half of the contribution to the top quintile portfolio. Generally, the\nmomentum factor is not very effective, but the value factor is effective on the Japanese stock market (Fama and French 2012). For practitioners, we feel this is in line with the actual Japanese stock market."}, {"heading": "Related Works", "text": "Many studies on stock return predictability using machine learning have been published. Cavalcante et al. (2016) presented a review of the application of several machine learning methods in finance. In their survey, most of these were\nforecasts of stock market returns. However, there is no paper that deals with the prediction method in terms of a multifactor model.\nLevin (1996) discussed the use of multilayer feed forward neural networks for predicting stock returns within the framework of the multi-factor model. Abe and Nakayama (2018) extended this model to deep learning and investigated the performance of the method on the Japanese stock market. They showed that deep neural networks generally outperform shallow ones, and the best networks also outperform representative machine learning models. These results indicate deep learning holds promise as a skillful machine learning method to predict stock returns in cross-section.\nHowever, these works are only for use as a return model, and the problem is that the viewpoint of a risk model is lacking. Nakagawa, Uchida, and Aoshima (2018) proposed the application of LRP to decompose the attributes of the predicted return as a risk model. However, they do not examine the influence on performance due to the approximation of LRP and not considering the time-dependency of factors. We thus extend this model to a time-varying multi-factor model with LSTM+LRP and analyze the effects of the LRP approximation on performance on the Japanese stock market."}, {"heading": "Conclusions", "text": "We proposed a deep recurrent factor model that is nonlinear and time-varying multi-factor model implemented with LSTM+LRP. The empirical analysis of the Japanese stock market shows the LRP approximation is effective in terms of return and risk models. Our model can capture nonlinear and time-varying relationship with factors and stock return in an interpretable way.\nIn terms of further study, we would like to confirm the effectiveness of our model on stock markets other than the Japanese one. Although we considered 16 factors, some other macroeconomic variables, such as foreign exchange rates, interest rates, and consumer price index, can be used as inputs."}, {"heading": "Acknowledgements", "text": "We thank Tsuyoshi Ogawa and Yuya Morooka for discussions and insights that helped clarify the ideas in this paper."}], "title": "Deep Recurrent Factor Model", "year": 2019}