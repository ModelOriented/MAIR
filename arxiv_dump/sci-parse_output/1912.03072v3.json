{"abstractText": "Advances in Artificial Intelligence in Education (AIEd) and the ever-growing scale of Interactive Educational Systems (IESs) have led to the rise of data-driven approaches for knowledge tracing and learning path recommendation. Unfortunately, collecting student interaction data is challenging and costly. As a result, there is no public largescale benchmark dataset reflecting the wide variety of student behaviors observed in modern IESs. Although several datasets, such as ASSISTments, Junyi Academy, Synthetic and STATICS are publicly available and widely used, they are not large enough to leverage the full potential of state-of-the-art data-driven models. Furthermore, the recorded behavior is limited to question-solving activities. To this end, we introduce EdNet, a large-scale hierarchical dataset of diverse student activities collected by Santa, a multi-platform self-study solution equipped with an artificial intelligence tutoring system. EdNet contains 131,417,236 interactions from 784,309 students collected over more than 2 years, making it the largest public IES dataset released to date. Unlike existing datasets, EdNet records a wide variety of student actions ranging from questionsolving to lecture consumption to item purchasing. Also, EdNet has a hierarchical structure which divides the student actions into 4 different levels of abstractions. The features of EdNet are domain-agnostic, allowing EdNet to be easily extended to different domains. The dataset is publicly released for research purposes. We plan to host challenges in multiple AIEd tasks with EdNet to provide a common ground for the fair comparison between different state-of-the-art models and to encourage the development of practical and effective methods.", "authors": [{"affiliations": [], "name": "Youngduck Choi"}, {"affiliations": [], "name": "Youngnam Lee"}, {"affiliations": [], "name": "Dongmin Shin"}, {"affiliations": [], "name": "Junghyun Cho"}, {"affiliations": [], "name": "Seoyon Park"}, {"affiliations": [], "name": "Seewoo Lee"}, {"affiliations": [], "name": "Jineon Baek"}, {"affiliations": [], "name": "Chan Bae"}, {"affiliations": [], "name": "Byungsoo Kim"}, {"affiliations": [], "name": "Jaewe Heo"}], "id": "SP:55350d50319668b82d106bbe1c2b4812e0760ca1", "references": [{"authors": ["G. Abdelrahman", "Q. Wang"], "title": "Knowledge tracing with sequential key-value memory networks", "year": 2019}, {"authors": ["H.S. Chang", "H.J. Hsu", "K.T. Chen"], "title": "Modeling exercise relationships in e-learning: A unified approach", "venue": "EDM. pp. 532\u2013535", "year": 2015}, {"authors": ["Y. Choi", "Y. Lee", "J. Cho", "J. Baek", "B. Kim", "Y. Cha", "D. Shin", "C. Bae", "J. Heo"], "title": "Towards an appropriate query, key, and value computation for knowledge tracing", "year": 2020}, {"authors": ["Y. Choi", "Y. Lee", "J. Cho", "J. Baek", "D. Shin", "S. Lee", "J. Shin", "C. Bae", "B. Kim", "J. Heo"], "title": "Assessment modeling: Fundamental pre-training tasks for interactive educational systems", "year": 2020}, {"authors": ["M. Feng", "N. Heffernan", "K. Koedinger"], "title": "Addressing the assessment challenge with an online system that tutors as it assesses", "venue": "User Modeling and User-Adapted Interaction 19(3), 243\u2013266", "year": 2009}, {"authors": ["Z. Huang", "Q. Liu", "C. Zhai", "Y. Yin", "E. Chen", "W. Gao", "G. Hu"], "title": "Exploring multiobjective exercise recommendations in online education systems", "venue": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management. pp. 1261\u20131270. ACM", "year": 2019}, {"authors": ["Z. Huang", "Y. Yin", "E. Chen", "H. Xiong", "Y. Su", "G Hu"], "title": "Ekt: Exerciseaware knowledge tracing for student performance prediction", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 2019}, {"authors": ["K.R. Koedinger", "R.S. Baker", "K. Cunningham", "A. Skogsholm", "B. Leber", "J. Stamper"], "title": "A data repository for the edm community: The pslc datashop", "venue": "Handbook of educational data mining 43, 43\u201356", "year": 2010}, {"authors": ["Y. Lee", "Y. Choi", "J. Cho", "A.R. Fabbri", "H. Loh", "C. Hwang", "Y. Lee", "S.W. Kim", "D. Radev"], "title": "Creating a neural pedagogical agent by jointly learning to review and assess", "venue": "arXiv preprint arXiv:1906.10910", "year": 2019}, {"authors": ["Y. Lee", "D. Shin", "H. Loh", "J. Lee", "P. Chae", "J. Cho", "S. Park", "J. Baek", "B. Kim", "Y. Choi"], "title": "Deep attentive study session dropout prediction in mobile learning environment", "year": 2020}, {"authors": ["Q. Liu", "S. Tong", "C. Liu", "H. Zhao", "E. Chen", "H. Ma", "S. Wang"], "title": "Exploiting cognitive structure for adaptive learning", "venue": "arXiv preprint arXiv:1905.12470", "year": 2019}, {"authors": ["T.S. Mandel"], "title": "Better Education Through Improved Reinforcement Learning", "venue": "Ph.D. thesis", "year": 2017}, {"authors": ["S. Pandey", "G. Karypis"], "title": "A self-attentive model for knowledge tracing", "venue": "arXiv preprint arXiv:1907.06837", "year": 2019}, {"authors": ["Z. Pardos", "W. Jiang"], "title": "Designing for serendipity in a university course recommendation system", "year": 2019}, {"authors": ["Z.A. Pardos", "R.S. Baker", "M.O. San Pedro", "S.M. Gowda", "S.M. Gowda"], "title": "Affective states and state tests: Investigating how affect and engagement during the school year predict end-of-year learning outcomes", "venue": "Journal of Learning Analytics 1(1), 107\u2013128", "year": 2014}, {"authors": ["C. Piech", "J. Bassen", "J. Huang", "S. Ganguli", "M. Sahami", "L.J. Guibas", "J. SohlDickstein"], "title": "Deep knowledge tracing", "venue": "Advances in neural information processing systems. pp. 505\u2013513", "year": 2015}, {"authors": ["S. Reddy", "S. Levine", "A. Dragan"], "title": "Accelerating human learning with deep reinforcement learning", "venue": "NIPS17 Workshop: Teaching Machines, Robots, and Humans", "year": 2017}, {"authors": ["D. Shawky", "A. Badawi"], "title": "A reinforcement learning-based adaptive learning system", "venue": "International Conference on Advanced Machine Learning Technologies and Applications. pp. 221\u2013231. Springer", "year": 2018}, {"authors": ["A. Vaswani", "N. Shazeer", "N. Parmar", "J. Uszkoreit", "L. Jones", "A.N. Gomez", "L. Kaiser", "I. Polosukhin"], "title": "Attention is all you need", "venue": "Advances in neural information processing systems. pp. 5998\u20136008", "year": 2017}, {"authors": ["J. Xu", "T. Xing", "M. Van Der Schaar"], "title": "Personalized course sequence recommendations", "venue": "IEEE Transactions on Signal Processing 64(20), 5340\u20135352", "year": 2016}, {"authors": ["J. Zhang", "X. Shi", "I. King", "D.Y. Yeung"], "title": "Dynamic key-value memory networks for knowledge tracing", "venue": "Proceedings of the 26th international conference on World Wide Web. pp. 765\u2013774. International World Wide Web Conferences Steering Committee", "year": 2017}, {"authors": ["G. Zhou", "H. Azizsoltani", "M.S. Ausin", "T. Barnes", "M. Chi"], "title": "Hierarchical reinforcement learning for pedagogical policy induction", "venue": "International Conference on Artificial Intelligence in Education. pp. 544\u2013556. Springer", "year": 2019}], "sections": [{"text": "Keywords: Dataset \u00b7 Education \u00b7 Artificial Intelligence \u00b7 AIEd \u00b7 Knowledge Tracing\nar X\niv :1\n91 2.\n03 07\n2v 3\n[ cs"}, {"heading": "1 Introduction", "text": "Knowledge tracing, the task of modelling a student\u2019s knowledge state through their learning activities over time, is a long-standing challenge of Artificial Intelligence in Education (AIEd). Since understanding a students knowledge state is a crucial step for many problems of interest including learning path recommendation, score prediction and dropout prediction, knowledge tracing is considered one of the most fundamental problems of AIEd.\nWith advances in data science and the increasing availability of Interactive Educational Systems (IESs), data-driven models that learn the complex nature of student behaviors from interaction data have become a common recipe for knowledge tracing [16,21,7,13,9]. However, the AIEd research community currently lacks a large-scale benchmark dataset which reflects the wide variety of student behaviors available through modern IESs. Although several datasets, such as ASSISTments [5,15], Junyi Academy [2], Synthetic [16] and STATICS [8], are available to the public and widely used by AIEd researchers, they are not large enough to leverage the full potential of data-driven models. Furthermore, the data they collect is limited to question-solving activities.\nIn this paper, we introduce EdNet5, a large-scale hierarchical dataset consisting of student interaction logs collected over more than 2 years from Santa6, a multi-platform, self-study solution equipped with artificial intelligence tutoring system that aids students in preparing for the TOEIC R\u00a9 (Test of English for International Communication R\u00a9) test. To the best of our knowledge, EdNet is the largest dataset open to the public, containing 131,441,538 interactions from 784,309 students. Aside from question-solving logs, EdNet also contains diverse student behaviors including but not limited to self-study activities, choice elimination, and course payment. EdNet has a hierarchical structure where the possible student actions in Santa are divided into 4 different levels of abstraction. This allows the researcher to select the level appropriate for the AIEd task at hand, for example, knowledge tracing or learning path recommendation. We release EdNet to the public under the Creative Commons Attribution-NonCommercial 4.0 International license for research purposes only."}, {"heading": "2 EdNet", "text": "EdNet is a dataset consisting of all student-system interactions collected over a period spanning two years by Santa, a multi-platform AI tutoring service with approximately 780,000 students in South Korea. Santa is available through Android, iOS and the Web. It aims to prepare students for the TOEIC (Test of English for International Communication R\u00a9) Listening and Reading Test. Each student communicates their needs and actions through Santa, to which the system responds by providing video lectures, assessing their response or giving expert commentary. Santa\u2019s UI and data-gathering process is described in Figure\n5 https://github.com/riiid/ednet 6 https://santatoeic.com\n1. As shown in the figure, the EdNet dataset contains various features of student actions such as the identity of the learning material consumed or the time spent by the student in solving a given problem."}, {"heading": "2.1 Properties of EdNet", "text": "Large-scale EdNet is composed of a total of 131,441,538 interactions collected from 784,309 students of Santa since 2017. Each student has generated an average of 441.20 interactions while using Santa. Based on those interactions, EdNet makes it possible for researchers to access large-scale real-world IES data. Moreover, Santa provides a total 13,169 problems and 1,021 lectures tagged with 293 types of skills, and each of them has been consumed 95,294,926 times and 601,805 times, respectively. To the best of our knowledge, this is the largest dataset in education available to the public in terms of the total number of students, interactions, and interaction types.\nDiversity EdNet offers the most diverse set of interactions among all existing public IES datasets as can be seen in Table 1. The set of behaviors directly related\nto learning is also richer in EdNet than in other datasets, as EdNet includes learning activities such as reading explanations and watching lectures which aren\u2019t provided in other datasets. The richness of the data enables researchers to analyze students from various perspectives. For example, purchasing logs may help analyze student\u2019s engagement with the learning process.\nHierarchy EdNet is organized into a hierarchical structure where each level contains different types of data points as shown in Figure 2. To provide the various types of data in a consistent and organized manner, EdNet offers the data in four different datasets named KT1, KT2, KT3 and KT4. As the postfix index of the datasets increases, the number of actions and types of actions involved also increase as shown in Table 1. The details of each dataset is described in Section 2.2.\nMulti-platform In an age dominated by various devices spanning from personal computers to smartphones and AI speakers, IESs must offer access from multiple platforms in order to stay competitive. Accordingly, Santa is a multiplatform system available on iOS, Android and Web and EdNet contains data points gathered from both mobile and desktop users. EdNet \u2019s platform-agnostic design allows the study of AIEd models suited for future multi-platform IESs, utilizing the data collected from different platforms in a consistent manner.\n2.2 Hierarchy of EdNet\nThe raw records obtained by Santa accurately and thoroughly represent each student\u2019s learning process. However, the unprocessed details of raw records are hard to utilize directly for AIEd tasks and require pre-processing to extract meaningful information. In order to aid the process, we pre-process the collected records into four datasets of different levels of abstractions named KT1,\nKT2, KT3 and KT4. The resolution of each dataset increases in the given order, starting from question-response interaction sequences used by most deep knowledge tracing models to the complete list of user actions gathered by Santa. The datasets were designed with particular tasks in mind so that one can use them readily for AIEd applications such as knowledge tracing, score prediction and dropout prediction. We describe each dataset of EdNet as the following.\nEdNet-KT1 In its simplest form, the learning session of a student can be described as a sequence of question-response pairs. That is,\n(q1, r1), (q2, r2), \u00b7 \u00b7 \u00b7 , (qt, rt)\nwhere qi is the i\u2019th question suggested by IES and ri is the student\u2019s response to qi. This is the format used by various deep-learning knowledge tracing models such as Deep Knowledge Tracing [16] and Self-Attentive Knowledge Tracing [13]. EdNet-KT1 is the record of question-response pairs collected by Santa from Apr. 18, 2017.\nWe have organized EdNet so that the questions come in bundles. A bundle is a collection of questions sharing a common passage, picture or listening material. For example, questions with ids q2319, q2320 and q2321 may share the same reading passage. In that case, the questions are said to form a bundle and will be presented to the student at the same time along with the corresponding shared passage. When a bundle is given, a student must respond all the included questions in order to complete the bundle.\nEdNet-KT2 A major limitation of the question-response sequence format is that it is a very concise summary of student activities. For example, a student may alternate between one of two answer choices before deciding on one and submitting their final answer. This potentially signals that they have narrowed the answer down to one of two choices but are unsure which one of the two are correct. Modern IESs have the capability to log such details, but the questionresponse format cannot effectively represent such situation, limiting the analyses that can be performed with EdNet-KT1. Since Aug. 27, 2018, Santa has\ncollected the full behavior of students to overcome this limitation. The resulting datasets, EdNet-KT2, EdNet-KT3 and EdNet-KT4, contain the compiled action sequences of each user. Each action represents a single unit of behavior. They are made by students in the Santa UI, and include such actions as watching a video lecture, choosing a response option, or reading a passage. By recording a student\u2019s behavior as-is, the datasets represent each student\u2019s behavior more accurately and allow AIEd models to incorporate the finer details of a student\u2019s learning history. EdNet-KT2, the simplest action-based dataset in EdNet, consists of the actions related to question-solving activities.\nEdNet-KT3 In Santa, a student may participate in various learning activities other than solving questions. These include reading through expert commentaries or watching lectures provided by the system. EdNet-KT3 incorporates information on these learning activities. This information can be utilized to infer the impact of learning activities on each student\u2019s knowledge state. For example, one could analyze the time each student spends studying certain expert commentaries and observing its effect on different learning behaviors and performance.\nEdNet-KT4 In EdNet-KT4, the complete list of actions collected by Santa is provided. The purpose of EdNet-KT4 is to provide the very fine details of\nstudent activity as recorded by Santa. This allows access to features and tasks specific to a particular design. For example, one may analyze the impact that purchasing a paid course has on the studying behavior of a student."}, {"heading": "3 Related Datasets", "text": ""}, {"heading": "3.1 Synthetic", "text": "Synthetic is a public dataset7 made by the authors of Deep Knowledge Tracing [16]. Based on Item Response Theory (IRT), a total of 4K virtual students answering a fixed set of 50 questions drawn from k \u2208 {1, . . . , 5} concepts are generated. More precisely, each student has a \u201dskill\u201d for each concept represented by a single number \u03b1, and each exercise has a difficulty represented by a number \u03b2. The probability that the student answer a question correctly is modelled by the 3PL model of IRT given as p(correct|\u03b1, \u03b2) = c + 1\u2212c\n1+e\u03b2\u2212\u03b1 , where c is\nthe probability of student guessing randomly (which is 0.25, as we assume that there are 4 choices for each question). Two datasets with k = 2, 5 are publicly available. 7 https://github.com/chrispiech/DeepKnowledgeTracing/tree/master/data/synthetic"}, {"heading": "3.2 ASSISTments", "text": "ASSISTments datasets [5,15] are collected from the ASSISTment system, an online tutoring system which provides instructional assistance while assessing students at the same time. Each ASSISTment consists of an original question from Massachusetts Comprehensive Assessment System (MCAS) 8th math test items, and a list of scaffolding questions created by domain experts. For each ASSISTment, a student first attempts an original question. If the student fails to answer the original question, scaffolding questions unfolds to guide the student towards the sub-steps required to solve the original question correctly. While solving the scaffolding questions, the student can give answers to the questions or ask for help-seeking behavior. Depending on the student actions, the system gives suitable feedbacks such as hints, buggy messages or answers to the scaffolding questions."}, {"heading": "3.3 STATICS2011", "text": "The STATICS2011 dataset contains 335 engineering student\u2019s question-solving logs from a one-semester statics course via online educational system developed by Carnegie Mellon University. The dataset can be found in PSLC datashop [8], which is not public but can be obtained by request8. The dataset is used by several works on knowledge tracing, such as DKVMN [21], SAKT [13], and SKVMN [1]."}, {"heading": "3.4 Junyi Academy", "text": "Junyi Academy9 is an e-learning platform in Taiwan that provides 722 mathematics questions. The Junyi Academy dataset was first introduced in [2], which is also available online in PSLC datashop10. For each question, there are two kinds of information that can be considered as tags - topic and area. There are 40 different kinds of topics (except nan denoting the absence of topic) that are assigned to each question, such as absolute-value, circle-properties, and fractions. area can be considered as a more general concept of topic, where each area contains several topics. There are a total of 7 areas (except nan) including arithmetic, logics, and algebra. It also provides question information data, such as knowledge map, prerequisites, expert-annotated time limit and similarity between two exercises, separately. This dataset has been is widely used for various educational tasks including knowledge tracing [1] and learning path recommendation [11].\n8 https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=507 9 http://www.junyiacademy.org/\n10 https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1198"}, {"heading": "3.5 PSLC Datashop", "text": "PSLC (Pittsburgh Science of Learning Center) datashop11 is an open data repository maintained by Carnegie Mellon University [8]. Various learning interaction datasets including STATICS2011, Junyi Academy datasets and also Elementary Chinese Course and Intelligent Writing Tutor are available."}, {"heading": "4 Applications of EdNet", "text": "In this section, we show three applications of EdNet : knowledge tracing, study session dropout prediction in mobile learning environments, and pre-training tasks for label-scarce problems in AIEd. We also discuss the possibility of developing student simulators with EdNet with an eye towards applications in Reinforcement Learning(RL)-based methods for learning path recommendation."}, {"heading": "4.1 Knowledge Tracing", "text": "Knowledge tracing is the problem of modeling a students knowledge state from their actions in learning activities. The recently published Separated Self-AttentIve Neural Knowledge Tracing (SAINT) is a Transformer-based [19] knowledge tracing model trained on EdNet-KT1 [3]. Like many other existing knowledge tracing models, SAINT tackles the classical problem of predicting student response correctness to each exercise, given the history of responses to previous exercises. Compared to previous knowledge tracing models, SAINT achieved state-of-theart performance with an dramatic improvement in Area Under receiver operating characteristic Curve (AUROC). The large scale of EdNet-KT1 data allows the model to capture complex relationships between student interactions through deep attention layers."}, {"heading": "4.2 Study Session Dropout Prediction in Mobile Learning Environments", "text": "[10] is the first work investigating the study session dropout prediction problem in mobile learning environments. This work defined a study session as a sequence of learning activities where the time interval between adjacent activities is less than 1 hour. Accordingly, study sessions are shorter in time, and occurs more frequently than the course dropout. Based on the definition, [10] proposed a Transformer-based Deep Attentive Study Session Dropout Prediction model (DAS). Empirical evaluations on EdNet-KT4 showed that DAS outperformed existing models.\n11 https://pslcdatashop.web.cmu.edu/"}, {"heading": "4.3 Pre-training Tasks for Label-scarce Educational Problems", "text": "Label-scarcity is a challenging issue in many subfields of AI, and AIEd is no exception. For instance, standardised exam scores cannot be obtained within IESs. The researcher must take action outside the IES to obtain them. Furthermore, some features available through IESs, including course dropout and review correctness, tend to be few in number since they occur sporadically in practice. To this end, [4] proposed Assessment Modeling, a pre-training method for general IESs. [4] defined the notion of an assessment, a specific type of educational interactive features available in IESs, and proposed using assessment prediction as a pre-training task for label-scare AIEd tasks. Using EdNet-KT4 as the training dataset, Assessment Modeling showed state-of-the-art results in both exam score and review correctness prediction, outperforming pre-training methods developed in the natural language processing community that learn representations of the contents of learning items."}, {"heading": "4.4 RL-based Learning Path Recommendation", "text": "Even if a student\u2019s knowledge state is fully understood, there still remains the task of providing an individualized, optimal learning path. In this regard, educational content recommendation has been studied extensively [20,14] with Reinforcement Learning (RL) emerging as a prominent method [11,6,22,18,17,12]. In the context of RL, a policy (e.g. tutoring strategy) is trained to maximize the reward function that evaluates the overall educational effect of the agent (tutor) over time. Most RL algorithms require repeated evaluations of the agent for training. As evaluating a tutoring strategy with real student is extremely costly, most methods use simulated students for training [11,6].\nEdNet offers multiple levels of features from which simulators of varying levels of fidelity can be developed (see Figure 3). For instance, one may build a simulator that generates a virtual student\u2019s response to newly suggested questions\nby training a model that predicts their response from their question-solving history with EdNet-KT1. With EdNet-KT4, more detailed actions such as lecturewatching, product purchase or answer choice elimination can be simulated in the same way. Each option trades off simplicity with fidelity. By allowing a range of options for this trade-off, EdNet gives the researcher the opportunity to find the most appropriate simulator that suits the particular goal of the agent being trained."}, {"heading": "5 Conclusion", "text": "In this paper, we introduced EdNet, a large-scale dataset in education gathered by the multi-platform service Santa. EdNet contains a very high-resolution record of each user\u2019s activities and, to date, it is much larger than any other public dataset in education. The hierarchical structure of EdNet allows researchers to approach diverse tasks in AIEd from various levels of abstraction. We believe that EdNet will provide fertile soil for further developments in AIEd, and we will continue to keep the dataset up-to-date."}, {"heading": "6 Acknowledgement", "text": "The authors would like to thank all the members of Riiid! for leading the Santa service successfully. EdNet could not have been compiled without their efforts."}], "title": "EdNet: A Large-Scale Hierarchical Dataset in Education", "year": 2020}