{"abstractText": "Background and Objective: In countries that enabled patients to choose their own providers, a common problem is that the patients did not make rational decisions, and hence, fail to use healthcare resources efficiently. This might cause problems such as overwhelming tertiary facilities with mild condition patients, thus limiting their capacity of treating acute and critical patients. Methods: To address such maldistributed patient volume, it is essential to oversee patients\u2019 choices before further evaluation of a policy or resource allocation. This study used nationwide insurance data, accumulated possible features discussed in existing literature, and used a deep neural network to predict the patients\u2019 choices of hospital levels. This study also used explainable artificial intelligence methods to interpret the contribution of features for the general public and individuals. In addition, we explored the effectiveness of changing data representations by comparing the performance of the model trained with and without the preprocessing by an autoencoder. Results: The results showed that the choice of patients was highly imbalanced. However, the model was still able to predict with high area under the receiver operating characteristics curve (AUC) (0.90), accuracy (0.90), sensitivity (0.94), and specificity (0.97) without initially finding the best-fit features. Generally, social approval of the provider by the general public (positive or negative) and the number of practicing physicians serving per ten thousand people of the located area are listed as the top effecting features. The changing data representation had a positive effect on the prediction improvement. All the performance indicators increased after applying the autoencoder. Conclusions: Deep learning methods can process highly imbalanced data and achieve high accuracy. The effecting features affect the general public and individuals differently. Addressing the sparsity and discrete nature of insurance data leads to better prediction. Applications using deep learning technology are promising in health policy making. More work is required to interpret models and practice implementation.", "authors": [{"affiliations": [], "name": "Lichin Chen"}, {"affiliations": [], "name": "Yu Tsao"}, {"affiliations": [], "name": "Ji-Tian Sheu"}], "id": "SP:c8c57dd2b8c2a4636719778d49148ad97289d31f", "references": [{"authors": ["Rotar", "A.M"], "title": "Shared decision making between patient and GP about referrals from primary care: Does gatekeeping make a difference", "venue": "PloS one,", "year": 2018}, {"authors": ["A Victoor"], "title": "Determinants of patient choice of healthcare providers: a scoping review", "venue": "BMC health services research,", "year": 2012}, {"authors": ["P. Vedsted", "F. Olesen"], "title": "Are the serious problems in cancer survival partly rooted in gatekeeper principles? An ecologic study", "venue": "British Journal of General Practice,", "year": 2011}, {"authors": ["D King"], "title": "Identifying quality indicators used by patients to choose secondary health care providers: a mixed methods approach", "venue": "JMIR mHealth and uHealth,", "year": 2015}, {"authors": ["A Victoor"], "title": "Free choice of healthcare providers in the Netherlands is both a goal in itself and a precondition: modelling the policy assumptions underlying the promotion of patient choice through documentary analysis and interviews", "venue": "BMC health services research,", "year": 2012}, {"authors": ["H.O. Birk", "L.O. Henriksen"], "title": "Which factors decided general practitioners\u2019 choice of hospital on behalf of their patients in an area with free choice of public hospital? A questionnaire study", "venue": "BMC health services research,", "year": 2012}, {"authors": ["F.W. Porell", "E.K. Adams"], "title": "Hospital choice models: a review and assessment of their utility for policy impact analysis", "venue": "Medical Care Research and Review,", "year": 1995}, {"authors": ["D. Fabbri"], "title": "Robone, The geography of hospital admission in a national health service with patient", "venue": "choice. Health Economics,", "year": 2010}, {"authors": ["F Kadri"], "title": "Time series modelling and forecasting of emergency department overcrowding", "venue": "Journal of medical systems,", "year": 2014}, {"authors": ["K Kim"], "title": "Predicting patient volumes in hospital medicine: A comparative study of different time series forecasting methods", "venue": "Scientific Report,", "year": 2014}, {"authors": ["B. Mielczarek"], "title": "Uzia\u0142ko-Mydlikowska. Using simulation to forecast the demand for hospital emergency services at the regional level", "venue": "Proceedings of the winter simulation conference", "year": 2012}, {"authors": ["Hoot", "N.R"], "title": "Forecasting emergency department crowding: a discrete event simulation", "venue": "Annals of emergency medicine,", "year": 2008}, {"authors": ["S Chauhan"], "title": "A Comparison of Shallow and Deep Learning Methods for Predicting Cognitive Performance of Stroke Patients From MRI Lesion Images", "venue": "Frontiers in Neuroinformatics,", "year": 2019}, {"authors": ["Wang", "H.-H"], "title": "Assessment of deep learning using nonimaging information and sequential medical records to develop a prediction model for nonmelanoma skin cancer", "venue": "JAMA dermatology,", "year": 2019}, {"authors": ["M. Alhussein", "G. Muhammad"], "title": "Voice pathology detection using deep learning on mobile healthcare framework", "venue": "IEEE Access, 2018", "year": 2018}, {"authors": ["A Esteva"], "title": "Dermatologist-level classification of skin cancer with deep neural networks", "venue": "Nature, 2017", "year": 2017}, {"authors": ["S Gehrmann"], "title": "Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives", "venue": "PloS one,", "year": 2018}, {"authors": ["R Fakoor"], "title": "Using deep learning to enhance cancer diagnosis and classification", "venue": "Proceedings of the international conference on machine learning", "year": 2013}, {"authors": ["E Choi"], "title": "Doctor ai: Predicting clinical events via recurrent neural networks. in Machine Learning for Healthcare Conference", "year": 2016}, {"authors": ["N Gutacker"], "title": "Choice of hospital: Which type of quality matters", "venue": "Journal of health economics, 2016", "year": 2016}, {"authors": ["M. Varkevisser", "S.A. van der Geest", "F.T. Schut"], "title": "Do patients choose hospitals with high quality ratings? Empirical evidence from the market for angioplasty in the Netherlands", "venue": "Journal of Health Economics,", "year": 2012}, {"authors": ["S. Li", "A. Hubner"], "title": "The Impact of Web-Based Ratings on Patient Choice of a Primary Care Physician Versus a Specialist: Randomized Controlled Experiment", "venue": "Journal of medical Internet research,", "year": 2019}, {"authors": ["Lu", "J.-F.R", "W.C. Hsiao"], "title": "Does universal health insurance make health care unaffordable? Lessons from Taiwan", "venue": "Health affairs,", "year": 2003}, {"authors": ["Wu", "T.-Y", "A. Majeed", "K.N. Kuo"], "title": "An overview of the healthcare system in Taiwan", "venue": "London journal of primary care,", "year": 2010}, {"authors": ["W.S.H. Chan"], "title": "Taiwan\u2019s healthcare report", "venue": "EPMA Journal,", "year": 2010}, {"authors": ["D. Scott"], "title": "Taiwan\u2019s single-payer success story \u2014 and its lessons for America, in VOX", "venue": "VOXMEDIA", "year": 2020}, {"authors": ["Pollack", "C.E"], "title": "Measuring care continuity: a comparison of claims-based methods", "venue": "Medical care,", "year": 2016}, {"authors": ["Chan", "C.-L"], "title": "Using an integrated COC index and multilevel measurements to verify the care outcome of patients with multiple chronic conditions", "venue": "BMC health services research,", "year": 2012}, {"authors": ["A. Higgins", "T. Zeddies", "S.D. Pearson"], "title": "Measuring the performance of individual physicians by collecting data from multiple health plans: the results of a two-state test", "venue": "Health affairs,", "year": 2011}, {"authors": ["W Liu"], "title": "A survey of deep neural network architectures and their applications", "year": 2017}, {"authors": ["V Sze"], "title": "Efficient processing of deep neural networks: A tutorial and survey", "venue": "Proceedings of the IEEE,", "year": 2017}, {"authors": ["A.M. Bur", "M. Shew"], "title": "New, Artificial intelligence for the otolaryngologist: a state of the art review. Otolaryngology\u2013Head and Neck Surgery, 2019", "year": 2019}, {"authors": ["M.V. Garc\u00eda", "J.L"], "title": "Aznarte, Shapley additive explanations for NO2 forecasting", "venue": "Ecological Informatics,", "year": 2020}, {"authors": ["M.T. Ribeiro", "S. Singh", "C. Guestrin"], "title": " Why should i trust you?\" Explaining the predictions of any classifier", "venue": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining", "year": 2016}, {"authors": ["Q. Wei", "R.L. Dunbrack Jr."], "title": "The role of balanced training and testing data sets for binary classifiers in bioinformatics", "venue": "PloS one,", "year": 2013}, {"authors": ["L. Min-Hau", "Y. Ann-Chi", "W. Tzai-Hung"], "title": "Using Regional Differences and Demographic Characteristics to Evaluate the Principles of Estimation of the Residence of the Population in National Health Insurance Research Databases (NHIRD)", "venue": "Taiwan Journal of Public Health,", "year": 2011}], "sections": [{"text": "Background and Objective: In countries that enabled patients to choose their own providers, a common problem is that the patients did not make rational decisions, and hence, fail to use healthcare resources efficiently. This might cause problems such as overwhelming tertiary facilities with mild condition patients, thus limiting their capacity of treating acute and critical patients. Methods: To address such maldistributed patient volume, it is essential to oversee patients\u2019 choices before further evaluation of a policy or resource allocation. This study used nationwide insurance data, accumulated possible features discussed in existing literature, and used a deep neural network to predict the patients\u2019 choices of hospital levels. This study also used explainable artificial intelligence methods to interpret the contribution of features for the general public and individuals. In addition, we explored the effectiveness of changing data representations by comparing the performance of the model trained with and without the preprocessing by an autoencoder. Results: The results showed that the choice of patients was highly imbalanced. However, the model was still able to predict with high area under the receiver operating characteristics curve (AUC) (0.90), accuracy (0.90), sensitivity (0.94), and specificity (0.97) without initially finding the best-fit features. Generally, social approval of the provider by the general public (positive or negative) and the number of practicing physicians serving per ten thousand people of the located area are listed as the top effecting features. The changing data representation had a positive effect on the prediction improvement. All the performance indicators increased after applying the autoencoder. Conclusions: Deep learning methods can process highly imbalanced data and achieve high accuracy. The effecting features affect the general public and individuals differently. Addressing the sparsity and discrete nature of insurance data leads to better prediction. Applications using deep learning technology are promising in health policy making. More work is required to interpret models and practice implementation.\nKeywords: access to care, patient choice, machine learning, deep learning, explainable AI"}, {"heading": "1. Introduction", "text": "While ensuring the accessibility to care, some countries applied a \u201cgate-keeping\u201d strategy and others empowered patients with the freedom to choose their own providers. In the gate-keeping strategy, the patients first visit general practitioners (GP) for medical advice, and the GP decides whether to refer the patient to a secondary or tertiary institution. The intention of the gate-keeping strategy is to enhance efficiency, regulate cost, and reduce wait time for secondary care. However, there are some limitations to this strategy such as GPs limiting the possibility of specialists responding to patient and market demands [1, 2]; further, the subsequent delayed referral can cause other problems [3]. Some countries have reformed their strategy to offer patients with the freedom to choose providers. Patients are to \u201cvote with their feet\u201d and choose health providers who fit their preferences and needs [4]. This strategy empowers the patients by prompting providers to compete for patients through a customer\u2013market mechanism, such as improving their services, such as care quality, efficiency, and wait time [2, 5]. However, such expectations has preconditions. Patients are expected to make their choices based on sufficient information and rational decision [2, 5], which is commonly not the case. Other studies report that patients have shown inadequate ability to use comparative information during provider selection [2, 6]. Past studies indicate that the patients\u2019 choice is a complex interrelationship between the characteristics of the patients, the providers, and the incident itself [2]. The decision may differ based on the characteristics of individuals, the characteristics of the provider, and the condition of the incidence, which makes it difficult to evaluate in advance.\nHowever, researchers have developed several techniques to simulate and forecast the patient flow, patient volume, resource allocation, and patient choices. The gravity model, for instance, calculates the spatial interaction between a community and a hospital using population mass of the community, capacity and service mix of hospitals, and distances (or traveling time) [7, 8]. The aggregate hospital choice model (AHCM) is intended to model hospital choices through the market share. Based on historical data, AHCM uses time-series techniques to forecast future patient volumes [9]. Forecast and simulation techniques such as mean absolute percentage errors, autoregressive integrated moving average (ARIMA), seasonal ARIMA [10], and discrete event simulation models [11, 12] have also been used previously. However, these theories have strict preconditions and partially explain the choice scenario. Recently, deep learning methods have gained popularity. They capture the underlying pattern of data by transforming data into a more abstract matter and classifying them based on the latent distribution [13, 14]. The deep learning approach has been proven effective and has shown excellent performance in a wide variety of applications [13, 15, 16], such as disease risk forecasting [17], vital signs classification into physiological symptoms [18, 19], image classification for diagnosis [20, 21], text-based medical condition recognition [22, 23], and clinical event forecasting [24]. However, irrespective of the outstanding performance, the results of the deep learning technology remained a blackbox, which merely provided the results without reasons or any information that\nindicated how the conclusion was reached. This incapability of the deep learning method to gain trust and convince people to use its results limited its implementation in healthcare field. Meanwhile, some previous studies indicate that the existing hierarchical coding scheme of electronic health recodes is not sufficiently representative [25, 26]. It does not quantify the inherited similarity between concepts, and using deep learning to project discrete encodings into vector spaces may lead to a better analysis and prediction. While insurance data are the most commonly used data in policymaking, it is necessary to investigate the pattern of insurance data before applying deep learning.\nThis study accumulates the possible features that were previously mentioned in related work on the patients\u2019 choices and aims to use deep neural networks (DNNs) to generalize and predict the patients\u2019 choices. Focusing on the hospital levels of the patients\u2019 choices, this study used explainable artificial intelligence (XAI) methods to interpret the effecting features for the general public and individuals. In addition, this study explored the representations of insurance data by comparing the performance of model training with and without the preprocessing of changing data representations. The data used were the insurance data of the National Health Insurance (NHI) of Taiwan."}, {"heading": "1.1 Effecting features of patients\u2019 choices", "text": "We characterized all the effecting features based on three main entities: the patient, the provider, and the incident. The characteristics of patients such as the age, gender, income, and previous medical experiences (positive and negative) were all possible features affecting the behavior of patients while accessing care [2, 6, 27]. Further, young people need relatively less care and females are more endurable than males; these facts along with the income of individuals affected the patients\u2019 willingness to visit a facility. Meanwhile, studies [28] indicated that the patients\u2019 satisfaction and loyalty were significantly related to the facility they would go to. When patients were satisfied with and loyal to a specific provider, they were less likely to change providers. Continuity of care was also considered an effecting feature, which could be indicated as the duration and frequency of visiting a provider (known as density); those who visited a provider regularly were less likely to change providers. The frequency of changing providers (known as dispersion) could also be an indicator of continuity of care.\nThe characteristics of a provider included the hospital reputation, hospital level, facilities at the hospital, and travel distances. Commonly, patients considered that institutes with higher levels (secondary and tertiary institutes) possess better equipment, more skillful physicians, and higher reputations. Some studies indicate that service quality affects the patients\u2019 demand [29], while others report that patients commonly neglect the quality indicators and prefer recommendations from associates [2]. Professionals such as GPs are tempted to decide based on feedback from patients and colleagues as well as their cooperation experiences with the department or hospital, rather than official information such as quality of service or wait time [6]. Some patients even decide based on review\nwebsites [4, 30], which is another form of social approval and recommendations from others. Studies [28] also indicate that the patients\u2019 choices may change according to the condition of the incident, for example, the severity of the condition, the complication of the disease, and the number of patients with chronic disease. The health status of the patients would affect their willingness to travel distance. Noncritical events and healthier patients would consider farther distance of travel and seek a second opinion. People would be tempted to go to emergency services as outpatient services are closed on weekends or holidays."}, {"heading": "1.2 Hospital choice of Taiwanese people", "text": "People in Taiwan have the freedom to choose their own providers without the referral of a GP [31, 32]. Under universal coverage, people do not possess the knowledge of choosing providers rationally. Other than choosing physicians, people commonly consider the level of the institute. Primary care service in Taiwan are usually a physician of a certain specialty who owns a clinic and acts as a private practitioner [31, 33]. Hence, the primary care service commonly referred to clinics irrespective of specialty. A secondary and tertiary care often referred to regional/district hospitals and medical centers. People commonly consider that \u201clarge hospitals possess more skillful physicians and better medical facilities,\u201d resulting in patients, irrespective of their medical severity, swarming to medical centers [31, 34]. According to a public opinion poll conducted in 2019 [35], although 85.3% of the respondents agreed that for a mild condition the patient should go to the primary care service nearby instead of tertiary hospitals, 70% considered institutes with higher levels to possess better professional skills, and 49% expressed having confidence in determining the severity of their own condition. This phenomenon causes the recession of the primary care service and overcrowding of the tertiary care [33]. Consequently, tertiary facilities are overwhelmed with mild-conditioned patients and have limited capacity to treat acute and critical patients [31, 32]. This also induces an increase in the cost of treating mild conditions. The \u201chierarchization of services,\u201d highlighted for several years, refers to visiting appropriate medical resources according to needs rather than swarming to tertiary institutes. Approaches to ease such extreme unbalanced patient volume have been proposed, such as increasing copayments, strengthening referral mechanisms, limiting outpatient service volumes for tertiary facilities, and providing incentives for cooperation between different levels of providers. However, such a phenomenon still exists [32, 33]. To address the maldistribution of patient volume, it is essential to oversee the choice of patients before strategy planning. This study aims to support the evaluation by providing a sophisticated tool to predict the patients\u2019 choice and provide the effecting features for them to do so.\n2. Material and Methods\nThe aim of this study is to predict the patients\u2019 choices of hospital levels and interpret the reasons for the prediction. In addition, this study demonstrates the effectiveness of changing the representation of insurance data. The data used were the insurance-claims data from the two million clinical declaration files and the Registry for Beneficiaries files from the Taiwan NHI research database (NHIRD), dated from January 1, 2008, to December 31, 2011. The data were originally sampled to ensure their representation of the population across Taiwan. The files included the demographic information and visiting records of outpatients and emergency settings. Some publicly announced data were added to enrich the records, including the \u201cphysician density\u201d information that referred to the number of practicing physicians serving per ten thousand people in each region of Taiwan [36]. The national calendar was used to retrieve information on weekends and national holidays. Incomplete or questionable data, such as individuals without birth date or gender (or with two genders), records without a date, birth date later than the visit date, patients without any visiting records, patients without a primary diagnosis, and incomplete information of visited hospitals were excluded. Eighteen features were included in the analysis, which were characteristics of the patients, providers, and incidents. The following section will further outline the definition and calculation equation of the features. The targeted prediction outcome of this research is the four hospital levels, namely the medical center, regional hospital, district hospital, and clinic."}, {"heading": "2.1 Characteristics of the Patient", "text": "The age, gender, low income (Yes/No), total number of visits, total number of diseases, total number of chronic diseases, and four continuity indicators were included as characteristics of the patient. The age was determined according to the date of the visit. The denotation of low income was the status identified when entering the insurance. The total number of visits was the number of visiting records during the study period. The total number of diseases and chronic diseases were identified using the encoded International Classification of Diseases (ICD) codes for each patient. The 4 continuity indicators captured the duration, density, dispersion, and continuity of an individual while accessing care [37-39]. To track duration and density of patients accessing care, the usual provider of care (UPC) and least usual provider of care (LUPC) were used to indicate the visiting ratio of medical institutes. The UPC represented the most frequently visited institute, and the LUPC represented the least frequently visited institute. The patients were required to visit the provider at least once to denote an institute as the LUPC. The sequential continuity of care index (SECOC) was used to calculate the change of providers, representing the dispersion of care. The Continuity of Care index (COCI) was a single indicator that represented the continuity of care for an individual. The calculation of the 4 continuity indicators are shown in equations (1), (2), (3), and (4), where N represents the total number of visits, n! denotes the number of visits to the ith provider, k is the number of providers once visited, and C\" is denoted as 1 when the jth provider is the same as the (j+1)th provider (0 if not).\nUPC = max(#! $ )\n(1)\nLUPC = min( n! N) (2)\nSECOC = 2 C\"\n$%&\n\"'& N \u2212 1 (3)\nCOCI = (\u2211!'&( n!)) \u2212 N N(N \u2212 1)\n(4)"}, {"heading": "2.2 Characteristics of the Provider", "text": "We characterized the providers with 3 indicators: the physician density of each region, the most frequent provider continuity (MFPC), and the least frequent provider continuity (LFPC). With reference to the patients\u2019 \u201cvote with their feet\u201d in choosing providers, we calculated the MFPC and LFPC to represent the patients\u2019 experiences and recommendations for each institute [40, 41]. The MFPC represented the frequency of being voted as the UPC, and the LFPC represented the frequency of being voted as the LUPC. Each patient could vote for only one MFPC and LFPC. The calculations are shown in equations (5) and (6), where p indicates the total number of patients, and UPC! and LUPC! indicate the ith patient who voted the provider as the UPC or LUPC, respectively.\nMFPC = \u2211 !'&\n* UPC! (5)\nLFPC = \u2211 !'&\n* LUPC! (6)"}, {"heading": "2.3 Characteristics of the Incident", "text": "The incident was characterized based on five encoded features. Through the encoded ICD codes and treatment codes of visiting records, we identified whether a surgery was involved (Yes/No), whether it was an emergency service (Yes/No), whether it was considered as a severe condition (Yes/No), whether the visit day was a work day (Yes/No), and the disease importance rate (DIR) of the target disease during that visit. The identification of surgeries and emergency services were based on the treatment codes defined by the NHIRD. The severity was defined based on emergency triage results. Triage results rank for level 1 to 3 (1 = resuscitation, 2 = emergency, and 3 = urgent) were listed as severe, and conditions that were included in the catastrophic illness announced by the NHI were also listed as severe. The date of the incident was distinguished as a work day or non-work day.\nTo capture whether the visit of the patient was a regular or singular event, we used the DIR to represent the importance of the target disease in that visit. The encoded primary diagnosis was identified as the target disease in that visit. The DIR represents the ratio of importance and is calculated as shown in equation (7), where N indicates the total number of visits of the patient, and di represents the total number of visits for disease di. We used only the primary diagnosis of the visit to identify the DIR.\nDIR = +! $\n(7)"}, {"heading": "2.4 Deep Learning Framework", "text": "This study used the DNN framework to train the patients\u2019 choices of hospital levels. DNN is a complex version of an artificial neural network (ANN) that contains multiple hidden layers [42, 43], where every neuron in layer \ud835\udc56 is fully connected to every other neuron in layer \ud835\udc56 + 1. In a multi-layer neural network, each layer of the network is trained to produce a higher level of representation of the observed pattern. Every layer produces a representation of the input pattern that is more abstract than the previous layer by composing more nonlinear operations [13, 44]. The computation is shown in equation (8). Each hidden layer computes a weighted \ud835\udc64\ud835\udc56\ud835\udc57 and bias \ud835\udc4f\ud835\udc56\ud835\udc57 of the output from the previous layer, followed by a nonlinear active function \ud835\udf0e that calculates the sum as outputs. The number of units in the previous layer is represented by \ud835\udc51 and the output of the previous layer by \ud835\udc65\ud835\udc57. Figure 1 demonstrates the DNN architecture.\ny@ = \u03c3(2x\"w!\" + b!\"\n+\n\"'&\n) (8)\nTo demonstrate the effect of changing data representations of insurance data, we designed a comparison. We used an autoencoder (AE) as the processor for the data representation change. AE is popular for processing scarce and noisy data [25, 26, 45]. It encoded the input into a lower dimension space \ud835\udc67 and then decoded the representation by reconstructing an approximate input \ud835\udc65%. The goal of the reconstruction was to minimize the mean square error of \ud835\udc65 and \ud835\udc65% . Equations (9) and (10)\ndemonstrate the computation of the encoder and decoder, where \ud835\udc4a and \ud835\udc4a\u2032 denote the respective\nweights and \ud835\udc4f and \ud835\udc4f\u2032 denote the respective bias of the encoder and decoder. Figure 2 demonstrates\nthe AE architecture.\nz = s(W, + b) (9)\nxK = s(W\u2032 + b\u2032) (10)\nXAI methods enhance the interpretability of machine learning models [46, 47]. This study adopted the shapley additive explanations (SHAP) [48]. SHAP combines the desirable characteristics of other interpretation frameworks, including local interpretable model-agnostic explanations (LIME) and deep learning important features (DeepLIFT). The SHAP value was computed using all combinations of the input, and the average marginal contribution of a feature value over all possible coalitions was calculated. SHAP has the ability to interpret models globally and locally, that is, to show the general effects of features on the whole population and individuals."}, {"heading": "2.5 Data processing flow", "text": "All features were aggregated into a visit vector. Due to the imbalanced distribution of hospital levels, this study used a random undersampling strategy to sample the majority label and balance the training set. The model was trained on balanced data and tested on actual distributed data [49]. Meanwhile, to deal with numerical features with different scale levels, all the numerical values (including the age, number of diseases and chronic diseases, number of visits, number of votes as MFPC and LFPC, and physician density) were normalized between 0 and 1, and the categorical features were transformed into a one-hot/dummy encoding before analysis. Those indicators that were already ratio figures (values between 0 and 1) were used accordingly (including COCI, UPC, LUPC, SECOC, and DIR). The data were randomly split into training data (80%) and testing data (20%). A five-fold cross-validation training strategy was used. The data processing flow is shown in Figure 3.\nThe proposed DNN model contained 18 input nodes (based on input features) and 3 hidden layers with 100 neurons each. The rectified linear unit (ReLU) active functions were used for each layer. Four output nodes symbolized the 4 hospital levels. Optimization was carried out by mini-batch stochastic gradient descent that iterated through small subsets of the training data and modified the parameters in the opposite direction of the gradient of the loss function to minimize the reconstruction error. The data representation changing comparison is done through the same training process, except that one is preprocessed with AE, and the other is not, as shown in Figure 4. The AE model consisted of 5 hidden layers; the neurons in those layers were 500, 250, 100, 250, and 500. The ReLU active function was used for the encoder (first 2 layer) and decoder (last 2 layer) and a sigmoid active function for the latent space conversion (the third layer).\nThe performance indicators used here are the area under the receiver operating characteristics curve (AUC), accuracy, sensitivity/recall, specificity, precision, and F1 score, as shown in equations (11) to (15), where TP, TN, FP, and FN denote for true positive, true negative, false positive, and false negative. For a multi-class classification of hospital levels, the macro average was used to generalize the performance, which computed the metric independently for each class and then took the average to consider each class equally. The AUC used the one-vs-rest scheme to demonstrate the general performance. The result also compared the SHAP value of the trained model, with and without AE preprocessing, to show the effect of representation change on feature importance. This study was implemented with Python version 3.7.6, combined with PyTorch framework 1.1.0 and scikit-learn 0.22.2.\nAccuracy = TP + TN TP + FP + FN + TN (11)\nSensitivity = Recall = TP\nTP + FN (12)\nSpecificity = TN\nTN + FP (13)\nPrecision = TP\nTP + FP (14)\nF1 = 2 \u2217 (Precision \u2217 Recall) Precision + Recall\n(15)"}, {"heading": "3. Results", "text": "A total of 566,767 patients and 8,805,562 visiting records were analyzed, where 72.42% patients chose to go to the clinics, 8.35% to the district hospital, 10.73% to the regional hospital, and 8.51% to the medical center. Tables 1 to 3 demonstrate the information of patients, providers, and incidents. The performance results are listed in Table 4. Processing without and with AE reached an AUC of 0.87 and 0.90, respectively. Therefore, changing data representations led to an increase of 0.03 in AUC.\nTotal number of visits per patient, mean (SD) 16.70 (15.39) UPC, mean (SD) 0.52 (0.22) LUPC, mean (SD) 0.19 (0.25) COCI, mean (SD) 0.09 (0.17) SECOC, mean (SD) 0.43 (0.27)\nSD: Standard Deviation\nTable 2. Information of Hospitals\nHospital information (n = 42,697)\nNumber of hospitals. (%) Hospital levels Medical center, 26 (0.06)\nRegional hospital 131 (0.31) District hospital 1,102 (2.58) Clinic 41,438 (97.05)\nMean (SD) MFPC 45.991 (168.76) LFPC 44.005 (120.25) Physician density 24.224 (21.90)\nSD: Standard Deviation\nTable 3. Information of Incidents\nInformation of Incidents (n = 8,805,562) Hospital levels, number of records (%)\nMedical center, 749,293 (8.51) Regional hospital 944,712(10.73) District hospital 734,976 (8.35) Clinic 6,376,581 (72.42)\nIs surgery, number of records (%) 245,908 (2.79) Is ER, number of records (%) 159,265 (1.81) Is severe, number of records (%) 307,563 (3.49) DIR, mean (SD) 0.130 (0.14) Work day, number of records (%) 7,373,122 (83.73)\nSD: Standard Deviation\nThe mean SHAP values are listed in Figure 5, with the MFPC, physician density, and LFPC listed as the top 3 factors. The contribution could be positive or negative. The contribution of other features, even combined together, was very less. The AE process changed the contribution ranking, shifting the physician density from the second to the third position. Figure 6 shows the interpretation analysis of individual cases. The base value represents the decision of the general public (56.13). The red color symbolizes the features that contributed positively and pushed the decision above the base value, and the blue color symbolizes the features that contributed negatively and pushed the decision below the base value. Figures 6(a) and 6(b) show cases processed by the model without AE, and 6(c) and 6(d) show cases processed by the model with AE. It appears that the processing of AE enlarges the less contributing features and makes them more visible on graphics."}, {"heading": "4. Discussion", "text": "With the outbreak of COVID-19, it has been highlighted that there are insufficient applications in assisting public health. Exploring the patients\u2019 choices of hospital levels is the cornerstone of evaluating policies for referrals, utilization of healthcare resources, and rerouting patient volume for the hierarchization of services, and during disease outbreaks or infection control. The choice of patients was highly imbalanced. Some of the features did not reflect the character of the general public, such as low continuity, visits often not involving surgery, emergency service, or the condition not being considered severe, However, the model could still predict with high sensitivity and specificity, without initially finding the best-fit features. This study tried to address the black-box problem of machine learning [15, 47] using the SHAP value. According to our result, three features could interpret the majority of patients\u2019 choices of hospital levels: the MFPC, LFPC, and physician density. However, the features affected individuals differently. Although entering the training process without previous data preprocessing is ideal, the performance of models can be improved by changing the data representation. It is straightforward that image and audio signals include disturbance and noise information, and using methods to eliminate noise leads to better predictions. Structured data were encoded with existing encoding schemes that were meaningful to people. The sparsity, discrete, and scarcity of data, which is invisible to the human eye, were difficult to notice. This study demonstrated the effectiveness of changing data representations. By merely adding preprocessing in advance, all the performance indicators increased, and the SHAP value became less extreme, allowing less contributing features to be observed. The discipline of social economics mostly focused on clarifying the causality and the interrelationship of factors that affect patients in choosing hospitals. However, the machine learning approach attempted to seek the underlying pattern of data and predict accurately without relying on existing knowledge. The choice indicated a certain underlying trend, but not necessarily complete reasons and causalities. This study provided an alternative approach to observe the patients\u2019 choice. The prediction was based on the trajectory of the de-identified patient-visit data, commonly collected by the insurance company. Hence, the model is highly achievable elsewhere as it neither involves\ncomplex information that is difficult to collect nor violates patient privacy. However, this study has several limitations. Distance to travel remains an important factor in choosing hospitals [7]. Although there are ways of using de-identified insurance data to project the region where patients live [50], such information is still based on hypothesis and cannot be validated accurately. Further analysis could be done based on decisions of patients of different regions and explore different decision choices due to misallocation of medical resources. Future applications using deep learning technology are promising in health policy making. A golden standard for interpreting machine learning models has not been established. The method of using the interpretation model and the generated scores can be further explored."}, {"heading": "Acknowledgements", "text": "This study was approved by the Research Ethics Committee at National Taiwan University (No. 202004EM035), and the waived informed patient consent for the data was already de-identified before analysis. The authors have no conflicts of interest to declare. Reference 1. Rotar, A.M., et al., Shared decision making between patient and GP about referrals from primary\ncare: Does gatekeeping make a difference? PloS one, 2018. 13(6). 2. Victoor, A., et al., Determinants of patient choice of healthcare providers: a scoping review. BMC\nhealth services research, 2012. 12(1): p. 272. 3. Vedsted, P. and F. Olesen, Are the serious problems in cancer survival partly rooted in gatekeeper\nprinciples? An ecologic study. British Journal of General Practice, 2011. 61(589): p. e508-e512. 4. King, D., et al., Identifying quality indicators used by patients to choose secondary health care\nproviders: a mixed methods approach. JMIR mHealth and uHealth, 2015. 3(2): p. e65. 5. Victoor, A., et al., Free choice of healthcare providers in the Netherlands is both a goal in itself and a\nprecondition: modelling the policy assumptions underlying the promotion of patient choice through documentary analysis and interviews. BMC health services research, 2012. 12(1): p. 441.\n6. Birk, H.O. and L.O. Henriksen, Which factors decided general practitioners\u2019 choice of hospital on behalf of their patients in an area with free choice of public hospital? A questionnaire study. BMC health services research, 2012. 12(1): p. 126.\n7. Porell, F.W. and E.K. Adams, Hospital choice models: a review and assessment of their utility for policy impact analysis. Medical Care Research and Review, 1995. 52(2): p. 158-195.\n8. Fabbri, D. and S. Robone, The geography of hospital admission in a national health service with patient choice. Health Economics, 2010. 19(9): p. 1029-1047.\n9. Kadri, F., et al., Time series modelling and forecasting of emergency department overcrowding. Journal of medical systems, 2014. 38(9): p. 107.\n10. Kim, K., et al., Predicting patient volumes in hospital medicine: A comparative study of different time series forecasting methods. Northwestern University, Illinois, USA, Scientific Report, 2014.\n11. Mielczarek, B. and J. Uzia\u0142ko-Mydlikowska. Using simulation to forecast the demand for hospital emergency services at the regional level. in Proceedings of the winter simulation conference. 2012.\n12. Hoot, N.R., et al., Forecasting emergency department crowding: a discrete event simulation. Annals of emergency medicine, 2008. 52(2): p. 116-125.\n13. Miotto, R., et al., Deep learning for healthcare: review, opportunities and challenges. Briefings in bioinformatics, 2018. 19(6): p. 1236-1246.\n14. Chauhan, S., et al., A Comparison of Shallow and Deep Learning Methods for Predicting Cognitive Performance of Stroke Patients From MRI Lesion Images. Frontiers in Neuroinformatics, 2019. 13(53).\n15. Xiao, C., E. Choi, and J. Sun, Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review. Journal of the American Medical Informatics Association, 2018. 25(10): p. 1419-1428.\n16. Esteva, A., et al., A guide to deep learning in healthcare. Nature medicine, 2019. 25(1): p. 24-29. 17. Wang, H.-H., et al., Assessment of deep learning using nonimaging information and sequential\nmedical records to develop a prediction model for nonmelanoma skin cancer. JAMA dermatology, 2019. 155(11): p. 1277-1283.\n18. Alhussein, M. and G. Muhammad, Voice pathology detection using deep learning on mobile healthcare framework. IEEE Access, 2018. 6: p. 41034-41041.\n19. Faust, O., et al., Deep learning for healthcare applications based on physiological signals: A review. Computer methods and programs in biomedicine, 2018. 161: p. 1-13.\n20. Esteva, A., et al., Dermatologist-level classification of skin cancer with deep neural networks. Nature, 2017. 542(7639): p. 115-118.\n21. Ardila, D., et al., End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography. Nature medicine, 2019. 25(6): p. 954-961.\n22. Gehrmann, S., et al., Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives. PloS one, 2018. 13(2): p. e0192360.\n23. Fakoor, R., et al. Using deep learning to enhance cancer diagnosis and classification. in Proceedings of the international conference on machine learning. 2013. ACM New York, USA.\n24. Choi, E., et al. Doctor ai: Predicting clinical events via recurrent neural networks. in Machine Learning for Healthcare Conference. 2016.\n25. Shickel, B., et al., Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR) analysis. IEEE journal of biomedical and health informatics, 2017. 22(5): p. 1589-1604.\n26. Miotto, R., et al., Deep patient: an unsupervised representation to predict the future of patients from the electronic health records. Scientific reports, 2016. 6(1): p. 1-10.\n27. Gutacker, N., et al., Choice of hospital: Which type of quality matters? Journal of health economics, 2016. 50: p. 230-246.\n28. Shabbir, A. and S.A. Malik, Measuring patients\u2019 healthcare service quality perceptions, satisfaction, and loyalty in public and private sector hospitals in Pakistan. International Journal of Quality & Reliability Management, 2016. 33(5): p. 538-557.\n29. Varkevisser, M., S.A. van der Geest, and F.T. Schut, Do patients choose hospitals with high quality ratings? Empirical evidence from the market for angioplasty in the Netherlands. Journal of Health Economics, 2012. 31(2): p. 371-378.\n30. Li, S. and A. Hubner, The Impact of Web-Based Ratings on Patient Choice of a Primary Care Physician Versus a Specialist: Randomized Controlled Experiment. Journal of medical Internet research, 2019. 21(6): p. e11188.\n31. Lu, J.-F.R. and W.C. Hsiao, Does universal health insurance make health care unaffordable? Lessons from Taiwan. Health affairs, 2003. 22(3): p. 77-88.\n32. Wu, T.-Y., A. Majeed, and K.N. Kuo, An overview of the healthcare system in Taiwan. London journal of primary care, 2010. 3(2): p. 115-119.\n33. Chan, W.S.H., Taiwan\u2019s healthcare report 2010. EPMA Journal, 2010. 1: p. 563-585. 34. Scott, D., Taiwan\u2019s single-payer success story \u2014 and its lessons for America, in VOX. 2020,\nVOXMEDIA. 35. Public Opinion Poll Report Summary. 2019, National Health Insurance Administration, Ministry of\nHealth and Welfare. 36. Statistics Yearbook of Practicing Physicians and Health Care Organizations in Taiwan. 2018, Taiwan\nMedical Association. 37. Pollack, C.E., et al., Measuring care continuity: a comparison of claims-based methods. Medical care,\n2016. 54(5): p. e30-e34. 38. Chan, C.-L., et al., Using an integrated COC index and multilevel measurements to verify the care\noutcome of patients with multiple chronic conditions. BMC health services research, 2012. 12(1): p. 405.\n39. MCHP. Concept: Measuring Majority of Care. 2015 2019.04.03]; Available from: http://mchpappserv.cpe.umanitoba.ca/viewConcept.php?conceptID=1108.\n40. Higgins, A., T. Zeddies, and S.D. Pearson, Measuring the performance of individual physicians by collecting data from multiple health plans: the results of a two-state test. Health affairs, 2011. 30(4): p. 673-681.\n41. Saint-Pierre, C., et al., Relationship between Continuity of Care in the Multidisciplinary Treatment of Patients with Diabetes and Their Clinical Results. Applied Sciences, 2019. 9(2): p. 268.\n42. Liu, W., et al., A survey of deep neural network architectures and their applications. Neurocomputing, 2017. 234: p. 11-26.\n43. Sze, V., et al., Efficient processing of deep neural networks: A tutorial and survey. Proceedings of the IEEE, 2017. 105(12): p. 2295-2329.\n44. Bur, A.M., M. Shew, and J. New, Artificial intelligence for the otolaryngologist: a state of the art review. Otolaryngology\u2013Head and Neck Surgery, 2019. 160(4): p. 603-611.\n45. X. Lu, et al., Speech Enhancement Based on Deep Denoising Autoencoder. Interspeech, 436-440, 2013.\n46. Arcadu, F., et al., Deep learning algorithm predicts diabetic retinopathy progression in individual patients. NPJ digital medicine, 2019. 2(1): p. 1-9.\n47. Garc\u00eda, M.V. and J.L. Aznarte, Shapley additive explanations for NO2 forecasting. Ecological Informatics, 2020. 56: p. 101039.\n48. Ribeiro, M.T., S. Singh, and C. Guestrin. \" Why should i trust you?\" Explaining the predictions of any classifier. in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2016.\n49. Wei, Q. and R.L. Dunbrack Jr, The role of balanced training and testing data sets for binary classifiers in bioinformatics. PloS one, 2013. 8(7).\n50. Min-Hau, L., Y. Ann-Chi, and W. Tzai-Hung, Using Regional Differences and Demographic Characteristics to Evaluate the Principles of Estimation of the Residence of the Population in National Health Insurance Research Databases (NHIRD). Taiwan Journal of Public Health, 2011. 30(4)."}], "title": "Using Deep Learning and Explainable Artificial Intelligence in Patients\u2019 Choices of Hospital Levels", "year": 2020}