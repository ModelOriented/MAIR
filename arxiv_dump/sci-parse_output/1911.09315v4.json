{"abstractText": "OneClass SVM is a popular method for unsupervised anomaly detection. As many other methods, it suffers from the black box problem: it is difficult to justify, in an intuitive and simple manner, why the decision frontier is identifying data points as anomalous or non anomalous. Such type of problem is being widely addressed for supervised models. However, it is still an uncharted area for unsupervised learning. In this paper, we evaluate some of the most important rule extraction techniques over OneClass SVM models, as well as present alternative designs for some of those algorithms. Together with that, we propose algorithms to compute metrics related with eXplainable Artificial Intelligence (XAI) regarding the \u201dcomprehensibility\u201d, \u201drepresentativeness\u201d, \u201dstability\u201d and \u201ddiversity\u201d of the extracted rules. We evaluate our proposals with different datasets, including real-world data coming from industry. With this, our proposal contributes to extend XAI techniques to unsupervised machine learning mod-", "authors": [{"affiliations": [], "name": "Alberto Barbado"}, {"affiliations": [], "name": "Oscar Corcho"}, {"affiliations": [], "name": "Richard Benjamins"}], "id": "SP:0e443570d212bf7e5e49405bb1fb976ac0d67f4a", "references": [{"authors": ["Alejandro Barredo Arrieta"], "title": "Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI", "venue": "Information Fusion", "year": 2020}, {"authors": ["Richard Benjamins", "Alberto Barbado", "Daniel Sierra"], "title": "Responsible AI by Design. 2019", "venue": "[cs.CY]. URL: https://arxiv.org/abs/1909", "year": 1909}, {"authors": ["Till Speicher"], "title": "A Unified Approach to Quantifying Algorithmic Unfairness", "venue": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD", "year": 2018}, {"authors": ["Moritz Hardt", "Eric Price", "Nathan Srebro"], "title": "Equality of Opportunity in Supervised Learning", "venue": "Proceedings of the 30th International Conference on Neural Information Processing Systems. NIPS\u201916", "year": 2016}, {"authors": ["Brian Hu Zhang", "Blake Lemoine", "Margaret Mitchell"], "title": "Mitigating Unwanted Biases with Adversarial Learning", "year": 2018}, {"authors": ["Rachel KE Bellamy"], "title": "AI fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias", "year": 1810}, {"authors": ["Pedro Saleiro"], "title": "Aequitas: A Bias and Fairness Audit Toolkit", "year": 2018}, {"authors": ["Leilani H Gilpin"], "title": "Explaining explanations: An overview of interpretability of machine learning", "venue": "IEEE 5th International Conference on data science and advanced analytics (DSAA). IEEE", "year": 2018}, {"authors": ["Shane T Mueller"], "title": "Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI", "year": 1902}, {"authors": ["Christoph Molnar"], "title": "Interpretable machine learning. Lulu.com, 2019", "venue": "URL: https://christophm.github.io/ interpretable-ml-book/", "year": 2019}, {"authors": ["Arthur Zimek", "Peter Filzmoser"], "title": "There and back again: Outlier detection between statistical reasoning and data mining algorithms", "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "year": 2018}, {"authors": ["Jacob Kauffmann", "Klaus-Robert M\u00fcller", "Gr\u00e9goire Montavon"], "title": "Towards explaining anomalies: a deep Taylor decomposition of one-class models", "venue": "Pattern Recognition", "year": 2020}, {"authors": ["Diogo V Carvalho", "Eduardo M Pereira", "Jaime S Cardoso"], "title": "Machine Learning Interpretability: A Survey on Methods and Metrics", "year": 2019}, {"authors": ["Fei Tony Liu", "Kai Ming Ting", "Zhi-Hua Zhou"], "title": "Isolation forest", "venue": "Eighth IEEE International Conference on Data Mining. IEEE", "year": 2008}, {"authors": ["Markus M Breunig"], "title": "LOF: identifying densitybased local outliers", "venue": "ACM sigmod record", "year": 2000}, {"authors": ["Bernhard Sch\u00f6lkopf"], "title": "Support vector method for novelty detection", "venue": "Advances in neural information processing systems", "year": 2000}, {"authors": ["David Martens"], "title": "Rule extraction from support vector machines: an overview of issues and application in credit scoring", "venue": "Rule extraction from support vector machines. Springer,", "year": 2008}, {"authors": ["Haydemar N\u00fa\u00f1ez", "Cecilio Angulo", "Andreu Catal\u00e0"], "title": "Rule extraction from support vector machines", "venue": "Esann", "year": 2002}, {"authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "title": "Anchors: High-precision model-agnostic explanations", "venue": "In: Thirty-Second AAAI Conference on Artificial Intelligence", "year": 2018}, {"authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "title": " Why should i trust you?\u201d Explaining the predictions of any classifier", "venue": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining", "year": 2016}, {"authors": ["Jerome H Friedman", "Bogdan E Popescu"], "title": "Predictive learning via rule ensembles", "venue": "The Annals of Applied Statistics", "year": 2008}, {"authors": ["Fulton Wang", "Cynthia Rudin"], "title": "Falling rule lists", "venue": "Artificial Intelligence and Statistics", "year": 2015}, {"authors": ["Sanjeeb Dash", "Oktay Gunluk", "Dennis Wei"], "title": "Boolean Decision Rules via Column Generation", "venue": "Advances in Neural Information Processing Systems 31. Ed. by S. Bengio et al. Curran Associates, Inc.,", "year": 2018}, {"authors": ["Vijay Arya"], "title": "One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques", "venue": "Sept. 2019", "year": 1909}, {"authors": ["Dennis Wei"], "title": "Generalized Linear Rule Models", "venue": "Proceedings of the 36th International Conference on Machine Learning", "year": 2019}, {"authors": ["Vijay Arya"], "title": "One explanation does not fit all: A toolkit and taxonomy of ai explainability techniques", "year": 1909}, {"authors": ["Vic Barnett"], "title": "Outliers in statistical data", "venue": "Tech. rep", "year": 1978}, {"authors": ["Sam Wilkinson"], "title": "Levels and kinds of explanation: lessons from neuropsychiatry", "venue": "Frontiers in psychology", "year": 2014}, {"authors": ["Frank C Keil"], "title": "Explanation and understanding", "venue": "Annu. Rev. Psychol", "year": 2006}, {"authors": ["David Arthur", "Sergei Vassilvitskii"], "title": "k-means++: The advantages of careful seeding", "venue": "Tech. rep. Stanford,", "year": 2006}, {"authors": ["Jinchao Ji"], "title": "An improved k-prototypes clustering algorithm for mixed numeric and categorical data", "venue": "In: Neurocomputing", "year": 2013}, {"authors": ["Karthik S Gurumoorthy"], "title": "Efficient Data Representation by Selecting Prototypes with Importance Weights", "venue": "IEEE International Conference on Data Mining (ICDM). IEEE", "year": 2019}, {"authors": ["Saket Sathe", "Charu Aggarwal"], "title": "LODES: Local density meets spectral outlier detection", "venue": "Proceedings of the 2016 SIAM International Conference on Data Mining. SIAM", "year": 2016}, {"authors": ["Meghana Padmanabhan"], "title": "Physician-friendly machine learning: A case study with cardiovascular disease risk prediction", "venue": "Journal of clinical medicine", "year": 2019}, {"authors": ["Catherine Blake"], "title": "UCI repository of machine learning databases", "venue": "In: http://www. ics. uci. edu/ \u0303 mlearn/MLRepository", "year": 1998}, {"authors": ["F. Pedregosa"], "title": "Scikit-learn: Machine Learning in Python", "venue": "Journal of Machine Learning Research", "year": 2011}, {"authors": ["Alberto Barbado"], "title": "Rule extraction in unsupervised outlier detection for XAI", "year": 2019}, {"authors": ["Lars Buitinck"], "title": "API design for machine learning software: experiences from the scikit-learn project", "venue": "ECML PKDD Workshop: Languages for Data Mining and Machine Learning", "year": 2013}, {"authors": ["Janis Klaise"], "title": "Alibi: Algorithms for monitoring and explaining machine learning models", "venue": "Version 0.3.2", "year": 2020}, {"authors": ["Rikard Konig", "Ulf Johansson", "Lars Niklasson"], "title": "G-REX: A versatile framework for evolutionary data mining", "venue": "IEEE International Conference on Data Mining Workshops", "year": 2008}, {"authors": ["David Arthur", "Sergei Vassilvitskii"], "title": "k-means++: The advantages of careful seeding", "venue": "Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics", "year": 2007}], "sections": [{"text": "Keywords XAI, OneClass SVM, unsupervised learning, rule extraction, anomaly detection, metrics"}, {"heading": "1. Introduction", "text": "Responsible Artificial Intelligence [1] is an emerging discipline that is gaining relevance both in academic and industrial research. An increasing number of organisations are defining policies and criteria for the usage of data and the development of support decision systems using AI techniques.\nFor example, Telefo\u0301nica has defined its own AI principles [2], which are organised into the following categories:\n\u2022 Detecting sensitive data in the datasets used to train Machine Learning (ML) models (for example, the use of gender information to support the decision of giving a credit score) or detecting whether there is a bias in the data, what may have an unwanted effect in decision making. Besides analysing directly the dataset, there are methods to perform an evaluation on a trained model to check whether there is any bias on its decisions. This is done using a group of metrics known as fairness metrics [3, 4, 5].\nCopyright c\u00a9 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n\u2022 Explaining how an algorithm reaches a conclusion in a way that is clear and intuitive for a human being. This is crucial not only to avoid the fear of considering AI as black boxes that may suddenly take harmful decisions in the future, but also to contribute to the democratisation of AI and increase trust on these systems.\nThe first group of challenges is being widely addressed by researchers, with tools to audit datasets and trained models to detect risks, and at the same time provide solutions to mitigate those biases [6, 7]. The second group is addressed through the use of Explainable AI (XAI) techniques, which can be applied to black-box models in order to obtain posthoc explanations based on the information that they provide. In the literature, there are many XAI proposals for supervised ML models. However, some of the most recent and thorough reviews on XAI [8, 9, 1, 10] do not mention the application of such techniques to unsupervised learning.\nOutlier detection is one of the tasks where unsupervised learning is applied. There is often no prior information about outliers in a dataset, hence unsupervised ML algorithms offer the chance to infer patterns and detect anomalies. However, not only is it important to detect outliers, but also to explain both why a particular datapoint has been labelled anomalous and how the model behaves globally (for instance, what features influence more for classifying a datapoint as outlier).\nThis is something that can be resolved with XAI techniques like rule extraction. This family of techniques can explain with an \u201dIF...THEN\u201d schema both the output of a particular datapoint or the global behaviour of the original model. In the case of outlier detection, they can explain both a particular outlier and also how the features of the whole model contribute to identify points as outliers or inliers. Recent literature deals with XAI applied over anomaly detection systems [11, 12]. However, to the best of our knowledge, there are no evaluations of rule extraction techniques for unsupervised ML outlier detection.\nMost outlier detection systems are more interested in explaining faithfully why a datapoint is an outlier, and what should have happened in order for it to be an inlier, rather than being able to cover all possible scenarios with explanations that may be wrong. For instance, in Telefo\u0301nica, if we\nar X\niv :1\n91 1.\n09 31\n5v 4\n[ cs\n.L G\n] 2\n9 Ju\nn 20\nwant to explain why the number of total calls to a call center at one day is anomalous, generally it is better to explain some days with total confidence even if that means not being able to explain all instances. Applying this over a rule extraction technique scenario, it means that the extracted rules need to have a 100% precision (P@1); rules that classify datapoints from one class (p.e. \u201doutliers\u201d) without including datapoints from the a other one. This is important because, if the rules extracted cover inliers, then the counterfactual explanation for how to turn an outlier into an inlier should lead to a scenario where the model will always classify it as an inlier.\nAnother open issue in XAI is how to evaluate the quality of explanations. The following concepts are mentioned in the literature [13, 10]:\n\u2022 \u201dComprehensibility\u201d: Are explanations easy enough to understand?\n\u2022 \u201dRepresentativeness\u201d: Are explanations relevant? Do they explain all possible cases?\n\u2022 \u201dStability\u201d: Do explanations match the predictions of the model? Or are there inconsistencies?\n\u2022 \u201dDiversity\u201d: Are explanations sufficiently different among them? Or are they redundant?\nEven though these concepts are addressed in the literature, to the best of our knowledge there are not many algorithmic implementations of them, and there are no empirical evaluations for rule extraction techniques.\nFollowing this, the main contributions of our work are:\n\u2022 Apply rule extraction techniques for unsupervised outlier detection models, using OCSVM as an example algorithm. The evaluated techniques are model-agnostic, so in order to offer a more general overview, we analyse the results using two different kernels: Radial Basis Function (RBF) and a Linear one.\n\u2022 Design and implement alternatives over one of the rule extraction algorithms from the literature. We also propose an algorithm to turn a local rule extraction model (Anchors) into a global one.\n\u2022 Quantify the quality of the explanations generated using XAI metrics that measure \u201dcomprehensibility\u201d, \u201drepresentativeness\u201d, \u201dstability\u201d and \u201ddiversity\u201d in a rule extraction scenario. We propose how to implement each one of them and obtain their results in our empirical evaluation.\n\u2022 Considering only P@1 rules, see the different results obtained and compare them using the metrics of the previous point. For this, we also group all metrics into a single function.\n\u2022 Since RBF kernels group inliers within one or more hyperspheres that separate them from outliers, we also analyse whether this process contributes to the rules extracted in this P@1 scenario. This could be true if the number of rules obtained for inliers using an RBF kernel are inferior than those obtained using a linear one.\nThe empirical evaluations carried out use both open datasets as well as real data from Telefo\u0301nica. Our evaluation\nconsists in analysing the results for the aforementioned metrics using different rule extraction algorithms over OCSVM models with the two aforementioned kernel configurations.\nThe rest of the paper is organized as follows. First, we describe some related work in the area of XAI and rule extraction applied to SVM. This chapter will also introduce the rule extraction techniques considered, as well as literature related to XAI metrics and the psychology of explanations. After identifying research opportunities derived from these works, the paper introduces some alternatives over some of the rule extraction techniques, as well as algorithms to compute the metrics described before. Following this, we present an empirical evaluation of our algorithm with several datasets. We then conclude, showing also potential future research lines of work."}, {"heading": "2. Related Work", "text": "This section reviews unsupervised ML models used for anomaly detection, and reviews previous work on rule extraction in SVM that is relevant for our proposal."}, {"heading": "2.1. Unsupervised ML for Anomaly Detection", "text": "Many algorithms for unsupervised anomaly detection exist. Examples are IsolationForest [14], Local anomaly Factor (LOF) [15] and OCSVM [16]. The latter has relevant advantages over the former ones, mainly in terms of computational performance. This is due to the fact that it creates a decision frontier using only the support vectors (like general supervised SVM) and that model training always leads to the same solution because the optimization problem is a convex one. However, SVM (hence OCSVM) algorithms are some of the most difficult ones to explain due to the mathematicallycomplex method that obtains the decision frontier.\nSVM for classification theoretically maps the data points available in the dataset to a higher dimensional space than the one determined by their features, so that the separation among classes may be done linearly. It uses a hyperplane obtained from data points from all of the classes. These data points, known as support vectors, are the ones that are closer to each other and the only ones needed to determine the decision frontier. However, it is not really necessary to map to a higher dimension due to the fact that the equation that appears in the optimization of the algorithm uses a dot product of those mapped points. Because of that, the only thing to be calculated is such dot product, something that can be accomplished with the well-known kernel trick. Hence instead of calculating explicitly the mapping to a higher dimension the equation is solved using a kernel function.\nIn OCSVM there are no labels. Hence all data points are considered to belong to a same class at the beginning. The decision frontier is computed trying to separate the region of the hyperspace with a higher number of data points close to each other from another that has small density, considering those points as anomalies. To do so the algorithm tries to define a decision frontier that maximizes the distance to the origin of the hyperspace and that at the same time separates from it the maximum number of data points. This compromise between those factors leads to the optimization of the\nalgorithm and allows obtaining the optimal decision frontier. Those data points that are separated are labeled as nonanomalous (+1) and the others are labeled as anomalous (-1).\nThe optimization problem is reflected in the following equations:\nminw,\u03bei,\u03c1 = 1 2 ||w||2 + 1 \u03bdn n\u2211 i=1 (\u03bei \u2212 \u03c1)\nsubject to: (w, \u03c6(xi)) \u2265 \u03c1\u2212 \u03bei for i = 1, ..., n\n\u03bei \u2265 0 for i = 1, ..., n\n(1)\nIn that equation, \u03bd is a hyper-parameter known as rejection rate, which needs to be selected by the user. It sets an upper bound on the fraction of anomalies that can be considered, and also defines a lower bound on the fraction of support vectors that can be considered. Using Lagrange techniques, the decision frontier obtained is the following one:\nf(x) = sgn((w, \u03c6(xi)\u2212 \u03c1)\u21d2\nf(x) = sgn( n\u2211 i=i \u03b1iK(xi, x)\u2212 \u03c1) (2)\nHence the hyper-parameters that must be defined in this method are the rejection rate, \u03bd, and the type of kernel used."}, {"heading": "2.2. Rule Extraction in SVM", "text": "Several papers deal with the importance of XAI applied to models such as SVM. In particular [17] aims to resolve the black box problem in SVM for supervised classification tasks. It obtains a set of rules that explain in a simple manner the boundaries that contain the values of the different classes. Thanks to that, it is easier to understand what are the conditions that will identify a data point as belonging to one class or to another (in OCSVM it would be belonging to class +1 - normal data - or class -1 - anomaly -). The challenge consists in discovering a way to map the algorithm results to a particular set of rules. There are two general ways to do it. One consists in inferring the rules directly from the decision frontier, using a decompositional rule extraction technique. The other (simpler) one uses a method called pedagogical rule extraction technique that does not care about the decision frontier itself and considers the algorithm as a black box from where to extract those rules depending on which class it uses to classify different relevant data points used as an input.\nThe first method is clearly more transparent, as it deals directly with the inner structure of the model. However, it is generally more difficult to implement. One way to implement it is with a technique known as SVM+ Prototypes [18], which consists in finding hypercubes using the centroids (or prototypes) of data points of each class and using as vertices the data points from that hyperspace area farther away from that centroid (or use directly the support vectors themselves if they are available). It will then infer a rule from the values of the vertices of the hypercube that contain the limits of all the points inside it, creating one rule for each hypercube.\nFor example, a dataset that contains two numerical features X and Y will be defined in a 2-dimensional space. The algorithm will create a square that contains the data points on each of the classes, as shown in Figure 1. The rule that justifies that a data point belongs to class 2 is: \u2022 Rule 1: CLASS 2 IF X\u2265X1 \u2227 Y\u2265Y1 \u2227 X\u2264X2 \u2227 Y\u2264Y2\nThe generated hypercubes may wrongly include points from the other class when the decision frontier is not linear or spherical, as shown in Figure 2. In this case the algorithm considers an additional number of clusters trying to include the points into a smaller hypercube, as shown in Figure 3.\nA rule will be generated for each hypercube, considering all those scenarios as independent, leading to this output: \u2022 Group 1: CLASS 1 IF X... \u2022 Group 2: CLASS 1 IF X...\nThere are some downsides of that method in supervised classification tasks, especially when the problem is not simply a binary classification or when the algorithm is performing a regression. For instance, the number of rules may grow immensely due to the fact that a set of rules will be generated\nfor each category and each set may contain a huge number of rule groups, leading to an incomprehensible output.\nHowever, in OCSVM these difficulties may be potentially mitigated due to two reasons. On the one hand, the explanations are reduced to rules that explain when a data point is not an anomaly (so there would be no need to define rules for the anomalies). On the other hand, the algorithm tries to group all non-anomalous points together, setting them apart from the outliers. Because of this, the chance to define a hypercube that does not contain a point from the another class may be higher than in a standard classification task. Both the unbalanced inherent nature of data points in anomaly detection (few anomalies vs. many more non-anomalous data points) and the fact that non-anomalous points tend to be closer to each other may help achieving good results with this method."}, {"heading": "2.3. Rule extraction techniques in XAI", "text": "The literature contains many rule extraction proposals that can contribute to XAI. The algorithms that provide these rules can be also classified according to XAI taxonomies, such as [1]. Among all the proposals, for this paper we are interested in rule extraction techniques that can be applied over an unsupervised machine learning model in order to generate explanations that explain how the whole model behaved. Thus, we analyse some model-agnostic post-hoc global techniques that, using as input the same dataset than the unsupervised model, and using as target the output of that model (indicating whether a datapoint is an inlier or outlier), can generate rules that explain how the original model behaves. We will also cover some references of modelagnostic post-hoc local techniques that provide rules to explain particular output instances.\nAs aforementioned, a general way to approximate any blackbox model globally is by using a surrogate supervised decision model trained over the same dataset, but instead of using the real labels (the ones used for the blackbox model), it is trained over the predictions of that blackbox model [10]. This may be accomplished with any ML model, but it is use-\nful to do it with a whitebox model that can be directly interpreted. Among these whitebox models, some of them may be used for rule extraction. An example is a Decision Tree (DT) model. DT allows explaining the classification logic of the blackbox model through the usage of rules, which can be used even for classifying new instances. The advantages of using a DT as a surrogate global model is its flexibility (it can be applied over any model in an agnostic way) and simplicity (it is a solution that is easy to explain). However, this approximation at the end leads to explain a proxy model, and not the actual data, since the surrogate model never sees the true target values.\nAnchors [19] is a model-agnostic XAI technique that extracts rule explanations for individual data points. The purpose of Anchors is finding a decision rule that approximates the decision function of the blackbox model around that individual data point. This rule \u201danchors\u201d the prediction of that data point, so that any perturbation of the features of that point that are still inside the rule will always return the same output from the blackbox model. The approach is as follows. First, the algorithm generates candidate rules that may explain the data point. Then, it evaluates those candidate rules. In order to do that, Anchors generates permutations around the data point (similar data points to the original one) that yield the same result. The result is evaluated by calling the blackbox model (the oracle) and obtaining the classification for that data point. In order to optimize the exploration-exploitation of generating and evaluating data points, it uses a reinforcement learning approach with a Multi-Armed Bandit (MAB) approximation. In this MAB, each arm of the Bandit problem is a candidate rule, and the data points generated, after obtaining their classification result from the blackbox model, are used to compute a precision metric used to evaluate the candidate rule\u2019s payoff. This reinforcement learning approach helps minimizing the number of calls to the model in order to reduce the computational cost of the algorithm. Among all the candidate rules, the algorithm then checks if the best one of them matches a predefined convergence criteria. To do that, it filters rules according to a precision threshold, and selects form the remaining ones the one with highest coverage. That rule is used to explain that original data point. If there are no rules that match the convergence criteria, then the algorithm keeps iterating (using a beam search approach) using the B best rules from the previous step in order to generate new candidate rules for the following one. In those following steps, Anchors keep extending the rules with more features (in the first step, it only uses one feature per candidate rule). Thus, Anchors offers a model-agnostic approach that generate IFTHEN rules, easy to interpret, that are generated in an efficient way thanks to the usage of reinforcement learning (MAB) that can be parallelised. However, Anchors is very sensitive to its initial configuration, like many permutation approach algorithms, such as LIME [20]. Another important consideration of Anchors is that, while it keeps the calls to the oracle to a minimum (thanks to MAB), it still requires a lot of calls, and that can affect the runtime of the algorithm.\nRuleFit [21] is a model-agnostic surrogate model that learns a linear regression model (Lasso) that uses as features\nboth the original features of the model, as well as new generated features that represent decision rules. In order to accomplish that, first, a tree model is trained over the output and the input features, and the decision paths between the tree levels are turned into decision rules, except for the ones that lead to the leaf nodes, which are not considered. These rules are used as additional features, along with the original ones, on the Lasso surrogate model. Thanks to this, RuleFit yields both rules as well as their contribution, measured through the coefficients of the Lasso model. In summary, RuleFit generates a white-box model that includes rules as features, that can be interpreted as a standard linear regression one. The only caveat is that, for the original coefficients, the predicted outcome changes by |\u03b2j if feature xj changes by one unit if the other features remain unchanged, while for a feature-rule rk it is different; if all the conditions of the feature rk are met, the predicted outcome changes by \u03b1k (the weight associated to that rule-coefficient) for regression. Similarly, for classification tasks, when the conditions of rk are met, the odds for event vs. no-event changes by a factor of \u03b1k.\nSimilarly to RuleFit, SkopeRules [10] is another way to generate rules from tree ensembling techniques. They differ, however, in how they obtain the rules. First, SkopeRules generates the rules using surrogate tree ensembles trained using the input features and the target variable. Then, it applies a filtering step in which, using a threshold for Precision and Recall, some rules are removed and some are kept. This step allows to select only high-performing rules, and removing the ones that do not yield good results. The last step is known as \u201dsemantic rule duplication\u201d. This step eliminates duplicate rules (rules that are the same or very similar to other ones). It also eliminates again low-performing rules based on their results for a F1-metric. This allows to obtain high-performing as well as heterogeneous rules. The final set of rules is the output of SkopeRules, differing from RuleFit because it does not use a Lasso model to aggregate all rules.\nFalling Rule Lists (FRL) [22] are classification models that generate a sorted list of IF-THEN rules, thus, they can serve as a model-agnostic global post-hoc rule extraction technique. The rules are binary, and are looked one after the other, in order to see if a particular datapoint can be classified into one of the classes. The rules are sorted according to the probability of classifying a datapoint into that class using that rule. Due to that, FRL offers a list of IF-ELSE IF rules associated to a particular class with a decreasing probability score. This is inspired in the concept of healthcare triage: patients are classified within risk level groups, and the highest-risk ones should be considered first. The particular algorithm cited and used in this paper uses an approach for learning based on a Bayesian framework, instead of a greedy decision tree learning method, named Bayesian Falling Rule Lists (BFRL).\nBoolean Decision Rules via Column Generation (BRCG) [23] also provides a binary classifier by using disjuntive normal form (DNF, OR-of-ANDs) or conjuntive normal form (CNF, AND-of-ORs) through interpretable rules. In case of DNF (the one used in this paper), they provide an unordered set of decision rules that classify a datapoint into the pos-\nitive category if at least one of the rules is satisfied. This is different than other methods already mentioned, such as BFRL where the rules are ordered in an IF-THEN schema, or the surrogate DT model, that provides the rules in a tree structure schema. In this article, we use the BRCG-light approximation from [24], that replaces the integer programming solver used in the original paper by a heuristic beam search one.\nGeneralized Linear Rule Models (GLRM) [25] generate decision rules and combine within a linear model (generalized additive model, GAM). Thus, they provide both a nonlinear modelling, thanks to the decision rules, while keeping the interpretability by using a linear model that ensembles them. However, as [26] notice, while it is feasible to interpret linear combinations of rules, if the number of rules increases too much, there is a risk of losing the interpretability of the model. The authors of the original paper highlight that in order to reduce the rules generated and not lose interpretability, they use a rule selection technique based on column generation (CG). CG searches the spaces of rules and generates them only when they are needed, and then fits again the GLM model. This allows analysing again old rules, re-weight them, and discard the ones that are not needed anymore. This is different to other methods used in the literature, mainly pre-selecting a subset of candidate rules using optimization techniques, or a greedy optimization approach by adding rules one by one using sequential covering or boosting techniques."}, {"heading": "2.4. XAI for anomaly detection", "text": "There are already references in the literature that highlight the importance of combining outlier detection with the generation of insights that provide explanations about the decision process. One example is the work of [11], which covers different aspects related to outlier detection. First, authors reflect on the definition of \u201doutlier\u201d and the different possibilities to deal with them. Citing [27], an outlier is \u201can observation (or subset of observations) which appears to be inconsistent with the remainder of that set of data\u201d. Here, they indicate that the important part of the sentence is \u201dappears to\u201d, as it opens to the analysis of whether a datapoint is truly an outlier. This, combined with [28], defines a taxonomy of two levels: first, identifying \u201ddiscordant\u201d datapoints with the rest, and then, classifying them as \u201dtrue outliers\u201d (named \u201dcontaminants\u201d) or false positives. However, the authors recognize that solving this two-step procedure strongly depends on domain knowledge for most cases. The second part of the article defines a taxonomy for the different outlier detection methods: \u2022 Global vs local outliers: Outlier detection methods can\nuse either the whole dataset to identify outliers, or only a fraction of it.\n\u2022 Point anomalies, collective anomalies, and contextual anomalies: The first type refers to the detection of outliers at an individual level. The other two cases identify outliers inside a specific context.\n\u2022 Labeling vs scoring: Labeling refers to the direct (binary) identification of outliers, whereas scoring assigns a degree\nof \u201doutlierness\u201d to the datapoints.\n\u2022 Supervised vs unsupervised: outlier detection methods may consider prior knowledge about outliers (that, for ML methods can be used as labels to train the model), or they may work without any prior knowledge at all about outliers.\n\u2022 Parametric vs non-parametric: Parametric methods make assumptions about the underlying data distribution (mainly, that the data distribution is a Gaussian), and they adjust the dataset to that distribution in order to identify datapoints that are outliers. In contrast, non-parametric methods do not make any assumption about the underlying distribution. However, non-parametric methods still need assumptions about the configuration of their parameters.\nThe last part of the article, after analysing some of the different algorithms available, presents as a new and recent field XAI applied to outlier detection, indicating some previous works that deal with it. In our research, we only find [12] as a paper that explicitly deals with XAI applied to OCSVM models for outlier detection. Authors propose a model-specific method based on the concept that OCSVM models can be rewritten as pooling neural networks. Due to the asymmetry between inliers and outliers, they model with a min-pooling over distances for outliers, and a max-pooling over similarities for inliers. Thanks to turning OCSVM models to a neural network, they apply a deep Taylor decomposition (DTD) to obtain explanations in term of input features. DTD serves as a framework to apply layer-wise retropropagation (LRP) in order to obtain the feature contribution of the input features to a predicted output. The authors extend the explanations generated to include using both input features or support vectors.\nThe previous analysis of the literature shows that there is still an open research area to analyse model-agnostic rule extraction techniques over unsupervised outlier detection models, particularly for OCSVM."}, {"heading": "2.5. Metrics for XAI", "text": "Beyond indicating the importance of both detecting outliers and being able to explain how the decision took place, it is also crucial to quantify the quality of those explanations. There are some recent reviews in the literature that deal with the challenge of providing metrics in XAI, such as in [13]. In that article, authors analyse the literature and define a taxonomy of properties that should be considered in the individual explanations generated by XAI techniques.\n\u2022 Accuracy: It is related to the usage of the explanations to predict the output using unseen data by the model.\n\u2022 Fidelity: It refers to how well the explanations approximate the underlying model. The explanations will have high fidelity if their predictions are constantly similar to the ones obtained by the blackbox model. Generally, if the explanations have high consistency and the model has high accuracy, the explanations will also have high accuracy.\n\u2022 Consistency: It refers to the similarity of the explanations obtained over two different models trained over the same input dataset. High consistency appears when the explanations obtained from the two models are similar. However, a low consistency may not be a bad result since the models may be extracting different valid patterns from the same dataset due to the \u201dRashomon Effect\u201d (seemingly contradictory information is fact telling the same from different perspectives).\n\u2022 Stability: It measures how similar the explanations obtained are for similar datapoints. Opposed to consistency, stability measures the similarity of explanations using the same underlying model.\n\u2022 Comprehensibility: This metric is related to how well a human will understand the explanation. Due to this, it is a very difficult metric to define mathematically, since it is affected by many subjective elements related to human\u2019s perception (such as context, background, prior knowledge, etc.). However, there are some objective elements that can be considered in order to measure \u201dcomprehensibility\u201d, such as whether the explanations are based on the original features (or based on synthetic ones generated after them), the length of the explanations (how many features they include), or how many explanations are considered. In general terms, using the original features, while keeping the number of explanations generated and the features used to a minimum, will increase comprehensibility.\n\u2022 Certainty: It refers to whether the explanations include the certainty of the model about the prediction or not.\n\u2022 Importance: Some XAI methods that use features for their explanations include a weight associated with the relative importance of each of those features.\n\u2022 Novelty: Some explanations may include whether the datapoint to be explained comes from a region of the feature space that is far away from the distribution of the training data. This is something important to consider in many cases, since the explanation may not be reliable due to the fact that the datapoint to be explained is very different from the ones used to generate the explanations.\n\u2022 Representativeness: It measures how many instances are covered by the explanation. Explanations can go from explaining a whole model (p.e. weights in linear regression) to only be able to explain one datapoint. As already mentioned, this metric deals with quantifying the quality of the explanations for an individual datapoint. However, they are also perfectly applicable for rule extraction techniques where the outputs (rules) for the whole dataset can also be analysed in those terms. In this context, one additional aspect to consider is \u201ddiversity\u201d, a metric that indicates whether the explanations are redundant or repetitive and can already be mostly covered by another explanation, or if they provide insights that are not deducible from the other explanations available.\nFor our research regarding rule extraction, we will focus in analysing the degree of \u201dcomprehensibility\u201d of the rules, the coverage of those rules of the datapoints available (\u201drepresentativeness\u201d), if the rules approximate the underlying\nmodel (\u201dstability\u201d), and if they have overlaps among them and are redundant (\u201ddiversity\u201d). The challenge here is quantifying those metrics. Due to that, we will propose and use algorithms to quantify them in a rule extraction scenario."}, {"heading": "2.6. The psychology of explanations", "text": "In ML, explanations are the \u201ckey\u201d to open blackbox algorithms, and are therefore likely to play an important role in possible future AI regulations. It is expected that in certain domains or applications, whenever an algorithm takes an autonomous decision or provides a recommendation that has a significant impact on people\u2019s lives, some kind of explanation is required [29]. In this paper, we have quantified several quality parameters of explanations generated by different methods for non-supervised learning algorithms, including the comprehensibility of the generated explanations. But for explanations to be comprehensible and effective for people in different situations, we also need to consider the consumer of the explanations: the people.\nHow do people understand explanations? In psychology, explanations are seen as crucial for human knowledge and learning, as they are considered proofs of understanding. According to Wilkinson [30], there are three kinds of views of explanations: the formal-logical view (an explanation is like a deductive proof given some propositions), the ontological view (events -state of affairs- explain other events), and the pragmatic view (an explanation needs to be understandable by the \u201cdemander\u201d). Explanations that are sound from a formal-logical or ontological view, but leave the demander in the dark, are not considered good explanations. For example, a very long chain of logical steps or events (e.g. hundreds) without any additional structure can hardly be considered a good explanation for a person, simply because he or she will lose track.\nWilkinson introduces two more concepts to define the adequacy of explanations for demanders. The level of explanation refers to whether the explanation is given at a high-level or more detailed level. The right level depends on the knowledge and the need of the demander: he or she may be satisfied with some parts of the explanation happening at the higher level, while other parts need to be at a more detailed level. The kind of explanation refers to notions like causal explanations and mechanistic explanations. Causal explanations provide the causal relationship between events but without explaining how they come about (a kind of \u201cwhy\u201d question). For instance, smoking causes cancer. A mechanistic explanation would explain the mechanism whereby smoking causes cancer (a kind of \u201chow\u201d question). Causal explanations can be further divided into common-cause explanations (a single cause has several consequences), common-effect explanations (several causes converge to one consequence), and simple linear chain explanations (one causes leads to one consequence) [31].\nAs said, a satisfactory explanation does not exist by itself, but depends on the demander\u2019s need. In the context of ML algorithms, we can distinguish between several typical demanders of explainable algorithms [1]:\n\u2022 Domain experts: those are the \u201cprofessional\u201d users of the\nmodel, such as medical doctors who have a need to understand the workings of the model before they can accept and use the model.\n\u2022 Regulators, external and internal auditors: like the domain experts, those demanders need to understand the workings of the model in order to certify its compliance with company policies or existing laws and regulations.\n\u2022 Practitioners: professionals that use the model in the field where they take users\u2019 input and apply the model, and subsequently communicate the result to the users\u2019 situations, such as loan applications.\n\u2022 Redress authorities: the designated competent authority to verify that an algorithmic decision for a specific case is compliant with the existing laws and regulations.\n\u2022 Users: people to whom the algorithms are applied and that need an explanation of the result.\n\u2022 Data scientists, developers: technical people who develop or reuse the models and need to understand the inner workings in detail. In summary, for explainable AI to be effective, the final consumers (people) of the explanations need to be duly considered when designing XAI systems."}, {"heading": "3. Method", "text": "We first describe the intuition behind our rule extraction approach fom an OCSVM model for anomaly detection. Then, we describe in detail the algorithm implementation."}, {"heading": "3.1. Algorithm Intuition", "text": "We propose using rule extraction techniques within OCSVM models for anomaly detection, by generating hypercubes that encapsulate the non-anomalous data points, and using their vertices as rules that explain when a data point is considered non-anomalous. As already mentioned in the introduction, [18] proposes an algorithm to extract rules from a SVM model by performing clustering over the datapoints that belong to one of the classes. The clustered datapoints will be used to obtain a geometric surface that enclose the rest of the datapoints inside. There are two ways to accomplish it: building hypercubes or building hyperspheres. This paper will focus the analysis over the first approach: building hypercubes. For this scenario, the algorithm obtains the furthermost datapoints from inside the cluster that will be used as vertices in a hypercube, so they enclose the rest of datapoints of that category inside. In case that the hypercube generated encloses points from the other category, then the number of clusters will be increased, aiming to obtain smaller cubes that could fit the data without including points from the other class. This is done in iteratively until no points from the other class are inside the hypercubes, or a maximum number of predefined iterations is reached. During the process, if a hypercube does not contain points from the other class, then that hypercube is translated into a rule, and those datapoints are removed from the following iteration steps.\nImages 4 and 5 shows an example application of this algorithm for a 2D space. In image 4 appears the initial scenario,\nwhere the first step in the iteration process consists in applying one cluster over the dataset for datatpoints of one of the classes (blue ones). However, with one cluster, the 2D square that enclose the datapoints contains points from the other class, so more clusters need to be applied. As 5 shows, iteration 3 (with 3 clusters) is the first one with squares without red points, so those subspaces are turned into rules and the points inside them removed from the iteration process, that starts again with one cluster for the remaining datapoints. Iteration 6 will be the last one, and 5 rules have been extracted up to that point.\nThe approximation proposed before is not the only one that can be applied in order to extract the rules. Image 6 shows one of our alternative proposals over [18] method. Instead of removing datapoints that are inside a rule without points from the other class, the process always keeps all datapoints in every iteration since there could be clustering patters that could only be found if all points are together. In this approach, the number of clusters is constantly increased until no datapoints from the other class are inside the hypercubes, or the maximum number of iterations is reached. We will further address this method as \u201dkeep\u201d in the remaining of the paper. In contrast, the references to [18] method will be addressed as \u201dkeep reset\u201d.\nAnother proposal that we include in this paper over [18] is splitting the subspaces in a binary partition scheme. This is an alternative over the original proposal, that constantly\nincreases the number of clusters until one rule has only datapoints from the same class, and then restarting the clustering process from the beginning for the remaining ones. We will address this method as \u201dsplit\u201d for the remaining of the paper. Image 7 shows how the same 2D example using this approach.\nAccording to the taxonomy for XAI in [10], our method has the following characteristics:\n\u2022 Post-hoc: Explainability is achieved using external techniques.\n\u2022 Global and individual: Explanations serve to explain how the whole model works, as well as why a specific data point is considered anomalous or non-anomalous.\n\u2022 Model-agnostic: As with other techniques for global explanations [10], the only information needed to build the explanations are the input features and the outcomes of the system after fitting the model.\n\u2022 Counterfactual: The explanations for why a data point is anomalous also include information on the changes that should take place in the feature values in order to consider that data point as non-anomalous.\nSince the explanation algorithm is model-agnostic, it can work for any blackbox model. The only information needed is the train dataset and the outputs from the model. To illustrate it, this paper will show evaluations over OCSVM models with different kernels: radial basis function (RBF) and linear kernel.\nRegarding the clustering technique itself, potentially any algorithm could be used, both for [18] or for any of out two proposals over it from this paper. However, there is a caveat that should be considered. The clustering algorithm needs to take into account if the features are only numerical, categorical (non ordinal), or both.\nOne algorithm that will be used in this paper for extracting the hypercubes is K-Means ++ [32]. However, this clustering algorithm is designed for numerical features, and categorical ones should be treated differently. In that case, the approximation would be to extract a rule for each of the possible combinations of categorical values among the data points that are not considered anomalous. Considering again the aforementioned 2-dimensional example, with variable X being binary categorical, a dataset may look like in Figure 8:\nIn that case, two rules would be extracted, one for each of the possible states of X:\n\u2022 Rule 1: NOT OUTLIER IF X = 0 \u2227 Y \u2265 Y2 \u2227 Y \u2264 Y1 \u2022 Rule 2: NOT OUTLIER IF X = 1 \u2227 Y \u2265 Y4 \u2227 Y \u2264 Y3\nGenerally speaking, the algorithm logic can be summarised as:\n\u2022 Apply OCSVM to the dataset to create the model. \u2022 Depending on the characteristics of variables, do:\n\u2013 Case 1. Numerical only: Iteratively create clusters in the non-anomalous data (starting with one cluster) and create a hypercube using the centroid and the points further away from it. Check whether the hypercube contains any data point from the anomalous group; if it does, repeat using one more cluster than before. End when no anomalies are contained in the generated hypercubes. If there are anomalies and the data points in a cluster are inferior to the number of vertices needed for\nthe hypercube, complete the missing vertices with artificial datapoints and end when there are no anomalies or when the convergence criterion is reached.\n\u2013 Case 2. Categorical only: The rules will correspond directly to the different value states contained in the dataset of non-anomalous points.\n\u2013 Case 3. Both numerical and categorical. This case would be analogous to Case 1, but data points will be filtered for each of the combinations of the categorical variables states. For each combination, there will be a set of rules for the numerical features.\n\u2022 Use these vertices to obtain the boundaries of that hypercube and directly extract rules from them. Besides K-Means++, there are other clustering algorithms that could be applied. In this paper we will analyse also the rules obtained by applying K-Prototypes [33]. The advantage of using K-Prototypes is that it can work directly with both categorical and numerical features."}, {"heading": "3.2. Algorithm Description", "text": "Algorithm 1 contains the proposal for rule extraction for an OCSVM model that may be applied over a dataset with either categorical or numerical variables (or both). ocsvm rule extract is the main function of the algorithm. Regarding input parameters, X is the input data frame with the features, ln is a list with the numerical columns, lc is a list with the categorical columns, d is a dictionary with the hyperparameters for OCSVM (kernel type, upper bound on the fraction of training errors and a lower bound of the fraction of support vectors, \u03bd, and the kernel coefficient, \u03b3). This function starts with the feature scaling of the numerical features (function featureScaling). After that, it fits an OCSVM model with all the data available and detects the anomalies within it, generating two datasets, Xy with the anomalous data points and Xn with the rest (function filterAnomalies).\nThe next step is checking the type of cluster algorithm, defined in the variable m. If it is K-Prototypes, then all columns are considered together. For this case, the algorithm directly calls getR() function to obtain the rules.This function receives as input a matrix with anomalous and nonanomalous data points, Xy and Xn respectively. It also receives the list of names of those features, l, and the type of approximation for obtaining the hypercubes: \u201dkeep reset\u201d, \u201dkeep\u201d or \u201dsplit\u201d. This is specified with the input variable t.\nIf cluster algorithm is K-Means++, the approach is similar, but first it is checked if the features are numerical, categorical or both. In case of only numerical columns, it directly calls function getR. If all the features are categorical, then the rules for non-anomalous data points will simply be the unique combination of values for them. If there are both categorical and numerical features, the algorithm obtains the hypercubes (as mentioned for numerical features only) for the subset of data points associated to each combination of categorical values.\nFunction getR() simply then calls different subfunctions depending on the t parameter value, but in any of the cases, the approach is similar: cluster non-anomalous data points in a set of hypercubes that do not contain any anomalous\nAlgorithm 1 Main pipeline 1: procedure OCSVM RULE EXTRACT(X, ln, lc, d,m, t) 2: for c \u2208 lc do 3: X[:, c]\u2190 featureScaling(X[:, c]) 4: end for 5: model\u2190 OneClassSVM(d) 6: model.fit(X) 7: preds\u2190 model.train(X) 8: distances\u2190 model.decisionFunction(X) 9: Xy, Xn \u2190 filterAnomalies(X, preds) 10: if m = kprototypes then 11: l\u2190 ln + lc 12: rules\u2190 getR(Xn, Xy, X, l,m, t) 13: else 14: if len(l1) = 0 then 15: rules\u2190 getR(Xn, Xy, X, ln,m, t) 16: else if len(l2) = 0 then 17: rules\u2190 getUnique(Xn, lc) 18: else 19: cat\u2190 getUnique(Xn, lc) 20: rules empty list 21: for c \u2208 cat do 22: Xnf , Xyf \u2190 filterCat(Xn, Xy, c) 23: rules.append(getR(Xnf , Xny, ln,m, t)) 24: end for 25: end if 26: end if 27: rules\u2190 featureUnscaling(rules, ln) 28: rules\u2190 pruneRules(rules, ln, lc) 29: return rules 30: end procedure\ndata points. The \u201dkeep\u201d apporach, described in algorithm 2, iteratively increases the number of clusters (hypercubes) until there are no anomalous points within any hypercube. The function outPosition checks whether the rules defined based on the vertices of the hypercube do not include any data point from the anomalous subset, Xy . getRulesKeep then calls function getVertices (described in algorithm 3) with a specific number of clusters, ncl. This function performs the clustering over the non-anomalous data points, Xn, using the function getClusters that returns the label of the cluster for each data point, as well as the centroid position for each cluster using the specified cluster algorithm. Then, it iterates through each cluster and first obtains the subset of data points for that clusterXnc with the function insideCluster. After that, if there are enough data points in that cluster (more data points than the vertices of the hypercube) it computes the distance of each of them to the centroid with computeDistance and uses the furthest nv as vertices. In case there are less datapoints than the number of vertices that a hypercube of that dimensionality has, then all of them are used limits, and some of the vertices will be collapsed into the same datapoint. This scenario does not stop the iterations, since a hypercube in this situation could still include outliers, needing further splitting. As long as there are no outliers inside the rules, they are stored in rules list. How-\never, as soon as there is one rule with outliers inside, then the whole process is repeated again with one more cluster. This keeps taking place until no outliers are inside the rules or the maximum number of iterations is reached.\nAlgorithm 2 Rule Extraction - Keeping all datapoints 1: procedure GETRULESKEEP(Xn, Xy, nv, ln) 2: max iter reference value 3: check \u2190 True 4: nclusters \u2190 0 5: while check do 6: rules empty list 7: if nclusters > max iter then 8: check \u2190 False 9: else 10: ncl \u2190 ncl + 1 11: vInfo\u2190 getV ertices(Xn, X, nv, ln, ncl) 12: for iterV alue \u2208 vInfo do 13: rulescluster \u2190 iterV alue[0] 14: Xnc \u2190 iterV alue[1] 15: ly \u2190 outPosition(rulescluster, Xy) 16: if len(ly) = 0 then 17: rules.append(rulescluster) 18: check \u2190 False 19: else 20: check \u2190 True 21: end if 22: end for 23: end if 24: end while 25: return rules 26: end procedure\nAlgorithm 3 Additional functions 1: procedure GETVERTICES(Xn, nv, ln, ncl) 2: dbounds empty list 3: dpoints empty list 4: labels, centroids\u2190 getClusters(Xn, ln, ncl) 5: for c \u2208 ncl do 6: Xnc \u2190 insideCluster(labels,Xn) 7: if len(Xnc) > nv then 8: vertices\u2190 computeDist(Xnc, labels[c]) 9: else 10: vertices\u2190 Xn 11: end if 12: dbounds.append(vertices) 13: dpoints.append(Xnc) 14: end for 15: return dbounds, dpoints 16: end procedure\nThe \u201dsplit\u201d approach is defined in algorithm 4. This function has some similarities with 2 with the following differences. Instead increasing the number of clusters in every iteration, ncl is always 2. Also, l sub receives the data after every split. Initially, l sub contains only one dataset, the inliers Xn. However, after another iteration, its value is set\nto the data from the clusters in which the rules did contain some outlier.\nAlgorithm 4 Rule Extraction - Binary partition apporach 1: procedure GETRULESSPLIT(Xn, Xy, nv, ln) 2: max iter reference value 3: check \u2190 True 4: l sub\u2190 [Xn] 5: rules empty list 6: while check do 7: if len(l sub) == 0 or j > max iter then 8: break 9: end if 10: l ori\u2190 l sub 11: l sub\u2190 [] 12: for d in l ori do 13: ncl \u2190 2 14: vInfo\u2190 getV ertices(Xn, X, nv, ln, ncl) 15: for iterV alue \u2208 vInfo do 16: rulescluster \u2190 iterV alue[0] 17: Xnc \u2190 iterV alue[1] 18: ly \u2190 outPosition(rulescluster, Xy) 19: if len(ly) = 0 then 20: rules.append(rulescluster) 21: check \u2190 False 22: else 23: check \u2190 True 24: l sub\u2190 l sub.append(Xnc) 25: end if 26: end for 27: end for 28: end while 29: return rules 30: end procedure\nIn any of the three methods, after obtaining the rules, function featureUnscaling is used to express rules in their original values (not the scaled ones used for the ML models). And function pruneRules checks whether there are rules that may be included inside others; that is, for each rule it checks whether there is another with a bigger scope that will include it as a subset case."}, {"heading": "3.3. Influence of the kernel", "text": "As mentioned before, OCSVM models are configured using mainly three hyperparameters: \u03bd, \u03b3 and the kernel type. Depending on the kernel type, the construction of the decision frontier to differentiate between outliers and inliers changes. In particular, Radial Basis Function (RBF) kernel will find hyperspheres (one or more) that enclose the inliers, leaving outliers outside.\nThe diverse density of outliers versus inliers highlights that there may be differences in the rules depending on which class they enclose. Mainly, since the decision function is a hypersphere, the intuition is that it will be easier to find rules that enclose all those points. Figure 9 illustrates this idea."}, {"heading": "3.4. Algorithms for metrics", "text": "As mentioned before, the metrics considered in this paper are divided into four subsets: comprehensibility, representativeness, stability and diversity. Since, to the best of our knowledge, some of these metrics are not implemented within the main XAI framerworks, we propose within these paper a set of algorithms to compute them in a rule extraction scenario.\n\u2022 Metrics for comprehensibility: Number of rules (n rules), size of the rules (size rules).\n\u2022 Metrics for representativeness: Percentage of datapoints explained with P@1 rules (per p1) and the median percentage coverage of datapoints by each rule (p1 coverage).\n\u2022 Metrics for stability: How many artificial points (similar to a subset of prototypes from the dataset) are classified by the rules within the same class (rule agreement), how many of those new artificial datapoints have the same predictions that the original blackbox model (precision vs model).\n\u2022 Metrics for diversity: Degree of hyperspace overlapping between all the rules (score intersect).\nThe metrics for \u201dcomprehensibility\u201d are directly analyzed from the rules themselves; n rules is computed counting the number of rules generated, and size rules is computed checking the elements that define the rule (p.e. X > 3 AND X < 7 AND Y > 1 have a size rules = 3 while X > 3 have a size rules = 1).\nThe metric per p1 for \u201drepresentativeness\u201d simply checks the percentage of datapoints for the target class explained with P@1 rules. The other metric in this group is p1 coverage. It checks the median performance of the rules themselves: it computes the median percentage of coverage for the target class by each rule.\nThe metrics rule agreement and precision vs model computes the \u201dstability\u201d metrics of the hypercubes. The first step is obtaining the prototypes from the dataset and generate random samples near them. Then, obtain the prediction of the original model for those dummy samples and checks,\nif when the prediction is inlier/outlier, there is at least one rule that includes that datapoint within it. To check the level of agreement between the rules, since the artificial datapoints near the prototypes should belong to the same class, the function checks if the final prediction using all rules is the same for all of them.\nThe steps for these metric are described below, and the detailed pseudocode appears in algorithm 5.\nRule agreement:\n\u2022 Choose N prototypes that represent the original hyperspace of data\n\u2022 Generate M samples close to each of those N prototypes using Protodash algorithm [34]; the hypothesis is that close points should be generally predicted belonging to the same class.\n\u2022 For each of those N*M datapoints (M datapoints per each N prototype) check whether the rules (all of them) predict them as inliner or outlier; the datapoints that come into the function are either outliers or inliers. If they are inliers, then the rules identify an artificial datapoint (of those M*N) as inlier if it is outside every rule. If the datapoints are outliers it\u2019s the same reversed: a datapoint is an inlier if no rule includes it.\n\u2022 Then, it is checked the % of datapoints labeled as the assumed correct class (inliers or outliers), neighbours of that prototype compared to the total neighbours of that prototype.\n\u2022 All the % for each prototype are averaged into one %.\nModel agreement:\n\u2022 The % of predictions for the artificial datapoints aforementioned that are the same between the rules and the original OCSVM model.\nAlgorithm 5 receives the dataset X of inliers/outliers (depending if the rules are computed for inliers or outliers), the rules Xr and the OCSVM fitted and trained model clf . Then obtains the protoypes with ProtodashExplainer() function and generates the random samples Xs near them with randomNear(), where an upper and lower limits (ths, thl) can be defined for how close are those points to the prototypes. Then, it checks which rules enclose that datapoint with checkInR(), and if at least one of them encloses the datapoint, it is considered that it can be classified using the rules. The metric precision vs model is specified in n precision variable, that checks the percentage of agreement between the classifications using the rules and the ones with the model, through checkInModel() function. Finally, rule agreement is included in the variable n agreement, that checks the percentage of predictions, using the rules, that match the category of datapoints used in X (inliers/outliers).\nThe metric to measure \u201ddiversity\u201d is score intersect, and it analyses if the rules are different with few overlapping concepts. This is computed checking the area of the hypercubes of the rules that overlaps with another one. The way to check this is by seeing the 2D planes of each hypercube (by\nAlgorithm 5 Stability 1: procedure GETAGREEMENT(X,Xr, clf ) 2: Xp \u2190 ProtodashExplainer(X) 3: Xs \u2190 [] 4: for p \u2208 Xp do 5: Xs \u2190 Xs.append(randomNear(p, thl, ths)) 6: end for 7: n precision\u2190 0 8: l rules\u2190 [] 9: for d \u2208 Xs do 10: l iter \u2190 [] 11: for r \u2208 Xr do 12: l iter \u2190 l iter.append(checkInR(d, r)) 13: end for 14: r rules\u2190 max(l iter) 15: r model\u2190 checkInModel(d, clf) 16: if r rules = r model then 17: n precision\u2190 n precision+ 1 18: end if 19: l rules\u2190 l rules.append(r rules 20: end for 21: n precision\u2190 n precision/len(Xs) 22: n agreement\u2190 l rules[= 1]/len(Xs) 23: return n precision, n agreement 24: end procedure\nkeeping two degrees of freedom for the features in the hyperplane coordinates; n-2 features are maintained and the other two are changed between their max/min values in order to obtain the vertices of that 2D plane). Then, it is computed the area of the 2D planes for the rules that overlaps, adding for all possible 2D planes the total area overlapped for each rule. In order to compute a score, the features are normalized in order to have values between 0 and 1. The pseudocode for this metric appears in algorithm 6. Algorithm 6 receives the dataset X of inliers/outliers (depending if the rules are computed for inliers or outliers), the rulesXr, the list of columns for numerical features l n and the one for categorical l c. The first step is obtaining all the two tuples combinations of numerical features, using combinations() function. After that, it obtains the combination of categorical values with function unique(), and then normalizes the numerical values with normalize() in order to consider the overlapping of rules equal for all features. The algorithm then analyses separately the rules that belong to each categorical combination values. For each of those subset of rules X r i, if there are at least two rules, then it defines the tuples of possible rule combinations, combR. Then, it iterates per each combination of two numerical features. These two features will correspond to the features that will be changed, leaving the rest of the l fix features fixed, in order to extract 2D planes from the hypercubes, using scorePolys() function, and storing those planes in polys variable.\nImage 10 describes the process for an example in a 3D space. Since all the rules translate into a hypercube, we can choose two features at a time (leaving the rest fixed) and obtain the coordinates for those 2D planes (using their ver-\ntices values). Then, for two rules, we can see the area of overlapping between those 2D hyperplanes. This is repeated for all 2D planes of the hypercubes, computing the mean value of all overlapped planes. Since the features are normalized, all the overlapped areas will have a value between 0 (no overlap) and 1 (total overlap), so the final mean value of all overlaps will be between 1 and 0. In order to express a score value, the final result will be 1\u2212 score i, so a perfect score will be the one corresponding to no overlap between the rules. The algorithm also returns the number of intersections.\nAlgorithm 6 Diversity 1: procedure GETINTERSCORE(X,X r, l n, l c) 2: l free\u2190 combinations(l n, 2) 3: X c\u2190 unique(X[l c]) 4: X[l n] = normalize(X[l n]) 5: score\u2190 [] 6: n inter \u2190 0 7: for cat \u2208 rows(X c) do 8: X r i\u2190 X r[cat] 9: if len(X r i) > 2 then 10: combR\u2190 combinations(X r i, 2) 11: for pairf \u2208 l free do 12: l fix\u2190 l n[! = pairf ] 13: polys\u2190 get2D(combR, l fix, pairf ) 14: score i, n i\u2190 scorePolys(polys) 15: score\u2190 score.appends(1\u2212 score i) 16: n inter \u2190 n inter + n i 17: end for 18: end if 19: end for 20: score\u2190 mean(score) 21: return rules 22: end procedure"}, {"heading": "3.5. From local to global rules", "text": "Anchors [19] is one way of extracting rules for XAI. However, Anchors, as mentioned before, is a local method that explains one datapoint with rules. To be able to use it in the evaluation carried out in this paper, we need to turn Anchors\ninto a global method. A simple way to do that is extracting rules for each datapoint of the input dataset, and prune those rules in order to keep the most relevant ones. This way, the whole dataset is explained, and the results can be compared with the remaining algorithms.\nFrom the computational cost side, since obtaining Anchors rules for each datapoint is costly, we propose using Protodash [34] for scenarios when the dataset is too big. In this case, Protodash will select the relevant prototypes from the dataset, and Anchors will obtain the rules only for those points."}, {"heading": "3.6. Pruning rules", "text": "Many of the rules obtained with all the methods described above are suboptimal, since they can be enclosed into another bigger rule. In order to reduce the number of rules, and remove redundancies, we apply a simple pruning technique prior to the evaluation and computing of metrics. We check every hypercube generated and see if their limits are inside any other rule. If they are, we eliminate that rule from the set of rules. We check this for every rule against every other rule in the dataset, and we keep checking it in a loop until no rules are eliminated."}, {"heading": "3.7. Combining everything", "text": "There is a question that will arise at this point: Which rule would be better? One with better results in \u201dcomprehensibility\u201d, or one with better results at, for instance, \u201dDiversity\u201d? When there is a need to choose a trade-off, which criteria should be prioritized? The answer to this will heavily depend upon the domain needs. However, in general terms, that criteria can be answered by computing the metrics all together with the usage of a function. final metric = f(C,R, S,D) with C representing the comprehensibility metrics, R the representativeness, S the stability and D the diversity. There is another aspect that can be considered while creating a function to encapsulate all metrics. In general, it is better to have a lower value for comprehensibility metrics (less rules, less rule size) since that contributes to an enhancement of comprehensibility. Regarding the rest of the metrics, higher values are better. Thus, a simple way to compute this is adding the results for representativeness, stability and diversity (adjusting their relative importance by a set of weights), and dividing by comprehensibility results. With this, a higher final value will be better. This is expressed in Equation 3.\nC = 1\n\u03b11 \u2217 n rules+ \u03b12 \u2217 size rules R = \u03b21 \u2217 per p1 + \u03b22 \u2217 p1 cov S = \u03b31 \u2217 rule ag + \u03b32 \u2217 p vs m\nD = \u03b8 \u2217 score int final metric = C \u2217 (R+ S +D)\n(3)\nSince the values for the metric of comprehensibility are the only ones that are not in a range o 0 to 1, we normalize them before computing this metric in order to have all values in the same range."}, {"heading": "4. Evaluation", "text": "We use our algorithm over different datasets (both public and from Telefonica\u2019s real data), to evaluate the following hypotheses: \u2022 It is possible to apply post-hoc model-agnostic XAI tech-\nniques for unsupervised outlier detection models that offer both global and local explanations with counterfactual information. This is exemplified analysing rule extraction techniques over OCSVM models.\n\u2022 It is possible to quantify the quality of explanations with XAI metrics that measure \u201dcomprehensibility\u201d, \u201drepresentativeness\u201d, \u201dstability\u201d and \u201ddiversity\u201d in a rule extraction technique scenario. This will be exemplified using the rule extraction algorithms detailed in this paper.\n\u2022 Some rule extraction algorithms for OCSVM models are better suited if the aim are P@1 rules. In particular, [18] and the two modifications introduced in this paper will offer better P@1 rules than other rule extraction techniques. This will be evaluated using both the metrics and algorithms mentioned in the previous point. We will also compute the metrics into one single value, using the Equation 3 with all the weights with a value of 1.\n\u2022 Even if the techniques are model-agnostic (can be applied to any model), there may be differences in the metrics obtained depending on the model hyperparameters. Since OCSVM using RBF kernel tends to group the inliers in one (or many) hyperspheres, the metrics for inlier\u2019s rules may be different than those for outlier\u2019s. In particular, the number of rules for inliers and RBF kernel will be less than the ones obtained.\n\u2022 The same hypotheses from the previous point could be extended for the comparison between linear and RBF kernel. RBF kernel for inliers will yield less rules than the Linear one for inliers. The datasets used belong to different domains, have different sizes and different number of features (both categorical and numerical). They are indicated in Table 1: \u2022 Datasets 1 and 2 about seismic activity [35]. Dataset 1 is\nbi-dimensional with only numerical features (\u2019gdenergy\u2019, \u2019gdpuls\u2019). Dataset 2 has 2 categorical features (\u2019hazard\u2019, \u2019shift\u2019) and 7 numerical (\u2019seismoacoustic\u2019, \u2019shift\u2019, \u2019genergy\u2019, \u2019gplus\u2019, \u2019gdenergy\u2019, \u2019gdpuls\u2019, \u2019hazard\u2019, \u2019bumps\u2019, \u2019bumps2\u2019).\n\u2022 Dataset 3 about cardiovascular diseases [36]. There are 4 categorical features (\u2019smoke\u2019, \u2019alco\u2019, \u2019active\u2019, \u2019is man\u2019) and 7 numerical (\u2019age\u2019, \u2019height\u2019, \u2019weight\u2019, \u2019ap hi\u2019, \u2019ap lo\u2019,\u2019cholesterol\u2019,\u2019gluc\u2019).\n\u2022 Dataset 4 from a call center at Telefo\u0301nica (TEF Comms). It is real data that includes the total number of calls received in one of its services during every hour. Using these data, some features are extracted (weekday), and they are cyclically transformed, so that each time feature turns into two features for the sine and cosine components. The rules in this case are also transformed back into the original features in order to enhance rule comprehension.\n\u2022 Dataset 5 contains Telefo\u0301nica\u2019s data about IoT deviced attached to cars for vehicle tracking. The data is aggregated in daily windows for each vehicle, representing features that model the daily behaviour of that vehicle. It contains 49 numerical features (such as the number of events with high RPM or the maximum temperature of the coolant), and 12 categorical ones (binary variables that indicate the model and make of that car).\n\u2022 Dataset 6 refers to US census for year 1990 [37]. It has 2 categorical features (\u2019dAncstry1 3\u2019, \u2019dAncstry1 4\u2019) and 4 numerical ones (\u2019dAge\u2019, \u2019iYearsch\u2019, \u2019iYearkwrk\u2019, \u2019dYrsserv\u2019).\nWe ran experiments with the following infrastructure: the implementations of the OCSVM algorithm, the K-Means++ clustering and the DT algorithms are based on Scikit-Learn [38]. The rest of the code described in Algorithms 1 and 2 were developed from scratch, and available in Github [39].\nOCSVM models use as hyperparameters: \u03bd = 0.1, \u03b3 = 0.1, kernel = rbf or \u03bd = 0.1, \u03b3 = 0.1, kernel = linear for linear kernel. K-means++ models use max iter = 100, n init = 10, randomState = 0. K-Prototypes uses init =\u2032 Huang\u2032,max iter = 5, n init = 5. DT uses default parameters, with randomState = 42 and Gini criterion to find the best splits. All Protodash applications use kernelType =\u2032 Gaussian\u2032, sigma = 2, with m = 1000 for the samples used in the Anchors rule extraction step, and m = len(rules) for the computation of metrics, having m at least a value of 20. RuleFit uses tree size = len(feature cols) \u2217 2, rfmode =\u2032 classify\u2032 with len(feature cols) the number of features that appear in each dataset. RuleFit also considers only rules with a non zero coefficient, and with an importance > 0. For SkopeRules, since we want only P@1 rules, we use random state = 42, precision min = 1.0, recall min = 0.0. FRL and Anchors use both their default library parameters. BRLG uses lambda0 = 1e \u2212 3, lambda1 = 1e \u2212 3, CNF = False. LOGRR uses lambda0 = 0.005, lambda1 = 0.001, useOrd = True. GRLM uses maxSolverIter = 2000 considering only coefficients with value > 0.\nDataset 1 allows us to visually see the rules obtained using different the different methods. Figure 12 shows the results of applying the proposal of [18], while 11 and 13 shows the results by applying our two alternative methods, using for\nall the cases the same RBF kernel and K-Means++ clustering. To visually see the changes with other methods, Figure 14 shows the rules for inliers obtained with a DT surrogate method, and 15 shows the results using Anchors while considering the restriction of using only P@1 rules. As we can see, the results are quite different. \u201dSplit\u201d and \u201dkeep reset\u201d methods generate rules that cover the whole dataset, though they have overlapping between them. \u201dKeep\u201d method does not have any overlapping, but generates a lot of rules. Anchors does not seem to cover the whole dataset. And DT method generates good rules that do not have any degree of overlapping.\nAs we mentioned before, the analysis will also consider a Linear kernel to show how the rules extraction methods can be applied over any model, as well as seeing if there\nare changes in the metrics used even though the methods are model-agnostic by themselves. As an example, Figures and 17 show the rules extracted using the same Dataset 1 but considering a Linear kernel, and using RuleFit and BRLG methods respectively.\nAs mentioned before, the rules considered are always P@1. This means that rules that are not P@1 are discarded for any of the analyses carried out. As an example, Figure 18 shows rules generated for BRLG, RBF kernel and outliers where some of those rules are not P@1 (they contain datapoints from the other class).\nThe previous Figures shown how if was possible to apply rule extraction techniques over a OCSVM model using a simple 2D dataset in order to be able to visualize the results. Going beyond this, we apply different rule extraction techniques over the datasets mentioned before, which include already existing solutions in the literature, as well as our\nproposed modifications over [18], and over Anchors [19] in order to turn it into a global rule extraction model. We have already seen that these rule extraction techniques are all model-agnostic because we applied them over a OCSVM model regardless of the kernel. However, we are going to keep these two kernel configurations for the next analysis in order to see potential differences in the metrics obtained.\nThus, for the following analysis (measurement of comprehensibility\u201d, \u201drepresentativeness\u201d, \u201dstability\u201d and \u201ddiversity\u201d), we are going to use the rule extraction algorithms described in the literature, as well as that kernel configuration of OCSVM (RBF or linear) over the 6 datasets mentioned before. Two caveats to take into account is that K-Prototypes clustering can only be use for the datasets that have categorical features (all expect datasets 1 and 4), and that we we are only going to use RBF kernel for the dataset 6.\nThe results for the clustering-based methods can be seen in Table 6, and for the remaining methods in Table 7. Those tables present the median aggregated value for each of the metrics aforementioned among the different datasets involved. We also include the results per dataset for Anchors modification in Table 8.\nThe first thing that can be seen is that clustering-based methods always yield P@1 rules regardless of the kernel type, the clustering technique used, or the algorithm alternative. This is an important aspect, specially compared to methods such as brlg, logrr or FRL that are not able to generate P@1 rules for some situations. This is also true for Anchors, RuleFit, DT and SkopeRules.\nRegarding comprehensibility (n rules and size rules), for\ninliers and linear kernel, using K-Means clustering always yield more rules than using any of the other rule extraction methods, regardless of the algorithm used out of the three proposals. The number of rules obtained is mostly equivalent for the three clustering-based algorithm proposed. The same is applicable to linear kernel and outliers datapoints: more rules using clustering-based methods with K-Means than using the other methods, with a stable number of rules. Exactly the same can be said about the size of rules for this configurations. Analysing the results with RBF kernel, we can see that the number of rules obtained are higher than using linear one, and then, even higher also than with the other methods (though the rule size is similar regardless of the kernel). Thus, considering only the comprehensibility area, clustering-based methods generally yield rules with a similar rule size than the remaining methods, and regarding the number of rules, it slightly increases for RBF kernel, and increases more for K-Prototypes than for K-Means if the method used is split.\nFor per p1, first, we can see that split and keep reset methods yield constantly better results than keep method, regardless of the kernel, clustering method or if it is inliers or outliers. If the datapoints are inliers, the metric is similar for both split or keep reset. However, if it is for outliers, split seems to offer better results. Regarding p1 cov, K-Means offer better results than K-Prototypes in general. The keep reset method generates rules with better coverage, generally speaking, than the other cluster-based methods. The per p1 value for the remaining methods is similar for DT and RuleFit if the kernel is linear and for inliers and outliers. However, when using RBF kernel, the results fall for every other method except for RuleFit. The coverage of RuleFit rules is on pair with the clustering-based methods. It is worth noticing that one of the best coverages is obtained with Anchors when using a linear kernel and for outliers. This highlights that the rules extracted with this method are able to cover a huge amount of the hyperspace.\nFor all the methods that yield P@1 rules, the rule agreement seem to be on pair, offering similar results. Regarding the precision versus the original model, for the clusteringbased methods, K-Means offer more better results than KPrototypes. However, for inliers, the results are quite similar, with the exception of RBF kernel, where K-Prototypes and split outperforms every other combination. Comparing the three algorithm proposals, both split and keep reset offer stable similar results, while keep drops in some of the scenarios. The precision versus model is clearly better than with the other rule extraction algorithm: clustering-based methods approximate better the decision frontier of the underlying model.\nIn this area, clustering-based methods are clearly outperformed by the other rule extraction techniques, though it is logical. Clustering-based methods yield more rules, and that may lead to more overlapping, and then less score in this metric. Regarding only the clustering-based methods, the results are quite similar for all of them. It is worth noticing how SkopeRules yields many perfect scores (no overlapping at all).\nThe aggregated metrics results into one single value ap-\npear at Table 9 for clustering-based methods, and in Table 10 for the remaining ones. This final metric is computed by obtaining it first for each dataset and then compute the median value among all the individual metrics per dataset. In order to penalize the algorithms that do not yield P@1 rules for some datasets, we consider a final metric of 0 for those cases, and thus, it will lower the final result. In the results we can see how, for clustering algorithms and using K-Means, the results are always above 7 points, regardless of the kernel or type of points considered. The highest values obtained are with keep reset method. In contrast, K-Prototypes tend to yield lower values than using our proposal with K-Means. The Krusal-Wallis Test included in Table 12 shows how the original [18] method does not seem to yield significantly different results than the ones obtained by our alternatives over it.\nRegarding the other rule extraction algorithms, we see how none of them yields better results than clustering ones for inliers and rbf, with the exception of DT that gives similar results. The best results obtained, which are for Anchors, RuleFit and FRL, are obtained for outliers. SkopeRules, while yielding lower results, have also better metrics for outliers than inliers. This may indicate how these rule extraction algorithms work better for sparse datapoints (outliers) while for inliers, the algorithms that give better results are the clustering ones. There is one caveat to take into account: while offering consistent results (and generally better for inliers), clustering-based techniques generate more rules than the other methods, as shown in those Tables mentioned before.\nRegarding the influence of the kernel in order to see if the rule extraction algorithms are indeed model-agnostic or if there are significant differences in the final metric, we apply again a Kuskal-Wallis Test to see significant differences in the median value obtained from the metrics calculated for each dataset. As Table 11 shows, the p-value is always above the threshold (both for 0.05 or 0.1), and thus, we cannot affirm that there are significant differences. This indicates how all the methods appear to be model-agnostic.\nThe next hypothesis checked is if the kernel used affects the number of rules generated, since a RBF kernel groups the inlier datapoints inside hypershperes. We will analyse these by comparing the P@1 rules extracted for each dataset for outliers with RBF kernel, inliers with a linear kernel, and inliers with RBF kernel, in order to see if this last configuration yield less number of rules. We are going to use for this part only the clustering-based methods since they were the ones that yielded more consistent P@1 rules. The results can be seen in Table 2 for k-means clustering and in 3 for K-Prototypes clustering.\nFor K-Means clustering and split method, out of the 6 datasets, we see slight differences in the number of P@1 rules. Kruskal-Wallis Test was conducted to examine the differences on the number of rules obtained comparing the rbf and inliers scenario against linear and inliers or rbf and outliers. This is shown in Tables 4 and 5. No significant differences are found for any of the clustering methods. Thus, we don\u2019t see significant differences between those cases.\nUsing K-Prototypes does not change much the results\nover K-Means. The main difference is that K-Prototypes have more combinations of scenarios where there are no P@1 rules. In neither split, nor keep, nor keep reset, the number of rules for inliers and RBF kernel is steadily lower than the ones with the other configurations. This is reinforced with the results of the Kruskal-Wallis Test."}, {"heading": "4.1. Software Used", "text": "The main libraries used for the work done in this paper are the following: \u2022 OCSVM, DT [40] \u2022 Anchors [41] \u2022 Protodash, GRLM, BRLG [24] \u2022 RuleFit [42] \u2022 SkopeRules [43] \u2022 FRL [44]\nAs we mentioned before, we also provide a library with all the developed algorithms [39]."}, {"heading": "4.2. Limitations of our Approach", "text": "Regarding the XAI metrics and evaluations, the first limitation to consider is that the only model used is OCSVM (with two types of kernel). Even though the algorithms used and the metric definitions are model-agnostic and may be potentially applied over other outlier detection models, the results may differ if other unsupervised models or kernels are used. Together with this, our suggestion of a function that aggregates every metric is a simple baseline that can be further improved.\nAlso, the analyses carried out are focused in P@1 rules. Thus, the conclusions may be different if all the rules extracted are used, regardless of their precision value.\nFinally, all the rules (for cluster-based methods) and all the checking to see if a data point is inside a hypercube (for all methods) are defined with inequalities (\u2264, \u2265). Because of that, the results may be different if we allow values from the other class to be at the limit of the hypercube."}, {"heading": "5. Conclusion", "text": "In this paper we have analysed the application of XAI techniques over unsupervised outlier detection models through the usage of rule extraction methods applied to OCSVM models. Among the rule extraction techniques, we used both algorithms from the literature, as well as new alternatives that we propose and evaluate together with them. Our first aim was analysing the quality of the rules extracted from a XAI perspective. We have done this by defining metrics for different aspects related to XAI: comprehensiviliy, representativeness, stability and diversity, as well as proposing a function to aggregate all those metrics together. We evaluated those metrics over different datasets, both from public sources as well as from Telefo\u0301nica\u2019s, using communications and IoT generated data for that purpose. The results for the metrics show how from among the rule extraction techniques considered, clustering-based techniques yield results with less variation than other algorithms in a context\nof P@1 rules, at the expense of generating more rules than those obtained with those other methods. Related to those clustering-based techniques, we saw how one of our algorithm proposals yield similar results than the ones obtained with the baseline algorithm from the literature.\nOur evaluation considered model-agnostic techniques that can be applied over any black-box model. In order to check this empirically, we have used OCSVM models with different types of kernel configurations (linear and RBF). We saw how, indeed, all rule extraction techniques provide similar results regardless of the kernel used.\nWe also analysed if the number of rules extracted for inliers and using a RBF kernel are significantly lower than those for outliers or those obtained with other kernels such as a linear one, since a RBF kernel in a OCSVM model tends to group all the points inside a hypersphere. This analysis was also focused for P@1 rules. In this regard, we were not able to see any significant differences in the number of rules extracted with any of the kernel configurations."}, {"heading": "5.1. Future Work", "text": "There are several research lines that can be pursued following the work presented at this paper. The first one to consider is benchmarking these results against other rule extraction techniques not covered in this paper. An example is G-Rex algorithms [45]. Another research line that can be followed is analysing the metrics of the rule extraction techniques over other unsupervised anomaly detection models, such as IsolationForests [14] or LOF [15], as well as using other kernel configurations in OCSVM (such as a polinomial one). Also, while we have proposed a vanilla function to incorporate the metrics belonging to different XAI areas, there is much room of improvement over it in order to find an optimal function that weights appropriately every term. Finally, rule extraction should also be designed to consider all types of comparisons (\u2265, \u2264, > and <), and this is something that could also be considered in the cluster-based methods developed."}], "title": "Rule Extraction in Unsupervised Anomaly Detection for Model Explainability: Application to OneClass SVM", "year": 2020}