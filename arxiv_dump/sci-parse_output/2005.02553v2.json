{
  "abstractText": "Interpretability of learning-to-rank models is a crucial yet relatively under-examined research area. Recent progress on interpretable ranking models largely focuses on generating post-hoc explanations for existing black-box ranking models, whereas the alternative option of building an intrinsically interpretable ranking model with transparent and self-explainable structure remains unexplored. Developing fully-understandable ranking models is necessary in some scenarios (e.g., due to legal or policy constraints) where post-hoc methods cannot provide sufficiently accurate explanations [48]. In this paper, we lay the groundwork for intrinsically interpretable learning-to-rank by introducing generalized additive models (GAMs) into ranking tasks. Generalized additive models (GAMs) are intrinsically interpretable machine learning models and have been extensively studied on regression and classification tasks. We study how to extend GAMs into ranking models which can handle both item-level and list-level features and propose a novel formulation of ranking GAMs. To instantiate ranking GAMs, we employ neural networks instead of traditional splines or regression trees. We also show that our neural ranking GAMs can be distilled into a set of simple and compact piece-wise linear functions that are much more efficient to evaluate with little accuracy loss. We conduct experiments on three data sets and show that our proposed neural ranking GAMs can achieve significantly better performance than other traditional GAM baselines while maintaining similar interpretability.",
  "authors": [
    {
      "affiliations": [],
      "name": "Honglei Zhuang"
    },
    {
      "affiliations": [],
      "name": "Xuanhui Wang"
    },
    {
      "affiliations": [],
      "name": "Michael Bendersky"
    },
    {
      "affiliations": [],
      "name": "Alexander Grushetsky"
    },
    {
      "affiliations": [],
      "name": "Yonghui Wu"
    },
    {
      "affiliations": [],
      "name": "Petr Mitrichev"
    },
    {
      "affiliations": [],
      "name": "Ethan Sterling"
    },
    {
      "affiliations": [],
      "name": "Nathan Bell"
    },
    {
      "affiliations": [],
      "name": "Walker Ravina"
    },
    {
      "affiliations": [],
      "name": "Hai Qian"
    }
  ],
  "id": "SP:115b19ff93896f1dab4dc1d3a263ba351fcbe520",
  "references": [
    {
      "authors": [
        "Daniel Berg"
      ],
      "title": "Bankruptcy prediction by generalized additive models",
      "venue": "Applied Stochastic Models in Business and Industry 23,",
      "year": 2007
    },
    {
      "authors": [
        "Harald Binder",
        "Gerhard Tutz"
      ],
      "title": "A comparison of methods for the fitting of generalized additive models",
      "venue": "Statistics and Computing 18,",
      "year": 2008
    },
    {
      "authors": [
        "Sebastian Bruch",
        "Masrour Zoghi",
        "Mike Bendersky",
        "Marc Najork"
      ],
      "title": "Revisiting Approximate Metric Optimization in the Age of Deep Neural Networks",
      "year": 2019
    },
    {
      "authors": [
        "Chris Burges",
        "Tal Shaked",
        "Erin Renshaw",
        "Ari Lazier",
        "Matt Deeds",
        "Nicole Hamilton",
        "Greg Hullender"
      ],
      "title": "Learning to rank using gradient descent",
      "year": 2005
    },
    {
      "authors": [
        "Christopher Burges",
        "Krysta Svore",
        "Paul Bennett",
        "Andrzej Pastusiak",
        "Qiang Wu"
      ],
      "title": "Learning to rank using an ensemble of lambda-gradient models",
      "venue": "In Proceedings of the learning to rank Challenge",
      "year": 2011
    },
    {
      "authors": [
        "Christopher J.C. Burges"
      ],
      "title": "From RankNet to LambdaRank to LambdaMART: An Overview",
      "venue": "Technical Report Technical Report MSR-TR-2010-82. Microsoft Research",
      "year": 2010
    },
    {
      "authors": [
        "Christopher J Burges",
        "Robert Ragno",
        "Quoc V Le"
      ],
      "title": "Learning to rank with nonsmooth cost functions",
      "venue": "In NeurIPS",
      "year": 2007
    },
    {
      "authors": [
        "Rich Caruana",
        "Yin Lou",
        "Johannes Gehrke",
        "Paul Koch",
        "Marc Sturm",
        "Noemie Elhadad"
      ],
      "title": "Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission",
      "year": 2015
    },
    {
      "authors": [
        "Olivier Chapelle",
        "Yi Chang"
      ],
      "title": "Yahoo! learning to rank challenge overview",
      "venue": "In Proceedings of the learning to rank challenge",
      "year": 2011
    },
    {
      "authors": [
        "Chong Chen",
        "Min Zhang",
        "Yiqun Liu",
        "Shaoping Ma"
      ],
      "title": "Neural attentional rating regression with review-level explanations",
      "year": 2018
    },
    {
      "authors": [
        "Alexandra Chouldechova",
        "Trevor Hastie"
      ],
      "title": "Generalized additive model selection",
      "venue": "arXiv preprint arXiv:1506.03850",
      "year": 2015
    },
    {
      "authors": [
        "Alexandra Chouldechova",
        "Aaron Roth"
      ],
      "title": "The Frontiers of Fairness in Machine Learning",
      "year": 2018
    },
    {
      "authors": [
        "J Shane Culpepper",
        "Fernando Diaz",
        "Mark D Smucker"
      ],
      "title": "Research frontiers in information retrieval: Report from the third strategic workshop on information retrieval in lorne (swirl 2018)",
      "venue": "In ACM SIGIR Forum,",
      "year": 2018
    },
    {
      "authors": [
        "Finale Doshi-Velez",
        "Been Kim"
      ],
      "title": "Towards a rigorous science of interpretable machine learning",
      "venue": "arXiv preprint arXiv:1702.08608",
      "year": 2017
    },
    {
      "authors": [
        "Mengnan Du",
        "Ninghao Liu",
        "Xia Hu"
      ],
      "title": "Techniques for interpretable machine learning",
      "venue": "Commun. ACM 63,",
      "year": 2019
    },
    {
      "authors": [
        "John Duchi",
        "Elad Hazan",
        "Yoram Singer"
      ],
      "title": "Adaptive subgradient methods for online learning and stochastic optimization",
      "venue": "Journal of Machine Learning Research 12,",
      "year": 2011
    },
    {
      "authors": [
        "Jerome H Friedman"
      ],
      "title": "Greedy function approximation: a gradient boosting machine",
      "venue": "Annals of statistics",
      "year": 2001
    },
    {
      "authors": [
        "Leilani H Gilpin",
        "David Bau",
        "Ben Z Yuan",
        "Ayesha Bajwa",
        "Michael Specter",
        "Lalana Kagal"
      ],
      "title": "Explaining explanations: An approach to evaluating interpretability of machine learning",
      "year": 2018
    },
    {
      "authors": [
        "Geoffrey Hinton",
        "Oriol Vinyals",
        "Jeff Dean"
      ],
      "title": "Distilling the Knowledge in a Neural Network",
      "year": 2015
    },
    {
      "authors": [
        "Giles Hooker"
      ],
      "title": "Discovering additive structure in black box functions",
      "venue": "In KDD",
      "year": 2004
    },
    {
      "authors": [
        "Giles Hooker"
      ],
      "title": "Generalized functional anova diagnostics for highdimensional functions of dependent variables",
      "venue": "Journal of Computational and Graphical Statistics 16,",
      "year": 2007
    },
    {
      "authors": [
        "Kalervo J\u00e4rvelin",
        "Jaana Kek\u00e4l\u00e4inen"
      ],
      "title": "Cumulated gain-based evaluation of IR techniques",
      "venue": "ACM Transactions on Information Systems (TOIS) 20,",
      "year": 2002
    },
    {
      "authors": [
        "Alexandros Karatzoglou",
        "Linas Baltrunas",
        "Yue Shi"
      ],
      "title": "Learning to rank for recommender systems",
      "venue": "In RecSys",
      "year": 2013
    },
    {
      "authors": [
        "Guolin Ke",
        "Qi Meng",
        "Thomas Finley",
        "Taifeng Wang",
        "Wei Chen",
        "Weidong Ma",
        "Qiwei Ye",
        "Tie-Yan Liu"
      ],
      "title": "LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In NeurIPS",
      "year": 2017
    },
    {
      "authors": [
        "Juhi Kulshrestha",
        "Motahhare Eslami",
        "Johnnatan Messias",
        "Muhammad Bilal Zafar",
        "Saptarshi Ghosh",
        "Krishna P Gummadi",
        "Karrie Karahalios"
      ],
      "title": "Search bias quantification: investigating political bias in social media and web search",
      "venue": "Information Retrieval Journal 22,",
      "year": 2019
    },
    {
      "authors": [
        "Yi Lin",
        "Hao Helen Zhang"
      ],
      "title": "Component selection and smoothing in multivariate nonparametric regression",
      "venue": "The Annals of Statistics 34,",
      "year": 2006
    },
    {
      "authors": [
        "Tie-Yan Liu"
      ],
      "title": "Learning to Rank for Information Retrieval",
      "year": 2009
    },
    {
      "authors": [
        "Yin Lou",
        "Jacob Bien",
        "Rich Caruana",
        "Johannes Gehrke"
      ],
      "title": "Sparse partially linear additive models",
      "venue": "Journal of Computational and Graphical Statistics 25,",
      "year": 2016
    },
    {
      "authors": [
        "Yin Lou",
        "Rich Caruana",
        "Johannes Gehrke"
      ],
      "title": "Intelligible models for classification and regression",
      "year": 2012
    },
    {
      "authors": [
        "Yin Lou",
        "Rich Caruana",
        "Johannes Gehrke",
        "Giles Hooker"
      ],
      "title": "Accurate intelligible models with pairwise interactions",
      "year": 2013
    },
    {
      "authors": [
        "Scott M Lundberg",
        "Su-In Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "NeurIPS",
      "year": 2017
    },
    {
      "authors": [
        "Craig Macdonald",
        "Rodrygo LT Santos",
        "Iadh Ounis"
      ],
      "title": "The whens and hows of learning to rank for web search",
      "venue": "Information Retrieval 16,",
      "year": 2013
    },
    {
      "authors": [
        "Lukas Meier",
        "Sara Van de Geer",
        "Peter B\u00fchlmann"
      ],
      "title": "High-dimensional additive modeling",
      "venue": "The Annals of Statistics 37,",
      "year": 2009
    },
    {
      "authors": [
        "Vito Muggeo"
      ],
      "title": "Estimating Regression Models with Unknown Break-Points. Statistics in medicine",
      "year": 2003
    },
    {
      "authors": [
        "Vito Muggeo"
      ],
      "title": "Segmented: An R Package to Fit Regression Models With Broken-Line Relationships",
      "venue": "R News",
      "year": 2008
    },
    {
      "authors": [
        "Vinod Nair",
        "Geoffrey E Hinton"
      ],
      "title": "Rectified linear units improve restricted boltzmann machines",
      "year": 2010
    },
    {
      "authors": [
        "Ziad Obermeyer",
        "Brian Powers",
        "Christine Vogeli",
        "Sendhil Mullainathan"
      ],
      "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
      "venue": "Science",
      "year": 2019
    },
    {
      "authors": [
        "Rama Kumar Pasumarthi",
        "Sebastian Bruch",
        "Xuanhui Wang",
        "Cheng Li",
        "Michael Bendersky",
        "Marc Najork",
        "Jan Pfeifer",
        "Nadav Golbandi",
        "Rohan Anil",
        "Stephan Wolf"
      ],
      "title": "TF-Ranking: Scalable tensorflow library for learning-to-rank",
      "year": 2019
    },
    {
      "authors": [
        "Ashley Petersen",
        "Daniela Witten"
      ],
      "title": "Data-adaptive additive modeling",
      "venue": "Statistics in medicine 38,",
      "year": 2019
    },
    {
      "authors": [
        "Forough Poursabzi-Sangdeh",
        "Daniel G Goldstein",
        "Jake M Hofman",
        "Jennifer Wortman Vaughan",
        "Hanna Wallach"
      ],
      "title": "Manipulating and measuring model interpretability",
      "year": 2018
    },
    {
      "authors": [
        "Tao Qin",
        "Tie-Yan Liu"
      ],
      "title": "Introducing LETOR 4.0 Datasets",
      "venue": "CoRR abs/1306.2597",
      "year": 2013
    },
    {
      "authors": [
        "Tao Qin",
        "Tie-Yan Liu",
        "Hang Li"
      ],
      "title": "A general approximation framework for direct optimization of information retrieval measures",
      "venue": "Information retrieval 13,",
      "year": 2010
    },
    {
      "authors": [
        "Pradeep Ravikumar",
        "John Lafferty",
        "Han Liu",
        "Larry Wasserman"
      ],
      "title": "Sparse additive models",
      "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology) 71,",
      "year": 2009
    },
    {
      "authors": [
        "Dani\u00ebl Rennings",
        "FelipeMoraes",
        "Claudia Hauff"
      ],
      "title": "AnAxiomatic Approach to Diagnosing Neural IR Models. In ECIR",
      "year": 2019
    },
    {
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "title": "Why should i trust you?: Explaining the predictions of any classifier",
      "year": 2016
    },
    {
      "authors": [
        "Cynthia Rudin"
      ],
      "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
      "venue": "Nature Machine Intelligence",
      "year": 2019
    },
    {
      "authors": [
        "David Sculley",
        "Gary Holt",
        "Daniel Golovin",
        "Eugene Davydov",
        "Todd Phillips",
        "Dietmar Ebner",
        "Vinay Chaudhary",
        "Michael Young",
        "Jean-Francois Crespo",
        "Dan Dennison"
      ],
      "title": "Hidden technical debt in machine learning systems",
      "venue": "In Advances in neural information processing systems",
      "year": 2015
    },
    {
      "authors": [
        "Avanti Shrikumar",
        "Peyton Greenside",
        "Anshul Kundaje"
      ],
      "title": "Learning important features through propagating activation differences",
      "year": 2017
    },
    {
      "authors": [
        "Jaspreet Singh",
        "Avishek Anand"
      ],
      "title": "Posthoc interpretability of learning to rank models using secondary training data",
      "venue": "In SIGIR Workshop on Explainable Recommendation and Search",
      "year": 2018
    },
    {
      "authors": [
        "Jaspreet Singh",
        "Avishek Anand"
      ],
      "title": "EXS: Explainable Search Using Local Model Agnostic Interpretability",
      "venue": "In WSDM",
      "year": 2019
    },
    {
      "authors": [
        "Mukund Sundararajan",
        "Ankur Taly",
        "Qiqi Yan"
      ],
      "title": "Axiomatic attribution for deep networks",
      "venue": "In ICML",
      "year": 2017
    },
    {
      "authors": [
        "Manisha Verma andDebasis Ganguly"
      ],
      "title": "LIRME: Locally Interpretable Ranking Model Explanation",
      "venue": "In SIGIR",
      "year": 2019
    },
    {
      "authors": [
        "Mike Wu",
        "Michael C Hughes",
        "Sonali Parbhoo",
        "Maurizio Zazzi",
        "Volker Roth",
        "Finale Doshi-Velez"
      ],
      "title": "Beyond sparsity: Tree regularization of deep models for interpretability",
      "year": 2018
    },
    {
      "authors": [
        "Xuezhou Zhang",
        "Sarah Tan",
        "Paul Koch",
        "Yin Lou",
        "Urszula Chajewska",
        "Rich Caruana"
      ],
      "title": "Axiomatic Interpretability for Multiclass Additive Models",
      "year": 2019
    },
    {
      "authors": [
        "Yongfeng Zhang",
        "Jiaxin Mao",
        "Qingyao Ai"
      ],
      "title": "WWW Tutorial on Explainable Recommendation and Search",
      "year": 2019
    }
  ],
  "sections": [
    {
      "text": "In this paper, we lay the groundwork for intrinsically interpretable learning-to-rank by introducing generalized additive models (GAMs) into ranking tasks. Generalized additive models (GAMs) are intrinsically interpretable machine learning models and have been extensively studied on regression and classification tasks. We study how to extend GAMs into ranking models which can handle both item-level and list-level features and propose a novel formulation of ranking GAMs. To instantiate ranking GAMs, we employ neural networks instead of traditional splines or regression trees. We also show that our neural ranking GAMs can be distilled into a set of simple and compact piece-wise linear functions that are much more efficient to evaluate with little accuracy loss. We conduct experiments on three data sets and show that our proposed neural ranking GAMs can achieve significantly better performance than other traditional GAM baselines while maintaining similar interpretability.\nKEYWORDS Generalized additive models; learning to rank; interpretable ranking models"
    },
    {
      "heading": "1 INTRODUCTION",
      "text": "Learning-to-rank (LTR) [28] has been extensively studied [4, 6, 7, 17, 25, 40] with broad applications in various fields [24, 33]. While many studies focus on building more accurate ranking models, few pay attention to the model interpretability. The lack of interpretability can lead to many issues in practice, such as difficult troubleshooting, opacity to potential social bias [26], vulnerability to feature corruption, and high maintenance costs [49]. The latest SWIRL workshop report [13] lists model transparency as one of the key issues that the IR community should focus on in the following years. Hence, there is an emerging need to develop more transparent and interpretable learning-to-rank models.\nThere are roughly two categories of techniques to achieve model interpretability [15]: one aims to build intrinsically interpretable models where the model structure per se is understandable; the other aims to generate post-hoc explanations of an existing blackbox model. In the specific application of learning-to-rank, there are\nHotel A\nHotel C Hotel B\nHotel D\nItems: Query: \u201chotel\u201d\nContext:\nUser Device =\nRelevance\nPrice\nDistance\n0.4 0.2\n0.3 0.2\n0.3 0.6\nSu b-\nsc or\ne\n!\"\n!#\n!$\n%\" !\"\n%# !#\n%$ !$\nSu b-\nsc or e Su bsc or e\n\u2211\n'\" '# '$\nHotel A\nHotel D\nHotel B\nHotel C\n%\"\n%#\n%$\nGeneralized Additive Model Output:Input: (items, context) Item ranking\nFigure 1: An example of a ranking GAM for local search. For each input feature x j (e.g. price, distance), a sub-model produces a sub-score fj (x j ). Context features (e.g. user device type) can be utilized to derive importance weights of submodels. The ranking score of each item is a weighted sum of sub-scores. The output is a ranked list of items sorted by their ranking scores.\na few recent studies [46, 51, 52, 54] focusing on generating post-hoc explanations for existing models, whereas intrinsically interpretable learning-to-rank models remain relatively unexplored1.\nAlthough the post-hoc explanations are valuable and insightful for some applications, they can also suffer from being inaccurate about actual model behaviors, insufficient to understand model details or unable to incorporate information outside of the database, as pointed out in a recent study [48]. Hence, it is necessary to develop an intrinsically interpretable LTR model as an alternative for scenarios where ranking models need to be fully understandable by a human observer.\nFor example, consider the cases where a ranking system is involved in determining bail or parole, deployment of police in city neighborhoods, loan eligibility assessment, advertisement targeting, or guiding medical treatement decisions \u2013 all of which are highly\n1Tree-based models [6, 17, 25] are often considered more interpretable than neural models. However, the state-of-the-art implementations of tree-based models, like LambdaMART, often involve thousands of deep and wide trees, tree ensembles and bagging [5], making them virtually impossible to interpret by humans.\nar X\niv :2\n00 5.\n02 55\n3v 2\n[ cs\n.I R\n] 1\n4 M\nay 2\n02 0\nplausible scenarios today [12, 34, 39]. In such high-stakes decisionmaking scenarios, researchers are morally (and often legally) obligated to develop and deploy interpretable models. The contribution of each individual feature in these models should be examinable and understandable, to ensure transparency, accountability and fairness of the outcomes.\nGeneralized additive models (GAMs) [19] provide a promising option to build such intrinsically interpretable models and have been used in many domains like finance [1] and health [8, 56]. The output of a GAM is the sum of the outputs of multiple sub-models, where each sub-model only takes an individual feature as input. A GAM has a higher model capacity than a linear model as submodels can be more flexible than linear functions, while staying intelligible comparing with a black-box model. Each sub-model of a GAM precisely reflects the contribution of each input feature to the final output results. Previous studies [30, 56] primarily applied GAMs to regression or classification. However, to the best of our knowledge, how to build GAMs for learning-to-rank tasks has not been well-studied.\nA learning-to-rank task has different input and objective from classification or regression. The goal is to rank a list of items given some context. Hence, there would be both item-level features and list-level context features available. In Figure 1, we show an example of local search. Based on a user query \u201chotel\u201d, a set of item-level features x j \u2019s are computed (e.g. relevance score and distance) for each item (hotel). In addition, there could be list-level context features (e.g. user device type). A ranking GAM should not only inherit the intelligibility of GAMs, but can also take the context features into account. As presented in Figure 1, the ranking GAM consists of several isolated sub-models, where each sub-model only takes a single item-level feature x j as input and outputs a corresponding sub-score fj (x j ). In addition, the context features are used to derive importance weights for item-level sub-scores before they are summed up as the final ranking score. This ensures that not only the contribution of each item-level feature is interpretable, but also the contributions of the context features, which is crucial in the high-stakes decision-making scenarios.\nThere aremultiple challenges to adapt existing GAMs for ranking tasks. As we will show later, directly projecting the context features from list-level to item-level is not effective for ranking tasks. How to leverage context features (e.g. user device type) in a ranking GAM is not clear. Moreover, traditional GAMs are only trained with loss functions for regression or classification tasks. It is unclear how effective such models can be trained with ranking losses.\nTo overcome these challenges, we propose a novel neural GAM model for learning-to-rank tasks. In such a model, we employ standalone neural networks to instantiate sub-models for each individual feature. The flexibility of neural network framework enables us to implement the ranking GAM structure which incorporates list-level context features and optimize the model with ranking losses. The model can also seamlessly handle both numerical and non-numerical features.\nIn summary, we make the following contributions in this paper:\n\u2022 We formally define the structure of ranking GAMs in both the context-absent and context-present scenarios.\n\u2022 We propose to instantiate ranking GAMs by neural networks using a novel neural architecture that can leverage context features effectively and can be trained with ranking losses. \u2022 We develop a novel technique to distill each sub-model of a ranking GAM into a simple piece-wise linear function. \u2022 We evaluate our proposed neural ranking GAMs on three learning-to-rank data sets and show the effectiveness."
    },
    {
      "heading": "2 RELATEDWORK",
      "text": "Interpretable learning-to-rank. Model interpretability [57] becomes a popular research topic in recent years [10, 32, 47, 50, 53, 55]. Current studies on interpretable learning-to-rank mainly focus on generating interpretation for an existing black-box model. Singh et al. [52] describe a system to quantify and visualize the effect of each term on a certain decision of a given ranking model, such as why a document is ranked higher than another. They also attempt to distill a given ranking model with a subset of interpretable features in [51]. Verma et al. [54] also study a similar problem to quantify the contribution of terms in a specific document ranking generated by a given ranking model. Rennings et al. [46] propose a diagnostic data set based on a set of axioms to identify potential shortcomings in an existing IR system. However, there are few studies specifically designed to build \u201cintrinsically\u201d interpretable ranking models where each component of the model is understandable. Generalized additive model. Proposed by Hastie et al. [19], generalized additive models (GAMs) provide a class of models which are more flexible than linear models, yet remain more interpretable than complicated models such as deep neural networks. Binder et al. [2] provide a thorough study on fitting GAMs with regression splines. Lou et al. [30] also compare GAMs with different function instantiations. They extend the comparing methods to include regression trees and conduct experiments on both classification and regression tasks. Their studies shows that shallow bagged trees perform better comparing to other functions such as splines. Zhang et al. [56] further studies to train GAMs specifically for multi-class classification tasks.\nTo obtain more accurate models, higher-order feature interactions were introduced to the additive models. Lou et al. [31] propose an efficient algorithm to identify feature pairs with interactions. A series of studies by Hooker [21, 22] also aim to discover additive structure with higher-order feature interactions. Meanwhile, some other studies tackle the problem in high-dimensional data where the number of features is huge. Others aim to reduce the number of features utilized in the model [27, 35, 41, 45] by imposing sparsity penalty. Lou et al. [29] introduce to partially replace the non-linear function of some features by linear function to reduce the model complexity. They provide an algorithm to automatically select which features should use linear functions and which should use non-linear functions. Chouldechova et al. [11] also explore similar ideas. However, to the best of our knowledge, none of these studies focus on applying GAMs to learning-to-rank problems."
    },
    {
      "heading": "3 PROBLEM FORMULATION",
      "text": "In this section, we start by defining notations for a learning-to-rank problem. Then we formalize generalized additive model (GAM) and propose a novel formulation of ranking GAM."
    },
    {
      "heading": "3.1 Learning to Rank",
      "text": "In a ranking problem, we denote a data set with N lists as D = {(q,X, y)}N1 . For a specific list (q,X, y) \u2208 D, q = (q1, \u00b7 \u00b7 \u00b7 ,qm ) is a context feature vector consisting ofm list-level contextual signals (e.g. query features in search tasks, user information in recommendation tasks); X = {xi }li=1 is a set of l data items, each represented by a feature vector xi ; y = {yi }li=1 is a set of relevance labels of corresponding data items where a higher yi \u2208 R indicates that the item xi is more relevant. Let\u03a0l denote the set of all permutations of l data items. The optimal ranking \u03c0\u2217 \u2208 \u03a0l can always be obtained by ranking items xi \u2019s according to their relevance labels yi \u2019s from highest to lowest.\nThe typical learning-to-rank setting aims to learn a ranker \u03c6 from a training data set DL with given relevance labels, such that for any list (q,X), the inferred ranking \u03c0\u0302 = \u03c6(q,X) can be as close to the optimal ground-truth ranking \u03c0\u2217 as possible.\nSpecifically, in this work, we infer the ranking by scoring each item individually and sorting them based on their scores. For each list (q,X) with given context features and item features, we aim to learn a scoring function F which takes both the context features q and an individual item\u2019s features xi as input, and output a ranking score y\u0302i \u2208 R:\ny\u0302i = F (q, xi )\nThe final predicted ranking \u03c0\u0302 will simply be generated by ranking all the items in X based on their inferred ranking scores y\u0302i \u2019s.\nIt is worth noting that there is not yet a common understanding on a formal definitions of interpretability in learning-to-rank. In this paper, we confine our discussion within the interpretability offered by generalized additive models (GAMs). We will briefly review the formal definition of GAMs, and then propose a novel ranking GAM definition with similar interpretability."
    },
    {
      "heading": "3.2 GAM",
      "text": "A generalized additive model (GAM) [19, 30] learns a function for each individual input feature respectively. Previous studies typically focus on applying generalized additive models on classification or regression tasks with numeric features. Formally, we denote a data set asD = {(xi ,yi )}Ni=1 where each xi = (xi1, \u00b7 \u00b7 \u00b7 ,xin ) is a feature vector containing n features and yi is the target. For a regression task, yi \u2208 R is a real value, while for a binary classification task yi \u2208 {0, 1} is a binary value. A generalized additive model takes a feature vector xi and outputs y\u0302i with the following structure:\n\u0434(y\u0302i ) = f1(xi1) + f2(xi2) + \u00b7 \u00b7 \u00b7 + fn (xin ) (1)\nEach fj (\u00b7) is a function to be learned for the j-th feature. The function can be instantiated by different classes of functions, such as linear functions, splines or trees/ensemble of trees [30]. \u0434(\u00b7) is a link function that links the sum of all fj (xi j )\u2019s to the model output. For example, \u0434(\u00b7) could be an identity function for regression tasks, while for a binary classification task its inverse function \u0434\u22121(\u00b7) could be a logistic function \u0434\u22121(u) = 11+exp(\u2212u) .\nThe model does not involve any interactions between features, which could lead to compromise on performance. However, the simple structure also introduces many appealing benefits in practices. Since each fj (\u00b7) is essentially a univariate function, the relationship\nbetween a feature\u2019s value and the final response can be accurately quantified and visualized by plotting fj (\u00b7). This transparency can greatly reduce the cost for model troubleshooting and maintenance."
    },
    {
      "heading": "3.3 Ranking GAM",
      "text": "Traditional GAMs are designed for classification and regression problems. There are no systematic studies to develop GAMs for ranking problems. In this subsection, we define ranking GAMs, which are designed to tackle the special structure of ranking problems while maintaining intelligibility of traditional GAMs. Context-absent ranking. We start our discussion by the contextabsent ranking scenario, where the list-level context features q are not available. In this scenario, a ranking GAM essentially applies a traditional GAM for regression on each item xi in the listX as a scoring function. Given each item\u2019s representation xi = (xi1, \u00b7 \u00b7 \u00b7 ,xin ), the ranking score y\u0302i can be derived by:\ny\u0302i = F (xi ) = f1(xi1) + f2(xi2) + \u00b7 \u00b7 \u00b7 + fn (xin ) (2)\nNote that the item-level features can be context-dependent. For example, the BM25 scores are item-level features but depend on both queries (contexts) and documents (items).\nHowever, not all context features can be effectively projected to item-level features, e.g., the time in a day when a query is sent in search tasks (like 9 a.m. or 9 p.m.). In this case, the context-absent ranking formalization is not compatible with such a context feature. Context-present ranking. Now we discuss the definition of our ranking GAM in the context-present scenario where list-level context features q = (q1, \u00b7 \u00b7 \u00b7 ,qm ) are available. A straightforward solution would be to project context features q as item-level features and apply a traditional GAM as an item scoring function like in the context-absent setting:\ny\u0302i = F (q, xi ) = f1(xi1) + f2(xi2) + \u00b7 \u00b7 \u00b7 + fn (xin ) + fn+1(q1) + fn+2(q2) + \u00b7 \u00b7 \u00b7 + fn+m (qm ) (3)\nUnfortunately, this model structure cannot fully leverage the signals from context features in learning-to-rank scenarios. On one hand, most ranking losses used for training only involve the differences of predicted ranking scores (y\u0302i \u2212 y\u0302i\u2032) between items. Obviously, the sub-model terms of context features fn+k (qk ) will be canceled out as all items within the same list share the same context feature values. On the other hand, most ranking metrics only care about the order of items \u03c0\u0302 , which is not related to context feature sub-model terms fn+k (qk ) either.\nIn order to leverage context features for a GAM model, we propose the following ranking GAM model that utilizes context features to derive importance weights when combining item-level features. Specifically, the predicted ranking score of each item is:\ny\u0302i = F (q, xi ) = n\u2211 j=1 m\u2211 k=1 w j,k (qk )fj (xi j ) (4)\nwhere both fj (\u00b7) and w j,k (\u00b7) are arbitrary univariate functions to be learned. It is worth noting that when the context features q are fixed, the predicted ranking score can still be decomposed as sum\nof functions of each item-level feature: y\u0302i = F (q, xi ) = n\u2211 j=1 ( w j (q)fj (xi j ) ) (5)\nwherew j (q) = \u2211m k=1w j,k (qk ) can be interpreted as the importance weight of the j-th item feature derived from all the context features. For example, in a search task, item features like distance might be more important if users are searching for hotels, while the content relevance might be more important if users are searching for a convention center. And notice that the weight function w j (q) is also an additive model with regard to each context feature."
    },
    {
      "heading": "4 NEURAL RANKING GAM",
      "text": "In this section, we propose our method that instantiates ranking GAM based on neural networks."
    },
    {
      "heading": "4.1 Context-Absent Neural Ranking GAM",
      "text": "We start with the context-absent scenario, where a ranking data set can be represented as D = {(X, y)}N1 as the context features q are not available. We will build a scoring function that predicts the ranking score y\u0302i for each data item xi in each list X.\nFor simplicity, we focus on a single data item in a list and omit the subscripts. A data item can be represented as x = {x1,x2, \u00b7 \u00b7 \u00b7 ,xn } where x j represents the j-th feature of the data item x.\nWe build a standalone neural network for each feature xi which outputs a single \u201csub-score\u201d si \u2208 R. This leads to n separate neural networks in total. In principle, users have the flexibility to construct any neural network structure with legitimate input and output. One can even build a different network structure for each feature according to its characteristics.\nIn our practice, we simply adopt a feed-forward network structure with L hidden layers for each feature as shown in Figure 2. Specifically, for each item feature x j , we can have\nzj1 = \u03c3 (Wj1x j + bj1) zj2 = \u03c3 (Wj2zj1 + bj2) . . .\nzjH = \u03c3 (WjH zj(H\u22121) + bjH )\nwhere zh is the output of the h-th hidden layer; Wjh and bjh are weight matrix and bias vector of the h-th hidden layer to be trained; \u03c3 (\u00b7) is the non-linear activation function. We choose the Rectifier (ReLU) [38] as the activation function.\nThe sub-score of feature x j can be obtained by feeding the output of the final hidden layer into a dense layer:\nfj (x j ) = sj =WjzjH + bj (6)\nBased on the n neural networks we build for all the n features, we can obtain the final predicted score for item x by simply taking the sum of all the sub-scores:\ny\u0302 = F (x) = \u2211 j fj (x j ) = \u2211 j sj (7)\nAnd the final predicted ranking of list \u03c0\u0302 can be obtained by simply ranking all the items x\u2019s in the list according to their predicted ranking scores."
    },
    {
      "heading": "4.2 Context-Present Neural Ranking GAM",
      "text": "In this subsection, we describe the neural network instantiation of the context-present ranking GAMs where context features q of each list are available. In this design, the module for item features remains similar as the context-absent setting. In addition, we build another neural additivemodule for context features qwhich outputs an importance weights vector for item feature sub-models instead of a score.\nWe again focus on the scoring of a single data item and temporarily omit the subscripts. Specifically, an item in list X is denoted as x = (x1, \u00b7 \u00b7 \u00b7 ,xn ), and the context features are denoted as q = (q1, \u00b7 \u00b7 \u00b7 ,qm ). The sub-score fj (x j ) for each item feature x j is instantiated in the same way (Equation (6)) as the contextabsent model. From each individual context feature qk , we derive an n-dimensional weighting vector \u03b1k . As shown in Figure 3, the weighting vector can be obtained by a T -layer feed-forward neural network structure, where\nzk1 = \u03c3 (Wk1qk + bk1) zk2 = \u03c3 (Wk2zk1 + bk2) . . .\nzkT = \u03c3 (WkT zk (T\u22121) + bkT )\nSimilarly, zkt \u2019s are hidden layer outputs and Wkt , bkt are model parameters to be learned. Then we use a softmax layer on top of the final dense layer to derive \u03b1k .\n\u03b1k = softmax(Wk zkT ) (8)\nwhere the j-th dimension of the weighting vector \u03b1 (j)k indicates the importance of the j-th item feature in x considering the k-th context feature. Notice that\u03b1 (j)k exactly corresponds to the value of function w j,k (qk ) in Equation (4). The intuition of using a softmax layer is to prevent the derived importance weights to be negative or to be extremely large on some item features, which would substantially compromise the model interpretability.\nWe denote the overall weighting vector as \u03b1 \u2208 Rn . We obtain \u03b1 by taking the summation of weighting vectors \u03b1k from all them\ncontext features in q:\n\u03b1 = m\u2211 k=1 \u03b1k (9)\nThe final ranking score is generated by taking the weighted sum of sub-model fj (x j )\u2019s as described in Equation (5), where the weight of the j-th item featurew j (q) equals to \u03b1 (j), i.e. the j-th dimension of the overall weighting vector."
    },
    {
      "heading": "4.3 Remarks",
      "text": "Ranking losses. Both neural ranking GAMs can be trained with any ranking loss functions. In this work, we train our model with approximate NDCG loss from [3, 44]. It is worth noting that regression losses such as Mean Squared Error (MSE) L(y, y\u0302) = | |y \u2212 y\u0302| |2 can be also used as loss functions for ranking. We will compare traditional GAMs optimizing regression loss with the proposed ranking GAMs in our experiments. Non-numerical features. Another advantage of adopting neural networks is the flexibility to handle non-numerical features such as categorical or textual features, since handling such features in traditional GAM instantiated by splines or trees is non-trivial. Such features can be seamlessly incorporated into GAMs instantiated by neural networks by deriving embedding vectors. Notice that the introduction of embedding will not affect the final visualization of sub-models for non-numerical features."
    },
    {
      "heading": "5 SUB-MODEL DISTILLATION",
      "text": "Model distillation [20] is a widely-adopted technique to simplify deep neural networks. The general idea is to train a smaller, simpler model by minimizing the loss between its output and that of a more larger, complex model. Given the special architecture of our proposed neural GAM model, we propose to distill each sub-model individually. The benefit of sub-model distillation is multi-fold: the distilled sub-models can be faster to perform inference; they are also smaller in size which is beneficial for on-device deployment;\nthey could potentially be more interpretable due to their simpler structure. We focus on distilling sub-models of numerical features where we utilize piece-wise regression (also known as segmented regression) [36]."
    },
    {
      "heading": "5.1 Piece-wise Regression",
      "text": "We are given a numerical feature x and its sub-model f (x) learned in a GAM. The goal of piece-wise regression is to find a piecewise linear function (PWL) that is as close to f (x) as possible. A PWL function can be described by a set of K knots, denoted as S = {(xk ,yk )}Kk=1 where xk \u2019s in the knots are ordered, i.e. xk < xk+1. The definition of PWL function based on the knots S is:\nPWLS (x) =  y1 if x < x1, yk+1\u2212yk xk+1\u2212xk (x \u2212 xk ) + yk if xk \u2264 x \u2264 xk+1, yK if x > xK .\nPWLS (x) is a linear function between any two adjacent knots and becomes flat at two ends. Thus, the K knots uniquely determine the PWL function. For the practice of sub-model distillation, a small K (e.g. around 3 to 5) is usually sufficient.\nFormally, the goal of piece-wise regression is to find the set of optimal knots S = {(xk ,yk )}Kk=1 that minimize the empirical loss on a training data set D = {(xi , f (xi )}Ni=1. In particular, we use the Mean Squared Error (MSE) as our loss function and have the following optimization problem:\nS\u2217 = argmin S={(xk ,yk )}Kk=1 1 |D| \u2211 D\nf (xi ) \u2212 PWLS (xi ) 2 (10) Note that knots S = {(xk ,yk )}Kk=1 are not necessarily a subset of the training data D = {(xi , f (xi )}Ni=1.\nSuch a formulation can be solved a generic piece-wise regression package such as [37]. However, such a package is usually slow and not scalable to large data sets. In the next section, we propose a greedy algorithm for this problem."
    },
    {
      "heading": "5.2 Fitting Algorithm",
      "text": "The major challenge of our fitting algorithm is to determine the xk \u2019s for the K knots: {xk }Kk=1. With xk \u2019s determined, the optimal yk \u2019s can be computed by a method similar to least squares, which we will not elaborate in this paper due to limited space.\nOur method first generates a set of x \u2019s as knot candidates P . Given all x \u2019s in the training data D = {(xi , f (xi )}, we simply construct P by a heuristic using percentile boundary of 0%, 1%, \u00b7 \u00b7 \u00b7 , 99%, 100% of D, resulting in at most 101 elements in P .\nWith a given set of candidate knots P , our problem becomes a combinatorial optimization one, where one needs to find a subset S \u2282 P with size K that minimizes the loss in Equation (10). We denote the loss as L(S). A brute-force algorithm is to enumerate all the possible subset of P with size K , but the computational cost is intractable. Thus, we propose a greedy algorithm in Algorithm 1. The algorithm first constructs an initial set of knots in a greedy fashion and then refine it until convergence. More specifically, \u2022 Knots Initialization. The algorithm greedily construct an initial set S of size K by adding x \u2019s iteratively from P (See\nAlgorithm 1: Finding Knots for Piece-wise Regression Input: Training data D, candidates P , output size K . Output: Knots {(xk ,yk )}Kk=1. 1: Let S \u2190 {minx \u2208P x} 2: for k \u2190 2 to K do 3: x\u2217 \u2190 argminx \u2208P\\S L(S \u222a {x}) 4: S \u2190 S \u222a {x\u2217} 5: end for 6: repeat 7: for all x \u2208 S do 8: x\u2217 \u2190 argminx \u2032\u2208P\\S L(S \u222a {x \u2032} \\ {x}) 9: if L(S \u222a {x\u2217} \\ {x})) < L(S) then 10: S \u2190 S \u222a {x\u2217} \\ {x} 11: end if 12: end for 13: until Convergence. 14: return {(xk ,yk )|xk \u2208 S} after solving yk \u2019s for S .\nLine 1-5). In each step, the x\u2217 that best minimizes the loss is added into the S . \u2022 Knots Refinement. The algorithm iterates over each knot in S and tries to assess whether it can be replaced by another candidate knot to further minimize the loss (See Line 6-13). The procedure stops when there is no improvement after we loop over all xk \u2208 S once. Though the greedy algorithm may be stuck into local minimums in theory, we found that it outputs reasonably good PWL functions in practice as shown in our experiments. Since K is usually very small, finding yk when xk are given can be done efficiently."
    },
    {
      "heading": "6 EXPERIMENTS",
      "text": "In this section, we conduct experiments to answer the following two main research questions: \u2022 RQ1: How do our proposed neural ranking GAMs perform as compared to traditional GAMs on LTR problems? \u2022 RQ2: How does the interpretability of neural ranking GAMs change comparing to traditional GAMs?\nWe first describe our experimental setup including data sets and comparing methods. Then we present the experimental results to answer the above research questions."
    },
    {
      "heading": "6.1 Data Sets",
      "text": "We use three data sets in our experiments. Two of them are public benchmark ones and they do not contain context features. The third one is a private data set that contains non-numerical context features. A summary of the data sets is shown in Table 1. YAHOO. Yahoo! Learning to Rank Challenge data [9] is a publicly available data set. The original data set contains two sets for different purposes: Set1 and Set2. Set1 is the one commonly used for LTR evaluation. It consists of three partitions for training, validation and testing respectively. In this data set, each document is represented as up to 700 numerical features. Each feature has been normalized into the range of [0, 1] by the inverse cumulative distribution. The meaning of each feature is not disclosed. There is\nno list-level context feature in this data set. Documents are labeled with 5-level relevance labels from 0 to 4. WEB30K. WEB30K [43] is a public learning-to-rank data set released by Microsoft. We use Fold1 out of the total five folds in the original data. Similarly to the YAHOO data set, Fold1 has the training, validation and testing partitions. In this data set, each document is represented by 136 numerical features. The meaning of each feature is disclosed and the range of each feature varies. Some query-dependent features are already captured by item-level features such as \u201ccovered query term number\u201d. There is no additional list-level context feature available in this data set. Documents are also labeled with 5-level relevance labels from 0 to 4. Chrome Web Store (CWS). CWS is a private data set that we collected by sub-sampling from the Chrome Web Store logs. Each list in this data set corresponds to a visit to Chrome Web Store. The items in the list were the ones shown to a user and we collect the user actions like clicks or installations as our labels. For each item, we computed 15 numerical features. Moreover, each list contains 3 context features indicating users\u2019 region and language settings and the path of user visits and they are non-numerical. Similarly, we also partition the data set into three parts for training, validation and testing."
    },
    {
      "heading": "6.2 Experiment Setup",
      "text": "Comparingmethods. Themethods compared in our experiments are as follows:\n\u2022 Tree-based GAM (Tree GAM).We train tree-based GAMwith regression loss (mean squared error, i.e., MSE). We use opensourced software MLTK2 which implements GAM proposed by Lou et al. [30]. \u2022 Tree-based Ranking GAM (Tree RankGAM). We also try to train tree-based GAM with ranking loss. Since GAM has not been studied for ranking problems before, there is no existing implementations of GAM specifically designed for optimizing ranking loss. We use LambdaMART implemented by another open-sourced package3 LightGBM [25], and confine the depths of trees in the model to be 1 so that the final model can be decomposed as Equation (2). The number of trees in LightGBM is set to 1, 000. \u2022 Neural GAM (Neural GAM).We use neural networks instead of trees to construct GAMs. The model has similar structure with the context-absent neural ranking GAM, but is trained with regression loss (MSE) instead of ranking loss. \u2022 Context-Absent Neural Ranking GAM (Neural RankGAM). The context-absent neural ranking GAM is presented in Section 4.1 which only takes item features. We train the model with a ranking loss (approximate NDCG). \u2022 Context-Present Neural Ranking GAM (Neural RankGAM+). The context-present neural GAMs for ranking are presented in Section 4.2. It can leverage context features to derive importance weights for item features. We also train the model with a ranking loss (approximate NDCG).\n2https://github.com/yinlou/mltk 3https://github.com/Microsoft/LightGBM\nOur neural ranking GAMs are implemented based on the opensourced TensorFlow Ranking library [40]. Hyperparameters. For neural ranking GAMs, we tune the hyperparameters and choose the following in our experiments. For YAHOO and WEB30K, we construct a neural network with L = 2 layers for each item feature xi and the dimensions are 16 and 8 respectively. For CWS data set, we also build a neural network with L = 2 layers for each item feature xi with dimensions as 64 and 32. Moreover, we build a neural network with H = 2 layers for each context feature qi with dimensions as 128 and 64 for CWS. Since all context features in CWS data set are categorical, we use a d-dimensional (d = 300) embedding layer before the hidden layers for categorical features. We use AdaGrad [16] as the optimizer. Evaluation Metrics. Normalized Discounted Cumulative Gain (NDCG) is a standard metric for evaluating ranking quality with respect to items with graded relevance [23]. In our experiments, we utilize NDCGk as the evaluation metrics with different settings of k (i.e., 1, 5, 10) to evaluate the performance of each ranking method."
    },
    {
      "heading": "6.3 Performance Comparison (RQ1)",
      "text": "We first compare the performances of our proposed neural ranking GAMs to baselines. Table 2 presents the overall performance comparison on all the tree data sets. We have the following observations.\nThe first message is the necessity of developing ranking GAMs specifically for LTR problems. Compared with traditional GAMs which optimize regression loss, both Tree RankGAM and Neural RankGAM achieve substantial improvements. For example, on YAHOO, Neural RankGAM achieves NDCG5 of 71.32%, while the Neural GAM achieves only 69.62%. On WEB30K, Neural RankGAM achieves NDCG5 of 43.29%, about +10% higher than Neural GAM with regression loss. This confirms the importance to enable traditional GAMs to optimize ranking losses for LTR problems, as the performance can be extensively improved with exactly the same interpretability.\nMoreover, on the CWS data set where context features are available, our proposed context-present neural ranking GAM (Neural RankGAM+) achieve significantly better performance than the context-absent version and Tree RankGAM. As one can observed, Neural RankGAM+ achieves +4.9% improvement in terms of NDCG5 comparing to the context-absent Neural RankGAM. The improvement shows that context-present Neural RankGAM+ can effectively leverage context features, which is a disadvantage of the traditional tree-based GAMs."
    },
    {
      "heading": "6.4 Interpretability Analysis (RQ2)",
      "text": "It is still an ongoing debate [14, 18, 42] on how to quantitatively measure model interpretability. Considering the challenges and the\nlack of consensus on a rigorous method to evaluate model interpretability, we instead only focus on the family of GAMs. We argue that our proposed models have similar, if not better, interpretability as traditional GAMs on LTR problems.\nThe major differences between our proposed neural ranking GAMs and traditional GAMs are the adoption of ranking losses, the integration of context features, and the instantiation by neural network structures. We show how these differences affect the model interpretability respectively. RankGAM vs. GAM. First, we show that optimizing ranking losses benefits the visualization of sub-model fj (\u00b7) in LTR tasks. Specifically, we study the the correlation between the effective visual range of fj (\u00b7) curve and the actual importance of the j-th feature. We define the \u201cfeature importance\u201d of the j-th feature x j in a specific model by the NDCG5 drop on validation data sets if perturbing x j values within every lists by random shuffling. We denote this as \u2206NDCG5(j). We also define the \u201ceffective range\u201d (\u2206fj ) of a sub-model fj (\u00b7) by the difference between its maximum and minimum values evaluated from a sample of x j values, excluding the bottom and top 5%. Ideally, if the learned sub-models can intuitively reflect the impact of their corresponding features on the final predicted results, we should observe a strong correlation between \u2206NDCG5(j) and \u2206fj .\nTo verify this, we plot the \u2206fj and \u2206NDCG5(j) values for all features on WEB30K data set. We conduct the experiments comparing Neural GAM trained with a regression loss (MSE) and Neural RankGAM trained with a ranking loss (ApproxNDCG). Figure 4 shows the results, where each point corresponds to the \u2206f value\nand the \u2206NDCG5 value of a feature. As one can observe from Figure 4(b), the sub-models learned with a ranking loss show a positive correlation between the sub-model\u2019s effective range and the importance of the corresponding feature in the final ranking performance. In comparison, as Figure 4(a) presents, the sub-models learned with a regression loss does not necessarily reflect their feature importance on ranking performance. This is primarily due to the nature of ranking problem where correctly identifying high-ranked items are valued more than distinguishing between massive low-ranked items. The results again verify the necessity to develop ranking specific GAMs as the interpretability can also be improved. Neural vs. Tree RankGAM. Second, we compare the interpretability of neural sub-models and tree-based sub-models by visualizing sub-models of the most important features4 for both Tree RankGAM and Neural RankGAM+ on CWS data set. For each feature, we estimate the distribution and plot the f (x) function for x values above the bottom 5% and below the top 5% of all data points in the training data. Figure 5 show the curves learned by Tree RankGAM and Neural RankGAM+.\nAs one can observe, the curves of each feature learned by both methods seem to have similar trends, which confirms the neural submodels are as effective as tree-based sub-models.We also notice that the curves in Tree RankGAM are non-continuous, with potentially steep \u201csteps\u201d (e.g. around x = 2.5 in Figure 5(b) and around x = 5 in Figure 5(c)), whereas the curves learned by Neural RankGAM+with ReLU activation functions are continuous with less steep slopes. The more continuous curves usually can generalize better, but largely depend on the real applications. By changing the activation function in Neural RankGAMs, it is also possible to change the corresponding behaviors. Context feature interpretability. Finally, we show how to visualize the contribution of context features so as to achieve interpretability. Figure 6 illustrates how item features are weighed based on different values of a specific context feature \u201cregion\u201d. This visualization is sufficient for users to discover and analyze patterns of context feature contribution to the final results. As a running example, it can be observed in Figure 6 that the learned feature importance vectors seem to be similar across regions with high geographical and/or cultural proximity. For instance, the US and the GB have similar feature importance vectors as they share similar languages and cultures."
    },
    {
      "heading": "6.5 Sub-Model Distillation",
      "text": "We also show how sub-model distillation can further improve the scalability of our models. We select Neural RankGAM on YAHOO andWEB30K and Neural RankGAM+ on the CWS data set. We use a 5-segment piece-wise linear functions to distill each sub-model fi (\u00b7) in above selected models. Table 3 compares the performance before and after the distillation, where the distilled ones are named with a \u201c(D)\u201d suffix. The results show that the distilled models have only small NDCG losses. On all the data sets, the drop of performance in terms of NDCG10 are less than \u22121%. Moreover, as Table 4 shows, distilling sub-models substantially reduces model inference time.\n4The importance of a feature is measured by \u2206NDCG5 as defined above.\nOn both YAHOO and WEB30K data sets5, sub-model distillation achieves 17-23X speed-up.\nTo better visualize the distilled sub-models, we select a set of most important features for the Neural RankGAM onWEB30K data set. The feature importance is measured by \u2206NDCG5 as defined in Section 6.4. Figure 7 plots the value of originally learned fj (x)\u2019s at some randomly sampled data points from the training data set and the distilled f\u0302j (x)\u2019s for the selected features. Clearly, the piece-wise linear function fits the data very well, especially in dense areas with a lot of data points from training data. 5We do not disclose the inference times for the CWS data set due to its proprietary nature, but the conclusions are similar.\nAdmittedly, it could be observed that the error of the distilled sub-model in sparse areas with fewer data points from training data could be larger (e.g. around x = 200 in Figure 7(a) or around x = \u2212120 in Figure 7(b)). Data points around these areas may actually have high ranking scores. Hence, errors for these data points might lead to larger performance drops in terms of ranking metrics, as shown in the relatively larger performance drop on WEB30K data set. Developing a sub-model distillation technique specifically for ranking is another non-trivial task. Therefore, we leave it for future study.\nEach sub-model does not need to be a high capacity model. In Figure 8, we fix the number of hidden layers L = 2 but vary the number of dimensions for hidden layers from (4, 2), (8, 4) to (64, 32) on both the YAHOO and WEB30K data sets. The performance basically saturates for hidden layer dimensions greater than (16, 8). It verifies that a relative simple network is sufficient for sub-models."
    },
    {
      "heading": "6.6 Improving Black-Box Models",
      "text": "We show that on some data sets, striving for interpretability can also provide insights for improving black-box DNN models. Specifically, we take the trained Neural RankGAM and use sub-model outputs as features to feed into a fully-connected feed-forward network. The fully-connected neural networks have similar configuration as [3]. Table 5 shows our preliminary results on WEB30K. It can be shown that this hybrid model can further improve the performance of the vanilla DNNmodel, whereas simply increasing the number of layers or neurons does not [3]. This might provide some insights on how training GAM-style models can effectively learn some knowledge from the data that can eventually benefit all other models."
    },
    {
      "heading": "7 CONCLUSIONS",
      "text": "In this paper, we explore building intrinsically interpretable learning-to-rank models by adapting generalized additive models (GAMs). Different from previous GAMs that mainly focus on regression or classification, our proposed ranking GAMs can capture both list-level context features and item-level features of ranking tasks. While traditional GAMs are instantiated with splines or trees, we choose neural networks for more flexible model structures, training objectives and feature types. Our experiments verify that the proposed ranking GAMs outperform traditional GAMs on LTR tasks and effectively leverage list-level context features to further improve the performance, while maintaining interpretability of GAMs. We also present how to distill sub-models into simple piece-wise linear functions for further simplicity.\nAs an early exploration on building intrinsically interpretable LTR models, we stick to the most basic form of GAM. However, we are aware that there are numerous directions to further develop and understand ranking GAMs: (1) Incorporating limited pairwise feature interactions to improve model accuracy with reasonable interpretability (similar to [31]); (2) Enabling users to dictate constraints such as monotonicity on sub-models; (3) Combining ranking GAMs with fully-fledged neural networks or decision tree models to achieve both high accuracy and high interpretability; (4) Studying the formal definition and the evaluation methodology of ranking model interpretability."
    },
    {
      "heading": "ACKNOWLEDGMENTS",
      "text": "We thank Vytenis Sakenas, Dmitry Osmakov, Olexiy Oryeshko for implementing early version of Neural RankGAM and piece-wise regression for us. We also thank Po Hu, Janelle Lee, and Chary Chen for preparing data sets for our experiments."
    }
  ],
  "title": "Interpretable Learning-to-Rank with Generalized Additive Models",
  "year": 2020
}
