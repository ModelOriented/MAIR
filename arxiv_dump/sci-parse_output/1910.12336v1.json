{
  "abstractText": "Feature importance estimates that inform users about the degree to which given inputs influence the output of a predictive model are crucial for understanding, validating, and interpreting machine-learning models. However, providing fast and accurate estimates of feature importance for high-dimensional data, and quantifying the uncertainty of such estimates remain open challenges. Here, we frame the task of providing explanations for the decisions of machine-learning models as a causal learning task, and train causal explanation (CXPlain) models that learn to estimate to what degree certain inputs cause outputs in another machine-learning model. CXPlain can, once trained, be used to explain the target model in little time, and enables the quantification of the uncertainty associated with its feature importance estimates via bootstrap ensembling. We present experiments that demonstrate that CXPlain is significantly more accurate and faster than existing model-agnostic methods for estimating feature importance. In addition, we confirm that the uncertainty estimates provided by CXPlain ensembles are strongly correlated with their ability to accurately estimate feature importance on held-out data.",
  "authors": [
    {
      "affiliations": [],
      "name": "Patrick Schwab"
    }
  ],
  "id": "SP:44ed5e92546a2373e0ab8d68dfa2eaff2d52f7bc",
  "references": [],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": "Explanation methods for machine-learning models play an important role in researching, developing, and using predictive models as information on what features were important for a given output enable us to better understand, validate, and interpret model decisions [1\u20135]. However, complex models, such as ensemble models and deep neural networks, are often difficult to interrogate. To address this apparent dichotomy between performance and interpretability [6], researchers have developed a number of attribution methods that provide estimates of the importance of input features towards a model\u2019s output for specific types of models [4, 7\u201315], and for any machine-learning model [6, 16].\nHowever, providing fast and accurate feature importance estimates for any machine-learning model is challenging because there exists a wide variety of intricate machine-learning models with different underlying model structures, algorithms, and decision functions, which makes it difficult to develop an optimised and unified approach to importance attribution. Furthermore, importance estimates of state-of-the-art methods are typically associated with significant uncertainty [3, 17\u201319], and it is therefore difficult for users to judge when importance estimates can be expected to be accurate.\nIn this work, we present a new approach to estimating feature importance for any machine-learning model using causal explanation (CXPlain) models. CXPlain uses a causal objective to train a supervised model to learn to explain another machine-learning model. This approach can be applied to any machine-learning model, since it has no requirements on the predictive model to be explained. In particular, it does not require retraining or adapting the original model. We demonstrate experimentally that CXPlain is significantly more accurate than most existing methods, fast, and able to produce accurate uncertainty estimates. Source code is available at https://github.com/d909b/cxplain.\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nar X\niv :1\n91 0.\n12 33\n6v 1\n[ cs\n.L G\n] 2\n7 O\nct 2"
    },
    {
      "heading": "2 Related Work",
      "text": "CXPlain SG [8] / IG [10] DeepSHAP [1, 6] LIME [16] SHAP [6]\nAccuracy high moderate high high high Model-agnostic 3 5 5 3 3 Uncertainty estimates 3 5 5 5 5 Computation time fast fast fast slow slow\n2\nexplanation methods without changing the explained model\u2019s prediction [19]. These studies highlight the importance of informing users when a given explanation is uncertain and should be discounted.\nIn contrast to existing works, CXPlain is an explanation model trained with a causal objective to learn to explain the decisions of any machine-learning model without the need to retrain, adapt, or have in-depth knowledge of the explained model. To the best of our knowledge, CXPlain is the first feature importance estimation method that is simultaneously (1) significantly more accurate than most existing methods, (2) compatible with any machine-learning model and data modality, (3) able to provide uncertainty estimates via bootstrap resampling, and (4) fast at evaluation time (Table 1)."
    },
    {
      "heading": "3 Methodology",
      "text": "Problem Setting. We consider a setting in which we are given a predictive model f\u0302 which processes inputs X consisting of p input features, or groups of features, xi with i \u2208 [0 . . p \u2212 1] to produce outputs y\u0302 \u2208 Rk of any dimensionality k. The predictive model f\u0302 is scored according to an objective function L : y \u00d7 y\u0302 \u2192 s that computes a scalar loss s \u2208 R after comparing the model\u2019s predictive output y\u0302 to a ground-truth output y \u2208 Rk. The mean squared error (MSE) for regression models and the categorical crossentropy for classification models are commonly used examples of such objectives. We note that we specifically do not require access to, or knowledge of, the process by which f\u0302 produces its output, nor do we require f\u0302 to be differentiable or of any specific form. Additionally, we are given N \u2208 N independent and identically distributed (i.i.d.) pairs of sample covariates X and ground-truth outputs y as training data. Given this setting, our goal is to train an explanation model f\u0302exp that produces accurate estimates A\u0302 with elements a\u0302i corresponding to the importances assigned to each of the p input features xi to the predictive model f\u0302 .\nX y^f\n^ predictive model\nfexp ^ explanation model A\ninput model output\n^\nFigure 1: CXPlain trains an explanation model f\u0302exp (bottom) to learn to estimate importance scores A\u0302 for a predictive target model f\u0302 (top) given features X .\nCausal Explanations (CXPlain). The main idea behind CXPlain is to train a separate explanation model f\u0302exp to explain the predictive model f\u0302 (Figure 1). This flexible framework has the advantage that we do not need to retrain or adapt the predictive model f\u0302 to explain its decisions. To train the explanation model, we utilise a causal objective function that quantifies the marginal contribution of either a single input feature or group of input features towards the predictive model\u2019s accuracy [14, 20]. This approach, in essence, transforms the task of producing feature importance estimates for a given predictive model\ninto a supervised learning task that we can address with existing supervised machine-learning models.\nCausal Objective. The core component of CXPlain is the causal objective that enables us to optimise explanation models to learn to explain another predictive model. The causal objective we build on was first introduced to jointly learn to produce accurate predictions and estimates of feature importance in a single neural network model [14]. However, the original formulation of the causal objective required a specific attentive mixture of experts architecture. In this work, we contribute an adapted version of the causal objective from [14] that does not require a specific model structure, and that can be used to train explanation models to learn to explain any machine-learning model. The causal objective introduced in [14] was based on the Humean definition of causality used by Granger [36], who defined a causal relationship xi \u2192 y\u0302 between random variables xi and y\u0302 to exist if we are better able to predict y\u0302 using all available information than if the information apart from xi had been used [14]. i.e. if the absence of xi as a feature decreases our ability to predict y\u0302. Granger [36]\u2019s definition of causality was based on two key assumptions: (1) That our set of available variables X contains all relevant variables for the causal problem being modelled, and (2) that xi temporally precedes y\u0302 [36]. In the general setting, these assumptions can not be verified from observational data [37]. However, in our specific setting, we know a priori that the inputs of the predictive model f\u0302 mathematically always precede its output, and that the explained model\u2019s output, on deterministic hardware and software, is not influenced by variables other than those present in its set of input features. We can therefore use the given definition to quantify the degree to which an input feature caused a marginal improvement in the predictive performance of the predictive model\n3\nf\u0302 . Given input covariates X , we therefore denote \u03b5X\\{i} as the predictive model\u2019s error without including any information from the ith input feature and \u03b5X as the predictive model\u2019s error when considering all available input features. To calculate \u03b5X\\{i} and \u03b5X , we first compute the outputs y\u0302X\\{i} and y\u0302X of the predictive model f\u0302 without and with the ith input feature xi, respectively: y\u0302X\\{i} = f\u0302(X \\ {i}) (1) y\u0302X = f\u0302(X) (2) There are several different approaches to obtaining X \\ {i} from the full set of input features, depending on the type of input data. For most types of data, masking the respective input feature xi at index i with zeroes, when the zero value has no special meaning, or replacing it with the mean value across the entire data set are both valid choices [20, 21, 24]. More sophisticated feature masking schemes that consider the masked feature\u2019s distribution [38, 39] could be a more principled alternative to masking with point-wise estimates. Given X \\ {i}, we compare the predictions y\u0302X\\{i} and y\u0302X with the ground-truth labels y using the predictive model\u2019s loss function L to calculate \u03b5X\\{i} and \u03b5X : \u03b5X\\{i} = L(y, y\u0302X\\{i}) (3) \u03b5X = L(y, y\u0302X) (4) Following Granger [36]\u2019s definition of causality, we define the degree \u2206\u03b5i to which the ith input feature causally contributed to the predictive model\u2019s output y\u0302 as the decrease in error, as measured by its loss L, associated with adding that feature to the set of available information sources [14]:\n\u2206\u03b5X,i = \u03b5X\\{i} \u2212 \u03b5X (5)\nLastly, we normalise the importance scores \u03c9i to relative contributions \u2208 [0, 1] with \u03a3i\u03c9i = 1 [14]:\n\u03c9i(X) = \u2206\u03b5X,i\u2211p\u22121 j=0 \u2206\u03b5X,j\n(6)\nWe then arrive at our causal objective Lcausal = 1N \u2211N\u22121 l=0 KL(\u2126Xl , A\u0302Xl) [14] that aims to minimise the Kullback-Leibler (KL) divergence [40] between the target importance distribution \u2126 with \u2126(i) = \u03c9i(X) for a given sampleX , and the distribution of importance scores A\u0302 with A\u0302(i) = a\u0302i as estimated by f\u0302exp based on X . Using Lcausal, we can train supervised learning models to learn to explain any other machine-learning model based solely on its outputs, and without the need to retrain the model to be explained. Precomputing the importances \u2126 for each training sample X takes N(p+ 1) evaluations of the target predictive model at training time. For high-dimensional images, it is sensible to group non-overlapping regions of adjacent pixels into feature groups, since removing single pixels in high-dimensional images is unlikely to strongly affect a predictive model\u2019s output [21]. This also significantly limits the number of feature groups p for which importances \u03c9i have to be precomputed. We note that estimating A\u0302 is not necessary in situations in which ground truth labels are readily available, e.g. during model development. In those situations, \u2126 can directly be used to explain f\u0302 .\nExplanation Models. In principle, any supervised machine learning model that can be trained with a custom objective could be used as a causal explanation model. In this work, we focus on neural explanation models. Using deep neural networks as causal explanation models has the advantage that these models are able to extract high-level feature representations from high-dimensional and unstructured data [41], and thus remove the need to perform manual feature engineering. We leave the exploration of other classes of explanation models to future work. A priori, it is not clear which architectures would be most suitable to be used in neural explanation models. Absent any prior knowledge about the structure of the input data, multilayer perceptrons (MLPs) are likely a sensible default choice. However, since architectures that exploit the spatial or temporal structure of input data have been shown to be efficacious, we reason that, depending on the data modality of the input features of the model to be explained, special-purpose architectures, such as convolutional neural networks [42] for images and attentive neural networks for texts [43], could perform better than MLPs. In particular, U-nets [44] that have been designed for image segmentation, a task that involves mapping input pixels to segmentation labels, may perform well as causal explanation models for images since segmentation is semantically similar to explanation, which involves mapping input pixels to importance scores. To determine whether or not specialised model architectures can achieve better performances in neural explanation models, we experimentally evaluate both MLPs and U-nets.\nUncertainty of Importance Estimates. In addition to producing accurate estimates of feature importance, we wish to provide uncertainty estimates ui that quantify the uncertainty associated with each individual feature importance estimate a\u0302i produced by a CXPlain model. In particular, we\n4\nwould like to calculate confidence intervals CIi,\u03b3 = [ci,\u03b12 , ci,1\u2212\u03b12 ] with lower bounds ci,\u03b12 and upper bounds ci,1\u2212\u03b12 at confidence level \u03b3 = 1\u2212 \u03b1 for each assigned feature importance estimate a\u0302i. The width ui = ci,1\u2212\u03b12 \u2212 ci,\u03b12 of CIi,\u03b3 can subsequently be used to quantify the uncertainty of a\u0302i. To derive uncertainty estimates for causal explanation models, we propose the use of bootstrap ensemble methods, specifically using bootstrap resampling [45, 46]. To train bootstrap ensembles of causal explanation models, we first draw N training samples X at random with repeats from the original training set. We then train an explanation model using the before-mentioned causal objective until convergence on the selected subset of the training set. We repeat this process M times to obtain a bootstrap ensemble of M explanation models (Algorithm in Appendix B). We use the median of the attributions a\u0302i of the ensemble members as the assigned importance of the bootstrap ensemble, and the \u03b12 and 1\u2212 \u03b12 quantiles as lower and upper bounds of its CI, respectively. The efficacy of bootstrap ensembles for estimating the uncertainty in outputs of neural networks has been demonstrated in, e.g., [47], but this work is, to the best of our knowledge, the first to consider using bootstrap ensembles of explanation models to quantify the uncertainty in assigned importance scores. We note that Monte Carlo dropout [48], which uses dropout [49] at evaluation time, is an alternative method for estimating uncertainty for the outputs of neural networks that does not require explicitly training an ensemble of models, but may not always produce uncertainty estimates of the same quality as ensembles [47]."
    },
    {
      "heading": "4 Experiments",
      "text": "Our experiments aimed to answer the following questions:\n1 How does the feature importance estimation performance of CXPlain compare to that of existing state-of-the-art methods? 2 How does the computational performance of CXPlain compare to existing model-agnostic and model-specific methods for feature importance estimation? 3 Are uncertainty estimates computed via bootstrap resampling of CXPlain models qualitatively and quantitatively correlated with their ability to accurately determine feature importance?\nTo answer these questions, we performed extensive experiments on several benchmarks that compare both the computational as well as the estimation performance of CXPlain to existing state-of-the-art methods for feature importance estimation. To enable a meaningful comparison, we focus most of our experiments on image classification tasks, where we are best able to visualise and quantify the performance of feature importance estimation methods, and on neural network models as models to be explained, since most existing model-specific attribution methods that we wish to compare to were developed exclusively for neural networks. However, we note that CXPlain as a method is compatible with any machine-learning model, data modality, and both regression as well as classification tasks. We used Mann\u2013Whitney\u2013Wilcoxon (MWW) tests [50] to calculate p-values for the main comparisons.\n4.1 Determining Important Features in MNIST and ImageNet\nTo compare the accuracy of CXPlain to existing state-of-the-art methods for feature importance estimation, we evaluated its ability to identify important features in MNIST [51] and ImageNet [52] images. To do so, we followed the experimental design first proposed by Shrikumar et al. [1], and\n5\nSource MaskedMask ssh://d909b@ssh.schwabpatrick.com:909/usr/bin/python -u /home/d909b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5 Using TensorFlow backend. /usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797 INFO: Seed is 909 2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1) INFO: Loading MNIST data. INFO: Run with args: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 16) 160 input_1[0][0] __________________________________________________________________________________________________ activation_1 (Activation) (None, 28, 28, 16) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] __________________________________________________________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] __________________________________________________________________________________________________ activation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] __________________________________________________________________________________________________ add_1 (Add) (None, 28, 28, 16) 0 activation_1[0][0] activation_3[0][0] __________________________________________________________________________________________________ activation_4 (Activation) (None, 28, 28, 16) 0 add_1[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] __________________________________________________________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] __________________________________________________________________________________________________ activation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] __________________________________________________________________________________________________ add_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation_6[0][0] __________________________________________________________________________________________________ activation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0] __________________________________________________________________________________________________ conv2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0] __________________________________________________________________________________________________ activation_8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0] __________________________________________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 16) 2320 activation_8[0][0] __________________________________________________________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0] __________________________________________________________________________________________________ add_3 (Add) (None, 28, 28, 16) 0 activation_7[0][0] activation_9[0][0] __________________________________________________________________________________________________ activation_10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] __________________________________________________________________________________________________ conv2d_8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0] __________________________________________________________________________________________________ activation_11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] __________________________________________________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] __________________________________________________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0] __________________________________________________________________________________________________ activation_13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] __________________________________________________________________________________________________ activation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] __________________________________________________________________________________________________ add_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation_12[0][0] __________________________________________________________________________________________________ activation_14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] __________________________________________________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] __________________________________________________________________________________________________ activation_15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] __________________________________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0] __________________________________________________________________________________________________ activation_16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] __________________________________________________________________________________________________ add_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation_16[0][0] __________________________________________________________________________________________________ activation_17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] __________________________________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0] __________________________________________________________________________________________________ activation_18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] __________________________________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] __________________________________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] __________________________________________________________________________________________________ add_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation_19[0][0] __________________________________________________________________________________________________ activation_20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] __________________________________________________________________________________________________ conv2d_15 (Conv2D) (None, 7, 7, 64) 18496 activation_20[0][0] __________________________________________________________________________________________________ activation_21 (Activation) (None, 7, 7, 64) 0 conv2d_15[0][0] __________________________________________________________________________________________________\nconv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] __________________________________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0] __________________________________________________________________________________________________ activation_23 (Activation) (None, 7, 7, 64) 0 conv2d_17[0][0] __________________________________________________________________________________________________ activation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0] __________________________________________________________________________________________________ add_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0] __________________________________________________________________________________________________ activation_24 (Activation) (None, 7, 7, 64) 0 add_7[0][0] __________________________________________________________________________________________________ conv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] __________________________________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0] __________________________________________________________________________________________________ conv2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0] __________________________________________________________________________________________________ activation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0] __________________________________________________________________________________________________ add_8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0] __________________________________________________________________________________________________ activation_27 (Activation) (None, 7, 7, 64) 0 add_8[0][0] __________________________________________________________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activation_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] __________________________________________________________________________________________________ conv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] __________________________________________________________________________________________________ activation_29 (Activation) (None, 7, 7, 64) 0 conv2d_21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0] __________________________________________________________________________________________________ activation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0] __________________________________________________________________________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0] __________________________________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 130 atten_1[0][0] __________________________________________________________________________________________________ activation_31 (Activation) (None, 2) 0 dense_1[0][0] ================================================================================================== Total params: 270,882 Trainable params: 270,882 Non-trainable params: 0 __________________________________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense_3 (Dense) (None, 75) 58875 _________________________________________________________________ activation_63 (Activation) (None, 75) 0 _________________________________________________________________ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0 ================================================================= Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9\nobserved = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\n8 \u2192 3\nDeepSHAP\nSHAP\nCXPlain (U-net)\nLIME\nFigure 4: A comparison of the top 10% most important pixels (= Mask) as identified by CXPlain (U-net), DeepSHAP, SHAP, and LIME on the same sample test set image (Source) of the 8 vs. 3 MNIST benchmark. With accurate estimates, the Masked image should more closely resemble a 3 than an 8, since the pixels that most distinguished an 8 as an 8 should have been removed.\nSource MaskedAttribution\nssh://d909b@ssh.schw bpatrick.co :909/usr/bin/python -u /home/d909b/bin causa _explanations/ aus l_explanations/apps/main.py --output_directory=/ho e/d909b/models/cex_mai _1_cxplain_20.1h uncertainty --loa _existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/hom /d909b/models/cex_main_1_cxplain_20. h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_siz 100 --num_l yers=2 --dropout=0.0 --lear ing_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do not_save_attributio s --source_digit=8 -target_digit=3 --attack_method=random --attack_epsil n=1 --attack_num_samples=100 --defence_method=none --discr te_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5 Using TensorFlow backend. /usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.uma h_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap_samples': 5, 'do_adversarial training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_unc rtainties': True, 'num_adversarial_sampl s': 1000, 'hyperopt_against_eval_set': F lse, 'num_ep chs': 5 , 'explanation_m del_name': 'explanation.npz', copy_to_local': False, 'attack iter tions': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_lay rs': 2, 'fr ction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': F lse, 'do_evaluat ': False, 'wit _tensorbo rd': F lse, 'do_augment': False, 'with_b ': False, 'attack num_samples': 100, 'do_hyperopt : F lse, 'at ack_epsilon': 1, 'save_attributions': False, 'save_predicti ns': True, 'target_digit': 3, 'load_exi ting': '/home/d909b/models/cex_main_1/mod l.npz', 'source_digit': 8, 'calculate_robustn ss': False, 'discrete at ack_type : 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertain y', 'load_existing_cxp ain': '/home/d909b/model /cex_main_1_cx lain_20.1h/best_explanation npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dro out': 0.0, 'defe ce_method': 'none', 'num_gpus': 1, 'imagen t_folder': '/hom /d909b/backup/imagenettrain-prep/', 'attack_method': 'rand m', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': Fals , 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797 INFO: Seed is 909 2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/c da_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_run ime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/ ommon_runtim /gpu/gpu_device.cc:1115] Created Ten orFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1) INFO: Loading MNIST data. INFO: Run with args: {'num_boostrap_samples': 5, 'do_adversarial training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_unc rtainties': True, 'num_adversarial_sampl s': 1000, 'hyperopt_against_eval_set': F lse, 'num_ep chs': 5 , 'explanation_m del_name': 'explanation.npz', copy_to_local': False, 'attack iter tions': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_lay rs': 2, 'fr ction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': F lse, 'do_evaluat ': False, 'wit _tensorbo rd': F lse, 'do_augment': False, 'with_b ': False, 'attack num_samples': 100, 'do_hyperopt : F lse, 'at ack_epsilon': 1, 'save_attributions': False, 'save_predicti ns': True, 'target_digit': 3, 'load_exi ting': '/home/d909b/models/cex_main_1/mod l.npz', 'source_digit': 8, 'calculate_robustn ss': False, 'discrete at ack_type : 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertain y', 'load_existing_cxp ain': '/home/d909b/model /cex_main_1_cx lain_20.1h/best_explanation npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dro out': 0.0, 'defe ce_method': 'none', 'num_gpus': 1, 'imagen t_folder': '/hom /d909b/backup/imagenettrain-prep/', 'attack_method': 'rand m', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': Fals , 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. ____________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================ input_1 (InputLayer) (None, 28, 28, 1) 0 ____________________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 16) 160 input_1[0][0] ____________________________________________________________________________ activation_1 (Activation) (None, 28, 28, 16) 0 conv2d_1[0][0] ____________________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] ____________________________________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] ____________________________________________________________________________ conv2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] ____________________________________________________________________________ activation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] ____________________________________________________________________________ add_1 (Add) (None, 28, 28, 16) 0 activation_1[0][0] activation_3[0][0] ____________________________________________________________________________ activation_4 (Activation) (None, 28, 28, 16) 0 add_1[0][0] ____________________________________________________________________________ conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] ____________________________________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] ____________________________________________________________________________ conv2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] ____________________________________________________________________________ activation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] ____________________________________________________________________________ add_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation_6[0][0] ____________________________________________________________________________ activation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0] ____________________________________________________________________________ conv2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0] ____________________________________________________________________________ activation_8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0] ____________________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 16) 2320 activation_8[0][0] ____________________________________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0] ____________________________________________________________________________ add_3 (Add) (None, 28, 28, 16) 0 activation_7[0][0] activation_9[0][0] ____________________________________________________________________________ activation_10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] ____________________________________________________________________________ conv2d_8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0] ____________________________________________________________________________ activation_11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] ____________________________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] ____________________________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0] ____________________________________________________________________________ activation_13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] ____________________________________________________________________________ activation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] ____________________________________________________________________________ add_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation_12[0][0] ____________________________________________________________________________ activation_14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] ____________________________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] ____________________________________________________________________________ activation_15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] ____________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0] ____________________________________________________________________________ activation_16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] ____________________________________________________________________________ add_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation_16[0][0] ____________________________________________________________________________ activation_17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] ____________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0] ____________________________________________________________________________ activation_18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] ____________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] ____________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] ____________________________________________________________________________ add_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation_19[0][0] ____________________________________________________________________________ activation_20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] ____________________________________________________________________________ conv2d_15 (Conv2D) (None, 7, 7, 64) 18496 activation_20[0][0] ____________________________________________________________________________ activation_21 (Activation) (None, 7, 7, 64) 0 conv2d_15[0][0] ____________________________________________________________________________\nconv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] ____________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0] ____________________________________________________________________________ activation_23 (Activation) (None, 7, 7, 64) 0 conv2d_17[0][0] ____________________________________________________________________________ activation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0] ____________________________________________________________________________ add_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0] ____________________________________________________________________________ activation_24 (Activation) (None, 7, 7, 64) 0 add_7[0][0] ____________________________________________________________________________ conv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] ____________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0] ____________________________________________________________________________ conv2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0] ____________________________________________________________________________ activation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0] ____________________________________________________________________________ add_8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0] ____________________________________________________________________________ activation_27 (Activation) (None, 7, 7, 64) 0 add_8[0][0] ____________________________________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] ____________________________________________________________________________ activation_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] ____________________________________________________________________________ conv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] ____________________________________________________________________________ activation_29 (Activation) (None, 7, 7, 64) 0 conv2d_21[0][0] ____________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0] ____________________________________________________________________________ activation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0] ____________________________________________________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0]\n____________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0]\n____________________________________________________________________________ dense_1 (Dense) (None, 2) 130 atten_1[0][0] ____________________________________________________________________________ activation_31 (Activation) (None, 2) 0 dense_1[0][0] ================================================================ Total params: 270,882 Trainable params: 270,882 Non-trainable params: 0 ____________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param #\n================================================================ input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense_3 (Dense) (None, 75) 58875 _________________________________________________________________ activation_63 (Activation) (None, 75) 0 _________________________________________________________________ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0\n================================================================ Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading ex sting CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: S ved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.9 994917356212 , with AUPRC (weighted) = 0.9999 4928093 339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9 observed = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, .19488319718703, .8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.89876054637767 4, 1.037649214136879, 0.511836717633935 , 2.083070000264211, 1.302903762457773, .8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.810480534840899 , 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, .7860688071695486, 1.2776682986304249, 1.658015438393448 , 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, .6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, .7886172116728509, 1.1807222822302033, .8768496962883034, .2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, .8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\nGorilla or Zebra?\nSHAP\nCXPlain (U-net)\nLIME\nFigure 5: A comparison of the feature importance scores (= Attribution) as estimated by CXPlain (U-net), SHAP, and LIME on the same sample test set image (Source) of the Gorilla vs. Zebra ImageNet benchmark. We found that CXPlain (U-net) produces attribution maps that are, subjectively and qualitatively, more semantically focused on the most salient regions of the image.\ntrained binary classification models to distinguish between two digit types (8 vs. 3) on MNIST (model accuracy: 99.85%), and two object categories (Gorilla vs. Zebra) on ImageNet (model accuracy: 96.73%). As a preprocessing step, pixel values were scaled to be in the range of [0, 1] prior to training. We then used several importance estimation methods to determine which input pixels were most important for the classification models\u2019 decisions on N = 100 test images. We masked the top 10 and 30% of those most important pixels for MNIST and ImageNet, respectively, and measured the resulting change in the classification models\u2019 confidences by computing the difference in log odds\n\u2206log-odds = log-odds(poriginal)\u2212 log-odds(pmasked) (7) where log-odds(p) = log( p1\u2212p ), and poriginal and pmasked are the classification models\u2019 outputs p \u2208 [0, 1] for the original image and the masked image with the top pixels removed, respectively. To ensure that the explanations ei of all methods are on the same scale, we normalised them to the range of [0, 1] using the transformation a\u0302i = |ei|/\u03a3Ni=0|ei|. We plotted the assigned importances and the resulting masked images to qualitatively assess each methods\u2019 ability to determine the salient features in the original image (Figures 4 and 5). We additionally recorded the mean and standard deviation of the time taken (in seconds) to compute the feature importance estimates for each method on the same hardware (Appendix C) over 10 and 5 runs with the same parameters and random seed for MNIST and ImageNet, respectively (Figures 6 and 7). Further training details are given in Appendix A.\n4.2 Quantifying Uncertainty in Estimates of Feature Importance\nTo quantitatively and qualitatively assess the accuracy of the uncertainty estimates provided by bootstrap ensembles of CXPlain models, we analysed whether their uncertainty estimates ui are correlated with their errors in feature importance estimation on held-out MNIST test samples. We evaluated several numbersM of bootstrap resampled models in order to determine how the number of ensemble members affects the uncertainty estimation performance of bootstrap ensembles of CXPlain models. In addition, we also evaluated the performance of randomly selected uncertainty estimates as a baseline for comparison. In general settings, it is difficult to evaluate uncertainty estimates for feature importance estimation methods, since we typically do not have per-feature ground-truth attributions to evaluate against. However, by comparing the ranking implied by the ground-truth change in log-odds to the ranking implied by the explanation model we are able to define a rank error REi for each xi. Formally, the rank error REi = |rank\u2206log-odds(i)\u2212 rankf\u0302exp(i)| is the difference in rank between the true rank\u2206log-odds implied by \u2206log-odds, and the estimated rankf\u0302exp implied by the explanation model, where rankb(i) defines the rank of xi from 0 to p\u2212 1 implied by b. As correlation metric, we used Pearson\u2019s \u03c1 to measure the correlation between the rank error REi and the uncertainty estimates ui = ci,95% \u2212 ci,5% defined by the bootstrap resampled \u03b3 = 90% CIs for each importance estimate a\u0302i in the top 2.5% of pixels by \u2206log-odds across N = 100 unseen images from the MNIST test set. We limited the evaluation to all pixels with a \u2206log-odds greater than 0.\n6\nIf our uncertainty estimates are well calibrated, we would expect to see a high correlation between the uncertainty estimates ui and the magnitude of rank errors REi, since that would indicate that the uncertainty estimates ui accurately quantify how certain the feature importance estimates a\u0302i are on previously unseen sample images. For the comparison of the resulting distributions of correlation scores, we applied the Fisher z-transform to the correlation scores in order to correct for the skew in the distribution of the sample correlation [53]. Figure 9 depicts visualisations of the calculated ground-truth log odds, the rank errors of the explanation model\u2019s importance estimates, and the uncertainty for each importance estimate for three test set images. We used the same hyperparameters as in the previous experiment to train the ensembled CXPlain (MLP) models (Appendix A)."
    },
    {
      "heading": "5 Results and Discussion",
      "text": "Predictive Performance. We found that, on the MNIST benchmark, CXPlain (U-net) was competitive with the best competing state-of-the-art feature importance estimation method, DeepSHAP. We also found that CXPlain (U-net) produced significantly (p < 0.001, MWW) more accurate feature importance estimates than CXPlain (MLP) - indicating that model architectures specifically tailored for the image domain are more effective than MLPs in neural explanation models (Figure 2). On the ImageNet benchmark, CXPlain significantly (p < 0.01, MWW) outperformed the best competing feature importance estimation method, LIME (Figure 3). We also found that the model-specific attribution methods Simple Gradient and Integrated Gradients performed relatively poorly across both benchmarks, and were consistently outperformed by the model-agnostic attribution methods, CXPlain, and DeepSHAP. Qualitatively, we found that the estimates of feature importance provided by CXPlain were more focused on the subjectively more important semantic regions of the sample images from both MNIST and ImageNet (Figures 4 and 5; more in Appendix D). Other methods, in contrast, produced more superfluous attributions. This behavior is exhibited in Figure 5 where SHAP and LIME both attribute significant importance to the wall behind the gorilla, whereas CXPlain focused nearly all its attention on the gorilla itself, with the exception of the window frame receiving some importance outside the top 30% of importances of that sample image. We believe this could be due to the fact that the causal objective strongly penalises attributions outside regions of interest - leading to qualitatively more focused estimates of importance.\nComputational Performance. In terms of computational performance, we found that CXPlain computed feature importance estimates significantly faster than the state-of-the-art model-agnostic attribution methods, LIME and SHAP, on both the MNIST and ImageNet benchmarks (Figures 6 and 7). Gradient-based attribution methods and CXPlain performed similarly. On ImageNet, the gap between LIME and SHAP and the faster methods was considerably larger than on MNIST, since the large numbers of model evaluations for LIME and SHAP were slower on higher-dimensional images.\nQuality of Uncertainty Estimates. We found that, quantitatively, even relatively small CXPlain ensembles with just M = 5 bootstrap resampled models produce uncertainty estimates that are significantly (p < 0.001, MWW, compared to Random) correlated with its ability to accurately estimate feature importances on N = 100 previously unseen test images (Figure 8). We also found\n7\n*** ***\n\u22121\n0\n1\n2\n3\n4\nRandom CXPlain (M=5) CXPlain (M=10) CXPlain (M=50) CXPlain (M=100)\nz\u2212 tr\nan sf\nor m\ned P\nea rs\non \u2032s\n\u03c1\nUncertainty Estimation Accuracy\nFigure 8: A comparison of the distributions of the z-transformed Pearson\u2019s correlations \u03c1 between the uncertainty estimates ui produced by various numbers M of bootstrapped ensembles of CXPlain models and the Random baseline, and the ground-truth rank errors of the top 2.5% most important pixels acrossN = 100 unseen test images from the MNIST benchmark (higher is better). *** = significantly different (p < 0.001, MWW)\nInput Rank Error EstimatedUncertaintylog-odds ssh://d909b@ssh.schwabpatrick.com:909/usr/bin/python -u /home/d909b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5 Using TensorFlow backend. /usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797 INFO: Seed is 909 2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1) INFO: Loading MNIST data. INFO: Run with args: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 16) 160 input_1[0][0] __________________________________________________________________________________________________ activation_1 (Activation) (None, 28, 28, 16) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] __________________________________________________________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] __________________________________________________________________________________________________ activation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] __________________________________________________________________________________________________ add_1 (Add) (None, 28, 28, 16) 0 activation_1[0][0] activation_3[0][0] __________________________________________________________________________________________________ activation_4 (Activation) (None, 28, 28, 16) 0 add_1[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] __________________________________________________________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] __________________________________________________________________________________________________ activation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] __________________________________________________________________________________________________ add_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation_6[0][0] __________________________________________________________________________________________________ activation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0] __________________________________________________________________________________________________ conv2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0] __________________________________________________________________________________________________ activation_8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0] __________________________________________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 16) 2320 activation_8[0][0] __________________________________________________________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0] __________________________________________________________________________________________________ add_3 (Add) (None, 28, 28, 16) 0 activation_7[0][0] activation_9[0][0] __________________________________________________________________________________________________ activation_10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] __________________________________________________________________________________________________ conv2d_8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0] __________________________________________________________________________________________________ activation_11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] __________________________________________________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] __________________________________________________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0] __________________________________________________________________________________________________ activation_13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] __________________________________________________________________________________________________ activation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] __________________________________________________________________________________________________ add_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation_12[0][0] __________________________________________________________________________________________________ activation_14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] __________________________________________________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] __________________________________________________________________________________________________ activation_15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] __________________________________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0] __________________________________________________________________________________________________ activation_16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] __________________________________________________________________________________________________ add_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation_16[0][0] __________________________________________________________________________________________________ activation_17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] __________________________________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0] __________________________________________________________________________________________________ activation_18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] __________________________________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] __________________________________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] __________________________________________________________________________________________________ add_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation_19[0][0] __________________________________________________________________________________________________ activation_20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] __________________________________________________________________________________________________\nconv2d_15 (Conv2D) (None, 7, 7, 64) 18496 activation_20[0][0] __________________________________________________________________________________________________ activation_21 (Activation) (None, 7, 7, 64) 0 conv2d_15[0][0] __________________________________________________________________________________________________ conv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] __________________________________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0] __________________________________________________________________________________________________ activation_23 (Activation) (None, 7, 7, 64) 0 conv2d_17[0][0] __________________________________________________________________________________________________ activation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0] __________________________________________________________________________________________________ add_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0] __________________________________________________________________________________________________ activation_24 (Activation) (None, 7, 7, 64) 0 add_7[0][0] __________________________________________________________________________________________________ conv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] __________________________________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0] __________________________________________________________________________________________________ conv2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0] __________________________________________________________________________________________________ activation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0] __________________________________________________________________________________________________ add_8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0] __________________________________________________________________________________________________ activation_27 (Activation) (None, 7, 7, 64) 0 add_8[0][0] __________________________________________________________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activation_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] __________________________________________________________________________________________________ conv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] __________________________________________________________________________________________________ activation_29 (Activation) (None, 7, 7, 64) 0 conv2d_21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0] __________________________________________________________________________________________________ activation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0] __________________________________________________________________________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0] __________________________________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 130 atten_1[0][0] __________________________________________________________________________________________________ activation_31 (Activation) (None, 2) 0 dense_1[0][0] ================================================================================================== Total params: 270,882 Trainable params: 270,882 Non-trainable params: 0 __________________________________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense_3 (Dense) (None, 75) 58875 _________________________________________________________________ activation_63 (Activation) (None, 75) 0 _________________________________________________________________ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0 ================================================================= Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9\nobserved = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\n\u0394\nUncertainty Estimation Samples\nFigure 9: Visualisations of the calculated groundtruth change in log odds \u2206log-odds, the Rank Errors of the explanation model\u2019s feature importance estimates, and the Estimated Uncertainty for each feature importance estimate as obtained via bootstrap resampling (M = 100) for three unseen sample test set images (Input) from the MNIST benchmark. Note the visual similarity of the Rank Error and the Estimated Uncertainty.\nthat increasing the size M of the bootstrap ensemble further significantly (p < 0.001 for M = 5 to M = 100, MWW) increases this correlation, and, thus, the quality of the provided uncertainty estimates. Qualitatively, there was a high visual similarity between the uncertainty estimates ui provided by the CXPlain ensembles for each input feature xi and the magnitude of rank errors REi committed by its importance estimates a\u0302i (Figure 9). The large differences in importance estimation accuracy between state-of-the-art feature importance estimation methods shown in the MNIST and ImageNet benchmarks indicate that many of the importance estimates they provide are not truthful to the predictive model f\u0302 to be explained, and that measures of uncertainty are necessary to fully understand the expected reliability of feature importance estimates.\nLimitations. While they are fast at evaluation time, a limitation of CXPlain models is that they have to be trained to learn to explain a predictive model. However, this one-off compute cost typically amortises quickly, since CXPlain is significantly faster at evaluation time than existing model-agnostic importance estimation methods. Another important point to note is that the associations identified by CXPlain models are only causal in the sense that they quantify the degree to which the input features xi caused a marginal improvement in the predictive performance of the predictive model f\u0302 . Associations reported by CXPlain, in particular, do not in any way indicate that there is a causal relationship between the explained model\u2019s input and output variables in the real world."
    },
    {
      "heading": "6 Conclusion",
      "text": "We presented CXPlain, a new method for learning to estimate feature importance for any machinelearning model. CXPlain is based on the idea of training a separate explanation model to learn to estimate which features are important for a given output of a target predictive model using a causal objective. This approach has several advantages over existing ones: It is compatible with any machine-learning model, can produce estimates of feature importance quickly after training, and may be combined with bootstrap resampling to obtain uncertainty estimates for the provided feature importance scores. We showed experimentally that CXPlain is significantly more accurate in estimating feature importance than existing model-agnostic methods on both MNIST and ImageNet benchmarks, while being orders of magnitude faster at providing importance estimates than stateof-the-art model-agnostic methods. We also found that, analogous to standard supervised learning tasks, special-purpose model architectures may improve the performance of neural explanation models in images, and that the bootstrap resampled uncertainty estimates for the importance scores of an explanation model are significantly correlated with CXPlain\u2019s ability to accurately estimate feature importance - indicating that bootstrap resampling is a suitable approach for quantifying the uncertainty of importance estimates. Causal explanation models that both produce accurate estimates of feature importance and their uncertainties quickly for any machine-learning model and data modality may enable users to better understand, validate, and interpret machine-learning models, while also informing them when their explanations can not be expected to be accurate.\n8\nAcknowledgments\nThis work was partially funded by the Swiss National Science Foundation (SNSF) project No. 167302 within the National Research Program (NRP) 75 \u201cBig Data\u201d. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPUs used for this research. Patrick Schwab is an affiliated PhD fellow at the Max Planck ETH Center for Learning Systems. We additionally thank the anonymous reviewers whose comments helped improve this manuscript."
    },
    {
      "heading": "A Hyperparameters",
      "text": "We implemented all our experiments using Python and TensorFlow [52], and used standardised compute hardware to run the experiments (see Appendix C). For both benchmarks, we used 10000 perturbed samples per explained image for both LIME and SHAP. The output layer of all CXPlain models had one output node for each of the p output feature importance scores ai, and was followed by a softmax activation. We used reference implementations provided by the method\u2019s original authors for LIME1, SHAP and DeepSHAP2, and our own implementations for Simple Gradient and Integrated Gradients. To keep the computation time for sensitivity-based attribution methods in a reasonable range, we explain non-overlapping connected regions of 2x2 pixels for the MNIST benchmarks, and regions of 16x16 pixels for the ImageNet benchmarks. Since the image dimensions were 28x28 for MNIST and 224x224 for ImageNet, the target attribution maps were of size 14x14 for both benchmarks. To keep the comparison meaningful, we summed and renormalised the attributions for each block for the methods that produced per-pixel importances to downsample their attribution maps to the same resolution. For CXPlain, we also used a target attribution map size of 14x14. For the ImageNet benchmark, we split the dataset at random stratified by class into training (60%), validation (20%), and test set (20% of all samples). For MNIST, we used the splits from [49].\nMNIST Benchmark. As target predictive model, we used a binary classifier ResNet-20 model using rectified linear (ReLu) units without batch normalisation [53] that was trained with the Adam [54] optimiser, a learning rate of 0.001, weight decay of 0.001, a batch size of 32, for a maximum of 50 epochs and an early stopping patience of 12 on the validation set loss, and achieved a test set accuracy of 99.85% in distinguishing between the two digit classes. The CXPlain (MLP) model was trained with the Adam [54] optimiser, a learning rate of 0.001, a batch size of 100, 2 hidden layers, H hidden units per hidden layer each followed by a scaled exponential linear unit (SELU) activation [55], for a maximum of 50 epochs with an early stopping patience of 12 on the validation set loss. The CXPlain (U-net) model was trained with the Adam [54] optimiser for a maximum of 50 epochs with an early stopping patience of 12 on the validation set loss, a learning rate of 0.002, a batch size of 128, K filters in the first convolutional layer and K \u2217 2layer_index filters in every subsequent pair of convolutional layer for a maximum of 2 pairs of convolutional layers in the first stage of the U-net followed by a max pooling operation that reduced the dimensionality of the layer input both in width and height in half. The same steps were then mirrored in the inverse direction as outlined in [41] until the target attribution map dimension of 14 \u2217 14 was reached. Each convolutional layer was followed by a ReLu activation. We used a total of 5 hyperparameter optimisation runs on the validation set to select the number H of hidden units per hidden layer of the CXPlain (MLP) model, the number K of initial convolutional filters of the CXPlain (U-net) model, and the dropout probability of both at random from predefined ranges (Tables S1 and S2). The CXPlain (MLP) model selected after\n1https://github.com/marcotcr/lime 2https://github.com/slundberg/shap\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nhyperparameter optimisation used a dropout rate of 4.01%, 126 hidden units per hidden layer, and was trained in 288.73 seconds after precomputing \u2126 for each sample X . The CXPlain (U-net) model selected after hyperparameter optimisation used a dropout rate of 0.001%, 77 initial convolutional filters, and was trained in 499.38 seconds after precomputing \u2126 for each sample X . We used the digits 8 and 3 for the MNIST benchmark.\nImageNet Benchmark. As target predictive model, we used a binary classifier ResNet-32 model using rectified linear (ReLu) units without batch normalisation [53] that was trained with the Adam [54] optimiser, a learning rate of 0.01, a batch size of 32, for a maximum of 250 epochs and an early stopping patience of 12 on the validation set loss, and achieved a test set accuracy of 96.73% in distinguishing between the two object classes. During training, we used automated data augmentation that transformed the image with a randomised shear, zoom, width shift, and height shift of up to 10%, rotated the image at most 20 degrees and flipped the images horizontally at random. The CXPlain (U-net) model was trained with the Adam [54] optimiser, a learning rate of 0.001, a batch size of 32, K filters in the first convolutional layer and K \u2217 2layer_index filters in every subsequent pair of convolutional layer for a maximum of 5 pairs of convolutional layers in the first stage of the U-net followed by a max pooling operation that reduced the dimensionality of the layer input both in width and height in half. The same steps were then mirrored in the inverse direction as outlined in [41]. Each convolutional layer was followed by a ReLu activation. We used a total of 5 hyperparameter optimisation runs on the validation set to select the number K of initial convolutional filters and dropout probability of the CXPlain (U-net) model at random from predefined ranges (Table S3). The CXPlain (U-net) model selected after hyperparameter optimisation used a dropout rate of 5.61%, 12 initial convolutional filters, and was trained in 372.14 seconds after precomputing \u2126 for each sample X . The ImageNet synsets we used for the benchmark were zebra (n02391049) and gorilla (n02480855).\nTwitter Sentiment Analysis Benchmark. In addition to the benchmarks presented in the main body of the paper, we also performed qualitative experiments using a sentiment analysis model for short text messages in order to demonstrate the efficacy of CXPlain for data modalities other than images, and target predictive models other than neural networks. As training dataset, we used a random subset of N = 100000 short messages (50000 positive and 50000 negative messages) from the dataset available at http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip. Like the ImageNet benchmark, we split the dataset at random stratified by class into training (60%), validation (20%), and test set (20% of all samples). We then trained a random forest (RF) classifier with 64 trees to classify short messages as being either positive or negative in content as our target predictive model. The model achieved a test set accuracy of 76.32%. The RF model received word count vectors over a vocabulary initialised with the training set as inputs. The input text was lowercased, punctuation was removed, and the words were preprocessed using the Natural Language Toolkit (NLTK) tokeniser available at https://www.nltk.org/. As explanation model, we trained a CXPlain (MLP) model that received a fixed length sequence of 96 word IDs according to the previously mentioned vocabulary in order to determine which words were most important for the RFs outputs. Messages shorter than 96 were padded with the zero ID that was not assigned to any other words, and words that were not in the training vocabulary were assigned an ID representing unknown words that was not assigned to any other words. The CXPlain (MLP) used an initial embedding layer to transform the word IDs into an embedding space that was followed by a number of L hidden layers with H hidden units each. Each layer was followed by a SeLU activation [55]. The CXPlain (MLP) model was trained with the Adam [54] optimiser, a learning rate of 0.0001, a batch size of 128, and a dropout percentage pdropout for a maximum of 100 epochs and an early stopping patience of 12 on the validation set loss. H , L and pdropout were selected at random from predefined ranges over 5 hyperparameter optimisation runs using the lowest validation loss as the selection criterium (Table S4). The CXPlain (MLP) model selected after hyperparameter optimisation used a dropout rate of 5.47%, 162 hidden units per hidden layer, 1 hidden layer, and was trained in 126.28 seconds after precomputing \u2126 for each sample X . To remove the information from the ith word xi for the calculation of the causal objective, we simply deleted the respective word from the sentence. See Appendix E for qualitative samples of importances assigned by the selected CXPlain (MLP) to short text messages from the Twitter Sentiment Analysis benchmark.\n2"
    },
    {
      "heading": "B Training Bootstrap Ensembles of Causal Explanation Models",
      "text": "Algorithm 1 Training Bootstrap Ensembles of Causal Explanation Models. Input:\n1: Training dataset T consisting of N samples X with ground-truth labels y 2: Size M of ensemble 3: Target predictive model f\u0302 to be explained\nOutput: Ensemble E of M causal explanation models 4: procedure TRAIN_EXPLANATION_ENSEMBLE: 5: E \u2190 Empty 6: for i from 0 to M \u2212 1 do 7: Tsubset \u2190 Draw N pairs of samples (X , y) at random with repeats from T 8: Train explanation model CXPlaini until convergence using Lcausal with f\u0302 and Tsubset. 9: Add CXPlaini to E\nreturn E"
    },
    {
      "heading": "C Computing Infrastructure",
      "text": "We used the same hardware for all experiments: Intel Core i5 7600K, Nvidia GeForce Titan Xp, 32 GB RAM."
    },
    {
      "heading": "D Qualitative Samples for the MNIST and ImageNet Benchmarks",
      "text": "We present more qualitative samples from the MNIST benchmark in Figure S1, and more qualitative samples from the ImageNet benchmark in Figure S2."
    },
    {
      "heading": "E Qualitative Samples for the Twitter Sentiment Analysis Benchmark",
      "text": "We show qualitative samples of the importances assigned to short messages in the Twitter Sentiment Analysis benchmark by the CXPlain (MLP) in Table S5. We found that, qualitatively, the explanations of CXPlain (MLP) provided for the RF were indeed high for words that have positive or negative connotations, and, subjectively, appeared to be semantically meaningful.\n3\nTable S1: Hyperparameter ranges used to train CXPlain (MLP) in the MNIST benchmark.\nHyperparameter Values\nNumber of hidden units per hidden layer H [70, 140] Dropout percentage pdropout [0%, 10%]\nTable S2: Hyperparameter ranges used to train CXPlain (U-net) in the MNIST benchmark.\nHyperparameter Values\nNumber of initial convolutional filters K [65, 80] Dropout percentage pdropout [0%, 10%]\nTable S3: Hyperparameter ranges used to train CXPlain (U-net) in the ImageNet benchmark.\nHyperparameter Values\nNumber of initial convolutional filters K [8, 24] Dropout percentage pdropout [0%, 10%]\nTable S4: Hyperparameter ranges used to train CXPlain (MLP) in the Sentiment Analysis benchmark.\nHyperparameter Values\nNumber of hidden units per hidden layer H [64, 180] Number of hidden layers L [1, 3] Dropout percentage pdropout [0%, 10%]\n4\nSource MaskedMask ssh://d909b@ssh.schwabpatrick.com:909/usr/bin/python -u /home/d909b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5 Using TensorFlow backend. /usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797 INFO: Seed is 909 2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1) INFO: Loading MNIST data. INFO: Run with args: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 16) 160 input_1[0][0] __________________________________________________________________________________________________ activation_1 (Activation) (None, 28, 28, 16) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] __________________________________________________________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] __________________________________________________________________________________________________ activation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] __________________________________________________________________________________________________ add_1 (Add) (None, 28, 28, 16) 0 activation_1[0][0] activation_3[0][0] __________________________________________________________________________________________________ activation_4 (Activation) (None, 28, 28, 16) 0 add_1[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] __________________________________________________________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] __________________________________________________________________________________________________ activation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] __________________________________________________________________________________________________ add_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation_6[0][0] __________________________________________________________________________________________________ activation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0] __________________________________________________________________________________________________ conv2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0] __________________________________________________________________________________________________ activation_8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0] __________________________________________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 16) 2320 activation_8[0][0] __________________________________________________________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0] __________________________________________________________________________________________________ add_3 (Add) (None, 28, 28, 16) 0 activation_7[0][0] activation_9[0][0] __________________________________________________________________________________________________ activation_10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] __________________________________________________________________________________________________ conv2d_8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0] __________________________________________________________________________________________________ activation_11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] __________________________________________________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] __________________________________________________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0] __________________________________________________________________________________________________ activation_13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] __________________________________________________________________________________________________ activation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] __________________________________________________________________________________________________ add_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation_12[0][0] __________________________________________________________________________________________________ activation_14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] __________________________________________________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] __________________________________________________________________________________________________ activation_15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] __________________________________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0] __________________________________________________________________________________________________ activation_16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] __________________________________________________________________________________________________ add_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation_16[0][0] __________________________________________________________________________________________________ activation_17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] __________________________________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0] __________________________________________________________________________________________________ activation_18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] __________________________________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] __________________________________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] __________________________________________________________________________________________________ add_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation_19[0][0] __________________________________________________________________________________________________ activation_20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] __________________________________________________________________________________________________ conv2d_15 (Conv2D) (None, 7, 7, 64) 18496 activation_20[0][0] __________________________________________________________________________________________________ activation_21 (Activation) (None, 7, 7, 64) 0 conv2d_15[0][0] __________________________________________________________________________________________________ conv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] __________________________________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0] __________________________________________________________________________________________________ activation_23 (Activation) (None, 7, 7, 64) 0 conv2d_17[0][0] __________________________________________________________________________________________________ activation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0] __________________________________________________________________________________________________ add_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0] __________________________________________________________________________________________________ activation_24 (Activation) (None, 7, 7, 64) 0 add_7[0][0] __________________________________________________________________________________________________ conv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] __________________________________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0] __________________________________________________________________________________________________ conv2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0] __________________________________________________________________________________________________ activation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0] __________________________________________________________________________________________________ add_8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0] __________________________________________________________________________________________________ activation_27 (Activation) (None, 7, 7, 64) 0 add_8[0][0] __________________________________________________________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activation_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] __________________________________________________________________________________________________ conv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] __________________________________________________________________________________________________ activation_29 (Activation) (None, 7, 7, 64) 0 conv2d_21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0] __________________________________________________________________________________________________ activation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0] __________________________________________________________________________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0] __________________________________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 130 atten_1[0][0] __________________________________________________________________________________________________ activation_31 (Activation) (None, 2) 0 dense_1[0][0] ================================================================================================== Total params: 270,882 Trainable params: 270,882 Non-trainable params: 0 __________________________________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense_3 (Dense) (None, 75) 58875 _________________________________________________________________ activation_63 (Activation) (None, 75) 0 _________________________________________________________________ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0 ================================================================= Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9 observed = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\n8 \u2192 3\nDeepSHAP\nSHAP\nCXPlain (U-net)\nLIME\nSource MaskedMask\nssh://d909b@ssh.schwabpatrick.com:909/usr/bi /python -u /home/d909b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5"
    },
    {
      "heading": "Using TensorFlow backend.",
      "text": "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boo ting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797"
    },
    {
      "heading": "INFO: Seed is 909",
      "text": "2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05- 0 16:48:02.201281: I tensor ow/core/commo _runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 p iBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)"
    },
    {
      "heading": "INFO: Loading MNIST data.",
      "text": "INFO: Ru with args: {'num_bo strap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 s eps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 1 ( ) ( , , , ) 160 input_1[0][0] i i 1 ( i i ) ( , , , ) 1[ ][ ] conv d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] ____________________________________ _____________________________________________________________ activation 2 (Activation) (None, 28, 28, 16) 0 conv2d 2[0][0] ________ _______________________________________ _________________________________________________ conv2d 3 (Conv2D) (None, 28, 28, 16) 2320 activation 2[0][0] ______ _______________________________________________ ___________________________________________ activation 3 (Activation) (None, 28, 28, 16) 0 conv2d 3[0][0] ________ __________________________________________ ______________________________________________ add 1 (Add) (None, 28, 28, 16) 0 activation 1[0][0] activation_3[0][0] i i 4 ( i i ) ( , , , ) add_1[0][0] conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] ____________________________________ _____________________________________________________________ activation 5 (Activation) (None, 28, 28, 16) 0 conv2d 4[0][0] ________ _________________________________________________________________________________________ conv2d 5 (Conv2D) (None, 28, 28, 16) 2320 activation 5[0][0] ______ _______________________________________________ ___________________________________________ activation 6 (Activation) (None, 28, 28, 16) 0 conv2d 5[0][0] ________ _________________________________________________________________________________________ add 2 (Add) (None, 28, 28, 16) 0 activation 4[0][0] activation_6[0][0]\nacti ation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0]\ncon 2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0]\ni i 8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0]\nconv2d_7 (Conv2D) (None, 28, 8, 16) 2320 activation_8[0][0] ____________________________________ _____________________________________________________________ activation 9 (Activation) (None, 28, 28, 16) 0 conv2d 7[0][0] ________ _________________________________________________________________________________________ add 3 (Add) (None, 28, 28, 16) 0 activation 7[0][0] activation_9[0][0]\ni i 0 ( i i ) ( , 28, 28, 16) add_3[0][0]\n8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0]\ni i 1 ( i i ) ( , , , ) 8[0][0]\nconv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] ____________________________________ _____________________________________________________________ conv2d 9 (Conv2D) (None, 14, 14, 32) 9248 activation 11[0][0] ________ _________________________________________________________________________________________ activation 13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] ______ ________________________________________________ __________________________________________ activation 12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] ________ _________________________________________________________________________________________ add 4 (Add) (None, 14, 14, 32) 0 activation 13[0][0] activation_12[0][0]\ni i 4 ( i i ) ( , , , ) add_4[0][0]\nconv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] ____________________________________ _____________________________________________________________ activation 15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] ________ _________________________________________________________________________________________ conv2d 12 (Conv2D) (None, 14, 14, 32) 9248 activation 15[0][0] ______ _______________________________________________ ___________________________________________ activation 16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] ________ _________________________________________ _______________________________________________ add 5 (Add) (None, 14, 14, 32) 0 activation 14[0][0] activation_16[0][0]\nacti ation_17 (Activation) (None, 14, 1 , 32) 0 add_5[0][0]\ncon 2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0]\ni i 18 ( i i ) ( , 14, 14, 32) 0 conv2d_13[0][0]\nconv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] ____________________________________ _____________________________________________________________ activation 19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] ________ ______________________________________ __________________________________________________ add 6 (Add) (None, 14, 14, 32) 0 activation 17[0][0] activation_19[0][0]\ni i 0 ( i i ) ( , 14, 14, 32) 0 add_6[0][0]\n5 ( ) ( , , , ) 18496 i i 0[ ][ ]\ni i 1 ( i i ) ( , , , ) 5[ ][ ]\nconv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] ____________________________________ _____________________________________________________________ conv2d 16 (Conv2D) (None, 7, 7, 64) 36928 activation 21[0][0] ________ ______________________________________ __________________________________________________ activation 23 (Activation) (None, 7, 7, 64) 0 conv2d 17[0][0] ______ _______________________________________________ ___________________________________________ activation 22 (Activation) (None, 7, 7, 64) 0 conv2d 16[0][0] ________ _________________________________________ _______________________________________________ add 7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0]\ni i 4 ( i i ) ( , , , ) add_7[0][0]\nconv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] ____________________________________ _____________________________________________________________ activation 25 (Activation) (None, 7, 7, 64) 0 conv2d 18[0][0] ________ ______________________________________ __________________________________________________ conv2d 19 (Conv2D) (None, 7, 7, 64) 36928 activation 25[0][0] ________________ _________________________________________ _______________________________________ activation 26 (Activation) (None, 7, 7, 64) 0 conv2d 19[0][0] ______________________________________________ ___________________________________________________ add 8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0]\ni i 27 ( i i ) ( , 7, 7, 64) 0 add 8[ ][ ] __________________________________________________________________________________________________ c nv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activatio _28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0]\nconv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] _________________________________ activation_29 (Activation) (Non , 7, 7, 64) 0 conv2d_21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation 29[0][0] __________________________________________________________________________________________________ activation 30 (Activation) (None, 7, 7, 64) 0 add 9[0][0] _____ ____________________________________________________________________________________________ average_pooling2d 1 (AveragePoo (None, 1, 1, 64) 0 activation 30[0][0] ________ _________________________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average pooling2d_1[0][0] _____ ____________________________________________________________________________________________ dense 1 (Dense) (None, 2) 130 atten 1[0][0] ________ _________________________________________________________________________________________ activation 31 (Activation) (None, 2) 0 dense 1[0][0] ================================================================================================== Total params: 270,882 Train ble params: 270,882 Non-trainable params: 0 __________________________________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense 3 (Dense) (None, 75) 58875 __________________________________________________________ ____ _ activation_63 (Activation) (N ne, 75) 0 _____________________________________________ ____ _ ______ _____ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshap _2 (Reshape) (None, 784) 0 ================================================================= Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9 observed = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\n8 \u2192 3\nDeepSHAP\nSHAP\nCXPlain (U-net)\nLIME\nFigure S1: Additional qualitative comparisons of the top 10% most important pixels (= Mask) as identified by CXPlain (U-net), DeepSHAP, SHAP, and LIME on two sample test set images (Source) of the 8 vs. 3 MNIST benchmark.\n5\nSource MaskedAttribution ssh://d909b@ssh.schwabpatrick.com:909/usr/bin/python -u /home/d909b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5 Using TensorFlow backend. /usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from numpy.core.umath_tests import inner1d INFO: Args are: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Running at 2019-05-10 16:48:02.083797 INFO: Seed is 909 2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 totalMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1) INFO: Loading MNIST data. INFO: Run with args: {'num_boostrap_samples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Built generators with 120 training samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 16) 160 input_1[0][0] __________________________________________________________________________________________________ activation_1 (Activation) (None, 28, 28, 16) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 16) 2320 activation_1[0][0] __________________________________________________________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] __________________________________________________________________________________________________ activation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] __________________________________________________________________________________________________ add_1 (Add) (None, 28, 28, 16) 0 activation_1[0][0] activation_3[0][0] __________________________________________________________________________________________________ activation_4 (Activation) (None, 28, 28, 16) 0 add_1[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 28, 28, 16) 2320 activation_4[0][0] __________________________________________________________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] __________________________________________________________________________________________________ activation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] __________________________________________________________________________________________________ add_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation_6[0][0] __________________________________________________________________________________________________ activation_7 (Activation) (None, 28, 28, 16) 0 add_2[0][0] __________________________________________________________________________________________________ conv2d_6 (Conv2D) (None, 28, 28, 16) 2320 activation_7[0][0] __________________________________________________________________________________________________ activation_8 (Activation) (None, 28, 28, 16) 0 conv2d_6[0][0] __________________________________________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 16) 2320 activation_8[0][0] __________________________________________________________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0] __________________________________________________________________________________________________ add_3 (Add) (None, 28, 28, 16) 0 activation_7[0][0] activation_9[0][0] __________________________________________________________________________________________________ activation_10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] __________________________________________________________________________________________________ conv2d_8 (Conv2D) (None, 14, 14, 32) 4640 activation_10[0][0] __________________________________________________________________________________________________ activation_11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] __________________________________________________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 32) 544 activation_10[0][0] __________________________________________________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0] __________________________________________________________________________________________________ activation_13 (Activation) (None, 14, 14, 32) 0 conv2d_10[0][0] __________________________________________________________________________________________________ activation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0] __________________________________________________________________________________________________ add_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation_12[0][0] __________________________________________________________________________________________________ activation_14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] __________________________________________________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 32) 9248 activation_14[0][0] __________________________________________________________________________________________________ activation_15 (Activation) (None, 14, 14, 32) 0 conv2d_11[0][0] __________________________________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0] __________________________________________________________________________________________________ activation_16 (Activation) (None, 14, 14, 32) 0 conv2d_12[0][0] __________________________________________________________________________________________________ add_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation_16[0][0] __________________________________________________________________________________________________ activation_17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] __________________________________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 32) 9248 activation_17[0][0] __________________________________________________________________________________________________ activation_18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] __________________________________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 32) 9248 activation_18[0][0] __________________________________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 32) 0 conv2d_14[0][0] __________________________________________________________________________________________________ add_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation_19[0][0] __________________________________________________________________________________________________ activation_20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] __________________________________________________________________________________________________ conv2d_15 (Conv2D) (None, 7, 7, 64) 18496 activation_20[0][0] __________________________________________________________________________________________________ activation_21 (Activation) (None, 7, 7, 64) 0 conv2d_15[0][0] __________________________________________________________________________________________________ conv2d_17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] __________________________________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0] __________________________________________________________________________________________________ activation_23 (Activation) (None, 7, 7, 64) 0 conv2d_17[0][0] __________________________________________________________________________________________________ activation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0] __________________________________________________________________________________________________ add_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation_22[0][0] __________________________________________________________________________________________________ activation_24 (Activation) (None, 7, 7, 64) 0 add_7[0][0] __________________________________________________________________________________________________ conv2d_18 (Conv2D) (None, 7, 7, 64) 36928 activation_24[0][0] __________________________________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0] __________________________________________________________________________________________________ conv2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0] __________________________________________________________________________________________________ activation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0] __________________________________________________________________________________________________ add_8 (Add) (None, 7, 7, 64) 0 activation_24[0][0] activation_26[0][0] __________________________________________________________________________________________________ activation_27 (Activation) (None, 7, 7, 64) 0 add_8[0][0] __________________________________________________________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activation_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] __________________________________________________________________________________________________ conv2d_21 (Conv2D) (None, 7, 7, 64) 36928 activation_28[0][0] __________________________________________________________________________________________________ activation_29 (Activation) (None, 7, 7, 64) 0 conv2d_21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0] __________________________________________________________________________________________________ activation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0] __________________________________________________________________________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0] __________________________________________________________________________________________________ atten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 130 atten_1[0][0] __________________________________________________________________________________________________ activation_31 (Activation) (None, 2) 0 dense_1[0][0] ================================================================================================== Total params: 270,882 Trainable params: 270,882 Non-trainable params: 0 __________________________________________________________________________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ atten_3 (Flatten) (None, 784) 0 _________________________________________________________________ dense_3 (Dense) (None, 75) 58875 _________________________________________________________________ activation_63 (Activation) (None, 75) 0 _________________________________________________________________ dense_4 (Dense) (None, 75) 5700 _________________________________________________________________ activation_64 (Activation) (None, 75) 0 _________________________________________________________________ dense_5 (Dense) (None, 196) 14896 _________________________________________________________________ activation_65 (Activation) (None, 196) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0 ================================================================= Total params: 79,471 Trainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9 observed = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\nGorilla or Zebra?\nSHAP\nCXPlain (U-net)\nLIME\nSource MaskedAttribution\nssh://d909b@ssh.schwabpatrick.com:909/u r/bin/python -u /h me/d9 9b/bin/causal_explanations/causal_explanations/apps/main.py --output_directory=/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty --load_existing=/home/d909b/models/cex_main_1/model.npz --load_existing_cxplain=/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz --dataset=mnist --num_epochs=50 --num_units=75 --batch_size=100 --num_layers=2 --dropout=0.0 --learning_rate=0.001 --l2_weight=0.000 --model_type=resnet --explanation_type=cxplain --do_not_save_attributions --source_digit=8 --target_digit=3 --attack_method=random --attack_epsilon=1 --attack_num_samples=100 --defence_method=none --discrete_attack_type=lsga --do_not_calculate_log_odds --do_not_calculate_robustness --num_explanation_samples=1000 --num_boostrap_samples=5"
    },
    {
      "heading": "Using TensorFlow backend.",
      "text": "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release. from n mpy.co e.umath_tests import inner1d"
    },
    {
      "heading": "I : Args are: {'num_boostrap_s mples': 5, 'do_adversarial_training': False, 'n_jobs': 4, 'explanation_type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'}",
      "text": "INFO: Running at 2019-05-10 16:48:02.083797"
    },
    {
      "heading": "INFO: Seed is 909",
      "text": "2019-05-10 16:48:02.092153: I tensor ow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-05-10 16:48:02.200813: I tensor ow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-05-10 16:48:02.201281: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582 pciBusID: 0000:01:00.0 to alMemory: 11.90GiB freeMemory: 11.55GiB 2019-05-10 16:48:02.201296: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-05-10 16:48:02.396536: I tensor ow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-05-10 16:48:02.396563: I tensor ow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-05-10 16:48:02.396569: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-05-10 16:48:02.396735: I tensor ow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11180 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)"
    },
    {
      "heading": "INFO: Loading MNIST data.",
      "text": "INFO: Run with args: {'num boostrap_samples': 5, 'do adversarial training': False, 'n jobs': 4, 'explanation type': 'cxplain', 'calculate_uncertainties': True, 'num_adversarial_samples': 1000, 'hyperopt_against_eval_set': False, 'num_epochs': 50, 'explanation_model_name': 'explanation.npz', 'copy_to_local': False, 'attack_iterations': 100, 'seed': 909, 'precomputed_attributions_train': '', 'num_layers': 2, 'fraction_of_data_set': 1, 'precomputed_attributions_val': '', 'calculate_log_odds': False, 'do_evaluate': False, 'with_tensorboard': False, 'do_augment': False, 'with_bn': False, 'attack_num_samples': 100, 'do_hyperopt': False, 'attack_epsilon': 1, 'save_attributions': False, 'save_predictions': True, 'target_digit': 3, 'load_existing': '/home/d909b/models/cex_main_1/model.npz', 'source_digit': 8, 'calculate_robustness': False, 'discrete_attack_type': 'lsga', 'num_hyperopt_runs': 35, 'thermometer_encoding_levels': 16, 'learning_rate': 0.001, 'batch_size': 100, 'output_directory': '/home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty', 'load_existing_cxplain': '/home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz', 'do_merge_lsf': False, 'slic_compactness': 10, 'do_hyperopt_on_lsf': False, 'l2_weight': 0.0, 'hyperopt_o set': 0, 'dataset': 'mnist', 'dropout': 0.0, 'defence_method': 'none', 'num_gpus': 1, 'imagenet_folder': '/home/d909b/backup/imagenettrain-prep/', 'attack_method': 'random', 'num_layers_cxplain': -1, 'early_stopping_patience': 12, 'do_train': False, 'num_explanation_samples': 1000, 'num_units': 75, 'test_set_fraction': 0.2, 'model_type': 'resnet', 'validation_set_fraction': 0.2, 'num_units_cxplain': -1, 'model_name': 'model.npz'} INFO: L aded generator with 11982 samples. Doing 120 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Loaded generator with 1984 samples. Doing 20 s eps of size 100 INFO: Built generators with 120 tr ining samples, 20 validation samples and 20 test samples. INFO: Started training feature extraction. ________ _______________________________________ _________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 28, 28, 1) 0 ________ __________________________________________ ______________________________________________ conv2d 1 (Conv2D) (None, 28, 28, 16) 160 input 1[0][0] ______ _______________________________________________ ___________________________________________ activation 1 (Activation) (None, 28, 28, 16) 0 conv2d 1[0][0] ________ __________________________________________ ______________________________________________ conv2d 2 (Conv2D) (None, 28, 28, 16) 2320 activation 1[0][0] ___ _____________________________________________ ________________________________________________ activation_2 (Activation) (None, 28, 28, 16) 0 conv2d_2[0][0] con 2d_3 (Conv2D) (None, 28, 28, 16) 2320 activation_2[0][0] acti ation_3 (Activation) (None, 28, 28, 16) 0 conv2d_3[0][0] dd_1 (Add) (None, 28, 28, 16) 0 activation_1[0] activation 3[0][0] ______ _______________________________________________ ___________________________________________ activation 4 (Activation) (None, 28, 28, 16) 0 add 1[0][0] ________ __________________________________________ ______________________________________________ conv2d 4 (Conv2D) (None, 28, 28, 16) 2320 activation 4[0][0] ___ _____________________________________________ ________________________________________________ activation_5 (Activation) (None, 28, 28, 16) 0 conv2d_4[0][0] con 2d_5 (Conv2D) (None, 28, 28, 16) 2320 activation_5[0][0] acti ation_6 (Activation) (None, 28, 28, 16) 0 conv2d_5[0][0] dd_2 (Add) (None, 28, 28, 16) 0 activation_4[0][0] activation 6[0][0] ______ _______________________________________________ ___________________________________________ activation 7 (Activation) (None, 28, 28, 16) 0 add 2[0][0] ______ _______________________________________________ ___________________________________________ conv2d 6 (Conv2D) (None, 28, 28, 16) 2320 activation 7[0][0] ________ _________________________________________________________________________________________ activation 8 (Activation) (None, 28, 28, 16) 0 conv2d 6[0][0] ________ _________________________________________________________________________________________ conv2d 7 (Conv2D) (None, 28, 28, 16) 2320 activation 8[0][0] ___ _____________________________________________ ________________________________________________ activation_9 (Activation) (None, 28, 28, 16) 0 conv2d_7[0][0]\ndd_3 (Add) (None, 28, 28, 16) 0 activation 7[ ][ ] activation 9[0][0] ______ ________________________________________________ __________________________________________ activation 10 (Activation) (None, 28, 28, 16) 0 add_3[0][0] ________ _________________________________________________________________________________________ conv2d 8 (Conv2D) (None, 14, 14, 32) 4640 activation 10[0][0] ______ ________________________________________________ __________________________________________ activation 11 (Activation) (None, 14, 14, 32) 0 conv2d_8[0][0] ________ _________________________________________________________________________________________ conv2d 10 (Conv2D) (None, 14, 14, 32) 544 activation 10[0][0] ___ _____________________________________________ ________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 32) 9248 activation_11[0][0]\ni i 3 i i , , , conv2d_1 [0][0]\nacti ation_12 (Activation) (None, 14, 14, 32) 0 conv2d_9[0][0]\ndd_4 (Add) (None, 14, 14, 32) 0 activation_13[0][0] activation 12[0][0] ______ ________________________________________________ __________________________________________ activation 14 (Activation) (None, 14, 14, 32) 0 add_4[0][0] ________ _________________________________________________________________________________________ conv2d 11 (Conv2D) (None, 14, 14, 32) 9248 activation 14[0][0] ___ _____________________________________________ ________________________________________________ activation_15 (Activation) (None, 14, 14, 32) conv2d_11[0][0]\ncon 2d_12 (Conv2D) (None, 14, 14, 32) 9248 activation_15[0][0]\nacti ation_16 (Activation) (None, 14, 1 , 32) 0 conv2d_12[0][0]\ndd_5 (Add) (None, 14, 14, 32) 0 activation_14[0][0] activation 16[0][0] ______ ___________________________________________________________________________________________ activation 17 (Activation) (None, 14, 14, 32) 0 add_5[0][0] ______ _______________________________________________ ___________________________________________ conv2d 13 (Conv2D) (None, 14, 14, 32) 9248 activation 17[0][0] ________ _________________________________________ _______________________________________________ activation 18 (Activation) (None, 14, 14, 32) 0 conv2d_13[0][0] ________ _________________________________________ _______________________________________________ conv2d 14 (Conv2D) (None, 14, 14, 32) 9248 activation 18[0][0] ___ ______________________________________________________________________________________________ activation_19 (Activation) (None, 14, 14, 3 ) conv2d_14[0][0]\ndd_6 (Add) (None, 14, 14, 32) 0 activation_17[0][0] activation 19[0][0] ______ _______________________________________________ ___________________________________________ activation 20 (Activation) (None, 14, 14, 32) 0 add_6[0][0] ________ _________________________________________ _______________________________________________ conv2d 15 (Conv2D) (None, 7, 7, 64) 18496 activation 20[0][0] ______ _______________________________________________ ___________________________________________ activation 21 (Activation) (None, 7, 7, 64) 0 conv2d 15[0][0] ________ _________________________________________ _______________________________________________ conv2d 17 (Conv2D) (None, 7, 7, 64) 2112 activation_20[0][0] ___ ______________________________________________________________________________________________ conv2d_16 (Conv2D) (None, 7, 7, 64) 36928 activation_21[0][0]\ni i 3 i i , , , conv2d_17[0][0]\nacti ation_22 (Activation) (None, 7, 7, 64) 0 conv2d_16[0][0]\ndd_7 (Add) (None, 7, 7, 64) 0 activation_23[0][0] activation 22[0][0] ______ _______________________________________________ ___________________________________________ activation 24 (Activation) (None, 7, 7, 64) 0 add 7[0][0] ________ _________________________________________ _______________________________________________ conv2d 18 (Conv2D) (None, 7, 7, 64) 36928 activation 24[0][0] ___ ______________________________________________________________________________________________ activation_25 (Activation) (None, 7, 7, 64) 0 conv2d_18[0][0]\ncon 2d_19 (Conv2D) (None, 7, 7, 64) 36928 activation_25[0][0]\nctivation_26 (Activation) (None, 7, 7, 64) 0 conv2d_19[0][0]\nadd_8 (Add) (None, 7, 7, 64) ctivation_24[0][0] activation 26[0][0] _____ ________________________________________ ___________________________________________________ activation 27 (Activation) (None, 7, 7, 64) 0 add 8[0][0] ________ ______________________________________ __________________________________________________ conv2d_20 (Conv2D) (None, 7, 7, 64) 36928 activation_27[0][0] __________________________________________________________________________________________________ activ tion_28 (Activation) (None, 7, 7, 64) 0 conv2d_20[0][0] __________________________________________________________________________________________________ conv2d 21 (Conv2D) (None, 7, 7, 64) 36928 activation 28[0][0] ___________________________________________________ ______________________________________________ activation 29 (Activation) (None, 7, 7, 64) 0 conv2d 21[0][0] __________________________________________________________________________________________________ add_9 (Add) (None, 7, 7, 64) 0 activation_27[0][0] activation_29[0][0]\n_________________________________ ac ivation_30 (Activation) (None, 7, 7, 64) 0 add_9[0][0]\n_________________________________ average_pooling2d_1 (AveragePoo (None, 1, 1, 64) 0 activation_30[0][0]\n_________________________________ a ten_1 (Flatten) (None, 64) 0 average_pooling2d_1[0][0]\n_________________________________ 1 (None, 2) 130 atten_1[0][0]\n_________________________________ i i 31 i i (None, 2) 0 dense_1[0][0]\n================================================================================================== Total params: 270,882 Trainable params: 270,882 Non-trai able params: 0\n_________________________________ INFO: Loading existing model from /home/d909b/models/cex_main_1/model.npz\nLayer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ a ten_3 (Flatten) (None, 784) 0 _________________________________________________________________ de se_3 (Dense) (None, 75) 58875\nactivati n_63 (Activation) (None, 75) 0 ____ __________ _________________________________________________ dense_4 (Dense) (N ne, 75) 5700 _________________________________________________________________ activati n_64 (Activ ion) (None, 75) 0 __________________________________________________ ______________ dense_5 (D nse) (None, 196) 14896 __________________________________________________ ______________ activati n_65 (Activ ion) (None, 196) 0 __________________________________________________ ______________ reshape_1 (Reshape) (None, 14, 14, 1) 0 _________________________________________________________________ lambda_2 (Lambda) (None, 28, 28, 1) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 784) 0 ======= ========================================================="
    },
    {
      "heading": "Total params: 79,471",
      "text": "T ainable params: 79,471 Non-trainable params: 0 _________________________________________________________________ INFO: Loading existing CXPlain model from /home/d909b/models/cex_main_1_cxplain_20.1h/best_explanation.npz build_explanation_model : took 1.81394100189 seconds. INFO: Saving loss history to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/losses.pickle INFO: Saving model predictions. INFO: Loaded generator with 11982 samples. Doing 120 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/train_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/val_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Saved model predictions to /home/d909b/models/cex_main_1_cxplain_20.1h_uncertainty/test_predictions.csv INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test AUROC (weighted) = 0.999994917356212 , with AUPRC (weighted) = 0.9999949280930339 , with r^2 (weighted) = 0.9957963109416453 , with f1 (weighted) = 0.9984879166751001 , with accuracy = 0.9984879032258065 , with error = 0.0015120967741935054 INFO: Loaded generator with 1984 samples. Doing 20 steps of size 100 INFO: Performance on test [n= 100 ] targets = [0.9] observed = [(1.1436718599626305, '+-', 0.5520538782615332)] INFO: Performance on test [n= 100 ] for target 0.9 observed = [1.3892620290955573, 1.1377237947530967, 0.8350603218815686, 0.8713871427716444, 1.8772789577296631, 1.0421385269639882, 1.2734869085839489, 0.5600630255113783, 1.2435160902712874, 2.0858731684436953, 0.6621914099533671, 0.6070763678776874, 0.8661585671984602, 1.0517880297070337, 2.9146049149183884, 0.6235869496235044, 0.9226209148366383, 0.896227432532063, 0.2670657996896821, 0.013821244358016503, 2.189807259704378, 0.8175433055816894, 1.19488319718703, 1.8930241978639137, 0.7730931068420339, 1.27811588137019, 0.9850174716812721, 1.1216892414631758, 0.573120152159161, 1.0232491128492835, 0.8987605463776784, 1.037649214136879, 0.5118367176339356, 2.083070000264211, 1.302903762457773, 0.8204965828874214, 1.6789029079041142, 1.623794531947206, 1.2545555949371687, 1.0012906768156877, 1.2462736163330106, 0.9057037790232868, 0.9469323067092333, 0.4383414096479612, 0.8104805348408998, 0.8851755920050628, 1.132267732268079, 1.6621074239888216, 0.934013287760548, 0.8349687929106586, 0.5289153327173624, 1.4440371769826026, 2.138591203347149, 1.2270851493051227, 2.142648193073443, 0.3385335850217482, 0.46770572775341435, 0.8527171407093351, 0.47953222713471033, 1.8026274831409246, 1.1812909273907717, 0.9314364881634934, 0.2302455728277166, 1.5633736254880761, 2.3031484613717335, 2.4174470115754003, 1.1201235152098241, 2.266265571565306, 1.3994960435747492, 0.7860688071695486, 1.2776682986304249, 1.6580154383934487, 0.757406483017344, 1.0043128902083016, 0.7231292579067669, 0.740787741347223, 0.7141079559712596, 0.6734593179701929, 0.6616112633542277, 0.9468177183380312, 0.7690791699258368, 1.0155653037702255, 0.6512117579059203, 0.9884971489035145, 0.6675223757172929, 1.7234492486644164, 0.7886172116728509, 1.1807222822302033, 0.8768496962883034, 1.2127882377541048, 1.0925325778269959, 0.5464445929844274, 2.096737223622148, 0.8172319369500524, 1.8495334324613373, 1.2724899666210199, 1.0701363404910589, 1.8738202234307906, 2.195503699637992, 1.8998484264924382]\nProcess nished with exit code 0\nGorilla or Zebra?\nSHAP\nCXPlain (U-net)\nLIME\nFigure S2: Additional qualitative comparisons of feature importance scores (= Attribution) as estimated by CXPlain (U-net), SHAP, and LIME on two same sample test set images (Source) of the Gorilla vs. Zebra ImageNet benchmark.\n6\nTable S5: Examples of short messages and the importances assigned by CXPlain (MLP) in the Twitter Sentiment Analysis benchmark. Deeper colors indicate higher importances, as indicated in the labelled examples in the header row of the table. All samples are labelled as positive in sentiment.\nShort messages highest importance lowest importance\nyou re welcome glad you enjoyed it\nis awesome thanks got some good lolz needed it xxx\ntoday its already busy i wish it was slow maybe later hopefully\nwhooooooo finally done with high school thank god just graduation now yay\nhappy emox awe i d be sad if you bear napped him\nthank you all so much for your kindness\nbout half way done packing gon na be a long ride thanks for the sketch hanna\nthanks for all the gr follows in the last hrs i m awed with each of you\nwhat are yall doing in the lb you guys should kick it at my place\nlooking forward to his birthday tomorrow\n7"
    }
  ],
  "title": "CXPlain: Causal Explanations for Model Interpretation under Uncertainty",
  "year": 2019
}
