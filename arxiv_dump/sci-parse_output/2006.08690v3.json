{
  "abstractText": "Decision tree optimization is notoriously difficult from a computational perspective but essential for the field of interpretable machine learning. Despite efforts over the past 40 years, only recently have optimization breakthroughs been made that have allowed practical algorithms to find optimal decision trees. These new techniques have the potential to trigger a paradigm shift where it is possible to construct sparse decision trees to efficiently optimize a variety of objective functions without relying on greedy splitting and pruning heuristics that often lead to suboptimal solutions. The contribution in this work is to provide a general framework for decision tree optimization that addresses the two significant open problems in the area: treatment of imbalanced data and fully optimizing over continuous variables. We present techniques that produce optimal decision trees over a variety of objectives including F-score, AUC, and partial area under the ROC convex hull. We also introduce a scalable algorithm that produces provably optimal results in the presence of continuous variables and speeds up decision tree construction by several orders of magnitude relative to the stateof-the art.",
  "authors": [
    {
      "affiliations": [],
      "name": "Jimmy Lin"
    },
    {
      "affiliations": [],
      "name": "Chudi Zhong"
    },
    {
      "affiliations": [],
      "name": "Diane Hu"
    },
    {
      "affiliations": [],
      "name": "Cynthia Rudin"
    },
    {
      "affiliations": [],
      "name": "Margo Seltzer"
    }
  ],
  "id": "SP:42f3bda98c3f4852e3dbcac53ceee4d8aaa96655",
  "references": [
    {
      "authors": [
        "U. A\u0131\u0308vodji",
        "J. Ferry",
        "S. Gambs",
        "Huguet",
        "M.-J",
        "M. Siala"
      ],
      "title": "Learning Fair Rule Lists",
      "venue": "arXiv e-prints, pp. arXiv:1909.03977,",
      "year": 1909
    },
    {
      "authors": [
        "E. Angelino",
        "N. Larus-Stone",
        "D. Alabi",
        "M. Seltzer",
        "C. Rudin"
      ],
      "title": "Learning certifiably optimal rule lists for categorical data",
      "venue": "In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),",
      "year": 2017
    },
    {
      "authors": [
        "E. Angelino",
        "N. Larus-Stone",
        "D. Alabi",
        "M. Seltzer",
        "C. Rudin"
      ],
      "title": "Learning certifiably optimal rule lists for categorical data",
      "venue": "Journal of Machine Learning Research,",
      "year": 2018
    },
    {
      "authors": [
        "K. Bennett"
      ],
      "title": "Decision tree construction via linear programming",
      "venue": "In Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society Conference,",
      "year": 1992
    },
    {
      "authors": [
        "K.P. Bennett",
        "J.A. Blue"
      ],
      "title": "Optimal decision trees",
      "venue": "Technical report, R.P.I. Math Report No. 214, Rensselaer Polytechnic Institute,",
      "year": 1996
    },
    {
      "authors": [
        "D. Bertsimas",
        "J. Dunn"
      ],
      "title": "Optimal classification trees",
      "venue": "Machine Learning,",
      "year": 2017
    },
    {
      "authors": [
        "R. Blanquero",
        "E. Carrizosa",
        "C. Molero-R\u0131o",
        "D.R. Morales"
      ],
      "title": "Optimal randomized classification trees",
      "year": 2018
    },
    {
      "authors": [
        "L. Breiman",
        "J.H. Friedman",
        "R.A. Olshen",
        "C.J. Stone"
      ],
      "title": "Classification and Regression Trees",
      "year": 1984
    },
    {
      "authors": [
        "Chang",
        "C.-C",
        "Lin",
        "C.-J"
      ],
      "title": "Libsvm: a library for support vector machines",
      "year": 2011
    },
    {
      "authors": [
        "C. Ferri",
        "P. Flach",
        "J. Hern\u00e1ndez-Orallo"
      ],
      "title": "Learning decision trees using the area under the ROC curve",
      "venue": "In International Conference on Machine Learning (ICML),",
      "year": 2002
    },
    {
      "authors": [
        "M. Garey"
      ],
      "title": "Optimal binary identification procedures",
      "venue": "SIAM J. Appl. Math.,",
      "year": 1972
    },
    {
      "authors": [
        "M. Garofalakis",
        "D. Hyun",
        "R. Rastogi",
        "K. Shim"
      ],
      "title": "Building decision trees with constraints",
      "venue": "Data Mining and Knowledge Discovery,",
      "year": 2003
    },
    {
      "authors": [
        "X. Hu",
        "C. Rudin",
        "M. Seltzer"
      ],
      "title": "Optimal sparse decision trees",
      "venue": "In Proceedings of Neural Information Processing Systems (NeurIPS),",
      "year": 2019
    },
    {
      "authors": [
        "A.R. Klivans",
        "R.A. Servedio"
      ],
      "title": "Toward attribute efficient learning of decision lists and parities",
      "venue": "Journal of Machine Learning Research,",
      "year": 2006
    },
    {
      "authors": [
        "J. Larson",
        "S. Mattu",
        "L. Kirchner",
        "J. Angwin"
      ],
      "title": "How we analyzed the COMPAS recidivism",
      "year": 2016
    },
    {
      "authors": [
        "N.L. Larus-Stone"
      ],
      "title": "Learning Certifiably Optimal Rule Lists: A Case For Discrete Optimization in the 21st Century. 2017",
      "venue": "Undergraduate thesis, Harvard College",
      "year": 2017
    },
    {
      "authors": [
        "H. Laurent",
        "R.L. Rivest"
      ],
      "title": "Constructing optimal binary decision trees is np-complete",
      "venue": "Information processing letters,",
      "year": 1976
    },
    {
      "authors": [
        "Loh",
        "W.-Y"
      ],
      "title": "Fifty years of classification and regression trees",
      "venue": "International Statistical Review,",
      "year": 2014
    },
    {
      "authors": [
        "W.S. Meisel",
        "D. Michalopoulos"
      ],
      "title": "A partitioning algorithm with application in pattern classification and the optimization of decision tree",
      "venue": "IEEE Trans. Comput.,",
      "year": 1973
    },
    {
      "authors": [
        "M. Menickelly",
        "O. G\u00fcnl\u00fck",
        "J. Kalagnanam",
        "K. Scheinberg"
      ],
      "title": "Optimal decision trees for categorical data via integer programming",
      "venue": "Preprint at arXiv:1612.03225,",
      "year": 2018
    },
    {
      "authors": [
        "J.N. Morgan",
        "J.A. Sonquist"
      ],
      "title": "Problems in the analysis of survey data, and a proposal",
      "venue": "J. Amer. Statist. Assoc.,",
      "year": 1963
    },
    {
      "authors": [
        "Y. Nan",
        "K.M. Chai",
        "W.S. Lee",
        "H.L. Chieu"
      ],
      "title": "Optimizing F-measure: A tale of two approaches",
      "venue": "arXiv preprint arXiv:1206.4625,",
      "year": 2012
    },
    {
      "authors": [
        "N. Narodytska",
        "A. Ignatiev",
        "F. Pereira",
        "J. MarquesSilva"
      ],
      "title": "Learning optimal decision trees with SAT",
      "venue": "In Proc. International Joint Conferences on Artificial Intelligence (IJCAI),",
      "year": 2018
    },
    {
      "authors": [
        "S. Nijssen",
        "E. Fromont"
      ],
      "title": "Mining optimal decision trees from itemset lattices",
      "venue": "In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),",
      "year": 2007
    },
    {
      "authors": [
        "S. Nijssen",
        "P Schaus"
      ],
      "title": "Learning optimal decision trees using caching branch-and-bound search",
      "venue": "In ThirtyFourth AAAI Conference on Artificial Intelligence,",
      "year": 2020
    },
    {
      "authors": [
        "H.J. Payne",
        "W.S. Meisel"
      ],
      "title": "An algorithm for constructing optimal binary decision trees",
      "venue": "IEEE Transactions on Computers,",
      "year": 1977
    },
    {
      "authors": [
        "Quinlan",
        "J.R. C"
      ],
      "title": "Programs for Machine Learning",
      "year": 1993
    },
    {
      "authors": [
        "C. Rudin",
        "S. Ertekin"
      ],
      "title": "Learning customized and optimized lists of rules with mathematical programming",
      "venue": "Mathematical Programming C (Computation),",
      "year": 2018
    },
    {
      "authors": [
        "C. Rudin",
        "Y. Wang"
      ],
      "title": "Direct learning to rank and rerank",
      "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),",
      "year": 2018
    },
    {
      "authors": [
        "S. Verwer",
        "Y. Zhang"
      ],
      "title": "Learning optimal classification trees using a binary linear program formulation",
      "venue": "In Proc. Thirty-third AAAI Conference on Artificial Intelligence,",
      "year": 2019
    },
    {
      "authors": [
        "M.G. Vilas Boas",
        "H.G. Santos",
        "Merschmann",
        "L.H. d. C",
        "G. Vanden Berghe"
      ],
      "title": "Optimal decision trees for the algorithm selection problem: integer programming based approaches",
      "venue": "International Transactions in Operational Research,",
      "year": 2019
    },
    {
      "authors": [
        "T. Wang",
        "C. Rudin",
        "F. Doshi-Velez",
        "Y. Liu",
        "E. Klampfl",
        "P. MacNeille"
      ],
      "title": "A Bayesian framework for learning rule sets for interpretable classification",
      "venue": "Journal of Machine Learning Research,",
      "year": 2017
    }
  ],
  "sections": [
    {
      "heading": "1. Introduction",
      "text": "Decision tree learning has served as a foundation for interpretable artificial intelligence and machine learning for over half a century (Morgan & Sonquist, 1963; Payne & Meisel, 1977; Loh, 2014). The major approach since the 1980\u2019s has been decision tree induction, where heuristic splitting and pruning procedures grow a tree from the top down and prune it back afterwards (Quinlan, 1993; Breiman et al., 1984). The problem with these methods is that they tend to produce suboptimal trees with no way of knowing how suboptimal the solution is. This leaves a gap between the performance that a decision tree might obtain and the performance that one actually attains, with no way to check on (or remedy) the size of this gap\u2013and sometimes, the gap can be large.\nFull decision tree optimization is NP-hard, with no polynomial-time approximation (Laurent & Rivest, 1976), leading to challenges in proving optimality or bounding the optimality gap in a reasonable amount of time, even for small datasets. It is possible to create assumptions that reduce hard decision tree optimization to cases where greedy algorithms suffice, such as independence between features (Klivans & Servedio, 2006), but these assumptions do not hold in reality. If the data can be perfectly separated with zero error, SAT solvers can be used to find optimal decision trees rapidly (Narodytska et al., 2018); however, real data is generally not separable, leaving us with no choice other than to actually solve the problem.\nDecision tree optimization is amenable to branch-andbound methods, implemented either via generic mathematical programming solvers or by customized algorithms. Solvers have been used from the 1990\u2019s (Bennett, 1992; Bennett & Blue, 1996) to the present (Verwer & Zhang, 2019; Blanquero et al., 2018; Nijssen et al., 2020; Bertsimas & Dunn, 2017; Rudin & Ertekin, 2018; Menickelly et al., 2018; Vilas Boas et al., 2019), but these generic solvers tend to be slow. A common way to speed them up is to make approximations in preprocessing to reduce the size of the search space. For instance, \u201cbucketization\u201d preprocessing is used in both generic solvers (Verwer & Zhang, 2019) and customized algorithms (Nijssen et al., 2020) to handle continuous variables. Continuous variables pose challenges to optimality; even one continuous variable increases the number of possible splits by the number of possible values of that variable in the entire database, and each additional split leads to an exponential increase in the size of the optimization problem. Bucketization is tempting and seems innocuous, but we prove in Section 3 that it sacrifices optimality.\nDynamic programming methods have been used for various decision tree optimization problems since as far back as the early 1970\u2019s (Garey, 1972; Meisel & Michalopoulos, 1973). Of the more recent attempts at this challenging problem, Garofalakis et al. (2003) use a dynamic programming method for finding an optimal subtree within a predefined larger decision tree grown using standard greedy induction. Their trees inherit suboptimality from the induction procedure used to create the larger tree. The DL8 algorithm (Nijssen & Fromont, 2007) performs dynamic pro-\nar X\niv :2\n00 6.\n08 69\n0v 3\n[ cs\n.L G\n] 1\n1 A\nug 2\n02 0\ngramming on the space of decision trees. However, without mechanisms to reduce the size of the space and to reduce computation, the method cannot be practical. A more practical extension is the DL8.5 method (Nijssen et al., 2020), which uses a hierarchical upper bound theorem to reduce the size of the search space. However, it also uses bucketization preprocessing, which sacrifices optimality; without this preprocessing or other mechanisms to reduce computation, the method suffers in computational speed.\nThe CORELS algorithm (Angelino et al., 2017; 2018; Larus-Stone, 2017), which is an associative classification method rather than an optimal decision tree method, breaks away from the previous literature in that it is a custom branch-and-bound method with custom bounding theorems, its own bit-vector library, specialized data structures, and an implementation that leverages computational reuse. CORELS is able to solve problems within a minute that, using any other prior approach, might have taken weeks, or even months or years. Hu et al. (Hu et al., 2019) adapted the CORELS philosophy to produce an Optimal Sparse Decision Tree (OSDT) algorithm that leverages some of CORELS\u2019 libraries and its computational reuse paradigm, as well as many of its theorems, which dramatically reduce the size of the search space. However, OSDT solves an exponentially harder problem than that of CORELS\u2019 rule list optimization, producing scalability challenges, as we might expect.\nThis work addresses two fundamental limitations in existing work: unsatisfying results for imbalanced data and and scalability challenges when trying to fully optimize over continuous variables. Thus, the first contribution of this work is to massively generalize sparse decision tree optimization to handle a wide variety of objective functions, including weighted accuracy (including multi-class), balanced accuracy, F-score, AUC and partial area under the ROC convex hull. Both CORELS and OSDT were designed to maximize accuracy, regularized by sparsity, and neither were designed to handle other objectives. CORELS has been generalized (A\u0131\u0308vodji et al., 2019; Chen & Rudin, 2018) to handle some constraints, but not to the wide variety of different objectives one might want to handle in practice. Generalization to some objectives is straightforward (e.g., weighted accuracy) but non-trivial in cases of optimizing rank statistics (e.g., AUC), which typically require quadratic computation in the number of observations in the dataset. However, for sparse decision trees, this time is much less than quadratic, because all observations within a leaf of a tree are tied in score, and there are a sparse number of leaves in the tree. Taking advantage of this permits us to rapidly calculate rank statistics and thus optimize over them. The second contribution is to present a new representation of the dynamic programming search space that exposes a high degree of computational reuse when mod-\nelling continuous features. The new search space representation provides a useful solution to a problem identified in the CORELS paper, which is how to use \u201csimilar support\u201d bounds in practice. A similar support bound states that if two features in the dataset are similar, but not identical, to each other, then bounds obtained using the first feature for a split in a tree can be leveraged to obtain bounds for the same tree, were the second feature to replace the first feature. However, if the algorithm checks the similar support bound too frequently, the bound slows the algorithm down, despite reducing the search space. Our method uses hash trees that represent similar trees using shared subtrees, which naturally accelerates the evaluation of similar trees. The implementation, coupled with a new type of incremental similar support bound, is efficient enough to handle a few continuous features by creating dummy variables for all unique split points along a feature. This permits us to obtain smaller optimality gaps and certificates of optimality for mixed binary and continuous data when optimizing additive loss functions several orders of magnitude more quickly than any other method that currently exists.\nOur algorithm is called Generalized and Scalable Optimal Sparse Decision Trees (GOSDT, pronounced \u201cghost\u201d). A chart detailing a qualitative comparison of GOSDT to previous decision tree approaches is in Appendix A."
    },
    {
      "heading": "2. Notation and Objectives",
      "text": "We denote the training dataset as {(xi, yi)}Ni=1 , where xi \u2208 {0, 1}M are binary features. Our notation uses yi \u2208 {0, 1}, though our code is implemented for multiclass classification as well. For each real-valued feature, we create a split point at the mean value between every ordered pair of unique values present in the training data. Following notation of Hu et al. (2019), we represent a tree as a set of leaves; this is important because it allows us not to store the splits of the tree, only the conditions leading to each leaf. A leaf set d = (l1, l2, ..., lHd) contains Hd distinct leaves, where li is the classification rule of the leaf i, that is, the set of conditions along the branches that lead to the leaf, and y\u0302leafi is the label prediction for all data in leaf i. For a tree d, we define the objective function as a combination of the loss and a penalty on the number of leaves, with regularization parameter \u03bb:\nR(d,x,y) = `(d,x,y) + \u03bbHd. (1)\nLet us first consider monotonic losses `(d,x,y), which are monotonically increasing in the number of false positives (FP ) and the number of false negatives (FN ), and thus can be expressed alternatively as l\u0303(FP, FN). We will specifically consider the following objectives in our implementation. (These are negated to become losses.)\n\u2022 Accuracy = 1\u2212 FP+FNN : fraction of correct predictions.\n\u2022 Balanced accuracy = 1 \u2212 12 ( FN N+ + FP N\u2212 ): the average of\ntrue positive rate and true negative rate. Let N+ be the number of positive samples in the training set and N\u2212\nbe the number of negatives. \u2022 Weighted accuracy = 1\u2212 FP+\u03c9FN\u03c9N++N\u2212 for a predetermined\nthreshold \u03c9: the cost-sensitive accuracy that penalizes more on predicting positive samples as negative. \u2022 F-score = 1\u2212 FP+FN2N++FP\u2212FN : the harmonic mean of precision and recall.\nOptimizing F-score directly is difficult even for linear modeling, because it is non-convex (Nan et al., 2012). In optimizing F-score for decision trees, the problem is worse \u2013 a conundrum is possible where two leaves exist, the first leaf containing a higher proportion of positives than the other leaf, yet the first is classified as negative and the second classified as positive. We discuss how this can happen in Appendix D and how we address it, which is to force monotonicity by sweeping across leaves from highest to lowest predictions to calculate the F-score (see Appendix D).\nWe consider two objectives that are rank statistics:\n\u2022 Area under the ROC convex hull (AUCch): the fraction of correctly ranked positive/negative pairs. \u2022 Partial area under the ROC convex hull (pAUCch) for predetermined threshold \u03b8: the area under the leftmost part of the ROC curve.\nSome of the bounds from OSDT (Hu et al., 2019) have straightforward extensions to the objectives listed above, namely the Upper Bound on Number of Leaves and Leaf Permutation Bound. The remainder of OSDT\u2019s bounds do not adapt. Our new bounds are the Hierarchical Objective Lower Bound, Incremental Progress Bound to Determine Splitting, Lower Bound on Incremental Progress, Equivalent Points Bound, Similar Support Bound, Incremental Similar Support Bound, and a Subset Bound. To focus our exposition, derivations and bounds for balanced classification loss, weighted classification loss, and F-score loss are in Appendix B, and derivations for AUC loss and partial AUC loss are in Appendix C, with the exception of the hierarchical lower bound for AUCch, which appears in Section 2.1 to demonstrate how these bounds work."
    },
    {
      "heading": "2.1. Hierarchical Bound for AUC Optimization",
      "text": "Let us discuss objectives that are rank statistics. If a classifier creates binary (as opposed to real-valued) predictions, its ROC curve consists of only three points (0,0), (FPR, TPR), and (1,1). The AUC of a labeled tree is the same as the balanced accuracy, because AUC = 12 ( TP N+ \u00d7 FP N\u2212 ) + (1\u2212 FPN\u2212 )\u00d7 TP N+ + 1 2 ((1\u2212 TP N+ )\u00d7(1\u2212 FP N\u2212 )), and since TP = N+ \u2212 FN , we have AUC = 12 ( N+\u2212FN N+ \u00d7 FP N\u2212 ) + (1 \u2212 FP N\u2212 )\u00d7 N+\u2212FN N+ + 1 2 ( FN N+ \u00d7 N\u2212\u2212FP N\u2212 ) = 1\u2212 1 2 ( FP N\u2212 + FN N+ ).\nThe more interesting case is when we have real-valued predictions for each leaf and use the ROC convex hull (ROCCH), defined shortly, as the objective.\nLet n+i be the number of positive samples in leaf i (n \u2212 i is the number of negatives) and let ri be the fraction of positives in leaf i. Let us define the area under the ROC convex hull (ROCCH) (Ferri et al., 2002) for a tree. For a tree d consisting ofHd distinct leaves, d = (l1, ..., lHd), we reorder leaves according to the fraction of positives, r1 \u2265 r2 \u2265 ... \u2265 rHd . For any i = 0, ...,Hd, define a labeling Si for the leaves that labels the first i leaves as positive and remaining Hd \u2212 i as negative. The collection of these labelings is \u0393 = S0, S1, ..., SHd , where each Si defines one of the Hd + 1 points on the ROCCH (see e.g., Ferri et al., 2002). The associated misranking loss is then 1-AUCch:\n`(d,x,y)=1\u2212 1 2N+N\u2212 H\u2211 i=1 n\u2212i [( i\u22121\u2211 j=1 2n+j ) +n+i ] . (2)\nNow let us derive a lower bound on the loss for trees that are incomplete, meaning that some parts of the tree are not yet fully grown. For a partially-grown tree d, the leaf set can be rewritten as d = (dfix, rfix, dsplit, rsplit,K,Hd), where dfix is a set of K fixed leaves that we choose not to split further and dsplit is the set ofHd\u2212K leaves that can be further split; this notation reflects how the algorithm works, where there are multiple copies of a tree, with some nodes allowed to be split and some that are not. rfix and rsplit are fractions of positives in the leaves. If we have a new fixed d\u2032fix, which is a superset of dfix, then we say d\u2032fix is a child of dfix. We define \u03c3(d) to be all such child trees:\n\u03c3(d) = {(d\u2032fix, r\u2032fix, d\u2032split, r\u2032split,K \u2032, H \u2032d) : dfix \u2286 d\u2032fix}. (3)\nDenote N+split and N \u2212 split as the number of positive and negative samples captured by dsplit respectively. Through additional splits, in the best case, dsplit can give rise to pure leaves, where positive ratios of generated leaves are either 1 or 0. Then the top-ranked leaf could contain up to N+split positive samples (and 0 negative samples), and the lowestranked leaf could capture as few as 0 positive samples and up to N\u2212split samples. Working now with just the leaves in dfix, we reorder the leaves in dfix by the positive ratios (rfix), such that \u2200i \u2208 {1, ...,K}, r1 > r2 > ... > rK . Combining these fixed leaves with the bounds for the split leaves, we can define a lower bound on the loss as follows.\nTheorem 2.1. (Lower bound for negative AUC convex hull) For a tree d = (dfix, rfix, dsplit, rsplit,K,Hd) using AUCch as the objective, a lower bound on the loss is\nb(dfix,x,y) 6 R(d,x,y), where:\nb(dfix,x,y) = 1\u2212 1\n2N+N\u2212 ( K\u2211 i=1 n\u2212i [ 2N+split + ( i\u22121\u2211 j=1 2n+j )\n+n+i ] + 2N+N\u2212split ) + \u03bbHd. (4)\nThis leads directly to a hierarchical lower bound for the negative of the AUC convex hull.\nTheorem 2.2. (Hierarchical objective lower bound for negative AUC convex hull) Let d = (dfix, rfix, dsplit, rsplit,K,Hd) be a tree with fixed leaves dfix and d\u2032 = (d\u2032fix, r \u2032 fix, d \u2032 split, r \u2032 split,K\n\u2032, H \u2032d) \u2208 \u03c3(d) be any child tree such that its fixed leaves d\u2032fix contain dfix, and H \u2032d > Hd, then b(dfix,x,y) 6 R(d \u2032,x,y).\nThis type of bound is the fundamental tool that we use to reduce the size of the search space: if we compare the lower bound b(dfix,x,y) for partially constructed tree d to the best current objective Rc, and find that b(dfix,x,y) \u2265 Rc, then there is no need to consider d or any subtree of d, as it is provably non-optimal. The hierarchical lower bound dramatically reduces the size of the search space. However, we also have a collection of tighter bounds at our disposal, as summarized in the next subsection.\nWe leave the description of partial AUC to Appendix C. Given a parameter \u03b8, the partial AUC of the ROCCH focuses only on the left area of the curve, consisting of the top ranked leaves, whose FPR is smaller than or equal to \u03b8. This metric is used in information retrieval and healthcare."
    },
    {
      "heading": "2.2. Summary of Bounds",
      "text": "Appendix B presents our bounds, which are crucial for reducing the search space. Appendix B presents the Hierarchical Lower Bound (Theorem B.1) for any objective (Equation 1) with an arbitrary monotonic loss function. This theorem is analogous to the Hierarchical Lower Bound for AUC optimization above. Appendix B also contains the Objective Bound with One-Step Lookahead (Theorem B.2), Objective Bound for Sub-Trees (Theorem B.3), Upper Bound on the Number of Leaves (Theorem B.4), Parent-Specific Upper Bound on the Number of Leaves (Theorem B.5), Incremental Progress Bound to Determine Splitting (Theorem B.6), Lower Bound on Incremental Progress (Theorem B.7), Leaf Permutation Bound (Theorem B.8), Equivalent Points Bound (Theorem B.9), and General Similar Support Bound (Theorem B.10). As discussed, no similar support bounds have been used successfully in prior work. In Section 4.2, we show how a new Incremental Similar Support Bound can be implemented within our specialized DPB (dynamic programming with bounds) algorithm to make decision tree optimization for\nadditive loss functions (e.g., weighted classification error) much more efficient. Bounds for AUCch and pAUCch are in Appendix C, including the powerful Equivalent Points Bound (Theorem C.3) for AUCch and pAUCch and proofs for Theorem 2.1 and Theorem 2.2. In Appendix G, we provide a new Subset Bound implemented within DPB algorithm to effectively remove thresholds introduced by continuous variables.\nNote that we do not use convex proxies for rank statistics, as is typically done in supervised ranking (learningto-rank). Optimizing a convex proxy for a rank statistic can yield results that are far from optimal (see Rudin & Wang, 2018). Instead, we optimize the original (exact) rank statistics directly on the training set, regularized by sparsity."
    },
    {
      "heading": "3. Data Preprocessing Using Bucketization Sacrifices Optimality",
      "text": "As discussed, a preprocessing step common to DL8.5 (Nijssen et al., 2020) and BinOct (Verwer & Zhang, 2019) reduces the search space, but as we will prove, also sacrifices accuracy; we refer to this preprocessing as bucketization.\nDefinition: The bucketization preprocessing step proceeds as follows. Order the observations according to any feature j. For any two neighboring positive observations, no split can be considered between them. For any two neighboring negative observations, no split can be considered between them. All other splits are permitted. While bucketization may appear innocuous, we prove it sacrifices optimality.\nTheorem 3.1. The maximum training accuracy for a decision tree on a dataset preprocessed with bucketization can be lower (worse) than the maximum accuracy for the same dataset without bucketization.\nThe proof is by construction. In Figure 1 we present a data set such that optimal training with bucketization cannot produce an optimal value of the objective. In particular, the optimal accuracy without bucketization is 93.5%, whereas the accuracy of training with bucketization is 92.2%. These numbers were obtained using BinOCT, DL8.5, and GOSDT. Remember, the algorithms provide a proof of optimality; these accuracy values are optimal, and the same values were found by all three algorithms.\nOur dataset is two-dimensional. We expect the sacrifice to become worse with higher dimensions."
    },
    {
      "heading": "4. GOSDT\u2019s DPB Algorithm",
      "text": "For optimizing non-additive loss function, we use PyGOSDT: a variant of GOSDT that is closer to OSDT (Hu et al., 2019). For optimizing additive loss functions we use GOSDT which uses dynamic programming with bounds\n(DPB) to provides a dramatic run time improvement. Like other dynamic programming approaches, we decompose a problem into smaller child problems that can be solved either recursively through a function call or in parallel by delegating work to a separate thread. For decision tree optimization, these subproblems are the possible left and right branches of a decision node.\nGOSDT maintains two primary data structures: a priority queue to schedule problems to solve and a dependency graph to store problems and their dependency relationships. We define a dependency relationship dep(p\u03c0, pc) between problems p\u03c0 and pc if and only if the solution of p\u03c0 depends on the solution of pc. Each pc is further specified as pjl or p j r indicating that it is the left or right branch produced by splitting on feature j.\nSections 4.1, 4.2, and 4.3 highlight two key differences between GOSDT and DL8.5 (since DL 8.5 also uses a form of dynamic programming): (1) DL8.5 uniquely identifies a problem p by the Boolean assertion that is a conjunctive clause of all splitting conditions in its ancestry, while GOSDT represents a problem p by the samples that satisfy the Boolean assertion. This is described in Section 4.1. (2) DL8.5 uses blocking recursive invocations to execute problems, while GOSDT uses a priority queue to schedule problems for later. This is described in Section 4.3. Section 4.4 presents additional performance optimizations. Section 4.5 presents a high-level summary of GOSDT. Note that GOSDT\u2019s DPB algorithm operates on weighted, additive, non-negative loss functions. For ease of notation, we use classification error as the loss in our exposition."
    },
    {
      "heading": "4.1. Support Set Identification of Nodes",
      "text": "GOSDT leverages the Equivalent Points Bound in Theorem B.9 to save space and computational time. To use this bound, we find the unique values of {x1, ..., xN}, denoted by {z1, ..., zU}, so that each xi equals one of the zu\u2019s. We store fractions z+u and z \u2212 u , which are the fraction of positive\nWe implement each sa as a bit-vector of length U and use it to uniquely identify a problem p in the dependency graph. The bits {sau}u of sa are defined as follows.\nsau = 1 \u21d0\u21d2 zu \u2208 sa. (6)\nWith each p, we track a set of values including its lower bound (lb) and upper bound (ub) of the optimal objective classifying its support set sa.\nIn contrast, DL8.5 identifies each problem p using Boolean assertion a rather than sa: this is an important difference between GOSDT and DL8.5 because many assertions a could correspond to the same support set sa. However, given the same objective and algorithm, an optimal decision tree for any problem p depends only on the support set sa. It does not depend on a if one already knows sa. That is, if two different trees both contain a leaf capturing the same set of samples s, the set of possible child trees for that leaf is the same for the two trees. GOSDT solves problems identified by s. This way, it simultaneously solves all problems identified by any a that produces s."
    },
    {
      "heading": "4.2. Connection to Similar Support Bound",
      "text": "No previous approach has been able to implement a similar support bound effectively. We provide GOSDT\u2019s new form of similar support bound, called the incremental similar support bound. There are two reasons why this bound works where other attempts have failed: (1) This bound works on partial trees. One does not need to have constructed a full tree to use it. (2) The bound takes into account the hierarchical objective lower bound, and hence leverages the way we search the space within the DBP algorithm. In brief, the bound effectively removes many similar trees from the search region by looking at only one of them (which does not need to be a full tree). We consider weighted, additive, non-negative loss functions: `(d,x,y) = \u2211 i weightiloss(xi, yi). Define the maximum weighted loss: `max = maxx,y[weight(x, y)\u00d7 loss(x, y)].\nTheorem 4.1. (Incremental Similar Support Bound) Consider two trees d = (dfix, dsplit,K,H) and D = (Dfix, Dsplit,K,H) that differ only by their root node (hence they share the same K and H values). Further, the root nodes between the two trees are similar enough that the support going to the left and right branches differ by at most \u03c9 fraction of the observations. (That is, there are \u03c9N observations that are captured either by the left branch of d and right branch of D or vice versa.) Define Suncertain as the maximum of the support within dsplit and Dsplit: Suncertain = max(supp(dsplit), supp(Dsplit)). For any child tree d\u2032 \u2208 \u03c3(d) grown from d (grown from the nodes in dsplit, that would not be excluded by the hierarchical objective lower bound) and for any child tree D\u2032 \u2208 \u03c3(D) grown from D (grown from nodes in Dsplit, not excluded by the hierarchical objective lower bound), we have:\n|R(d\u2032,x,y)\u2212R(D\u2032,x,y)| \u2264 (\u03c9 + 2Suncertain)`max.\nThe proof is in Appendix F. Unlike the similar support bounds in CORELS and OSDT, which require pairwise comparisons of problems, this incremental similar support bound emerges from the support set representation. The descendants \u03c3(d) and \u03c3(D) share many of the same support sets. Because of this, the shared components of their upper and lower bounds are updated simultaneously (to similar values). This bound is helpful when our data contains continuous variables: if a split at value v was already visited, then splits at values close to v can reuse prior computation to immediately produce tight upper and lower bounds."
    },
    {
      "heading": "4.3. Asynchronous Bound Updates",
      "text": "GOSDT computes the objective values hierarchically by defining the minimum objective R\u2217(p) of problem p as an aggregation of minimum objectives over the child problems pjl and p j r of p for 1 \u2264 j \u2264M .\nR\u2217(p) = min j (R\u2217(pjl ) +R \u2217(pjr)). (7)\nSince DL8.5 computes eachR\u2217(pjl ) andR \u2217(pjr) in a blocking call to the the child problems pjl and p j r, it necessarily computes R\u2217(pjl ) +R \u2217(pjr) after solving p j l and p j r, which is a disadvantage. In contrast, GOSDT computes bounds over R\u2217(pjl ) + R\n\u2217(pjr) that are available before knowing the exact values of R\u2217(pjl ) and R\n\u2217(pjr). The bounds over"
    },
    {
      "heading": "R\u2217(pjl ) and R",
      "text": "\u2217(pjr) are solved asynchronously and possibly in parallel. If for some j and j\u2032 the bounds imply that R\u2217(pjl ) + R \u2217(pjr) > R \u2217(pj \u2032 l ) + R \u2217(pj \u2032\nr ), then we can conclude that p\u2019s solution no longer depends on pjl and p j r. Since GOSDT executes asynchronously, it can draw this conclusion and focus on R\u2217(pj \u2032\nl ) + R \u2217(pj\n\u2032\nr ) without fully solving R\u2217(pjl ) +R \u2217(pjr).\nTo encourage this type of bound update, GOSDT uses the priority queue to send high-priority signals to each parent p\u03c0 of p when an update is available, prompting a recalculation of R\u2217(p\u03c0) using Equation 7."
    },
    {
      "heading": "4.4. Fast Selective Vector Sums",
      "text": "New problems (i.e., pl and pr) require initial upper and lower bounds on the optimal objective. We define the initial lower bound lb and upper bound ub for a problem p identified by support set s as follows. For 1 \u2264 u \u2264 U , define:\nzminu = min(z \u2212 u , z + u ). (8)\nThis is the fraction of minority class samples in equivalence class u. Then,\nlb = \u03bb+ \u2211 u suz min u . (9)\nThis is a basic equivalence points bound, which predicts all minority class equivalence points incorrectly. Also,\nub = \u03bb+ min (\u2211 u suz \u2212 u , \u2211 u suz + u ) . (10)\nThis upper bound comes from a baseline algorithm of predicting all one class.\nWe use the prefix sum trick in order to speed up computations of sums of a subset of elements of a vector. That is, for any vector zvec (e.g., zmin, z\u2212, z+), we want to compute a sum of a subsequence of zvec: we precompute (during preprocessing) a prefix sum vector zcumulative of the vector zvec defined by the cumulative sum zcumulativeu = \u2211u j=1 z vec j . During the algorithm, to sum over ranges of contiguous values in zvec, over some indices a through b, we now need only take zcumulative[b] \u2212 zcumulative[a \u2212 1]. This reduces a linear time calculation to constant time. This fast sum is leveraged over calculations with the support sets of input features\u2013for example, quickly determining the difference in support sets between two features."
    },
    {
      "heading": "4.5. The GOSDT Algorithm",
      "text": "Algorithm 1 constructs and optimizes problems in the dependency graph such that, upon completion, we can extract the optimal tree by traversing the dependency graph by greedily choosing the split with the lowest objective value. This extraction algorithm and a more detailed version of the GOSDT algorithm is provided in Appendix J. We present the key components of this algorithm, highlighting the differences between GOSDT and DL8.5. Note that all features have been binarized prior to executing the algorithm.\nLines 8 to 11: Remove an item from the queue. If its bounds are equal, no further optimization is possible and we can proceed to the next item on the queue.\nLines 12 to 18: Construct new subproblems, pl, pr by splitting on feature j. Use lower and upper bounds of pl and pr to compute new bounds for p. We key the problems by the bit vector corresponding to their support set s. Keying problems in this way avoids processing the same problem twice; other dynamic programming implementations, such as DL8.5, will process the same problem multiple times.\nLines 19 to 22: Update p with lb\u2032 and ub\u2032 computed using Equation 7 and propagate that update to all ancestors of p by enqueueing them with high priority (p will have multiple parents if two different conjunctions produce the same support set). This triggers the ancestor problems to recompute their bounds using Equation 7. The high priority ensures that ancestral updates occur before processing pl and pr. This scheduling is one of the key differences between GOSDT and DL8.5; by eagerly propagating bounds up the dependency tree, GOSDT prunes the search space more aggressively.\nLines 25 to 31: Enqueue pl and pr only if the interval between their lower and upper bounds overlaps with the interval between p\u2019s lower and upper bounds. This ensures that eventually the lower and upper bounds of p converge to a single value.\nLines 33 to 41: Define FIND OR CREATE NODE, which constructs (or finds an existing) problem p corresponding to support set s, initializing the lower and upper bound and checking if p is eligible to be split, using the Incremental Progress Bound to Determine Splitting (Theorem B.6) and the Lower Bound on Incremental Progress (Theorem B.7) (these bounds are checked in subroutine fails bounds). get lower bound returns lb using Equation 9. get upper bound returns ub using Equation 10.\nAn implementation of the algorithm is available at: https://github.com/Jimmy-Lin/ GeneralizedOptimalSparseDecisionTrees.\nAlgorithm 1 GOSDT(R, x, y, \u03bb)\n1: input: R, Z, z\u2212, z+, \u03bb // risk, samples, regularizer 2: Q = \u2205 // priority queue 3: G = \u2205 // dependency graph 4: s0 \u2190 {1, ..., 1} // bit-vector of 1\u2019s of length U 5: p0 \u2190 FIND OR CREATE NODE(G, s0) // root 6: Q.push(s0) // add to priority queue 7: while p0.lb 6= p0.ub do 8: s\u2190 Q.pop() // index of problem to work on 9: p\u2190 G.find(s) // find problem to work on 10: if p.lb = p.ub then 11: continue // problem already solved 12: (lb\u2032, ub\u2032)\u2190 (\u221e,\u221e) // loose starting bounds 13: for each feature j \u2208 [1,M ] do 14: sl, sr \u2190 split(s, j, Z) // create children 15: pjl \u2190FIND OR CREATE NODE(G, sl) 16: pjr \u2190FIND OR CREATE NODE(G, sr) // create bounds as if j were chosen for splitting 17: lb\u2032 \u2190 min(lb\u2032, pjl .lb+ pjr.lb) 18: ub\u2032 \u2190 min(ub\u2032, pjl .ub+ pjr.ub) // signal the parents if an update occurred 19: if p.lb 6= lb\u2032 or p.ub 6= ub\u2032 then 20: (p.lb, p.ub)\u2190 (lb\u2032, ub\u2032) 21: for p\u03c0 \u2208 G.parent(p) do // propagate information upwards 22: Q.push(p\u03c0.id,priority = 1) 23: if p.lb = p.ub then 24: continue // problem solved just now // loop, enqueue all children 25: for each feature j \u2208 [1,M ] do\n// fetch pjl and p j r in case of update\n26: repeat line 14-16 27: lb\u2032 \u2190 pjl .lb+ pjr.lb 28: ub\u2032 \u2190 pjl .ub+ pjr.ub 29: if lb\u2032 < ub\u2032 and lb\u2032 \u2264 p.ub then 30: Q.push(sl,priority = 0) 31: Q.push(sr,priority = 0) 32: return \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013 33: subroutine FIND OR CREATE NODE(G,s) 34: if G.find(s) = NULL // p not yet in graph 35: p.id\u2190 s // identify p by s 36: p.lb\u2190 get lower bound(s, Z, z\u2212, z+) 37: p.ub\u2190 get upper bound(s, Z, z\u2212, z+) 38: if fails bounds(p) then 39: p.lb = p.ub // no more splitting allowed 40: G.insert(p) // put p in dependency graph 41: return G.find(s)"
    },
    {
      "heading": "5. Experiments",
      "text": "We present details of our experimental setup and datasets in Appendix I. GOSDT\u2019s novelty lies in its ability to optimize a large class of objective functions and its ability to efficiently handle continuous variables without sacrificing optimality. Thus, our evaluation results: 1) Demonstrate our ability to optimize over a large class of objectives (AUC in particular), 2) Show that GOSDT outperforms other approaches in producing models that are both accurate and sparse, and 3) Show how GOSDT scales in its handling of continuous variables relative to other methods. In Appendix I we show time-to-optimality results.\nOptimizing Many Different Objectives: We use the FourClass dataset (Chang & Lin, 2011) to show optimal decision trees corresponding to different objectives. Figures 2 and 3 show the training ROC of decision trees generated for six different objectives and optimal trees for accuracy, AUC and partial area under ROC convex hull. Optimizing different objectives produces different trees with different FP and FN . (No other decision tree method is designed to fully optimize any objective except accuracy, so there is no comparison to other methods.)\nFigure 3. Trees for different objectives. A/B in the leaf node represents the number of positive/negative samples amongst the total samples captured in that leaf.\nBinary Datasets, Accuracy vs Sparsity: We compare\nmodels produced from BinOCT (Verwer & Zhang, 2019), CART (Breiman et al., 1984), DL8.5 (Nijssen et al., 2020), OSDT (Hu et al., 2019), and GOSDT. For each method, we select hyperparameters to produce trees of varying numbers of leaves and plot training accuracy against sparsity (number of leaves). GOSDT directly optimizes the tradeoff between training accuracy and number of leaves, producing points on the efficient frontier. Figure 4 and 5 show (1) that GOSDT typically produces excellent training and test accuracy with a reasonable number of leaves, and (2) that we can quantify how close to optimal the other methods are. Learning theory provides guarantees that training and test accuracy are close for sparse trees; more results are in Appendix I.\nContinuous Datasets, Slowdown vs Thresholds: We preprocessed by encoding continuous variables as a set of binary variables, using all possible thresholds. We then reduced the number of binary variables by combining sets of k variables for increasing values of k. Binary variables were ordered, firstly, in order of the indices of the continuous variable to which they correspond, and secondly, in order of their thresholds. We measure the slow-down introduced by increasing the number of binary variables relative\nto each algorithm\u2019s own best time. Figure 6 shows these results for CART, DL8.5, GOSDT, and OSDT. As the number of features increases (i.e., k approaches 1), GOSDT typically slows down less than DL8.5 and OSDT. This relatively smaller slowdown allows GOSDT to handle more thresholds introduced by continuous variables.\nAppendix I presents more results including training times several orders of magnitude better than the state-of-the-art.\nAn implementation of our experiments is available at: https://github.com/Jimmy-Lin/ TreeBenchmark."
    },
    {
      "heading": "6. Discussion and Future Work",
      "text": "GOSDT (and related methods) differs fundamentally from other types of machine learning algorithms. Unlike neural networks and typical decision tree methods, it provides a proof of optimality for highly non-convex problems. Unlike support vector machines, ensemble methods, and neural networks again, it produces sparse interpretable models without using convex proxies\u2013it solves the exact problem of interest in an efficient and provably optimal way. As usual, statistical learning theoretic guarantees on test\nerror are the tightest for simpler models (sparse models) with the lowest empirical error on the training set, hence the choice of accuracy, regularized by sparsity (simplicity). If GOSDT is stopped early, it reports an optimality gap, which allows the user to assess whether the tree is sufficiently close to optimal, retaining learning theoretic guarantees on test performance. GOSDT is most effective for datasets with a small or medium number of features. The algorithm scales well with the number of observations, easily handling tens of thousands.\nThere are many avenues for future work. Since GOSDT provides a framework to handle objectives that are monotonic in FP and FN , one could create many more objectives than we have enumerated here. Going beyond these objectives to handle other types of monotonicity, fairness, ease-of-use, and cost-related soft and hard constraints are natural extensions. There are many avenues to speed up GOSDT related to exploration of the search space, garbage collection, and further bounds."
    },
    {
      "heading": "A. Comparison Between Decision Tree Methods",
      "text": "(Garofalakis et al., 2003), and CART (Breiman et al., 1984). Green is a comparative advantage. Red is a comparative disadvantage. Blue highlights dynamic programming-based methods. White is neutral."
    },
    {
      "heading": "B. Objectives and Their Lower Bounds for Arbitrary Monotonic Losses",
      "text": "Before deriving the bounds for arbitrary monotonic losses, we first introduce some notation. As we know, a leaf set d = (l1, l2, ..., lHd) containsHd distinct leaves, where li is the classification rule of the leaf i. If a leaf is labeled, then y (leaf) i is the label prediction for all data in leaf i. Therefore, a labeled partially-grown tree d with the leaf set d = (l1, l2, ..., lHd) could be rewritten as d = (dfix, \u03b4fix, dsplit, \u03b4split,K,Hd), where dfix = (l1, l2, ..., lK) is a set of K fixed leaves that are not permitted to be further split, \u03b4fix = (y (leaf) 1 , y (leaf) 2 , ..., y (leaf) K ) \u2208 {0, 1}K are the predicted labels for leaves dfix, dsplit = (lK+1, lK+2..., lHd) is the set of Hd \u2212K leaves that can be further split, and \u03b4split = (y (leaf) K+1, y (leaf) K+2, ..., y (leaf) Hd\n) \u2208 {0, 1}K are the predicted labels for leaves dsplit.\nB.1. Hierarchical objective lower bound for arbitrary monotonic losses\nTheorem B.1. (Hierarchical objective lower bound for arbitrary monotonic losses) Let loss function `(d,x,y) be monotonically increasing in FP and FN . We now change notation of the loss to be only a function of these two quantities, written now as \u02dc\u0300(FP, FN). Let d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) be a labeled tree with fixed leaves dfix, and let FPfix and FNfix be the false positives and false negatives of dfix. Define the lower bound to the risk R(d,x,y) as follows (taking the lower bound of the split terms to be 0):\nR(d,x,y) \u2265 b(dfix,x,y) = `(dfix,x,y) + \u03bbH = \u02dc\u0300(FPfix, FNfix) + \u03bbH.\nLet d\u2032 = (d\u2032fix, \u03b4 \u2032 fix, d \u2032 split, \u03b4 \u2032 split,K \u2032, H \u2032) \u2208 \u03c3(d) be any child tree of d such that its fixed leaves d\u2032fix contain dfix and K \u2032 > K and H \u2032 > H . Then, b(dfix,x,y) 6 R(d\u2032,x,y).\nThe importance of this result is that the lower bound works for all (allowed) child trees of d. Thus, if d can be excluded via the lower bound, then all of its children can too.\nProof. Let FPfix and FNfix be the false positives and false negatives within leaves of dfix, and let FPsplit and FNsplit be the false positives and false negatives within leaves of dsplit. Similarly, denote FPfix\u2032 and FNfix\u2032 as the false positives and false negatives of d\u2032fix and let FPsplit\u2032 and FNsplit\u2032 be the false positives and false negatives of d \u2032 split. Since the leaves are mutually exclusive, FPd = FPfix + FPsplit and FNd = FNfix + FNsplit. Moreover, since \u02dc\u0300(FP, FN) is monotonically increasing in FP and FN , we have:\nR(d,x,y) = \u02dc\u0300(FPd, FNd) + \u03bbH > \u02dc\u0300(FPfix, FNfix) + \u03bbH = b(dfix,x,y). (11)\nSimilarly, R(d\u2032,x,y) > b(d\u2032fix,x,y). Since dfix \u2286 dfix\u2032 , FPfix\u2032 > FPfix and FNfix\u2032 > FNfix, thus \u02dc\u0300(FPfix\u2032 , FNfix\u2032) > \u02dc\u0300(FPfix, FNfix). Combined with H \u2032 > H , we have:\nb(dfix,x,y) = \u02dc\u0300(FPfix, FNfix) + \u03bbH 6 \u02dc\u0300(FPfix\u2032 , FNfix\u2032) + \u03bbH \u2032 = b(d\u2032fix,x,y) 6 R(d \u2032,x,y). (12)\nLet us move to the next bound, which is the one-step lookahead. It relies on comparing the best current objective we have seen so far, denoted Rc, to the lower bound. Theorem B.2. (Objective lower bound with one-step lookahead) Let d be a H-leaf tree with K leaves fixed and let Rc be the current best objective. If b(dfix,x,y) + \u03bb > Rc, then for any child tree d\u2032 \u2208 \u03c3(d), its fixed leaves d\u2032fix include dfix and H \u2032 > H . It follows that R(d\u2032,x,y) > Rc.\nProof. According to definition of the objective lower bound,\nR(d\u2032,x,y) > b(d\u2032fix,x,y) = \u02dc\u0300(FPfix\u2032 , FNfix\u2032) + \u03bbH \u2032\n= \u02dc\u0300(FPfix\u2032 , FNfix\u2032) + \u03bbH + \u03bb(H \u2032 \u2212H) > b(dfix,x,y) + \u03bb > R c,\n(13)\nwhere on the last line we used that since H \u2032 and H are both integers, then H \u2032 \u2212H \u2265 1.\nAccording to this bound, even though we might have a tree d whose fixed leaves dfix obeys lower bound b(dfix,x,y) 6 Rc, its child trees may still all be guaranteed to be suboptimal: if b(dfix,x,y) + \u03bb > Rc, none of its child trees can ever be an optimal tree. Theorem B.3. (Hierarchical objective lower bound for sub-trees and additive losses) Let loss functions `(d,x,y) be monotonically increasing in FP and FN , and let the loss of a tree d be the sum of the losses of the leaves. Let Rc be the current best objective. Let d be a tree such that the root node is split by a feature, where two sub-trees dleft and dright are generated with Hleft leaves for dleft and Hright leaves for dright. The data captured by the left tree is (xleft,yleft) and the data captured by the right tree is (xright,yright). Let b(dleft,xleft,yleft) and b(dright,xright,yright) be the objective lower bound of the left sub-tree and right sub-tree respectively such that b(dleft,xleft,yleft) 6 `(dleft,xleft,yleft) + \u03bbHleft and b(dright,xright,yright) 6 `(dright,xright,yright) + \u03bbHright. If b(dleft,xleft,yleft) > Rc or b(dright,xright,yright) > Rc or b(dleft,xleft,yleft) + b(dright,xright,yright) > R c, then the tree d is not the optimal tree.\nThis bound is applicable to any tree d, even if part of it has not been constructed yet. That is, if a partially-constructed d\u2019s left lower bound or right lower bound, or the sum of left and right lower bounds, exceeds the current best risk Rc, then we do not need to construct d since we have already proven it to be suboptimal from its partial construction.\nProof. R(d,x,y) = `(d,x,y) + \u03bbH = `(dleft,xleft,yleft) + `(dright,xright,yright) + \u03bbHleft + \u03bbHright > b(dleft,xleft,yleft) + b(dright,xright,yright). If b(dleft,xleft,yleft) > Rc or b(dright,xright,yright) > Rc or b(dleft,xleft,yleft) + b(dright,xright,yright) > Rc, then R(d,x,y) > Rc. Therefore, the tree d is not the optimal tree.\nB.2. Upper bound on the number of leaves\nTheorem B.4. (Upper bound on the number of leaves) For a dataset withM features, consider a state space of all trees. Let H be the number of leaves of tree d and let Rc be the current best objective. For any optimal tree d\u2217 \u2208 argmindR(d,x,y), its number of leaves obeys:\nH\u2217 6 min([Rc/\u03bb], 2M ) (14)\nwhere \u03bb is the regularization parameter.\nProof. This bound adapts directly from OSDT (Hu et al., 2019), where the proof can be found.\nTheorem B.5. (Parent-specific upper bound on the number of leaves) Let d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) be a tree, d\u2032 = (d\u2032fix, \u03b4 \u2032 fix, d \u2032 split, \u03b4 \u2032 split,K\n\u2032, H \u2032) \u2208 \u03c3(d) be any child tree such that dfix \u2286 d\u2032fix, and Rc be the current best objective. If d\u2032fix has lower bound b(d \u2032 fix,x,y) < R c, then\nH \u2032 < min ( H + [ Rc \u2212 b(dfix,x,y)\n\u03bb\n] , 2M ) . (15)\nwhere \u03bb is the regularization parameter.\nProof. This bound adapts directly from OSDT (Hu et al., 2019), where the proof can be found.\nB.3. Incremental Progress Bound to Determine Splitting and Lower Bound on Incremental Progress\nIn the implementation, Theorem B.6 below is used to check if a leaf node within dsplit is worth splitting. If the bound is satisfied and the leaf can be further split, then we generate new leaves and Theorem B.7 is applied to check if this split yields new nodes or leaves that are good enough to consider in the future. Let us give an example to show how Theorem B.6 is easier to compute than Theorem B.7. If we are evaluating a potential split on leaf j, Theorem B.6 requires FPj and FNj which are the false positives and false negatives for leaf j, but no extra information about the split we are going to make, whereas Theorem B.7 requires that additional information. Let us work with balanced accuracy as the loss function: for Theorem B.6 below, we would need to compute \u03c4 = 12 ( FNj N+ + FPj N\u2212 ) but for Theorem B.7 below we would need to calculate quantities for the new leaves we would form by splitting j into child leaves i and i+ 1. Namely, we would need FNi, FNi+1, FPi, and FPi+1 as well.\nTheorem B.6. (Incremental progress bound to determine splitting) Let d\u2217 = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) be any optimal tree with objective R\u2217, i.e., d\u2217 \u2208 argmindR(d,x,y). Consider tree d\u2032 derived from d\u2217 by deleting a pair of leaves li and li+1 and adding their parent leaf lj , d\u2032 = (l1, ..., li\u22121, li+2, ..., lH , lj). Let \u03c4 := \u02dc\u0300(FPd\u2032 , FNd\u2032)\u2212 \u02dc\u0300(FPd\u2032 \u2212FPlj , FNd\u2032 \u2212 FNlj ). Then, \u03c4 must be at least \u03bb.\nProof. `(d\u2032,x,y) = \u02dc\u0300(FPd\u2032 , FNd\u2032) and `(d\u2217,x,y) = \u02dc\u0300(FPd\u2032+FPli +FPli+1\u2212FPlj , FNd\u2032+FNli +FNli+1\u2212FNlj ). The difference between `(d\u2217,x,y) and `(d\u2032,x,y) is maximized when li and li+1 correctly classify all the captured data. Therefore, \u03c4 is the maximal difference between `(d\u2032,x,y) and `(d\u2217,x,y). Since l(d\u2032,x,y)\u2212 `(d\u2217,x,y) 6 \u03c4 , we can get `(d\u2032,x,y) + \u03bb(H \u2212 1) 6 `(d\u2217,x,y) + \u03bb(H \u2212 1) + \u03c4 , that is (and remember that d\u2217 is of size H whereas d\u2032 is of size H\u22121),R(d\u2032,x,y) 6 R(d\u2217,x,y)\u2212\u03bb+\u03c4 . Since d\u2217 is optimal with respect toR, 0 6 R(d\u2032,x,y)\u2212R(d\u2217,x,y) 6 \u2212\u03bb+\u03c4 , thus, \u03c4 > \u03bb.\nHence, for a tree d, if any of its internal nodes contributes less than \u03bb in loss, even though b(dfix,x,y) 6 R\u2217, it cannot be the optimal tree and none of its child tree could be the optimal tree. Thus, after evaluating tree d, we can prune it.\nTheorem B.7. (Lower bound on incremental progress) Let d\u2217 = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) be any optimal tree with objective R\u2217, i.e., d\u2217 \u2208 argmindR(d,x,y). Let d\u2217 have leaves dfix = (l1, ..., lH) and \u03b4fix = (y (leaf) 1 , y (leaf) 2 , ..., y (leaf) H ). Consider tree d\u2032 derived from d\u2217 by deleting a pair of leaves li and li+1 with corresponding labels y leaf i and y leaf i+1 and adding their parent leaf lj and its label y leaf j . Define ai as the incremental objective of splitting lj to get li, li+1: ai := `(d\u2032,x,y)\u2212 `(d\u2217,x,y). In this case, \u03bb provides a lower bound s.t. ai > \u03bb.\nProof. Let d\u2032 = (d\u2032fix, \u03b4 \u2032 fix, d \u2032 split, \u03b4 \u2032 split,K \u2032, H \u2032) be the tree derived from d\u2217 by deleting a pair of leaves li and li+1, and adding their parent leaf lj . Then,\nR(d\u2032,x,y) = `(d\u2032,x,y) + \u03bb(H \u2212 1) = ai + l(d\u2217,x,y) + \u03bb(H \u2212 1) = ai +R(d \u2217,x,y)\u2212 \u03bb. (16)\nSince 0 6 R(d\u2032,x,y)\u2212R(d\u2217,x,y), then ai > \u03bb.\nIn the implementation, we apply both Theorem B.6 and Theorem B.7. If Theorem B.6 is not satisfied, even though b(dfix,x,y) 6 R\u2217, it cannot be an optimal tree and none of its child trees could be an optimal tree. In this case, d can be pruned, as we showed before. However, if Theorem B.6 is satisfied, we check Theorem B.7. If Theorem B.7 is not satisfied, then we would need to further split at least one of the two child leaves\u2013either of the new leaves i or i+ 1\u2013in order to obtain a potentially optimal tree."
    },
    {
      "heading": "B.4. Permutation Bound",
      "text": "Theorem B.8. (Leaf Permutation bound) Let \u03c0 be any permutation of {1, ...,H}. Let d = (dfix, dsplit,K,H) and D = (Dfix, Dsplit,K,H) be trees with leaves (l1, ..., lH) and (l\u03c0(1), ..., l\u03c0(H)) respectively, i.e., the leaves in D correspond to a permutation of the leaves in d. Then the objective lower bounds of d and D are the same and their child trees correspond to permutations of each other.\nProof. This bound adapts directly from OSDT (Hu et al., 2019), where the proof can be found.\nTherefore, if two trees have the same leaves, up to a permutation, according to Theorem B.8, one of them can be pruned. This bound is capable of reducing the search space by all future symmetries of trees we have already seen."
    },
    {
      "heading": "B.5. Equivalent Points Bound",
      "text": "As we know, for a tree d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H), the objective of this tree (and that of its children) is minimized when there are no errors in the split leaves: FPsplit = 0 and FNsplit = 0. In that case, the risk is equal to b(dfix,x,y). However, if multiple observations captured by a leaf in dsplit have the same features but different labels, then no tree, including those that extend dsplit, can correctly classify all of these observations, that is FPsplit and FNsplit cannot be zero. In this case, we can apply the equivalent points bound to give a tighter lower bound on the objective.\nLet \u2126 be a set of leaves. Capture is an indicator function that equals 1 if xi falls into one of the leaves in \u2126, and 0 otherwise, in which case we say that cap(xi,\u2126) = 1. We define a set of samples to be equivalent if they have exactly the same feature values. Let eu be a set of equivalent points and let qu be the minority class label that minimizes the loss among points in eu. Note that a dataset consists of multiple sets of equivalent points. Let {eu}Uu=1 enumerate these sets.\nTheorem B.9. (Equivalent points bound) Let d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) be a tree such that lk \u2208 dfix for k \u2208 {1, ...,K} and lk \u2208 dsplit for k \u2208 {K + 1, ...,H}. For any tree d\u2032 \u2208 \u03c3(d),\n`(d\u2032,x,y) > \u02dc\u0300(FPfix + FPe, FNfix + FNe), where (17)\nFPe = N\u2211 i=1 U\u2211 u=1 H\u2211 k=K+1 cap(xi, lk) \u2227 1[yi = 0] \u2227 1[xi \u2208 eu]1[yi = qu]\nFNe = N\u2211 i=1 U\u2211 u=1 H\u2211 k=K+1 cap(xi, lk) \u2227 1[yi = 1] \u2227 1[xi \u2208 eu]1[yi = qu].\n(18)\nProof. Since d\u2032 \u2208 \u03c3(d), d\u2032 = (l\u20321, ..., l\u2032K , l\u2032K+1, ..., l\u2032K\u2032 , ..., lH\u2032) where we have both l\u2032k \u2208 d\u2032fix for k \u2208 {1, ...,K \u2032}, which are the fixed leaves and also l\u2032k \u2208 d\u2032split for k \u2208 {K \u2032 + 1, ...,H \u2032}. Note that for k \u2208 {1, ...,K}, l\u2032k = lk.\nLet \u2206 = d\u2032fix\\dfix which are the leaves in d\u2032fix that are not in dfix. Then `(d\u2032,x,y) = \u02dc\u0300(FPd\u2032 , FNd\u2032) = \u02dc\u0300(FPfix + FP\u2206 + FPsplit\u2032 , FNfix + FN\u2206 + FNsplit\u2032), where FP\u2206 and FN\u2206 are false positives and false negatives in d\u2032fix but not dfix and FPsplit\u2032 and FNsplit\u2032 are false positives and false negatives in d\u2032split. For tree d \u2032, its leaves in \u2206 are those indexed from K to\nK \u2032. Thus, the sum over leaves of d\u2032 from K to H \u2032 includes leaves from \u2206 and leaves from d\u2032split.\nFP\u2206 + FPsplit\u2032 = N\u2211 i=1 U\u2211 u=1 H\u2032\u2211 k=K+1 cap(xi, l\u2032k) \u2227 1[yi 6= y\u0302 (leaf) k ] \u2227 1[yi = 0] \u2227 1[xi \u2208 eu]\n> N\u2211 i=1 U\u2211 u=1 H\u2032\u2211 k=K+1 cap(xi, l\u2032k) \u2227 1[yi = 0] \u2227 1[xi \u2208 eu]1[yi = qu]\nFN\u2206 + FNsplit\u2032 = N\u2211 i=1 U\u2211 u=1 H\u2032\u2211 k=K+1 cap(xi, l\u2032k) \u2227 1[yi 6= y\u0302 (leaf) k ] \u2227 1[yi = 1] \u2227 1[xi \u2208 eu]\n> N\u2211 i=1 U\u2211 u=1 H\u2032\u2211 k=K+1 cap(xi, l\u2032k) \u2227 1[yi = 1] \u2227 1[xi \u2208 eu]1[yi = qu].\n(19)\nFor i \u2208 {1, ..., N}, the samples in dsplit are the same ones captured by either \u2206 or d\u2032split, that is \u2211H k=K+1 cap(xi, lk) =\u2211H\u2032\nk=K+1 cap(xi, l \u2032 k). Then\nFP\u2206 + FPsplit\u2032 > N\u2211 i=1 U\u2211 u=1 H\u2211 k=K+1 cap(xi, lk) \u2227 1[yi = 0] \u2227 1[xi \u2208 eu]1[yi = qu] = FPe. (20)\nSimilarly, FN\u2206 + FNsplit\u2032 > FNe. Therefore,\n`(d\u2032,x,y) = \u02dc\u0300(FPfix + FP\u2206 + FPsplit\u2032 , FNfix + FN\u2206 + FNsplit\u2032) > \u02dc\u0300(FPfix + FPe, FNfix + FNe). (21)"
    },
    {
      "heading": "B.6. Similar Support Bound",
      "text": "Given two trees that are exactly the same except for one internal node split by different features f1 and f2, we can use the similar support bound for pruning.\nTheorem B.10. (Similar support bound) Define d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) and D = (Dfix,\u2206fix, Dsplit,\u2206split,K,H) to be two trees that are exactly the same except for one internal node split by different features. Let f1 and f2 be the features used to split that node in d and D respectively. Let t1, t2 be the left and right sub-trees under the node f1 in d and let T1, T2 be the left and right sub-trees under the node f2 in D. Let \u03c9 be the observations captured by only one of t1 or T1, i.e.,\n\u03c9 := {i : [cap(xi, t1) \u2227 \u00accap(xi, T1) + \u00accap(xi, t1) \u2227 cap(xi, T1)]}. (22)\nLet FP\u2212\u03c9 and FN\u2212\u03c9 be the false positives and false negatives of samples except \u03c9. The difference between the two trees\u2019 objectives is bounded as follows:\n|R(d,x,y)\u2212R(D,x,y)| 6 \u03b3, where (23)\n\u03b3 := max a\u2208{0,...,|\u03c9|}\n[\u02dc\u0300(FP\u2212\u03c9 + a, FN\u2212\u03c9 + |\u03c9| \u2212 a)]\u2212 \u02dc\u0300(FP\u2212\u03c9, FN\u2212\u03c9). (24)\nThen we have \u2223\u2223\u2223\u2223 min d+\u2208\u03c3(d) R(d+,x,y)\u2212 min D+\u2208\u03c3(D) R(D+,x,y) \u2223\u2223\u2223\u2223 6 \u03b3. (25) Proof. The difference between the objectives of d and D is largest when one of them correctly classifies all the data in \u03c9 but the other misclassifies all of them. If d classifies all the data corresponding to \u03c9 correctly while D misclassifies them,\nR(d,x,y)\u2212R(D,x,y) > \u02dc\u0300(FP\u2212\u03c9, FN\u2212\u03c9)\u2212 max a\u2208{0,...,|\u03c9|} [\u02dc\u0300(FP\u2212\u03c9 + a, FN\u2212\u03c9 + |\u03c9| \u2212 a)] = \u2212\u03b3. (26)\nWe can get R(d,x,y)\u2212R(D,x,y) 6 \u03b3 in the same way. Therefore, \u03b3 > R(d,x,y)\u2212R(D,x,y) > \u2212\u03b3.\nLet d\u2217 be the best child tree of d, i.e., R(d\u2217,x,y) = mind+\u2208\u03c3(d)R(d+,x,y). Let D\u2032 \u2208 \u03c3(D) be its counterpart which is exactly the same except for one internal node split by a different feature. Then, using Equation 26,\nmin d+\u2208\u03c3(d) R(d+,x,y) = R(d\u2217,x,y) > R(D\u2032,x,y)\u2212 \u03b3 > min D+\u2208\u03c3(D) R(D+,x,y)\u2212 \u03b3. (27)\nSimilarly, using the symmetric counterpart to Equation 26 and the same logic, min D+\u2208\u03c3(D) R(D+,x,y) + \u03b3 >\nmin d+\u2208\u03c3(d)\nR(d+,x,y)."
    },
    {
      "heading": "C. Objectives and Their Lower Bounds for Rank Statistics",
      "text": "In this appendix, we provide proofs for Theorem 2.1 and Theorem 2.2, and adapt the Incremental Progress Bound to Determine Splitting and the Equivalent Points Bound for the objective AUCch. The Upper Bound on the Number of Leaves, Parent-Specific Upper Bound on the Number of Leaves, Lower Bound of Incremental Progress, and Permutation Bound are the same as the bounds in Appendix B. We omit these duplicated proofs here. At the end of this appendix, we define the objective pAUCch and how we implement the derived bounds for this objective. As a reminder, we use notation d = (dfix, rfix, dsplit, rsplit,K,Hd) to represent tree d.\nLemma C.1. Let d = (dfix, rfix, dsplit, rsplit,K,Hd) be a tree. The AUC convex hull does not decrease when an impure leaf is split.\nProof. Let li be the impure leaf that we intend to split, where i \u2208 {1, ...,Hd}. Let n+i be the positive samples in li and n \u2212 i negative samples. Suppose li is ranked in position \u201cpos.\u201d If the leaf is split once, it will generate two leaves li1 and li2 such that ri1 \u2265 ri \u2265 ri2 without loss of generality. Let d\u2032 be the tree that consists of the leaf set (l1, ..., li\u22121, li+1, ..., lHd , li1 , li2). If ri1 = ri = ri2 , then the rank order of leaves (according to the ri\u2019s) will not change, so AUCch will be unchanged after the split. Otherwise (if the rank order of leaves changes when introducing a child) we can reorder theH+1 leaves, leading to the following four cases. For the new leaf set (l1, ..., li\u22121, li+1, ..., lHd , li1 , li2), either:\n1. The rank of li1 is smaller than pos and the rank of li2 equals pos + 1 (requires ri1 > ri and ri \u2265 ri2 ); 2. The rank of li1 is smaller than pos and the rank of li2 is larger than pos + 1 (requires ri1 > ri and ri > ri2 ); 3. The rank of li1 is equal to pos and the rank of li2 is equal to pos + 1 (requires ri1 \u2265 ri and ri \u2265 ri2 ); 4. The rank of li1 is pos and the rank of li2 is larger than pos + 1 (requires ri1 \u2265 ri and ri > ri2 ).\nFigure 7 shows four cases of the positions of li1 and li2 .\nLet us go through these cases in more detail.\nFor the new leaf set after splitting li, namely (l1, ..., li\u22121, li+1, ..., lHd , li1 , li2), we have that:\n1. li1 has rank smaller than pos (which requires ri1 > ri) and li2 has rank pos + 1 (which requires ri \u2265 ri2 ). Let A = {la1 , la2 , ...laU } be a collection of leaves ranked before li1 and let B = {lb1 , lb2 , ...lbV } be a collection of leaves ranked after li1 but before pos + 1. In this case, recalling Equation (2), a change in the AUCch after splitting on leaf i is due only to a subset of leaves, namely li1 , lb1 , ..., lbV , li2 . Then we can compute the change in the AUCch as\nfollows:\n\u2206AUCch = 1\nN+N\u2212\n( n\u2212i1n + i1\n2 + ( V\u2211 v=1 n\u2212bv ) n+i1 + n \u2212 i2 [ n+i1 + ( V\u2211 v=1 n+bv ) + n+i2 2 ] \u2212 n\u2212i [( V\u2211 v=1 n+bv ) + n+i 2 ]) (28)\nTo derive the expression for \u2206AUCch , we first sum shaded areas of rectangles and triangles under the ROC curves\u2019 convex hull for both tree d and its child tree d\u2032, and then calculate the difference between the two shaded areas, as indicated in Figure 8 (a-c). This figure shows where each of the terms arises within the \u2206AUCch : terms n \u2212 bv n+i1 and n\u2212i2 [n + i1 + ( \u2211V v=1 n + bv )] come from the area of rectangles colored in dark pink in Figure 8 (b). Terms n\u2212i1 n+i1 2 and n\u2212i2 n+i2 2\nhandle the top triangles colored in light pink. Term n\u2212i ( \u2211V v=1 n + bv ) represents the rectangles colored in dark green in Figure 8 (a) and term n \u2212 i n + i\n2 deals with the triangles colored in light green. Subtracting green shaded areas from red shaded areas, we get \u2206AUCch , which is represented by the (remaining) pink area in Figure 8 (c).\nSimplifying Equation (28), we get\n\u2206AUCch = 1\nN+N\u2212\n( n+i1 ( V\u2211 v=1 n\u2212bv ) +n\u2212i2 ( V\u2211 v=1 n+bv ) \u2212n\u2212i ( V\u2211 v=1 n+bv ) + n\u2212i1n + i1 + 2n\u2212i2n + i1 + n\u2212i2n + i2 \u2212 n\u2212i n + i 2 ) . (29)\nRecall that n\u2212i = n \u2212 i1 + n\u2212i2 and n + i = n + i1 + n+i2 . Then, simplifying,\n\u2206AUCch = 1\nN+N\u2212\n( n+i1 ( V\u2211 v=1 n\u2212bv ) \u2212 n\u2212i1 ( V\u2211 v=1 n+bv ) + n+i1n \u2212 i2 \u2212 n\u2212i1n + i2 2 ) . (30)\nSince ri1 > rb1 > rb2 > ... > rbV , \u2200v \u2208 {1, 2, ..., V }, n+i1\nn+i1 +n\u2212i1\n> n+bv\nn+bv+n \u2212 bv\n. Then we can get n+i1n \u2212 bv > n+bvn \u2212 i1 . Hence\nn+i1( \u2211V v=1 n \u2212 bv ) \u2212 n\u2212i1( \u2211V v=1 n + bv ) > 0. Similarly, because ri1 > ri2 , n+i1\nn+i1 +n\u2212i1\n> n+i2\nn+i2 +n\u2212i2\n. Then n+i1n \u2212 i2 > n\u2212i1n + i2 .\nTherefore, \u2206AUCch > 0.\n2. li1 has a ranking smaller than pos (which requires ri1 > ri) and li2 has a ranking larger than pos + 1 (which requires ri > ri2 ).\nLet A = {la1 , ...laU } be a collection of leaves that ranked before li1 and B = {lb1 , ...lbV } be a collection of leaves that ranked after li1 but before pos + 1, and C = {lc1 , ..., lcW } be a collection of leaves that ranked after pos + 1 but before the rank of li2 . In this case, the change is caused by li1 , lb1 , ..., lbV , lc1 , ..., lcW , li2 . Then we can compute the change in the AUCch as follows:\n\u2206AUCch = 1\nN+N\u2212\n( n\u2212i1n + i1\n2 + ( V\u2211 v=1 n\u2212bv ) n+i1 + ( W\u2211 w=1 n\u2212cw ) n+i1 + n \u2212 i2 [ n+i1 + ( V\u2211 v=1 n+bv ) + ( W\u2211 w=1 n+cw ) + n+i2 2 ]\n\u2212 n\u2212i [( V\u2211\nv=1\nn+bv ) + n+i 2 ] \u2212 ( W\u2211 w=1 n\u2212cw ) n+i ) .\n(31) Similar to the derivation proposed in case 1, we first sum shaded areas of rectangles and triangles under the ROC curves\u2019 convex hull for both tree d and its child tree d\u2032 and then calculate the difference between two shaded areas as indicated in Figure 8 (d-f). These three subfigures show where each of the terms arises within the \u2206AUCch : terms n \u2212 bv n+i1 , n \u2212 cwn + i1\n, and n\u2212i2 [n + i1 +( \u2211V v=1 n + bv )+( \u2211W w=1 n + cw)] come from the area of rectangles colored in dark pink in Figure 8 (e). Terms n\u2212i1 n+i1 2 and n\u2212i2 n+i2 2 handle the top triangles colored in light pink. Terms n \u2212 i n + bv and n+i n \u2212 cw represent the rectangles colored in dark green in Figure 8 (d) and term n \u2212 i n + i\n2 deals with the triangles colored in light green. Subtracting green shaded areas from red shaded areas, we can get \u2206AUCch , which is represented by the light red area in Figure 8 (f). Recall that n\u2212i = n \u2212 i1 + n\u2212i2 and n + i = n + i1 + n+i2 . Then, simplifying Equation (31), we get\n\u2206AUCch = 1\nN+N\u2212 (( V\u2211 v=1 n\u2212bv ) n+i1 + ( W\u2211 w=1 n\u2212cw ) n+i1 + ( V\u2211 v=1 n+bv ) n\u2212i2 + ( W\u2211 w=1 n+cw ) n\u2212i2 \u2212 ( V\u2211 v=1 n+bv ) n\u2212i\n\u2212 ( W\u2211 w=1 n\u2212cw ) n+i + n\u2212i1n + i1 + 2n\u2212i2n + i1 + n\u2212i2n + i2 \u2212 n\u2212i n + i 2 )\n= 1\nN+N\u2212 (( V\u2211 v=1 n\u2212bv ) n+i1 \u2212 ( V\u2211 v=1 n+bv ) n\u2212i1 + ( W\u2211 w=1 n+cw ) n\u2212i2 \u2212 ( W\u2211 w=1 n\u2212cw ) n+i2 + n\u2212i2n + i1 \u2212 n\u2212i1n + i2 2 ) .\n(32)\nSince ri1 > rb1 > ... > rbV , \u2200v \u2208 {1, ..., V }, n+i1\nn+i1 +n\u2212i1\n> n+bv\nn+bvn \u2212 bv\n. Then we get n+i1n \u2212 bv > n+bvn \u2212 i1 . Thus, ( \u2211V v=1 n \u2212 bv )n+i1 \u2212 ( \u2211V v=1 n + bv )n\u2212i1 > 0. Similarly, since rc1 > ... > rcW > ri2 , \u2200w \u2208 {1, ...,W}, n + cwn \u2212 i2 > n+i2n \u2212 cw .\nThus, ( \u2211W w=1 n + cw)n \u2212 i2 \u2212 ( \u2211W w=1 n \u2212 cw)n + i2 > 0. Moreover, because ri1 > ri2 , n \u2212 i2 n+i1 > n \u2212 i1 n+i2 . Hence, \u2206AUCch > 0.\n3. li1 has a ranking same as pos (which requires ri1 \u2264 ri) and li2 has a ranking pos + 1 (which requires ri \u2264 ri2 ). In this case, the change of AUCch is caused by li1 and li2 . Then we compute the change in the AUCch as follows:\n\u2206AUCch = 1\nN+N\u2212\n( n\u2212i1n + i1\n2 + n\u2212i2n + i1\n+ n\u2212i2n + i2\n2 \u2212 n\n\u2212 i n + i\n2\n) . (33)\nWe derive the expression in the similar way as case 1 and case 2. Term n\u2212i2n + i1 comes from the area of rectangle colored in dark pink in Figure 8 (h) and terms n\u2212i1\nn+i1 2 and n\u2212i2 n+i2 2 handle the top triangles colored in light pink. Term n\u2212i n + i\n2 deals with the top triangle colored in light green in Figure 8 (g). Subtracting green shaded areas from pink shaded areas, we get \u2206AUCch , which is represented by the (remaining) pink area in Figure 8 (i). Recall n\u2212i = n \u2212 i1 + n\u2212i2 and n + i = n + i1 + n+i2 . Simplifying Equation (33), we get\n\u2206AUCch = 1\nN+N\u2212\n( n+i1n \u2212 i2 \u2212 n+i2n \u2212 i1\n2\n) (34)\nSince ri1 > ri2 , n + i1 n\u2212i2 \u2212 n + i2 n\u2212i1 . Therefore, \u2206AUCch > 0.\n4. li1 has a ranking same as pos (which requires ri1 \u2264 ri) and li2 has a ranking larger than pos + 1 (which requires ri > ri2 ).\nLet A = {la1 , ..., laU } be a collection of leaves that ranked before li1 and B = {lb1 , ..., lbV } be a collection of leaves that ranked after li1 but before li2 . In this case the change of AUCch is caused by li1 , lb1 , ..., lbV , li2 . Then we can compute the change as follows:\n\u2206AUCch = 1\nN+N\u2212\n( n\u2212i1n + i1\n2 + ( V\u2211 v=1 n\u2212bv ) n+i1 + n \u2212 i2 [ n+i1 + ( V\u2211 v=1 n+bv ) + n+i2 2 ] \u2212 n \u2212 i n + i 2 \u2212 ( V\u2211 v=1 n\u2212bv ) n+i ) (35)\nThe Figure 8 (j-l) show where each of the terms arises within the \u2206AUCch : terms n \u2212 bv n+i1 and n \u2212 i2 [n+i1 + ( \u2211V v=1 n + bv )] come from the area of rectangles colored in dark pink in Figure 8 (k) and terms n\u2212i1\nn+i1 2 and n\u2212i2 n+i2 2 handle triangles\ncolored in light pink. Term n\u2212bvn + i represents the rectangle colored in dark green in Figure 8 (j) and term\nn\u2212i n + i\n2 deals with the triangle colored in light green. Subtracting green shaded areas from pink shaded areas, we get \u2206AUCch , which is represented by the (remaining) pink area in Figure 8 (l). Recall n\u2212i = n \u2212 i1 + n\u2212i2 and n + i = n + i1 + n+i2 . Simplifying Equation (35), we get\n\u2206AUCch = 1\nN+N\u2212 (( V\u2211 v=1 n\u2212bv ) n+i1 + ( V\u2211 v=1 n+bv ) n\u2212i2 \u2212 ( V\u2211 v=1 n\u2212bv ) n+i + n\u2212i1n + i1 + 2n\u2212i2n + i1 + n\u2212i2n + i2 \u2212 n\u2212i n + i 2 )\n= 1\nN+N\u2212 (( V\u2211 v=1 n+bv ) n\u2212i2 \u2212 ( V\u2211 v=1 n\u2212bv ) n+i2 + n\u2212i2n + i1 \u2212 n\u2212i1n + i2 2 ) (36)\nSince rb1 > ... > rbv > ri2 , \u2200v \u2208 {1, ..., V }, n+bvn \u2212 i2 > n+i2n \u2212 bv . Thus, ( \u2211V v=1 n + bv )n\u2212i2 > ( \u2211V v=1 n \u2212 bv\n)n+i2 . Since ri1 > ri2 , n + i1 n\u2212i2 \u2212 n + i2 n\u2212i1 . Therefore, \u2206AUCch > 0.\nTherefore, once an impure leaf is split, the AUCch doesn\u2019t decrease. If the split is leading to the change of the rank order of leaves, then AUCch increases."
    },
    {
      "heading": "C.1. Proof of Theorem 2.1",
      "text": "Proof. Let tree d = (dfix, rfix, dsplit, rsplit,K,Hd) and leaves of tree d are mutually exclusive. According to Lemma C.1, for leaves that can be further split, we can do splits to increase the AUCch. In the best possible hypothetical case, all new generated leaves are pure (contain only positive or negative samples). In this case, AUCch is maximized for dsplit. In this\ncase, we will show that b(dfix,x,y) = 1\u2212 1N+N\u2212 ( K\u2211 i=1 n\u2212i [ N+split + ( i\u22121\u2211 j=1 n+j ) + 12n + i ] +N+N\u2212split ) + \u03bbHd as defined by Equation (4). Then b(dfix,x,y) \u2264 R(d,x,y).\nTo derive the expression for b(dfix,x,y), we sum areas of rectangles and triangles under the ROC curve\u2019s convex hull. Figure 9 shows where each of the terms arises within this sum: the first term in the sum, which is n\u2212i N + split, comes from the area of the lower rectangle of the ROC curve\u2019s convex hull, colored in green. This rectangle arises from the block of N+split\npositives at the top of the ranked list (within the split leaves, whose hypothetical predictions are 1). The n\u2212i ( i\u22121\u2211 j=1 n+j ) term handles the areas of the growing rectangles, colored in blue in Figure 9. The areas of the triangles comprising the top of the ROCCH account for the third term 12n \u2212 i n + i . The final term N\n+N\u2212split comes from the rectangle on the right, colored red, stemming from the split observations within a hypothetical purely negative leaf."
    },
    {
      "heading": "C.2. Proof of Theorem 2.2",
      "text": "Proof. According to Theorem 2.1, R(d\u2032,x,y) > b(d\u2032fix,x,y) and R(d,x,y) > b(dfix,x,y). Since dfix \u2286 d\u2032fix, leaves in dsplit but not in d\u2032split can be further split to generate pure leaves for tree d but fixed for tree d \u2032. Based on Lemma C.1 and\nHd 6 Hd\u2032 , b(dfix,x,y) 6 b(d\u2032fix,x,y). Therefore, b(dfix,x,y) 6 R(d \u2032,x,y).\nC.3. Incremental Progress Bound to Determine Splitting for Rank Statistics\nTheorem C.2. (Incremental progress bound to determine splitting for rank statistics) Let d\u2217 = (dfix, rfix, dsplit, rsplit,K,Hd) be any optimal tree with objective R\u2217, i.e., d\u2217 \u2208 argmindR(d,x,y). Consider tree d\u2032 derived from d\u2217 by deleting a pair of leaves li and li+1 and adding their parent leaf lj , d\u2032 = (l1, ..., li\u22121, li+2, ..., lHd , lj). Let n + j be the number of positive samples (n\u2212j be the number of negative samples) in leaf j. Calculate `(d \u2032,x,y) as in Equation (2). Define d\u2032\u2212j as the tree d\u2032 after dropping leaf j, adding two hypothetical pure leaves (i.e., one has all positives and the other has all negatives), and reordering the remaining Hd \u2212 2 leaves based on the fraction of positives. Then, we can calculate the loss of the tree d\u2032\u2212j as\n`(d\u2032\u2212j ,x,y) = 1\u2212 1\nN+N\u2212 (Hd\u22122\u2211 i=1 n\u2212i [ n+j + ( i\u22121\u2211 v=1 n+v ) + 1 2 n+i ] +N+n\u2212j ) . (37)\nLet \u03c4 := `(d\u2032,x,y)\u2212 `(d\u2032\u2212j ,x,y). Then \u03c4 must be at least \u03bb.\nProof. By the way `(d\u2032\u2212j ,x,y) is defined (using the same counting argument we used in the proof of Theorem 2.1), it is a lower bound for `(d\u2217,x,y). These two quantities are equal when the split leaves are all pure. So, we have `(d\u2032\u2212j ,x,y) \u2264 `(d\u2217,x,y). Since `(d\u2032,x,y) \u2212 `(d\u2217,x,y) 6 `(d\u2032,x,y) \u2212 `(d\u2032\u2212j ,x,y) = \u03c4 , we can get `(d\u2032,x,y) + \u03bb(Hd \u2212 1) 6 `(d\u2217,x,y) + \u03bb(Hd \u2212 1) + \u03c4 , that is (and remember that d\u2217 is of size Hd whereas d\u2032 is of size Hd \u2212 1), R(d\u2032,x,y) \u2264 R(d\u2217,x,y)\u2212\u03bb+ \u03c4 . Since d\u2217 is optimal with respect to R, then 0 6 R(d\u2032,x,y)\u2212R(d\u2217,x,y) 6 \u2212\u03bb+ \u03c4 , thus \u03c4 > \u03bb.\nSimilar to the Incremental Progress Bound to Determine Splitting for arbitrary monotonic losses, for a tree d, if any of its internal node contributes less than \u03bb in loss, it is not the optimal tree. Thus, after evaluating tree d, we can prune it.\nC.4. Equivalent points bound for rank statistics\nSimilar to the equivalent points bound for arbitrary monotonic losses, for a tree d = (dfix, rfix, dsplit, rsplit,K,Hd), the objective of this tree and its children is minimized when leaves that can be further split to generate pure leaves. In the case when it is possible to split the data into pure leaves, the risk could be equal to b(dfix,x,y). However, if multiple observations captured by a leaf in dsplit have the same features but different labels, then no tree, including those that extend dsplit, can correctly classify all of these observations; that is, leaves in dsplit can not generate pure leaves. In this case, we can leverage these equivalent points to give a tighter lower bound for the objective. We use the same notation for capture and set of equivalent points as in Appendix B, and minority class label is simply the label with fewer samples.\nLet d = (dfix, rfix, dsplit, rsplit,K,Hd) be a tree. Data in leaves from dsplit can be separated into U equivalence classes. For u = 1, ..., U , let Nu = \u2211N i=1 cap(xi, dsplit) \u2227 1[xi \u2208 eu], that is, the number of samples captured by dsplit belonging to\nequivalence set u, and let \u03b4u = \u2211N i=1 cap(xi, dsplit) \u2227 1[xi \u2208 eu]1[yi = qu] be the number of minority-labeled samples\ncaptured by dsplit in equivalence point set u. Then we define r\u0303u as the classification rule we would make on each equivalence class separately (if we were permitted):\nr\u0303u =\n{ \u03b4u Nu\nif \u03b4u \u2265 0 and qu = 1 Nu\u2212\u03b4u Nu if \u03b4u \u2265 0 and qu = 0.\nLet us combine this with dfix to get a bound. We order the combination of leaves in dfix and equivalence classes u \u2208 {1, ..., U} by the fraction of positives in each, Sort(r1, ..., ri, ..., rK , r\u03031, ..., r\u0303u, ..., r\u0303U ) from highest to lowest. Let us reindex these sortedK+U elements by index i\u0303. Denote n+\ni\u0303 as the number of positive samples in either the leaf or equivalence\nclass corresponding to i\u0303. (Define n\u2212i to be the number of negative samples analogously). We define our new, tighter, lower bound as:\nb(dequiv,x,y) = 1\u2212 1\nN+N\u2212 K+U\u2211 i\u0303=1 n\u2212 i\u0303 [( i\u0303\u22121\u2211 j=1 n+j ) + 1 2 n+ i\u0303 ] + \u03bbHd. (38)\nTheorem C.3. (Equivalent points bound for rank statistics) For a tree d = (dfix, rfix, dsplit, rsplit,K,Hd), Let tree d\u2032 = (d\u2032fix, r \u2032 fix, d \u2032 split, r \u2032 split,K\n\u2032, Hd\u2032) \u2208 \u03c3(d) be any child tree such that its fixed leaves d\u2032fix contain dfix and Hd\u2032 > Hd. Then b(dequiv,x,y) 6 R(d\u2032,x,y), where b(dequiv,x,y) is defined in Equation (38).\nProof. The proof is similar to the proof of Theorem 2.1 and Theorem 2.2.\nC.5. Partial area under the ROCCH\nWe discuss the partial area under the ROC convex hull in this section. The ROCCH for a decision tree is defined in Section 2.1, where leaves are rank-ordered by the fraction of positives in the leaves. Given a threshold \u03b8, the partial area under the ROCCH (pAUCch) looks at only the leftmost part of the ROCCH, that is focusing on the top ranked leaves. This measure is important for applications such as information retrieval and maintenance (see, e.g., Rudin & Wang, 2018). In our implementation, all bounds derived for the objective AUCch can be adapted directly for pAUCch, where all terms are calculated only for false positive rates smaller or equal to \u03b8.\nIn our code, we implement all of the rank statistics bounds, with one exception for the partial AUCCH \u2013 the equivalent points bound. We do not implement the equivalent points bound for partial AUCCH since the pAUCch statistic is heavily impacted by the leaves with high fraction of positives, which means that the leaves being repeatedly calculated for the objective tend not to be impure, and thus the equivalence points bound is less effective."
    },
    {
      "heading": "D. Optimizing F-score with Decision Trees",
      "text": "For a labeled tree d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H), the F-score loss is defined as\n`(d,x,y) = FP + FN\n2N+ + FP \u2212 FN . (39)\nFor objectives like accuracy, balanced accuracy and weighted accuracy, the loss of a tree is the sum of loss in each leaf. For F-score loss, however, FP and FN appear in both numerator and denominator, thus the loss no longer can be calculated using a sum over the leaves. Lemma D.1. The label of a single leaf depends on the labels of other leaves when optimizing F-score loss.\nProof. Let l1, ..., lHd be the leaves of tree d. Suppose Hd \u2212 1 leaves are labeled. Let FPHd\u22121 and FNHd\u22121 be the number of false positives and false negatives of these Hd \u2212 1 leaves, respectively. Let A = FPHd\u22121 + FNHd\u22121 and B = 2N+ + FPHd\u22121 \u2212 FNHd\u22121, and by these definitions, we will always have A \u2264 B. Let n + Hd\nbe the number of positive samples in leaf Hd and n\u2212Hd be the number of negative samples. The leaf\u2019s predicted label can be either positive or negative. The loss of the tree depends on this predicted label as follows:\nIf y\u0302(leaf)Hd = 1, there can be only false positives, thus `(d,x,y) = A+ n\u2212Hd B + n\u2212Hd . (40)\nIf y\u0302(leaf)Hd = 0, there can be only false negatives, thus `(d,x,y) = A+ n+Hd B \u2212 n+Hd . (41)\nCalculating loss (41) minus loss (40):\nA+ n+Hd B \u2212 n+Hd \u2212 A+ n\u2212Hd B + n\u2212Hd = (A+ n+Hd)\u00d7 (B + n \u2212 Hd )\u2212 (A+ n\u2212Hd)\u00d7 (B \u2212 n + Hd ) (B \u2212 n+Hd)(B + n \u2212 Hd ) . (42)\nDenote \u2206 as the numerator of (42), that is\n(A+ n+Hd)\u00d7 (B + n \u2212 Hd )\u2212 (A+ n\u2212Hd)\u00d7 (B \u2212 n + Hd ).\nThen we can get\n\u2206 = AB +An\u2212Hd +Bn + Hd + n+Hdn \u2212 Hd \u2212AB +An+Hd \u2212Bn \u2212 Hd + n\u2212Hdn + Hd\n(43)\n= 2n+Hdn \u2212 Hd +An+Hd +Bn + Hd +An\u2212Hd \u2212Bn \u2212 Hd . (44)\nThe value of \u2206 depends on A, B, n+Hd and n \u2212 Hd\n. Hence, in order to minimize the loss, the predicted label of leaf Hd is 0 if \u2206 \u2264 0 and 1 otherwise. Therefore, the predicted label of a single leaf depends on A and B, which depend on the labels of the other samples, as well as the positive and negative samples captured by that leaf.\nTheorem D.2. (Optimizing F-score Poses a Unusual Challenge) Let l1, ..., lHd be the leaves of tree d and let N+ be the number of positive samples in the dataset. Let \u03931 and \u03932 be two predicted labelings for the first Hd \u2212 1 leaves. Leaf Hd has a fixed predicted label. Suppose the loss for the F-score (Equation (39)) of the first Hd \u2212 1 leaves based on labeling method \u03931 is smaller than the loss based on labeling method \u03932 (where in both cases, leaf Hd has the same predicted label). It is not guaranteed that the F1 loss of the tree d based on the first labeling \u03931 is always smaller than the loss based on the second labeling \u03932.\nProof. Let FP (1)Hd\u22121 and FN (1) Hd\u22121 be the number of false positives and number of false negatives for the first Hd \u2212 1 leaves from the labeling method \u03931 and similarly define FP (2) Hd\u22121 and FN (2) Hd\u22121 for labeling method \u03932. Denote A1 = FP (1) Hd\u22121 + FN (1) Hd\u22121 and B1 = 2N + + FP (1) Hd\u22121 \u2212 FN (1) Hd\u22121. Similarly, denote A2 = FP (2) Hd\u22121 + FN (2) Hd\u22121 and B2 = 2N+ + FP (2) Hd\u22121 \u2212 FN (2) Hd\u22121. As we know from the assumptions of the theorem, A1 B1 \u2264 A2B2 .\nDenote FPHd and FNHd be the number of false positives and number of false negatives of the last leaf lHd .\nLet `(1)(d,x,y) and `(2)(d,x,y) be the loss of the tree d based on two different predicted labelings of the leaves.\nSuppose the predicted label of leaf lHd is 1. (An analogous result holds when the predicted label of leaf lHd is 0.) Then `(1)(d,x,y) =\nA1+FPHd B1+FPHd and `(2)(d,x,y) = A2+FPHdB2+FPHd . Let \u2206 be the numerator of `(2)(d,x,y)\u2212 `(1)(d,x,y).\n\u2206 = (A2 + FPHd)(B1 + FPHd)\u2212 (A1 + FPHd)(B2 + FPHd) = A2B1 \u2212A1B2 + (A2 \u2212B2 +B1 \u2212A1)FPHd . (45)\nSince A1B1 \u2264 A2 B2 , A2B1 \u2265 A1B2, that is, the first two terms together are nonnegative. Meanwhile, A1 \u2264 B1 and A2 \u2264 B2. Thus, \u2206 could be negative or positive. Therefore, even though the labeling method \u03931 leads to smaller loss for the first Hd\u2212 1 leaves and the label of the last leaf depends on the label of previous Hd\u2212 1 leaves, it is not guaranteed that the loss of the tree is smaller than that based on \u03932. It is easy to construct examples of A1, A2, B1, B2, and FPHd where the result is either positive or negative, as desired.\nLemma D.1 and Theorem D.2 indicate that optimizing F-score loss is much harder than other arbitrary monotonic losses such as balanced accuracy and weighted accuracy. Thus, we simplify the labeling step by incorporating a parameter \u03c9 at each leaf node s.t. li is labeled as 0 if \u03c9n+i 6 n \u2212 i and 1 otherwise \u2200i \u2208 {1, ...,Hd}."
    },
    {
      "heading": "E. Dynamic Programming Formulation",
      "text": "Note that this section describes standard dynamic programming, where possible splits describe subproblems. The more interesting aspects are the bounds and how they interact with the dynamic programming.\nWe will work only with the weighted misclassification loss for the following theorem, so that the loss is additive over the data: `(d,x,y) = \u2211 i weightiloss(xi, yi).\nWe denote (x,y) as a data set of features x and binary labels y containing a total of N samples and M features.\nInitial Problem: We define a tree optimization problem as a minimization of the regularized risk R(d,x,y) over the domain \u03c3(D), where D is a tree consisting of a single split leaf\nD = (Dfix, rfix, Dsplit, rsplit,K,H) = (\u2205, \u2205, Dsplit, rsplit, 0, 1)\nd\u2217 \u2208 argmind\u2208\u03c3(D)R(d,x,y). (46)\nSince all trees are descendants of a tree that is a single split leaf, this setup applies to tree optimization of any arbitrary data set x, y. We can rewrite the optimization problem as simply:\nd\u2217 \u2208 argmindR(d,x,y). (47)\nWe partition the domain d \u2208 \u03c3(D) intoM+1 cases: One Leaf Case andM Tree Cases. We solve each case independently, then optimize over the solutions of each case:\n\u03c3(D) = Leaf \u222a Tree1 \u222a Tree2 \u222a \u00b7 \u00b7 \u00b7 \u222a TreeM\nd\u2217Leaf \u2208 argmind\u2208\u03c3(Leaf)R(d,x,y) d\u2217Treei \u2208 argmind\u2208\u03c3(Treei)R(d,x,y)\nargmind\u2208\u03c3(D) \u2208 argmind\u2208{d\u2217Leaf ,d\u2217Tree1 ,d\u2217Tree2 ,...,d\u2217TreeM}.\nThe Leaf Case forms a base case in a recursion, while each Tree Case is a recursive case that further decomposes into two instances of tree optimization of the form described in (46).\nLeaf Case: In this case, d\u2217Leaf is a tree consisting of a single fixed leaf. This tree\u2019s only prediction r\u2217fix is a choice of two possible classes {0, 1}.\nr\u2217fix \u2208 argminrfix\u2208{true,false}R((dfix, rfix, \u2205, \u2205, 1, 1),x,y),\nd\u2217Leaf = (dfix, r \u2217 fix, \u2205, \u2205, 1, 1) (48)\nwhere a tie would be broken randomly.\nTree Case: For every possible i in the set feature indices {1, 2, 3, ...,M} we designate an ith Tree Case and an d\u2217Treei as the optimal descendent of a tree Di. We define Di as a tree consisting of a root split on feature i and two resulting split leaves dLeft and dRight so that:\nTreei = \u03c3(Di) (the children of Di)\nDi = (\u2205, \u2205, dsplit, rsplit, 0, 2) = (\u2205, \u2205, {dLeft, di}, {r\u2212i, ri}, 0, 2)\nd\u2217Treei \u2208 argmind\u2208\u03c3(Di)R(d,x,y). (49)\nInstead of directly solving (49), we further decompose this into two smaller tree optimization problems that match the format of (46). Since we are working with the weighted misclassification loss, we can optimize subtrees extending from from d\u2212i and di independently. We define data within the support set of d\u2212i as x\u2212i, y\u2212i. We define data within the support set of di as xi, yi. For each Di, we define an optimization over the extensions of the left split leaf d\u2212i as:\nLefti = (\u2205, \u2205, {d\u2212i}, rsplit, 0, 1).\nd\u2217Lefti \u2208 argmind\u2208\u03c3(Lefti)R(d,x \u2212i,y\u2212i). (50)\nBy symmetry, we define an optimization over the extensions of the right split leaf di:\nRighti = (\u2205, \u2205, {di}, rsplit, 0, 1)\nd\u2217Righti \u2208 argmind\u2208\u03c3(Righti)R(d,x i,yi). (51)\nd\u2217 Lefti is the optimal subtree that classifies x\u2212i and d\u2217 Righti is the optimal subtree that classifies xi. Together, with a root node splitting on the ith feature, d\u2217\nLefti combines with d\u2217 Righti to form d\u2217Treei . Thus, we can solve (50) and (51) to get the\nsolution of (49).\nIn (46) we defined a decomposition of an optimization problem over the domain \u03c3(D), where D is a tree consisting of a single split leaf. Both expressions (50) and (51) are also optimizations over the domain of children of a tree consisting of a single split leaf. Recall that the descendants of any tree consisting of only a single split leaf covers the space of all possible trees, therefore the trees are optimized over an unconstrained domain. We can thus rewrite (50) as:\nd\u2217Lefti \u2208 argmindR(d,x \u2212i,y\u2212i). (52)\nSymmetrically we can also rewrite (51) as:\nd\u2217Righti \u2208 argmindR(d,x i,yi). (53)\nObserve that (52) and (53) are simply tree optimization problems over a specific set of data (in this case x\u2212i,y\u2212i and xi,yi). Hence, these tree optimizations form a recursion, and each can be solved as though they were (47).\nTermination: To ensure this recursion terminates, we consider only splits where x\u2212i and xi are strict subsets of x. This ensures that the support strictly decreases until a minimum support is reached, which prunes all of Tree1 \u222a Tree2 \u222a \u00b7 \u00b7 \u00b7 \u222a TreeM leaving only the leaf case described in (48).\nIdentifying Reusable Work: As we perform this decomposition, we identify each problem using its data set x, y by storing a bit vector to indicate it as a subset of the initial data set. At each recursive step, we check to see if a problem has already been visited by looking for an existing copy of this bit vector.\nFigure 10 shows a graphical representation of the algorithm. Note that we use the following shortened notations in the figure:\n(x,y)k = (xk,yk) (54)\n(x,y)\u2212k = (x\u2212k,y\u2212k) (55)\n(x,y)k,l = (xk,l,yk,l). (56)\nEquation (54) denotes a data set (x,y) filtered by the constraint that samples must respond positive to feature k. Equation (55) denotes a data set (x,y) filtered by the constraint that samples must respond negative to feature k. Equation (56) denotes a data set (x,y) filtered by the constraint that samples must respond positive to both feature k and feature l.\nF. Incremental Similar Support Bound Proof We will work only with weighted misclassification loss for the following theorem, so that the loss is additive over the data:\n`(d,x,y) = \u2211 i weightiloss(xi, yi).\nDefine the maximum possible weighted loss:\n`max = max x,y [weight(x, y)\u00d7 loss(x, y)].\nThe following bound is our important incremental similar support bound, which we leverage in order to effectively remove many similar trees from the search region by looking at only one of them.\nTheorem F.1. (Incremental Similar Support Bound) Consider two trees d = (dfix, dsplit,K,H) and D = (Dfix, Dsplit,K,H) that differ only by their root node (hence they share the same K and H values). Further, the root nodes between the two trees are similar enough that the support going to the left and right branches differ by at most \u03c9 fraction of the observations. (That is, there are \u03c9N observations that are captured either by the left branch of d and right branch of D or vice versa.) Define Suncertain as the maximum of the support within dsplit and Dsplit:\nSuncertain = max(supp(dsplit), supp(Dsplit)).\nFor any child tree d\u2032 grown from d (grown from the nodes in dsplit, that would not be excluded by the hierarchical objective lower bound) and for any child tree D\u2032 grown from D (grown from the nodes in Dsplit, that would not be excluded by the hierarchical objective lower bound), we have:\n|R(d\u2032,x,y)\u2212R(D\u2032,x,y)| \u2264 (\u03c9 + 2Suncertain)`max.\nThis theorem tells us that any two child trees of d and D that we will ever generate during the algorithm will have similar objective values. The similarity depends on \u03c9, which is how many points are adjusted by changing the top split, and the other term involving Suncertain is determined by how much of the tree is fixed. If most of the tree is fixed, then there can be little change in loss among the children of either d or D\u2032, leading to a tighter bound. In standard classification tasks, the value of `max is usually 1, corresponding to a classification error for an observation.\nProof. We will proceed in three steps. The first step is to show that\nR(d,x,y)\u2212R(D,x,y) \u2264 \u03c9`max.\nThe second step is to show: R(d,x,y) \u2264 R(d\u2032,x,y) + Suncertain`max,\nfor all feasible children d\u2032 of d. The same bound will hold for D and any of its children D\u2032. The third step is to show\nR(d\u2032,x,y) \u2264 R(d,x,y) + Suncertain`max,\nwhich requires different logic than the proof of Step 2. Together, Steps 2 and 3 give\n|R(d\u2032,x,y)\u2212R(d,x,y)| \u2264 Suncertain`max.\nFrom here, we use the triangle inequality and the bounds from the three steps to obtain the final bound:\n|R(d\u2032,x,y)\u2212R(D\u2032,x,y)| = |R(d\u2032,x,y)\u2212R(d,x,y) +R(d,x,y)\u2212R(D,x,y) +R(D,x,y)\u2212R(D\u2032,x,y)| \u2264 |R(d\u2032,x,y)\u2212R(d,x,y)|+ |R(d,x,y)\u2212R(D,x,y)|+ |R(D,x,y)\u2212R(D\u2032,x,y)| \u2264 Suncertain`max + \u03c9`max + Suncertain`max,\nwhich is the statement of the theorem. Let us now go through the three steps.\nFirst step: Define \u201cmove\u201d as the set of indices of the observations that either go down the left branch of the root of d and the right of D, or that go down the right of d and the left of D. The remaining data will be denoted \u201c/move.\u201d These remaining data points will be classified the same way by both d and D. The expression above follows from the additive form of the objective R:\nR(d,x,y) = `(d,xmove,ymove) + `(d,x/move,y/move) + \u03bbH,\nR(D,x,y) = `(D,xmove,ymove) + `(D,x/move,y/move) + \u03bbH,\nand since `(d,x/move,y/move) = `(D,x/move,y/move) since this just considers overlapping leaves, we have:\n|R(d,x,y)\u2212R(D,x,y)| \u2264 |`(d,xmove,ymove)\u2212 `(D,xmove,ymove)| \u2264 \u03c9`max.\n(For the last inequality, the maximum is attained when one of `(d,xmove,ymove) and `(D,xmove,ymove) is zero and the other attains its maximum possible value.)\nSecond step: Recall that d\u2032 is a child of d so that d\u2032fix contains dfix. Let us denote the leaves in d\u2032fix that are not in dfix by d\u2032fix/dfix. Then,\nR(d\u2032,x,y) = `(d\u2032fix,x,y) + `(d \u2032 split,x,y) + \u03bbHd\u2032\n= `(dfix,x,y) + `(d \u2032 fix/dfix,x,y) + `(d \u2032 split,x,y) + \u03bbHd\u2032 .\nAdding `(dsplit,x,y) to both sides,\nR(d\u2032,x,y) + `(dsplit,x,y) = `(dfix,x,y) + `(dsplit,x,y) + `(d \u2032 fix/dfix,x,y) + `(d \u2032 split,x,y) + \u03bbHd\u2032\n= R(d,x,y) + `(d\u2032fix/dfix,x,y) + `(d \u2032 split,x,y) + \u03bb(Hd\u2032 \u2212H) \u2265 R(d,x,y),\nsince the terms we removed were all nonnegative. Now,\nR(d,x,y) \u2264 R(d\u2032,x,y) + `(dsplit,x,y) \u2264 R(d\u2032,x,y) + supp(dsplit)`max\n\u2264 R(d\u2032,x,y) + Suncertain`max.\nThird step: Here we will use the hierarchical objective lower bound. We start by noting that since we have seen d, we have calculated its objective R(d,x,y), and it must be as good or worse than than the current best value that we have seen so far (or else it would have replaced the current best). So Rc \u2264 R(d,x,y). The hierarchical objective lower bound (Theorem B.1) would be violated if the following holds. This expression states that b(d\u2032,x,y) is worse than R(d,x,y) (which is worse than the current best), which means we would have already excluded d\u2032 from consideration:\nRc \u2264 R(d,x,y) < b(d\u2032,x,y) = R(d\u2032,x,y)\u2212 `(d\u2032split,x,y).\nThis would be a contradiction. Thus, the converse holds:\nR(d\u2032,x,y)\u2212 `(d\u2032split,x,y) = b(d\u2032,x,y) \u2264 R(d,x,y).\nThus, R(d\u2032,x,y) \u2264 R(d,x,y) + `(d\u2032split,x,y).\nNow to create an upper bound for `(d\u2032split,x,y) as ` max times the support of d\u2032split. Since d \u2032 is a child of d, its support on the split leaves is less than or equal to that of d, supp(d\u2032split) \u2264 supp(dsplit). Thus, `(d\u2032split,x,y) \u2264 `maxsupp(dsplit) \u2264 `maxSuncertain. Hence, we have the result for the final step of the proof, namely:\nR(d\u2032,x,y) \u2264 R(d,x,y) + Suncertain`max."
    },
    {
      "heading": "G. Subset Bound Proof",
      "text": "We will work with the loss that is additive over the data for the following theorem. The following bound is our subset bound, which we leverage in order to effectively remove the thresholds introduced by the continuous variables, thus pruning the search space. Theorem G.1. (Subset Bound). Define d = (dfix, \u03b4fix, dsplit, \u03b4split,K,H) and D = (Dfix,\u2206fix, Dsplit,\u2206split) to be two trees with same root node. Let f1 and f2 be the features used to split the root node. Let t1, t2 be the left and right sub-trees under the root node split by f1 in d and let (xt1 ,yt1) and (xt2 ,yt2) be the samples captured by t1 and t2 respectively. Similarly, let T1, T2 be the left and right sub-trees under the root node split by f2 in D and let (xT1 ,yT1) and (xT2 ,yT2) be the samples captured by T1 and T2 respectively. Suppose t1, t2 are the optimal trees for (xt1 ,yt1) and (xt2 ,yt2) respectively, and T1, T2 are the optimal trees for corresponding (xT1 ,yT1) and (xT2 ,yT2). If R(t1,xt1 ,yt1) \u2264 R(T1,xT1 ,yT1) and (xt2 ,yt2) \u2286 (xT2 ,yT2), then R(d,x,y) \u2264 R(D,x,y).\nThis theorem tells us that when f1 and f2 are from different thresholds of a continuous variable, for example age \u2264 20 and age \u2264 18, (xt2 ,yt2) \u2286 (xT2 ,yT2) is always true. In this case, we need only develop and compare the two left sub-trees.\nProof. Since (xt2 ,yt2) \u2286 (xT2 ,yT2) and t2 and T2 are optimal trees for (xt2 ,yt2) and (xT2 ,yT2) respectively,\nR(t2,xt2 ,yt2) \u2264 R(T2,xt2 ,yt2) \u2264 R(T2,xT2 ,yT2).\nGiven R(t1,xt1 ,yt1) \u2264 R(T1,xT1 ,yT1),\nR(t1,xt1 ,yt1) +R(t2,xt2 ,yt2) \u2264 R(T1,xT1 ,yT1) +R(T2,xT2 ,yT2) R(d,x,y) \u2264 R(D,x,y).\n(57)"
    },
    {
      "heading": "H. Complexity of Decision Tree Optimization",
      "text": "In this section, we show the complexity of decision tree optimization. Theorem H.1. Let f(M) be the number of binary decision trees that can be constructed for the dataset with N samples, M binary features and K label classes. The complexity of f(M) is O(M !).\nProof. We show the proof by induction."
    },
    {
      "heading": "Base Case:",
      "text": "When M = 0, the dataset cannot be split and a predicted label is assigned to all samples. Therefore, the number of binary decision trees for the given dataset is equal to the number of classes K. Hence, f(0) = K."
    },
    {
      "heading": "Inductive Step:",
      "text": "WhenM > 0, the whole dataset can be split into two subsets by any of theM features. WithM possible ways to do the first split, 2M subsets of data are created. Since binary features only have two different values, 0 and 1, a binary feature used to produce the subsets cannot be used again. Therefore, each of the 2M subsets can only be separated using trees constructed from at most M \u2212 1 binary features. This produces a recursive definition of f(M). That is f(M) = 2Mf(M \u2212 1)."
    },
    {
      "heading": "Combining Step:",
      "text": "Each inductive step reduces M by one, guaranteeing its arrival at the base case. By combining the base case with the inductive step, a non-recursive definition of f(M) is produced.\nf(0) = K\nf(1) = 2\u00d7 1\u00d7 f(0) = 21 \u00d7 1\u00d7K f(2) = 2\u00d7 2\u00d7 f(1) = 22 \u00d7 2\u00d7 1\u00d7K f(3) = 2\u00d7 3\u00d7 f(2) = 23 \u00d7 3\u00d7 2\u00d7 1\u00d7K\n...\nf(M) = 2\u00d7M \u00d7 f(M \u2212 1) = 2M \u00d7M !\u00d7K\n(58)\nSince the term with the highest complexity in (2M )(M !)(K) is factorial, the complexity of f(M) is O(M !)"
    },
    {
      "heading": "I. Experiments",
      "text": "In this section, we elaborate on the experimental setup, data sets, pre-processing and post-processing. Additionally, we present extra experimental results that were omitted from the main paper due to space constraints."
    },
    {
      "heading": "I.1. Data Sets",
      "text": "We used a total of 11 data sets: Seven of them are from the UCI Machine Learning Repository (Dheeru & Karra Taniskidou, 2017), (monk1, monk2, monk3, tic-tac-toe, balance scale, car evaluation, iris), one from LIBSVM (Chang & Lin, 2011), (FourClass). The other three datasets are the ProPublica recidivism dataset (Larson et al., 2016) (COMPAS), the Fair Isaac credit risk data sets (FICO et al., 2018) (FICO), and the mobile advertisement data sets (Wang et al., 2017) (coupon). We predict which individuals are arrested within two years of release (N = 5,020) on the recidivism data set, whether an individual will default on a loan for the FICO dataset, and whether a customer is going to accept a coupon for a bar considering demographic and contextual attributes."
    },
    {
      "heading": "I.2. Preprocessing",
      "text": "Missing Values: We exclude all observations with missing values.\nmonk 1, monk 2, monk 3, tic-tac-toe, balance scale, and car evaluation: We preprocessed these data sets, which contain only categorical features, by using a binary feature to encode every observable categorical value.\niris: We encode a binary feature to represent every threshold between adjacent values for all four continuous features (sepal length, sepal width, petal length, petal width). From the 3-class classification problem, we form 3 separate binary classification problems. Each binary classification is 1 of the 3 classes against the remaining classes. These three problems are referred to as iris-setosa, iris-versicolor, and iris-virginica.\nFour Class: This dataset contains simulated points in a two-dimensional, bounded space with two classes that have irregular spreads over the space (241 positive samples and 448 negative samples). We split two continuous features into six categories (e.g. feature1 \u2264 50 and feature1 \u2264 100) and the value for each column is either 0 or 1.\nProPublica Recidivism (COMPAS): We discretized each continuous variable by using a binary feature to encode a threshold between each pair of adjacent values.\nProPublica Recidivism (COMPAS-2016): We selected features age, count of juvenile felony, count of juvenile misdemeanor, count of juvenile other crimes, count of prior crimes, and the target recidivism within two years. We replace count of juvenile felony, count of juvenile misdemeanor, count of juvenile other crimes with a single count called count of juvenile crimes which is the sum of count of juvenile felony, count of juvenile misdemeanor, count of juvenile other crimes. We discretized the count of prior crimes into four ranges count of prior crimes = 0, count of prior crimes = 1, count of prior crimes between 2 to 3, and count of prior crimes > 3. These four ranges are each encoded as binary features. Therefore, after preprocessing, these data contain 2 continuous features, 4 binary features, and one target.\nProPublica Recidivism (COMPAS-binary): We use the same discretized binary features of compas produced in (Hu et al., 2019) which are the following: sex = Female, age < 21, age < 23, age < 26, age < 46, juvenile felonies = 0, juvenile misdemeanors = 0, juvenile crimes = 0, priors = 0, priors = 1, priors = 2 to 3, priors > 3.\nFair Isaac Credit Risk (FICO): We discretized each continuous variable by using a binary feature to encode a threshold between each pair of adjacent values.\nFair Isaac Credit Risk (FICO-binary): We use the same discretized binary features of compas produced in (Hu et al., 2019) which are the following: External Risk Estimate < 0.49 , External Risk Estimate < 0.65, External Risk Estimate < 0.80, Number of Satisfactory Trades < 0.5, Trade Open Time < 0.6, Trade Open Time < 0.85, Trade Frequency < 0.45, Trade Frequency < 0.6, Delinquency < 0.55, Delinquency < 0.75, Installment < 0.5, Installment < 0.7, Inquiry < 0.75, Revolving Balance < 0.4, Revolving Balance < 0.6, Utilization < 0.6, Trade W. Balance < 0.33.\nMobile Advertisement (coupon): We discretized each continuous variable by using a binary feature to encode a threshold between each pair of adjacent values. We discretized each categorical variable by using a binary feature to encode each\nobservable categorical value.\nMobile Advertisement (bar-7): In order to predict whether a customer is going to accept a coupon for a bar, we selected features age, passengers, bar, restaurant20to50, direction same, and target. For features age, bar and direction we used the same encoding as we used for coupon. We modified passengers so that it is replaced with the binary feature passengers > 0. We modified restaurant20to50 so that it is replaced with the binary feature restaurant20to50=0, which is 0 if the number of times that they eat at a restaurant with average expense less than $20 per person is less than 4 times per month and 1 otherwise.\nData Set Summary: Table 2 presents a summary of the datasets."
    },
    {
      "heading": "I.3. Optimization Algorithms",
      "text": "CART: We run CART as a reference point for what is achievable with a greedy algorithm that makes no optimality guarantee. The algorithm is run using the Python implementation from Sci-Kit Learn. The depth and leaf count are constrained in order to adjust the resulting tree size.\nBinOCT: BinOCT is modified to run using only a single thread to make comparison across algorithms fair. This algorithm runs on the academic version of CPLEX. The depth is constrained to adjust the resulting tree size.\nDL8.5: DL8.5 is implemented in C++ and is run as a native extension of the Python interpreter. The depth is constrained to adjust the resulting tree size.\nBecause BinOCT and DL8.5 have hard constraints, rather than OSDT or GOSDT\u2019s soft constraints, GOSDT and OSDT\u2019s optimization problem is substantially harder than that of BinOCT and DL8.5. GOSDT and OSDT effectively consider a large number of possible tree sizes whereas the other algorithms consider only full trees of a given depth.\nOSDT: OSDT is implemented in Python and run directly. The regularization coefficient is varied to adjust the resulting tree size.\nPyGOSDT: PyGOSDT is an early Python implementation of GOSDT. The regularization coefficient is varied to adjust the resulting tree size.\nGOSDT: GOSDT is implemented in C++ and run as a native executable. The regularization coefficient is varied to adjust the resulting tree size."
    },
    {
      "heading": "I.4. Computing Infrastructure",
      "text": "The experiments for optimizing rank statistics were run on a personal laptop with a 2.6GHz i5-7300U processor and 8GB of RAM.\nAll other experiments were run on a 2.30 GHz (30 MB L3 cache) Intel Xeon E7-4870 v2 processor with 60 cores across 4 NUMA nodes. We disabled hyper-threading. The server has 512 GB RAM uniformly distributed (128 GB each) across the four NUMA nodes. The host OS is Ubuntu 16.04.6 LTS. We set a 5-minute time limit on all experiments, unless otherwise stated. All algorithms that support multi-threading are modified to run sequentially."
    },
    {
      "heading": "I.5. Experiments: Rank Statistics",
      "text": "Collection and Setup: We ran this experiment on the data set FourClass. We train models to optimize various objectives with 30 minute time limits. When the time limit is reached, our algorithm returns the current best tree considering the objectives.\nResults: Figure 11 shows the training ROC and test ROC of decision trees generated for six different objectives. Optimizing different objectives produces different trees with different FP and FN . Some interesting observations are that the pAUCch model performs as well as the AUCch model on the left part of the ROC curve, but then sacrifices some area under the middle and right of the curve (which is not as relevant to its objective) to obtain a sparser model (sparsity is relevant to the objective). The pAUCch and AUCch results illustrate how the objective allows us to trade off parts of the ROC curve (that are not important for some applications) with overall sparsity. Another interesting observation is that some of the models are extremely sparse: recall that each leaf is a single diagonal line on the ROC curve, so one can count the number of leaves by looking at the number of diagonal lines. In some cases, a well-chosen single split point can lead to a model with an excellent TPR/FPR tradeoff somewhere along the ROC curve."
    },
    {
      "heading": "I.6. Experiment: Accuracy vs Sparsity",
      "text": "Collection and Setup: We ran this experiment on the 6 data sets car evaluations, COMPAS-binary, tic-tac-toe, monk 1, monk 2, and monk 3. For the monk data sets, we used only the samples from the training set. For each data set we train models using varying configurations (described in the following sections) to produce models with varying number of leaves. For any single configuration, we perform a 5-fold cross validation to measure training accuracy and test accuracy for each fold. All runs that exceed the time limit of 5 minutes are discarded.\nWe omit PyGOSDT since it differs only from GOSDT in program speed, and would provide no additional information for\nthis experiment.\nBelow are the configurations used for each algorithm:\n\u2022 CART Configurations: We ran this algorithm with 6 different configurations: depth limits ranging from 1 to 6, and a corresponding maximum leaf limit of 2, 4, 8, 16, and 64.\n\u2022 BinOCT and DL8.5 Configurations: We ran these algorithms with 6 different configurations: depth limits ranging from 1 to 6.\n\u2022 OSDT and GOSDT Configurations: We ran these algorithms with 29 different regularization coefficients: 0.2, 0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0.009, 0.008, 0.007, 0.006, 0.005, 0.004, 0.003, 0.002, 0.001, 0.0009, 0.0008, 0.0007, 0.0006, 0.0005, 0.0004, 0.0003, 0.0002, and 0.0001.\nCalculations: For each combination of data set, algorithm, and configuration, we produce a set of up to 5 models, depending on how many runs exceeded the time limit. We summarize the measurements (e.g., training accuracy, test accuracy, and number of leaves) across the set of up to 5 models by plotting the median. We compute the 25th and 75th percentile and show them as lower and upper error values respectively.\nResults: Figure 12 shows that the objective optimized by GOSDT (same as OSDT) reliably produces a more efficient frontier between training accuracy and number of leaves. Figure 13 shows the same plots with test accuracy and number of leaves. The difference between frontiers sometimes becomes insignificant due to error introduced from generalization, particularly when the training accuracies between algorithms were close together. That is, if CART achieves a solution that is almost optimal, then it tends to achieve high test accuracy as well. Without methods like GOSDT or OSDT, one would not be able to determine whether CART\u2019s training solution is close to optimal for a given number of leaves. Further, if the training accuracies of the different algorithms are different (e.g., as in the monk2 data), this difference is reflected in an improved test accuracy for OSDT or GOSDT."
    },
    {
      "heading": "I.7. Experiment: Scalability",
      "text": "Collection and Setup: We ran this experiment on 4 data sets: bar-7, compas-2016, compas, and fico. The four data sets vary in the number of binary features required to fully represent their information. The number of binary features are, respectively, 14, 85, 647, and 1407. For each data set we show runtime as a function of both sample size and number of binary features used.\nEach data set is preprocessed so that categorical features produce one binary feature per unique value, and continuous features produce one binary feature per pair of adjacent values. The samples are then randomly shuffled. We measure run time on increasingly larger subsets of this data (with all binary features included), this is our measure of run time as a function of sample size. We also measure run time on increasingly larger numbers of binary features (with all samples included), this is our measure of run time as a function of binary features. For all experiments we continue increasing the difficulty until either the difficulty covers the full data set or a time limit of 5 minutes has been exceeded 3 times by the same algorithm.\nNote that when varying the number of binary features, we include all samples. This means that adding a feature to a large data set (e.g., COMPAS and FICO) generally increases the difficulty more than adding a feature to a small data set (e.g., bar-7 and COMPAS-2016). Likewise, when varying the number of samples, we include all binary features. This means that adding a feature to a high-dimensional data set (e.g., COMPAS and FICO) generally increases the difficulty more than adding a sample to a low-dimensional data set (e.g., bar-7 and COMPAS-2016). As a result, the sample size is not a good measure of difficulty when comparing across different data sets of completely different features. The number of binary features is a more robust measure when comparing across different data sets.\nBelow are the configurations used for each algorithm tested:\n\u2022 CART is configured to have a maximum depth of log2(32) and a maximum leaf count of 32.\n\u2022 BinOCT and DL8.5 are configured to have a maximum depth of log2(32).\n\u2022 OSDT and GOSDT are configured with a regularization coefficient of 132 .\nWhile we initially attempted to include BinOCT in this experiment, we were unable to find an instance where BinOCT reached completion with a maximum depth of log2(32) and a time limit of 5 minutes. Consequently, BinOCT was not included in this experiment.\nCalculations: We provide two measures of speed. Training time measures the number of seconds required for an algorithm to complete with a certificate of optimality. Slow-down measures the ratio of the algorithm\u2019s training time against its fastest training time over values of problem difficulty. We vary and measure problem difficulty in two separate ways. \u201cNumber of binary features\u201d indicates how many of the binary features generated by our binary encoding were included for training. \u201cNumber of samples\u201d indicates how many samples were included for training.\nResults: Figure 14 shows how each algorithm\u2019s training time varies as additional binary features are included. Figure 15 shows how each algorithm\u2019s training time varies as additional samples are included.\nFor bar-7 and compas-2016, we observe a logarithmic time complexity when increasing sample size. These problems are sufficiently represented and solvable at a small sample size. As a result, additional samples contribute diminishing increase in the difficulty of the problem. Under these circumstances, GOSDT, PyGOSDT, and OSDT have a significant performance advantage over DL8.5.\nFor all data sets we observe an approximately factorial time complexity when increasing the number of features. This is consistent with the theoretical worst-case time complexity of full tree optimization (see Theorem H.1). The sharp increase in run time results in a limit on the size of problems solvable in practice by each algorithm. We observe that while all full tree optimization algorithms have such a limit, GOSDT usually has a higher limit than other algorithms.\nFigure 16 show how each algorithm\u2019s relative slow-down varies with additional binary features. Figure 17 show how each algorithm\u2019s relative slow-down varies with additional samples. This reduces the effects of constant overhead, showing the asymptotic behavior of each algorithm. Our observations from Figure 14 and Figure 15 still hold under this analysis. Additionally, we observe that the slow-down of GOSDT and PyGOSDT under the bar-7 data set appears to become approximately constant; this is likely a result of additional samples belonging to already-present equivalence classes (the set of equivalence classes saturates). Recall that both PyGOSDT and GOSDT reduce the data set size to only the equivalence classes that are present in the data set, and thus scale in this quantity rather than the number of samples.\nOverall, we observe that both GOSDT, PyGOSDT and OSDT have an advantage over DL8.5 which becomes increasingly clearer as we test on data sets of greater difficulty. GOSDT and OSDT appears to perform better than PyGOSDT, with GOSDT having a slight advantage over OSDT on larger data sets.\nPrevious comparisons do not account for differences in implementation language. We observe that that GOSDT is several orders of magnitude faster and more scalable than DL8.5, both of which are implemented in C++. However, PyGOSDT is not quite as performant as OSDT, both of which are implemented in Python. This suggests, for data sets similar to the ones in this experiment, there are advantageous characteristics of OSDT that are worth further exploration for extensions of GOSDT."
    },
    {
      "heading": "I.8. Experiment: Time to Optimality",
      "text": "Collection and Setup: We ran this experiment on 4 data sets: bar-7, tic-tac-toe, car-evaluation, compas-binary, ficobinary, monk-1, monk-2, and monk-3. For each experiment, we run OSDT, GOSDT, and PyGOSDT with a regularization\ncoefficient of 0.005. For each run we track the progress of the algorithm by plotting the minimum objective score seen so far. Once the algorithm terminates or reaches a time limit of 30 minutes, the values are stored in a file.\nResults: Figure 18 shows the different behaviors between GOSDT, PyGOSDT, and OSDT. In general, both PyGOSDT and GOSDT complete their certificate of optimality earlier than OSDT.\nNote that PyGOSDT\u2019s implementation does not include high-priority bound updates. This causes PyGOSDT to maintain a higher objective score before making a sharp drop upon completion (with a certificate of optimality). GOSDT, on the other hand, behaves similarly to OSDT because both algorithms aggressively prioritize lowering the best observed objective score. We observe that under the tic-tac-toe data set this appears to be less advantageous. While PyGOSDT\u2019s progress initially appears less promising, it completed remarkably faster than both GOSDT and OSDT. This suggests that optimal prioritization is dependent on specifics of the optimization problem."
    },
    {
      "heading": "I.9. Optimal Trees",
      "text": "We present some of the trees that achieved the peak median accuracy from Section I.6. Figure 19 shows a comparison between the results of training BinOCT (a) and GOSDT (b) on the Monk 1 data set. GOSDT is able to produce a model with 20% higher accuracy than BinOCT even though both trees have 8 leaves. Figure 20 shows a comparison between DL8.5 (a) and GOSDT (b) on the Monk 2 data set. GOSDT is able to produce a model with 3% higher accuracy than DL8.5 even though both trees have 7 leaves. Figure 21 shows a comparison between BinOCT (a), DL8.5 (b), and GOSDT (c) on the Tic-Tac-Toe data set. GOSDT is able to produce a model with higher accuracy than both BinOCT and DL8.5 when all trees have 16 leaves.\nComparison to True Model: For the results shown in Figure 19, we know that the true model used to generate the data in Monk 1 is a set of logical rules:\nclass = (jacket = red) \u2228 (head = body).\nThe data set we train on does not encode binary features for equality between two features (e.g., head = body) and categorical variables head and body are only encoded using k\u22121 binary rules (this means one value from each categorical variable will be expressed with a negation of all other values). Altogether, this means our encoding forces the true model\nto instead be expressed as the following:\nclass =(jacket = red)\n\u2228 (head = round \u2227 body = round) \u2228 (head = square \u2227 body = square) \u2228 (head 6= round \u2227 head 6= square \u2227 body 6= round \u2227 body 6= square)\nWe can interpret the trees produced by BinOCT as the following set of logical rules:\nclass =(jacket = red \u2227 head = round) \u2228 (jacket 6= red \u2227 head = round \u2227 body = round) \u2228 (jacket = red \u2227 head 6= round \u2227 body = round) \u2228 (jacket 6= green \u2227 head 6= round \u2227 body 6= round).\nWe can interpret the trees produced by GOSDT as the following set of logical rules:\nclass =(jacket = red)\n\u2228 (head = round \u2227 body = round) \u2228 (head = square \u2227 body = square) \u2228 (head 6= round \u2227 head 6= square \u2227 body 6= round \u2227 body 6= square).\nIn this instance, BinOCT produces a model that is similar to the true model but has a few mismatches. This is mainly due to the structural constraints of BinOCT. GOSDT, after exploring a larger space while still penalizing complexity, is able to produce a model that perfectly matches with the ground truth."
    },
    {
      "heading": "I.10. Summary of Experimental Results",
      "text": "Experiment G.5 shows that the new set of objective functions allows GOSDT to produce trees with a more efficient ROC curve than the standard accuracy objective assumed by other algorithms.\nExperiment G.6 shows that the regularized risk objective used by OSDT and GOSDT produces the most efficient training accuracy vs. sparsity frontier. When placed under time constraints, GOSDT is able to produce more of the highly accurate models along this frontier than OSDT.\nExperiment G.7 shows that GOSDT is able to handle significantly more binary features than BinOCT, DL8.5, and, to a lesser extent, OSDT. Since binary features are used to encode thresholds over continuous features, GOSDT is able to handle continuous datasets of higher cardinality compared to other aforementioned methods.\nExperiment G.8 shows that GOSDT outpaces OSDT and PyGOSDT when it comes to reducing the optimality gap, this allows it to terminate with stronger optimality guarantees in the event of a premature termination.\nExperiment G.9 shows that optimizing an efficient training accuracy vs. sparsity frontier allows GOSDT to more accurately capture the ground truth compared to BinOCT when subject to the same sparsity constraints.\nTo summarize, we began this experimental section by showing the benefits of optimizing more sophisticated objective functions. We then showed the benefits of a more efficient algorithm to support these objectives. Finally, we closed this section by combining these two elements to produce provably optimal and interpretable models and showcase their advantages."
    },
    {
      "heading": "J. Algorithm",
      "text": "In addition to the main GOSDT algorithm (Algorithm 1), we present the subroutines get lower bound (Algorithm 2), get upper bound (Algorithm 3), fails bound (Algorithm 4), and split (Algorithm 5) used during optimization. We also present an extraction algorithm (Algorithm 6) used to construct the optimal tree from the dependency graph once the main GOSDT algorithm completes.\nAlgorithm 1 GOSDT(R,x,y, \u03bb)\n1: input: R, Z, z\u2212, z+, \u03bb // risk, unique sample set, negative sample set, positive sample set, regularizer 2: Q = \u2205 // priority queue 3: G = \u2205 // dependency graph 4: s0 \u2190 {1, ..., 1} // bit-vector of 1\u2019s of length U 5: p0 \u2190 FIND OR CREATE NODE(G, s0) // node for root 6: Q.push(s0) // add to priority queue 7: while p0.lb 6= p0.ub do 8: s\u2190 Q.pop() // index of problem to work on 9: p\u2190 G.find(s) // find problem to work on 10: if p.lb = p.ub then 11: continue // problem already solved 12: (lb\u2032, ub\u2032)\u2190 (\u221e,\u221e) // very loose starting bounds 13: for each feature j \u2208 [1,M ] do 14: sl, sr \u2190 split(s, j, Z) // create children if they don\u2019t exist 15: pjl \u2190FIND OR CREATE NODE(G, sl) 16: pjr \u2190FIND OR CREATE NODE(G, sr) // create bounds as if j were chosen for splitting 17: lb\u2032 \u2190 min(lb\u2032, pjl .lb+ pjr.lb) 18: ub\u2032 \u2190 min(ub\u2032, pjl .ub+ pjr.ub) // signal the parents if an update occurred 19: if p.lb 6= lb\u2032 or p.ub 6= ub\u2032 then 20: (p.lb, p.ub)\u2190 (lb\u2032, ub\u2032) 21: for p\u03c0 \u2208 G.parent(p) do // propagate information upwards 22: Q.push(p\u03c0.id,priority = 1) 23: if p.lb = p.ub then 24: continue // problem solved just now // loop, enqueue all children that are dependencies 25: for each feature j \u2208 [1,M ] do\n// fetch pjl and p j r in case of update from other thread\n26: repeat line 14-16 27: lb\u2032 \u2190 pjl .lb+ pjr.lb 28: ub\u2032 \u2190 pjl .ub+ pjr.ub 29: if lb\u2032 < ub\u2032 and lb\u2032 \u2264 p.ub then 30: Q.push(sl,priority = 0) 31: Q.push(sr,priority = 0) 32: return \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 33: subroutine FIND OR CREATE NODE(G,s) 34: if G.find(s) = NULL // p not yet in dependency graph 35: p.id\u2190 s // identify p by s 36: p.lb\u2190 get lower bound(s, Z, z\u2212, z+) 37: p.ub\u2190 get upper bound(s, Z, z\u2212, z+) 38: if fails bounds(p) then 39: p.lb = p.ub // no more splitting allowed 40: G.insert(p) // put p in dependency graph 41: return G.find(s)\nAlgorithm 2 get lower bound(s, Z, z\u2212, z+)\u2192 lb) input: s, Z, z\u2212, z+ // support, unique sample set, negative sample set, positive sample set output: lb // Risk lower bound // Compute the risk contributed if applying a class to every equivalance class independently for each equivalence class u \u2208 [1, U ] define // Values provided in Z z\u2212u = 1 N \u2211N i=1 1[yi = 0 \u2227 xi = zu]\nz+u = 1 N \u2211N i=1 1[yi = 1 \u2227 xi = zu] // Risk of assigning a class to equivalence class u zminu = min(z \u2212 u , z + u )\n// Add all risks for each class u // Add a single \u03bb which is a lower bound of the complexity penalty lb\u2190 \u03bb+ \u2211 u suz min u return lb\nAlgorithm 3 get upper bound(s, Z, z\u2212, z+)\u2192 ub input: s, Z, z\u2212, z+ // support, unique sample set, negative sample set, positive sample set output: ub // Risk upper bound // Compute the risk contributed if applying a single class to all samples in s for each equivalence class u \u2208 [1, U ] define // Add up the positive and negative class weights under equivalence class u z\u2212u = 1 N \u2211N i=1 1[yi = 0 \u2227 xi = zu]\nz+u = 1 N \u2211N i=1 1[yi = 1 \u2227 xi = zu]\n// Total the positive and negatives over all classes u, choosing the smaller total as the misclassification // Add a single \u03bb for the complexity penalty of a leaf ub\u2190 \u03bb+ min( \u2211 u suz \u2212 u , \u2211 u suz + u ) return ub\nAlgorithm 4 fails bounds(p)\u2192 v input: p // current problem output: v // boolean indicating valid problem // If this expression is true then the lower bound on incremental accuracy is crossed by all descendents // This works because since ub\u2212 lb is an upperbound on incremental accuracy for any descendent incremental accuracy \u2190 p.ub\u2212 p.lb \u2264 \u03bb // If this expression is true then the lower bound on leaf classification accuracy is crossed leaf accuracy \u2190 p.ub \u2264 2\u03bb if (incremental accuracy = True) \u2228 (leaf accuracy = True) then\nreturn True return False\nAlgorithm 5 split(s, j, Z)\u2192 sl, sr input: s, j, Z // support set, feature index, unique sample set output: sl, sr // left and right splits // Create the left key which is the subset of s such that feature j tests negative sl = {1[su = 1 \u2227 Zu,j = 0]|1 \u2264 u \u2264 U} // Create the right key which is the subset of s such that feature j tests positive sr = {1[su = 1 \u2227 Zu,j = 1]|1 \u2264 u \u2264 U} return sl, sr\nAlgorithm 6 extract(t)\u2192 s // Extract optimal tree after running the algorithm input: s // Key of the problem from which we want to build a tree output: t // Optimal tree p\u2190 FIND OR CREATE NODE(G, s) // Find the node associated to this key t\u2190 None // Create a null tree base bound\u2190 p.ub // The risk if we end this node as a leaf base prediction\u2190 0 // The prediction if we end this node as a leaf split bound\u2190\u221e // The risk if we split this node split feature\u2190 0 // The index of the feature we should use to split this node for each feature j \u2208 [1,M ] do // Check all possible features\nsl, sr \u2190 split(s, j, Z) // Key of the the children for this split pjl \u2190FIND OR CREATE NODE(G, sl) // Find left child pjr \u2190FIND OR CREATE NODE(G, sr) // Find right child // Check if the risk of this split is better than the best split risk so far if pjl .ub+ p j r.ub < split bound then\nsplit bound\u2190 pjl .ub+ pjr.ub // Update the best split risk split feature\u2190 j // Best feature index to split on which minimizes loss upper bound\n// Calculate the total positive and negative weights of each equivalence class for each equivalence class u \u2208 [1, U ] define\n// Values come from equivalence class matrix Z as seen in Algorithm 3 z\u2212u = 1 N \u2211N i=1 1[yi = 0 \u2227 xi = zu] // total negatives z+u = 1 N \u2211N i=1 1[yi = 1 \u2227 xi = zu] // total positives\n// Select only the positive and negative weights captured by s negatives\u2190 \u2211 u suz \u2212 u\npositives\u2190 \u2211 u suz + u // Set the leaf prediction based on class with the higher selected total weight if negatives < positives then\n// Leaf predicts the majority class as 1 since positive weights are higher base prediction.pred\u2190 1\n// Base case: If the risk of remaining as a leaf is better than splitting, remain as leaf if base bound \u2264 split feature\n// Construct and return a leaf node t.type\u2190 leaf t.prediction\u2190 base prediction return t\n// Recursive case: One of the splits performs better than the leaf // Generate left and right splits based on best split feature sl, sr \u2190 split(s, split feature, Z) // Recurse onto child keys to create left and right subtrees tl \u2190 extract(sl) tr \u2190 extract(sr) // Construct and return a split node containing the left and right subtrees t.type\u2190 tree t.split\u2190 split feature t.left\u2190 tl t.right\u2190 tr return t"
    }
  ],
  "title": "Generalized and Scalable Optimal Sparse Decision Trees",
  "year": 2020
}
