{"abstractText": "Despite the recent successes of deep learning, such models are still far from some human abilities like learning from few examples, reasoning and explaining decisions. In this paper, we focus on organ annotation in medical images and we introduce a reasoning framework that is based on learning fuzzy relations on a small dataset for generating explanations. Given a catalogue of relations, it efficiently induces the most relevant relations and combines them for building constraints in order to both solve the organ annotation task and generate explanations. We test our approach on a publicly available dataset of medical images where several organs are already segmented. A demonstration of our model is proposed with an example of explained annotations. It was trained on a small training set containing as few as a couple of examples.", "authors": [{"affiliations": [], "name": "R\u00e9gis Pierrard"}, {"affiliations": [], "name": "Jean-Philippe Poli"}, {"affiliations": [], "name": "C\u00e9line Hudelot"}], "id": "SP:d14678b59e6a42e2158fde3c0558d6f4b05c20e7", "references": [{"authors": ["I. Baaj", "J-P. Poli"], "title": "Natural language generation of explanations of fuzzy inference decisions", "venue": "2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),", "year": 2019}, {"authors": ["I. Biederman"], "title": "On the Semantics of a Glance at a Scene", "year": 1981}, {"authors": ["I. Bloch"], "title": "Fuzzy relative position between objects in image processing: a morphological approach", "venue": "IEEE transactions on pattern analysis and machine intelligence, 21(7):657\u2013664,", "year": 1999}, {"authors": ["I. Bloch"], "title": "On fuzzy distances and their use in image processing under imprecision", "venue": "Pattern Recognition, 32(11):1873\u20131895,", "year": 1999}, {"authors": ["I. Bloch"], "title": "Fuzzy spatial relationships for image processing and interpretation: a review", "venue": "Image and Vision Computing, 23(2):89\u2013110,", "year": 2005}, {"authors": ["D.V. Budescu", "H-H. Por", "S.B. Broomell"], "title": "Effective communication of uncertainty in the ipcc reports", "venue": "Climatic Change, 113(2):181\u2013200, Jul", "year": 2012}, {"authors": ["G.C. Cawley", "N.L.C. Talbot"], "title": "On over-fitting in model selection and subsequent selection bias in performance evaluation", "venue": "Journal of Machine Learning Research, 11(Jul):2079\u20132107,", "year": 2010}, {"authors": ["M. Cayrol", "H. Farreny", "H. Prade"], "title": "Fuzzy pattern matching", "venue": "Kybernetes, 11(2):103\u2013116,", "year": 1982}, {"authors": ["O. Colliot", "A.V. Tuzikov", "R.M. Cesar", "I. Bloch"], "title": "Approximate reflectional symmetries of fuzzy objects with an application in model-based object recognition", "venue": "Fuzzy Sets and Systems, 147(1):141 \u2013 163,", "year": 2004}, {"authors": ["A. Criminisi", "J. Shotton", "D. Robertson", "E. Konukoglu"], "title": "Regression forests for efficient anatomy detection and localization in ct studies", "venue": "Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging, pages 106\u2013 117,", "year": 2011}, {"authors": ["I. Donadello", "L. Serafini", "A. d\u2019Avila Garcez"], "title": "Logic tensor networks for semantic image interpretation", "venue": "In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence,", "year": 2017}, {"authors": ["F. Doshi-Velez", "B. Kim"], "title": "Towards a rigorous science of interpretable machine learning", "venue": "eprint arXiv:1702.08608,", "year": 2017}, {"authors": ["D. Dubois", "H. Fargier", "H. Prade"], "title": "Possibility theory in constraint satisfaction problems: Handling priority, preference and uncertainty", "venue": "Applied Intelligence, 6(4):287\u2013309,", "year": 1996}, {"authors": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "title": "One-shot learning of object categories", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(4):594\u2013 611, April", "year": 2006}, {"authors": ["M. Garnelo", "M. Shanahan"], "title": "Reconciling deep learning with symbolic artificial intelligence: representing objects and relations", "venue": "Current Opinion in Behavioral Sciences, 29:17 \u2013 23,", "year": 2019}, {"authors": ["A. Gatt", "E. Reiter"], "title": "Simplenlg: A realisation engine for practical applications", "venue": "Proceedings of the 12th European Workshop on Natural Language Generation, pages 90\u201393,", "year": 2009}, {"authors": ["L.H. Gilpin", "D. Bau", "B.Z. Yuan", "A. Bajwa", "M. Specter", "L. Kagal"], "title": "Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning", "venue": "ArXiv e-prints,", "year": 2018}, {"authors": ["A. Gonz\u00e1lez", "R. P\u00e9rez", "Y. Caises", "E. Leyva"], "title": "An efficient inductive genetic learning algorithm for fuzzy relational rules", "venue": "International Journal of Computational Intelligence Systems, 5(2):212\u2013230,", "year": 2012}, {"authors": ["D. Gunning"], "title": "Explainable artificial intelligence (xai)", "year": 2017}, {"authors": ["G. Hinton", "N. Frosst"], "title": "Distilling a neural network into a soft decision", "year": 2017}, {"authors": ["O. Jimenez-del Toro", "H. M\u00fcller", "M. Krenn", "K. Gruenberg", "A.A. Taha", "M. Winterstein", "I. Eggel", "A. Foncubierta-Rodr\u0131\u0301guez", "O. Goksel", "A. Jakab"], "title": "Cloud-based evaluation of anatomical structure segmentation and landmark detection algorithms: Visceral anatomy benchmarks", "venue": "IEEE transactions on medical imaging,", "year": 2016}, {"authors": ["H. Larochelle", "D. Erhan", "Y. Bengio"], "title": "Zero-data learning of new tasks", "venue": "Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 2, pages 646\u2013651,", "year": 2008}, {"authors": ["C-C. Lee", "P-C. Chung", "H-M. Tsai"], "title": "Identifying multiple abdominal organs from ct image series using a multimodule contextual neural network and spatial fuzzy rules", "venue": "IEEE Transactions on Information Technology in Biomedicine, 7(3):208\u2013217, Sep.", "year": 2003}, {"authors": ["F-F. Li", "R. VanRullen", "C. Koch", "P. Perona"], "title": "Rapid natural scene categorization in the near absence of attention", "venue": "Proceedings of the National Academy of Sciences, 99(14):9596\u20139601,", "year": 2002}, {"authors": ["Z.C. Lipton"], "title": "The mythos of model interpretability", "venue": "Queue, 16(3):30:31\u201330:57, June", "year": 2018}, {"authors": ["G. Litjens", "T. Kooi", "B.E. Bejnordi", "A.A. Adiyoso Setio", "F. Ciompi", "M. Ghafoorian", "J.A.W.M. van der Laak", "B. van Ginneken", "C.I. S\u00e1nchez"], "title": "A survey on deep learning in medical image analysis", "venue": "Medical Image Analysis,", "year": 2017}, {"authors": ["S.M. Lundberg", "S-I. Lee"], "title": "A unified approach to interpreting model predictions", "venue": "Advances in Neural Information Processing Systems 30, pages 4765\u2013 4774.", "year": 2017}, {"authors": ["G. Marcus"], "title": "Deep learning: A critical appraisal", "venue": "CoRR, abs/1801.00631,", "year": 2018}, {"authors": ["T. Miller"], "title": "Explanation in artificial intelligence: Insights from the social sciences", "venue": "Artifical Intelligence, 267:1\u201338, February", "year": 2019}, {"authors": ["S. Minton", "M.D. Johnston", "A.B. Philips", "P. Laird"], "title": "Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems", "venue": "Artificial Intelligence, 58(1):161 \u2013 205,", "year": 1992}, {"authors": ["O. Pauly", "B. Glocker", "A. Criminisi", "D. Mateus", "A.M. M\u00f6ller", "S. Nekolla", "N. Navab"], "title": "Fast multiple organ detection and localization in whole-body 9 mr dixon sequences", "venue": "Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI 2011, pages 239\u2013247,", "year": 2011}, {"authors": ["R. Pierrard", "J-P. Poli", "C. Hudelot"], "title": "A fuzzy close algorithm for mining fuzzy association rules", "venue": "Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations, pages 88\u201399,", "year": 2018}, {"authors": ["M.T. Ribeiro", "S. Singh", "C. Guestrin"], "title": "Why should i trust you?: Explaining the predictions of any classifier", "venue": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135\u20131144,", "year": 2016}, {"authors": ["H.R. Roth", "C.T. Lee", "H-C. Shin", "A. Seff", "L. Kim", "J. Yao", "L. Lu", "R.M. Summers"], "title": "Anatomy-specific classification of medical images using deep convolutional nets", "venue": "arXiv preprint arXiv:1504.04003,", "year": 2015}, {"authors": ["H. Shin", "M.R. Orton", "D.J. Collins", "S.J. Doran", "M.O. Leach"], "title": "Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4d patient data", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1930\u20131943, Aug", "year": 2013}, {"authors": ["S. Thorpe", "D. Fize", "C. Marlot"], "title": "Speed of processing in the human visual system", "venue": "Nature, 381(6582):520,", "year": 1996}, {"authors": ["M.C. Vanegas", "I. Bloch", "J. Inglada"], "title": "Fuzzy constraint satisfaction problem for model-based image interpretation", "venue": "Fuzzy Sets and Systems, 286:1 \u2013 29,", "year": 2016}, {"authors": ["Z. Xue", "S. Antani", "L.R. Long", "G.R. Thoma"], "title": "Automatic multi-label annotation of abdominal ct images using cbir", "venue": "Medical Imaging 2017: Imaging Informatics for Healthcare, Research, and Applications, volume 10138, page 1013807,", "year": 2017}, {"authors": ["L.A. Zadeh"], "title": "Fuzzy sets", "venue": "Information and Control, 8(3):338 \u2013 353,", "year": 1965}], "sections": [{"heading": "1 Introduction", "text": "In the last few years, explaining outputs returned by Artificial Intelligence (AI) algorithms has become more and more important [14, 20]. This echoes the dominance of deep neural networks, which reach very high performance in several visual recognition tasks but lack of explainability [29, 16]. Explaining decisions returned by intelligent systems is not only helpful for understanding their reasoning process, it is also essential for gaining acceptance and becoming trustworthy to humans [34]. In human-\ncentered fields like medical image analysis [27], decisions cannot be made relying blindly on a model since the consequences could be disastrous.\nWhile several definitions of interpretability and explainability exist in the literature [30, 18, 26, 12], there is no consensus among them and these two notions are sometimes used interchangeably. Overall, it emerges that interpretability is the ability to present insight into how a system works in understandable terms, whereas explainability is the ability to describe how a system works in an accurate and logical way. In this paper, we focus on rendering the reasoning process of our model to explain its decisions. To get explanations, a first family of methods consists in learning a local interpretable approximation model around the prediction returned by a blackbox model [28, 34]. Those approaches can deal with any model, so they are well-suited for deep neural networks. However, although they aim at extracting key characteristics that led to the output, they cannot exactly replicate the reasoning the black-box model performed. The second possibility is to use models that are propitious for generating explanations, such as decision trees, decision rules or by distilling an unexplainable model into an explainable one [21]. Their main advantage is that the reasoning leading to a specific output is easy to track, so it can be used for generating an explanation. However, those models may not be as effective as black-box models, since explainability usually comes at a cost. Indeed, there is a well-known trade-off between accuracy and explainabil-\nar X\niv :1\n91 2.\n12 93\n2v 1\n[ cs\n.C V\n] 3\nity [20]. In this paper, we propose to rely on this second family of approaches by counterbalancing this trade-off with very little need for labelled data whose acquisition is costly. Our approach is based on two conclusions from human image interpretation studies: (1) the importance of contextual and spatial relations in object and scene recognition [2], and (2) the ability of humans to learn from few examples [37, 25]. Several approaches focus on few data learning [23, 15] but they need side information. We propose to mix statistical and symbolic learning to train a model that learns to manipulate spatial relations from few examples.\nOur goal is to build a novel approach that can learn to reason and generate both annotations and explanations from just few examples. In our experiments, the organs to annotate all have properties and they are all linked by spatial relations. Thus, learning these relations and properties should help us to recognize them. Our approach relies on using fuzzy relations that take into account both quantitative and qualitative information, which enables to have a linguistic and thus understandable description of each relation. Learning fuzzy relations has already been proposed in [11] and in [19] to achieve higher classification performance but not for explaining the reasoning as we propose. Given an unknown example, the system looks for the set of objects that best satisfies the relations between the objects of interest. We model this as a constraint satisfaction problem. In Section 3, we describe the whole pipeline that consists in three main steps: assessing relations, extracting the most relevant ones and generating constraints for solving a constraint satisfaction problem and producing explanations. In Section 4, a demonstration of this approach is shown on a task of multiple organ recognition on medical images. This task is a good example of spatial reasoning since the spatial arrangement of the organs plays an important role in their recognition. In addition, working on medical images presents several challenges, including a need for explainability and the fact that datasets are usually small. We tested and compared our model to the state of the art and showed that our approach is able to achieve high accuracy and generate explanations in spite of a low number of training data."}, {"heading": "2 Background", "text": "The approach we present in the next section relies on learning relevant fuzzy relations between objects for defining a constraint satisfaction problem. All the notions that are involved are reminded in this section."}, {"heading": "2.1 Fuzzy Logic", "text": "Fuzzy logic and fuzzy set theory [40] can be seen as an extension of Boolean logic that enables to manage imprecision. In a universeA, a fuzzy set F is characterized by a mapping such as \u00b5F : A\u2192 [0, 1]. This mapping specifies in what extent each a \u2208 A belongs to F and it is called the membership function of F . If F is a non-fuzzy set, \u00b5F (a) is either 0, i.e. a is not a member of F , or 1, i.e. a is a member of F . This range of degrees is useful for dealing with vagueness.\nThe fuzzy logic framework is also convenient for expressing relations between two sets. Given two universes A and B, a binary fuzzy relation R is characterized by a mapping defined as \u00b5R : A \u00d7 B \u2192 [0, 1]. It assigns a degree of relationship to any (a, b) \u2208 A \u00d7 B. n-ary fuzzy relations are defined identically. Another advantage is that fuzzy logic allows using words instead of mathematical symbols."}, {"heading": "2.2 Fuzzy Constraint Satisfaction Problem", "text": "A constraint satisfaction problem (CSP) consists in assigning some values to a set of variables that must respect a set of constraints, such as scheduling problems [31] for instance. [13] presents an extension of CSPs to the fuzzy logic framework to deal with imprecise parameters and flexible constraints. This is called a fuzzy constraint satisfaction problem (FCSP). A FCSP is defined by a set of variables X , a set of domains D and a set of flexible constraints C. It is an appealing framework in the context of explainable annotation since it enables to both solve the annotation task (getting each variable assignment) and generate explanations using the constraints.\nTo solve a FCSP, the FAC-3 algorithm [13, 38] is usually applied to prune the search space. Then, a backtracking algorithm explores every possible solution. Finally, we get the best solution by picking the one that is the most consistent with the set of constraints C.\nStep 1: Assessing the relations from V\non the training set\nStep 2: Extracting frequent relations\nStep 3: Solving the FCSP and generating explained outputs\nExplanation: The red organ is the liver because it is to the right of the spleen,...\nliver\nright kidney\nright psoas major muscle\nurinary bladder\nleft psoas major muscle\nspleen\nn R\nFigure 1: Illustration of our explainable multiple organ annotation system. In step 1, the R fuzzy relations from the vocabulary V are evaluated on a training set of n images. In step 2, the most frequent of them are extracted to set constraints. In step 3, for each test image, a FCSP is defined and solved to label the different regions. An explanation is provided for each labeling based on the constraints that are used."}, {"heading": "3 Proposed Approach", "text": "In this section, we describe our new approach that aims at annotating regions of interest in images and at providing an explanation for each annotation. It consists of three steps: the assessment of fuzzy relations from a given vocabulary between the organs we are looking for (Sec. 3.1), the learning of the most relevant relations between the organs (Sec. 3.2) and the solving of a FCSP providing explanations for finding the regions that are the most consistent with the relevant relations and explaining the reasoning behind it (Sec. 3.3). An overview of the whole approach is illustrated in Figure 1."}, {"heading": "3.1 Step 1: Assessing Relations", "text": "This step aims at evaluating several relations between the regions of interest (the organs) so that we can later (in the following step) find the most relevant of them.\nLet us consider a training set Ttrain that contains n images {i1, . . . , in} and a set of labels Y that contains N labels {y1, . . . , yN} such as each image i \u2208 Ttrain is divided into K regions of interest {oi,1, . . . , oi,K} that are mapped to labels by the following function:\nf : {oi,1, . . . , oi,K}\u2192Y oi 7\u2192yj\n(1)\nLet us consider a set V = {R1, . . . ,RR} of relations. We call this set a vocabulary. It is set by an expert in the target task and it is composed of would-be relevant relations. For example, one relation can be a directional relation like to the left of or a distance relation like close to. The richer the vocabulary, the more expressive the system which should help to produce better annotations and explanations. Relations in V are automatically evaluated on the regions of interest of each image in Ttrain. The way they are computed depends on the definition of the relation, as shown in Sec. 4.2.2.\nFor any relation R \u2208 V , let \u03b1(R) denote its arity. R is evaluated for each possible \u03b1(R)-tuple of regions of interest. It is important to distinguish R from its evaluations on the different regions. The number of evaluations to perform is:\nn\u2211 p=1 R\u2211 j=1\nK!\n(K \u2212 \u03b1(Rj))! (2)\nAt the end of this step, we have a set of evaluated relations between organs {R(f(oi,v), f(oi,w)) | R \u2208 V, i \u2208 Ttrain, oi,v, oi,w \u2208 i} that can be seen as features."}, {"heading": "3.2 Step 2: Learning Relevant Fuzzy Relations", "text": "In this step, the objective is to extract among the previously assessed relations the most relevant of them. For a label y \u2208 Y , our postulate is that the relevant relations involving the regions labelled as y are the most frequent\nones since they should be verified by most, if not all, examples of these regions. Thus, learning the relevant relations is performed by mining the most frequent ones. It is done in a one-vs-all way since the relevant relations for one class of organs are not the same as for a different class. As each example from one class should be correlated to each other, we use a fuzzy mining algorithm that takes advantage of that [33].\nLet E(V) be the set of all the evaluations of relations from V on the labeled regions of interest. A subset of relations J is a set belonging to 2E(V). The mining algorithm we use is based on a fuzzy closure operator h : 2E(V) \u2192 2E(V) that enables to find all the closed sets of relations [33]. All the frequent closed sets of relations are computed and the frequent sets of relations can be derived from them. A set of relations is said to be frequent when its frequency in the dataset is larger than a given threshold. Since this step is performed in a one-vsall way, each class has its own threshold whose value is an hyperparameter determined during a validation phase. The value of this threshold has a direct impact on the number of frequent subsets of relations that are extracted. If it is too high, it is likely that no or few subsets of relations are seen as frequent, which may be not enough for discriminating classes. This would be a case of underfitting. On the other hand, if the threshold is too low, some irrelevant features will be kept. That would lead to overfitting. At the end of this step, for each label y \u2208 Y , we have a set of frequent subsets of evaluated relations Fy such as Fy \u2286 22 E(V) ."}, {"heading": "3.3 Step 3: Solving the FCSP and Generating Explanations", "text": "Given a test example i, we can obtain a set of potential regions of interest by segmentation. The goal of this step is to find the labels of the regions that best satisfy the relations between organs that were learnt in the previous step. This can be modelled as a FCSP. Also, since these relations are associated to a linguistic description, we can generate an explanation for each annotation.\nFor each label y \u2208 Y , we got at the end of the previous step a set Fy . Let us define Fmaxy such as :\nFmaxy = {z \u2208 Fy | Card(z) = max v\u2208Fy\n( Card(v) ) } (3)\nThis set corresponds to the set of the frequent subsets of relations of maximal size. Each evaluated relation R ( f(oi,v), f(oi,w) ) in the subsets of relations\nin \u22c3\ny\u2208Y Fmaxy is directly translated into a constraint cR ( f(oi,v), f(oi,w) ) . We can now build a model that is defined by the constraints that have been learned and its frequency thresholds. No iterative optimization process is needed, which makes it well suited to small training sets.\nThe test example i is divided into K regions of interest {oi,1, . . . , oi,K} that we want to annotate. The FCSP we get is the following :\nX = {oi,1, . . . , oi,K} (4)\nD = {Dj | Dj = Y, 1 \u2264 j \u2264 K} (5)\nC = {cR(f(oi,v), f(oi,w)) | R(f(oi,v), f(oi,w)) \u2208 U such as U \u2286 \u22c3 y\u2208Y Fmaxy } (6)\nThen, each constraint in C is evaluated, the FCSP is solved and the first part of the output, the labels, are returned. We obtain a new mapping fx such as :\nfi : {oi,1, . . . , oi,K}\u2192Y oi 7\u2192yj\n(7)\nThen, for each variable oi,j \u2208 X , an explanation is generated using the constraints in C. This is possible because the relations (and so the constraints) that we use are associated to a linguistic description. For instance, the constraint cRto the left of(A,B) (represented as a tuple (A,B,Rto the left of)) leads to: \u201cA is to the left ofB\u201d. Thus, using the constraints generated from Fmaxy enables to express an explanation in the form of \u201coutput BECAUSE cause1,...,causen\u201d. For a given label y, all the constraints related to y are extracted. The least satisfied constraint gives us a certainty factor to moderate the explanation [6], e.g. \u201dThis organ is likely to be annotated as the liver...\u201c. The constraints and the certainty factor are then sent to a surface realiser like simpleNLG [17] to aggregate them into a syntactically correct sentence."}, {"heading": "4 Case study", "text": "In this section, we detail the experiments we have performed on a dataset of medical images. The task is to perform explained multiple organ annotation by learning a model from few data. While multiple organ detection has been a regularly tackled topic in the literature [36, 10, 32, 24], multiple organ annotation has only been tackled in [39]. The principle of this method is to find images in the dataset that share visual characteristics with the image under study, and then to label it based on the labels from visually similar images. However, it cannot provide any explanation. In [24], abdominal organ detection is performed using fuzzy spatial rules, but these rules are not suited to other datasets and they have to be set by an expert before learning. Organ classification has been addressed in [35] using data augmentation to dodge the problem of having a small training set."}, {"heading": "4.1 Dataset", "text": "It is important to note that the field of XAI is currently lacking a dataset that mainly focuses on explanations. This is why we carried out our experiments on a segmentation dataset that we used for assessing the accuracy of our model and the reliability of the explanations it produces. This dataset is named Anatomy3 and has been presented in [22]. It contains 391 CT and MR images and their corresponding segmented organs. Images can be scans of the whole body (referred as CTwb and MRwb) or enhanced images of the abdomen (referred as CTce and MRce). Those are all 3D images that are actually the superposition of 2D slices. As we work on 2D images, we consider only slices in the following. We selected the slices to build a 2D image dataset. Figure 2 displays one example for each type of scan.\nThe set Y of organs (labels) we study is composed of the liver, the spleen, the urinary bladder, the left and right kidneys, the left and right lungs and the left and right psoas major muscles. We kept all the images that contain these 9 organs (and their corresponding segments), for a total of 35 examples and 315 segments in our dataset."}, {"heading": "4.2 Experimental Settings", "text": ""}, {"heading": "4.2.1 Model Training", "text": "The model we build with our approach consists in the frequent subsets of relations that are extracted. There are as many hyperparameters as labels and they correspond to the thresholds used for assessing the frequency of a subset of relations. Model selection is necessary to get optimized thresholds, which is why we used nested crossvalidation [7]: (1) an outer cross-validation is performed in which we get a training set and a test set for each iteration, (2) an inner cross-validation is performed on the training set of the outer cross-validation to get an inner training set and a validation set for tuning hyperparameters. This enables to get an unbiased error prediction.\nIn the inner cross-validation, hyperparameter tuning is performed using bayesian optimization over 20 iterations with a Gaussian process prior. The acquisition function is the expected improvement."}, {"heading": "4.2.2 Relations", "text": "Many fuzzy spatial relations have been studied in the literature [5]. In our experiments, we use directional, distance and symmetry relations. Directional and distance relations [3, 4] are computed as a fuzzy landscape and assessed using a fuzzy pattern matching approach [8]. As shown in Figure 3, the fuzzy landscape is generated by computing the fuzzy morphological dilation of a reference object by a structuring element whose shape determines the kind of relation. Let S be the space of the images. Let A be a reference object in S and \u00b5A,R the membership\nfunction associated to the fuzzy landscape representing the relation R whose reference object is A. Let \u00b5B be the membership function corresponding to an object B in S. The relation R between A and B is the result of the fuzzy degree of intersection \u00b5int between \u00b5A,R and \u00b5B such as [5]\n\u00b5int(\u00b5A,R, \u00b5B) =\n\u2211 x\u2208S min ( \u00b5A,R(x), \u00b5B(x) ) min\n( \u2211 x\u2208S \u00b5A,R(x), \u2211 x\u2208S \u00b5B(x) ) (8)\nFor instance, in Figure 3, the relation R is to the left of, the reference object A is the red organ and the object B is the blue organ.\nTo get a finite catalogue of relations, we constrained the parameters of these relations to express only relations such as above or close to.\nThe symmetry relation [9] we use consists in finding the line that maximizes a symmetry measure between two organs. Since this measure is not differentiable, a direct search method is used to solve this optimization problem, such as the downhill simplex method.\nWe also use one property that can be seen as a unary relation since it characterizes just one organ. It evaluates\nhow stretched an organ is. Given a segmented organ, a PCA is performed to get its two principal axes. Then, the organ is projected on both axis and the ratio of these projections is used to compute the degree corresponding to this property. However, this does not manage concave shapes well.\nOur vocabulary of relations V contains: to the left of, to the right of, below, above, close to, symmetrical to and stretched. That makes 6 binary and one unary relations. As we consider 9 organs, the number of relations to evaluate for one image is equal to 441, which contributes to make our model expressive. There is however a trade-off between the expressivity of the system and the computation time needed for assessing all these relations."}, {"heading": "4.3 Problem initialization", "text": "As stated in in Sec. 3, the whole process consists in three main steps. The inputs we deal with are segments provided in the datasets. They are not fuzzy, but the process is exactly the same whether we deal with fuzzy or crisp objects.\nThe intermediary goal is to generate constraints for defining a FCSP. Once solved, the FCSP returns the labels and constraints are used for generating explanations.\nThe variables are the segments provided in the dataset. Each of them corresponds to an organ. We have the following FCSP:\nX = {oliver, ospleen, obladder, or kidney, ol kidney, or lung, ol lung, or psoas, ol psoas}\nD = {Dliver, Dspleen, Dbladder, Dr kidney, Dl kidney, Dr lung, Dl lung, Dr psoas, Dl psoas}\nwhere Di is equal to Y . For each organ y, the flexible constraints are generated from the set of the frequent subsets of relations of maximal size Fmaxy to build a set of constraints C. Furthermore, since every organ is unique, there cannot be identical annotations in this problem. That means C has to be extended with constraints representing that two variables cannot be the same, which is the AllDifferent global constraint.\nThe definition of the FCSP is thus made automatically. Then, once the FCSP is defined, for a given example, it can be solved as described in Sec. 2.2."}, {"heading": "4.4 Results", "text": "Fig. 4 shows an example of output for an input image with 9 organs to annotate and thus 9 explanations to provide.\nWe evaluate our model using the accuracy, which is the ratio for all organs of the number of correct annotations over the total number of annotations. We got an accuracy of 100% for a model containing only directional relations. The outer cross-validation is actually a 3-fold cross-validation (23/24 training examples for 12/11 test examples in each iteration) and the inner one is a 4-fold cross-validation. As there are 9 organs to annotate, there are 9 hyperparameters that need to be set for extracting frequent relations (Table 1). Constraints could be added to the hyperparameter optimization process to make explanations longer or shorter. We observe the explanations rightfully rely on the relations that have been extracted and later turned into constraints. For example in Fig. 4, the set of constraints associated to the right kidney is: Cr kidney = {(xr kidney, xl kidney,Rsymmetrical to), (xr lung, xr kidney,Rabove), (xr kidney, xliver,Rto the left of), (xbladder, xr kidney,Rbelow), (xr kidney, xl kidney, Rto the right of), (xl kidney, xr kidney,Rto the left of)}. Some of these constraints may seem redundant, like the last two constraints in Cr kidney . That can happen because fuzzy morphological dilations depend on the shape of the reference object. As two different organs are never exactly the same, there are slight differences between those two constraints. Each organ is linked to such a set of constraints. The final set of constraints C is the union of all these sets.\nAssessing the quality of the explanations is tricky.\nWhat makes a good explanation ultimately depends on the knowledge and expectation of the end-user. Criteria like the coherence, the simplicity and the relevancy of the explanation are good indicators [30, 1], but they may not be easy to assess. Three evaluation methods are proposed in [12]: asking an expert, asking simple questions to a group of non-expert people or using a proxy model that has been proved to be explainable to assess the model under study.\nWe also investigated on the number of training examples that are required by our model to perform well. We get an accuracy of 99% at worst for a couple of training images (so 33 test examples). Actually, when dealing with just one training example, since our model looks for frequent relations to set the constraints, it will extract the relations whose evaluation is larger than the thresholds we talked about in Sec. 3.2. Any example that is not an outlier should then allow the model to perform well. Thus, we show that our approach can perform spatial reasoning and achieve high accuracy from just a pair of training examples.\nWe observe that our model outperforms the CNN classifier presented in [35], which does not achieve perfect accuracy. That model was trained on a bigger training set and does not provide any kind of explanation. The closest method to ours, which was presented in [39], does not\ngive any accuracy as a baseline. Its drawback is that it can miss labels, which happens at least once every five examples. In our approach, a label cannot be missing since every variable of the FCSP has to be associated to a domain.\nOn a side note, the generalisability of our approach depends on how well images are segmented (although fuzzy logic helps to deal with imprecision), how expressive the vocabulary is and how many outliers are in the dataset. Applications where one of this is missing may lead to a drop in performance regarding both annotations and explanations."}, {"heading": "5 Conclusion and Prospects", "text": "In this article, we present a novel visual learning and reasoning framework whose goal is to explain and annotate relevant objects in images. The problem is formalized as a fuzzy constraint satisfaction problem. It is based on fuzzy spatial relations, which are learned on a set of annotated objects in images and then translated into constraints. We demonstrated our approach on a medical image dataset and showed that our method takes advantage of symbolic learning and reasoning so that it explains its results and it only needs a couple of training examples to achieve 99% accuracy.\nIn the future, we would like to work on a strategy that makes the first step of the process faster. A first idea is to determine a hierarchical structure of the spatial relations to apply a topological sort. Moreover, since fuzzy logic enables to manage imprecise segments, the goal is to insert an unsupervised segmentation model before the model we presented here. This would enable to adapt to different kinds of images.\nFinally, this is a first step in mixing statistical machine learning (especially deep learning) for perception with symbolic learning and reasoning for higher level intelligence in order to create an explainable artificial intelligence."}], "title": "A New Approach for Explainable Multiple Organ Annotation with Few Data", "year": 2020}