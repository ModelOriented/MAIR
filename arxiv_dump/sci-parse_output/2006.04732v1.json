{
  "abstractText": "Black-box models in machine learning have demonstrated excellent predictive performance in complex problems and high-dimensional settings. However, their lack of transparency and interpretability restrict the applicability of such models in critical decision-making processes. In order to combat this shortcoming, we propose a novel approach to trading off interpretability and performance in prediction models using ideas from semiparametric statistics, allowing us to combine the interpretability of parametric regression models with performance of nonparametric methods. We achieve this by utilizing a two-piece model: the first piece is interpretable and parametric, to which a second, uninterpretable residual piece is added. The performance of the overall model is optimized using methods from the sufficient dimension reduction literature. Influence function based estimators are derived and shown to be doubly robust. This allows for use of approaches such as Double Machine Learning in estimating our model parameters. We illustrate the utility of our approach via simulation studies and a data application based on predicting the length of stay in the intensive care unit among surgery patients.",
  "authors": [
    {
      "affiliations": [],
      "name": "Numair Sani"
    }
  ],
  "id": "SP:0625e3167ed7a8eda431234a15a96fc0feae8336",
  "references": [
    {
      "authors": [
        "Ahmed Almashrafi",
        "Mustafa Elmontsri",
        "Paul Aylin"
      ],
      "title": "Systematic review of factors influencing length of stay in ICU after adult cardiac surgery",
      "venue": "BMC Health Services Research,",
      "year": 2016
    },
    {
      "authors": [
        "David Alvarez-Melis",
        "Tommi S Jaakkola"
      ],
      "title": "Towards robust interpretability with self-explaining neural networks",
      "venue": "In Proceedings of the 32nd International Conference on Neural Information Processing Systems,",
      "year": 2018
    },
    {
      "authors": [
        "Peter J Bickel",
        "Chris AJ Klaassen",
        "Ya\u2019acov Ritov",
        "J Klaassen",
        "Jon A Wellner",
        "YA\u2019Acov Ritov"
      ],
      "title": "Efficient and adaptive estimation for semiparametric models, volume 4",
      "year": 1993
    },
    {
      "authors": [
        "Jenna Burrell"
      ],
      "title": "How the machine \u2018thinks\u2019: Understanding opacity in machine learning algorithms",
      "venue": "Big Data & Society,",
      "year": 2016
    },
    {
      "authors": [
        "Victor Chernozhukov",
        "Denis Chetverikov",
        "Mert Demirer",
        "Esther Duflo",
        "Christian Hansen",
        "Whitney Newey",
        "James Robins"
      ],
      "title": "Double/debiased machine learning for treatment and structural parameters, 2018",
      "year": 2018
    },
    {
      "authors": [
        "Edward Choi",
        "Mohammad Taha Bahadori",
        "Jimeng Sun",
        "Joshua Kulas",
        "Andy Schuetz",
        "Walter Stewart"
      ],
      "title": "Retain: An interpretable predictive model for healthcare using reverse time attention mechanism",
      "venue": "In Advances in Neural Information Processing Systems,",
      "year": 2016
    },
    {
      "authors": [
        "R Dennis Cook",
        "Sanford Weisberg"
      ],
      "title": "Sliced inverse regression for dimension reduction: Comment",
      "venue": "Journal of the American Statistical Association,",
      "year": 1991
    },
    {
      "authors": [
        "Lynn V Doering",
        "Fardad Esmailian",
        "Flerida Imperial-Perez",
        "Sheri Monsein"
      ],
      "title": "Determinants of intensive care unit length of stay after coronary artery bypass graft surgery",
      "year": 2001
    },
    {
      "authors": [
        "Y. Dong",
        "B. Li"
      ],
      "title": "Dimension reduction for non-elliptically distributed predictors: Second-order methods",
      "year": 2010
    },
    {
      "authors": [
        "Finale Doshi-Velez",
        "Been Kim"
      ],
      "title": "Towards a rigorous science of interpretable machine learning, 2017",
      "year": 2017
    },
    {
      "authors": [
        "Mengnan Du",
        "Ninghao Liu",
        "Xia Hu"
      ],
      "title": "Techniques for interpretable machine learning",
      "venue": "arXiv preprint arXiv:1808.00033,",
      "year": 2018
    },
    {
      "authors": [
        "Ruth C Fong",
        "Andrea Vedaldi"
      ],
      "title": "Interpretable explanations of black boxes by meaningful perturbation",
      "venue": "In Proceedings of the IEEE International Conference on Computer Vision,",
      "year": 2017
    },
    {
      "authors": [
        "Trevor Hastie",
        "Robert Tibshirani",
        "Martin Wainwright"
      ],
      "title": "Statistical Learning With Sparsity: The Lasso and Generalizations",
      "year": 2015
    },
    {
      "authors": [
        "Trevor J Hastie"
      ],
      "title": "Generalized additive models. In Statistical models in S, pages 249\u2013307",
      "year": 2017
    },
    {
      "authors": [
        "Hidehiko Ichimura"
      ],
      "title": "Semiparametric least squares (sls) and weighted sls estimation of singleindex models",
      "year": 1991
    },
    {
      "authors": [
        "Andrew A Kramer",
        "Jack E Zimmerman"
      ],
      "title": "A predictive model for the early identification of patients at risk for a prolonged intensive care unit length of stay",
      "venue": "BMC medical informatics and decision making,",
      "year": 2010
    },
    {
      "authors": [
        "Himabindu Lakkaraju",
        "Ece Kamar",
        "Rich Caruana",
        "Jure Leskovec"
      ],
      "title": "Interpretable & explorable approximations of black box models, 2017",
      "year": 2017
    },
    {
      "authors": [
        "H L\u00e4uter. Silverman"
      ],
      "title": "bw: Density estimation for statistics and data analysis",
      "venue": "chapman & hall, london\u2013new york 1986,",
      "year": 1988
    },
    {
      "authors": [
        "D R Lawrence"
      ],
      "title": "Parsonnet score is a good predictor of the duration of intensive care unit stay following cardiac surgery",
      "year": 2000
    },
    {
      "authors": [
        "D R Lawrence",
        "O Valencia",
        "E E J Smith",
        "A Murday",
        "T Treasure"
      ],
      "title": "Parsonnet score is a good predictor of the duration of intensive care unit stay following cardiac surgery",
      "year": 2000
    },
    {
      "authors": [
        "Hyun Woo Lee",
        "Yeonkyung Park",
        "Eun Jin Jang",
        "Yeon Joo Lee"
      ],
      "title": "Intensive care unit length of stay is reduced by protocolized family support intervention: a systematic review and metaanalysis",
      "venue": "Intensive care medicine,",
      "year": 2019
    },
    {
      "authors": [
        "Bing Li",
        "Shaoli Wang"
      ],
      "title": "On directional regression for dimension reduction",
      "venue": "Journal of the American Statistical Association,",
      "year": 2007
    },
    {
      "authors": [
        "Ker-Chau Li"
      ],
      "title": "Sliced inverse regression for dimension reduction",
      "venue": "Journal of the American Statistical Association,",
      "year": 1991
    },
    {
      "authors": [
        "Ker-Chau Li"
      ],
      "title": "On principal hessian directions for data visualization and dimension reduction: Another application of stein\u2019s lemma",
      "venue": "Journal of the American Statistical Association,",
      "year": 1992
    },
    {
      "authors": [
        "Ker-Chau Li",
        "Naihua Duan"
      ],
      "title": "Regression analysis under link violation",
      "venue": "The Annals of Statistics,",
      "year": 1989
    },
    {
      "authors": [
        "Qi Li"
      ],
      "title": "Efficient estimation of additive partially linear models",
      "venue": "International Economic Review,",
      "year": 2000
    },
    {
      "authors": [
        "Zachary C. Lipton"
      ],
      "title": "The mythos of model interpretability, 2016",
      "year": 2016
    },
    {
      "authors": [
        "Yanyuan Ma",
        "Liping Zhu"
      ],
      "title": "A semiparametric approach to dimension reduction",
      "venue": "Journal of the American Statistical Association,",
      "year": 2012
    },
    {
      "authors": [
        "W. James Murdoch",
        "Chandan Singh",
        "Karl Kumbier",
        "Reza Abbasi-Asl",
        "Bin Yu"
      ],
      "title": "Definitions, methods, and applications in interpretable machine learning",
      "venue": "Proceedings of the National Academy of Sciences,",
      "year": 2019
    },
    {
      "authors": [
        "Razieh Nabi",
        "Ilya Shpitser"
      ],
      "title": "Semi-parametric causal sufficient dimension reduction of high dimensional treatments",
      "venue": "arXiv preprint arXiv:1710.06727,",
      "year": 2017
    },
    {
      "authors": [
        "V. Parsonnet",
        "D. Dean",
        "A.D. Bernstein"
      ],
      "title": "A method of uniform stratification of risk for evaluating the results of surgery in acquired adult heart disease",
      "venue": "Pt 2):I3\u201312,",
      "year": 1989
    },
    {
      "authors": [
        "Seyedeh Neelufar Payrovnaziri",
        "Zhaoyi Chen",
        "Pablo Rengifo-Moreno",
        "Tim Miller",
        "Jiang Bian",
        "Jonathan H Chen",
        "Xiuwen Liu",
        "Zhe He"
      ],
      "title": "Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review",
      "venue": "Journal of the American Medical Informatics Association,",
      "year": 2020
    },
    {
      "authors": [
        "K. Pearson"
      ],
      "title": "On lines and planes of closest fit to systems of points in space",
      "venue": "Philosophical Magazine,",
      "year": 1901
    },
    {
      "authors": [
        "Peter Pronovost",
        "Dale Needham",
        "Sean Berenholtz",
        "David Sinopoli",
        "Haitao Chu",
        "Sara Cosgrove",
        "Bryan Sexton",
        "Robert Hyzy",
        "Robert Welsh",
        "Gary Roth"
      ],
      "title": "An intervention to decrease catheterrelated bloodstream infections in the icu",
      "venue": "New England Journal of Medicine,",
      "year": 2006
    },
    {
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "title": "why should i trust you?\": Explaining the predictions of any classifier, 2016",
      "year": 2016
    },
    {
      "authors": [
        "Karen Simonyan",
        "Andrea Vedaldi",
        "Andrew Zisserman"
      ],
      "title": "Deep inside convolutional networks: Visualising image classification models and saliency",
      "year": 2013
    },
    {
      "authors": [
        "Paul Speckman"
      ],
      "title": "Kernel smoothing in partial linear models",
      "venue": "Journal of the Royal Statistical Society: Series B (Methodological),",
      "year": 1988
    },
    {
      "authors": [
        "Anastasios Tsiatis"
      ],
      "title": "Semiparametric theory and missing data",
      "venue": "Springer Science & Business Media,",
      "year": 2007
    },
    {
      "authors": [
        "Aad W Van der Vaart"
      ],
      "title": "Asymptotic statistics, volume 3",
      "venue": "Cambridge university press,",
      "year": 2000
    },
    {
      "authors": [
        "Qihua Wang"
      ],
      "title": "Dimension reduction in partly linear error-in-response models with validation data",
      "venue": "Journal of Multivariate Analysis,",
      "year": 2003
    },
    {
      "authors": [
        "Tong Wang"
      ],
      "title": "Gaining free or low-cost interpretability with interpretable partial substitute",
      "venue": "In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning,",
      "year": 2019
    },
    {
      "authors": [
        "Tong Wang",
        "Cynthia Rudin",
        "Finale Velez-Doshi",
        "Yimin Liu",
        "Erica Klampfl",
        "Perry MacNeille"
      ],
      "title": "Bayesian rule sets for interpretable classification",
      "venue": "In 2016 IEEE 16th International Conference on Data Mining (ICDM),",
      "year": 2016
    },
    {
      "authors": [
        "Svante Wold",
        "Kim Esbensen",
        "Paul Geladi"
      ],
      "title": "Principal component analysis",
      "venue": "Chemometrics and intelligent laboratory systems,",
      "year": 1987
    },
    {
      "authors": [
        "Yingcun Xia"
      ],
      "title": "A multiple-index model and dimension reduction",
      "venue": "Journal of the American Statistical Association,",
      "year": 2008
    }
  ],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": "Machine learning (ML) algorithms are becoming easier to train and deploy with high quality offthe-shelf software packages, and yield excellent prediction performance even in complex highdimensional settings. A known drawback of such complex models, however, is their opaqueness; it is difficult for a human being examining the model to understand why a particular prediction was made [4]. In domains such as healthcare, resume screening, and recidivism prediction, decisions based on output of predictive models have critical downstream consequences or ethical ramifications. In such cases it is crucial to understand why a particular prediction was made by the algorithm. Additionally, transparency in the underlying decision process engenders trust in these algorithms, making consumers more likely to utilize them.\nInterpretable Machine Learning is a growing and active field of research. While the precise meaning of \"interpretable\" remains ambiguous, researchers have aimed to lay down a broad framework for interpretable ML [10, 27, 29, 11, 32]. These papers outline the properties that models must possess in order to count as interpretable, put forth hierarchies and along with discussions of the merits and drawbacks of existing approaches to interpretable ML.\nPreprint. Under review.\nar X\niv :2\n00 6.\n04 73\n2v 1\n[ cs\n.L G\n] 8\nBroadly, there are two approaches to interpretable ML. The first approach involves developing models that possess certain interpretable properties themselves, such as rule-based models, simple parametric models and case-based models. For instance, [42] state that rule sets are interpretable in a certain sense, and propose a procedure for learning rule sets for the purpose of classification. [6] make use of an interpretable two-level attention model for prediction purposes. However, such models place constraints on model complexity, and often lose out on predictive performance.\nThe second approach, utilized when the performance of interpretable models is inadequate involves \u201cpost-hoc\" interpretability; i.e. interpreting an already trained black-box model. Examples of such approaches saliency maps [36, 12], producing local explanations - explanations for individual predictions [35] or global predictions[17]. However, such methods have their drawbacks as well since they only learn approximations of the underlying black-box, and it is hard to provide guarantees on the accuracy and reliability of such approximations.\nA new approach growing in popularity involves combining simple interpretable models with the predictive power of uninterpretable, black-box models. For example, [2] combined the interpretability of coefficients in a linear regression model with the model flexibility of neural networks to yield greater performance while preserving interpretability, whilst [41] learned an interpretable model in place of a black-box model for subsets of the data, while leaving the rest of the black-box model intact.\nIn this paper, we utilize a similar approach to interpretability as above. We start with a simple parametric model relating a set of interpretable features to the outcome, and add a more complicated function consisting of uninterpretable features in a way that improves its performance as much as possible. This function may be viewed as an \u201cuninterpretable residual\u201d, augmenting a simple parametric model. We use ideas from sufficient dimension reduction literature [28] and semiparametric statistics [38], to estimate such a residual under minimal assumptions about the underlying data generating process.\nThe paper is organized as follows. In Section 2, we put forth our reasoning on the tradeoff between interpretability and model performance and motivate the structure of our interpretable model. Section 3 describe the concepts utilized in fitting our model, namely Sufficient Dimension Reduction (SDR) and semiparametric statistics. Section 4 formally describes our interpretable model, while Section 5 demonstrates the performance of our model on simulated data as well as a prediction task using healthcare data. Section 6 contains our conclusions."
    },
    {
      "heading": "2 The Tradeoff Between Interpretability And Performance",
      "text": "In order to demonstrate the tradeoff between interpretability and performance, and to motivate our interpretable model, we will consider a healthcare example. We aim to develop a predictive model for Intensive Care Unit (ICU) length of stay for patients who have undergone cardiac surgery, using a detailed institutionally collected electronic health record. Accurate prediction of ICU Length of stay (LOS) is of interest to clinicians as it allows them to plan for measures such as palliative care consultation, early mobility therapy or discharge to a long-term acute care facility [16]. Additionally, it also allows for clinicians to target interventions described in [21]. Prolonged ICU stays are also related to catheter related bloodstream infections[34], hence accurate prediction of LOS can allow clinicians to implement additional safeguards against healthcare associated infections (HAIs).\nIn such a setting, building a useful prediction model involves a tradeoff. One approach is to use modern ML algorithms, capable of learning complex relationships in the data and providing good empirical performance. However, such methods are often opaque, making it hard for clinicians to understand why a particular prediction was made for a particular patient and ascertain why the model prediction disagrees with current clinical consensus. Additionally, interpretable models that predict undesirable outcomes can be useful for informing practice and ultimately improving patient care.\nOn the other end of the spectrum, one could utilize risk scores based on relatively simple statistical models defined on a small set of clinically interpretable variables Xint thought to strongly influence the outcome of interest. For example, the Parsonnet score [31] is used to predict post cardiac surgery mortality. It is based on a relatively small set of variables thought to influence risk, including gender, obesity, diabetes status, the presence of hypertension, age, the number of previous operations, and so on [19], and each variable gets a certain number of points, and these points are calculated out a 100 and interpreted as a percentage. Such a risk score is an oversimplification as the set of variables truly\nrelevant for the given outcome is much larger than what is used in risk score models. Furthermore, it is likely that the true regression surface relating this much larger, uninterpretable set of variables Xuint to the outcome Y is very complicated.\nOur approach aims to bridge the gap between the true (but likely uninterpretable) regression surface E0[Y |Xuint, Xint] and the interpretable (but likely inaccurate) regression surface Eint[Y |Xint] used in practice. To accomplish this, our approach starts with a simple model Eint[Y |Xint], such as a linear regression XTint\u03c8, and augments it with an unrestricted function r() of a low dimensional version X\u2217uint of the uninterpretable set of features Xuint, obtained via a function g : Xuint 7\u2192 X\u2217uint known up to a finite set of parameters \u03b3. We do so in such a way that the resulting surfaceXTint\u03c8+r(g(Xuint; \u03b3)) is close to the true surface E0[Y |Xuint, Xint]. Our task is to find the parameter set \u03b2 \u2261 (\u03c8, \u03b3) that best captures E0[Y |Xuint, Xint] given a set of realizations of the observed data distribution p0(Y,Xuint, Xint). Successfully solving our task yields a surface that does a much better job of capturing features of the true surface E0, while retaining much of the interpretable structure of Eint. In particular, we can view r() as a kind of low-dimensional uninterpretable residual that when added to an interpretable model improves performance. This addition allows the subject matter expert to explicitly examine cases where a simpler model Eint differs from a better performing one by examining the behavior of r(), and we provide examples examining this in our experiments section. We emphasize again that r() is completely unrestricted.\nWe approach the problem of learning \u03b2 using ideas from the sufficient dimension reduction (SDR) literature and semiparametric statistics."
    },
    {
      "heading": "3 Sufficient Dimension Reduction and Semiparametic Statistics",
      "text": "Sufficient Dimension Reduction refers to a popular class of methods that perform dimension-reduction while taking the feature outcome relationships into account. These methods are different from those such as Principal Components Analysis (PCA)[43], which ignore the relationships between features and outcomes. A rich literature exists in statistics on sufficient dimension reduction (SDR), discussed in the Supplement. Broadly, the SDR problem is set up as:\nLet X be a p-dimensional covariate vector and Y be a univariate response variable. The goal of SDR is to find a known function r(.; \u03b3), with a much smaller range than the domain, parameterized by \u03b3 such that E0[Y | X] = E[Y | r(X; \u03b3)], where E0 is the true regression surface.\nOften this function is assumed to be linear, in which case the goal is to find \u03b3 \u2208 Rp\u00d7d, where d < p, such that Y depends on X only through XT \u03b3. That is,\nE0[Y | X] = E[Y | XT \u03b3]. (1)\nd is often referred to as the structural dimension. In a seminal paper, [28] recast the estimation problem in SDR as an estimation problem in a semiparametric model. This yielded a set of estimators of \u03b3 that do not rely on strong assumptions on the observed data distribution. This approach has since been extended to causal inference problems with high dimensional treatments [30].\nSemiparametric estimators draw inferences from iid realizations Z1, . . . , Zn drawn from a general class of probability densities p(Z; \u03b8) parameterized by \u03b8T = (\u03b2T , \u03b7T ), where \u03b2 \u2208 Rq denotes the (finite dimensional) set of target parameters, and \u03b7 denotes a possibly infinite dimensional set of nuisance parameters. This type of model is termed semiparametric, since it has both a parametric and a non-parametric component. [38, 3] describe a geometric approach to performing estimation in such settings, using the Hilbert space of scores of the model. In such a framing, semiparametric estimators for \u03b2 with attractive properties correspond to elements of the orthogonal complement of the nuisance tangent space of the model. A detailed review of this approach can be found in the Supplement."
    },
    {
      "heading": "4 The Interpretable Model",
      "text": "In this section we define our model, henceforth referred to as the IML (Interpretable Machine Learning) model.\nAssume we are interested in learning the regression function E0[Y |X] from realizations of the observed data distribution p0(Y,X), where Y is a continuous valued outcome, X is partitioned\ninto a (small) set of interpretable features Xint, and a (large) set of uninterpretable features Xuint of size p. Our semiparametric model requires there exists a matrix \u03b3 of size p \u00d7 d such that Y = h(Xint;\u03c8) + r(X T uint\u03b3) + where E[ | Xint, Xuint] = 0, and E[Y | Xint, Xuint] = E[Y | Xint, XTuint\u03b3]. No other restrictions are placed on the model. We denote our model (the set of distributions with above restrictions) byMint. In words,Mint assumes the regression surface we wish to learn is representable as a simple function h() of interpretable features Xint parameterized by \u03c8, and a complicated function r() of a projection of Xuint from its original dimension p to a smaller dimension d - referred henceforth as the structural dimension - chosen by the user, as given by the shape of \u03b3. Importantly, r() is completely unrestricted.\nWe derive the space of influence functions yielding RAL estimators for \u03b2 \u2261 (\u03c8, \u03b3) by deriving \u039b\u22a5, the orthogonal complement of the nuisance tangent space ofMint.\nTheorem 1. The set of all influence functions, i.e. the orthogonal complement of the nuisance tangent space, for \u03b2 inMint is given as follows,\n\u039b \u22a5 int = {( A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3] ) \u00d7 ( Y \u2212 h(Xint;\u03c8)\u2212 r(XTuint\u03b3) )} where A(Xint, Xuint) is any |\u03b2|-dimensional function of {Xint, Xuint}.\nGiven an arbitrary element \u03c6A(\u03b2) \u2208 \u039b\u22a5int,we get a consistent RAL estimator by solving the estimating equation of the form E[\u03c6A(\u03b2)] = 0. The variance of such an estimator is given by the variance of \u03c6A(\u03b2).\nAccording to Theorem 1, the class of our estimators may be viewed as augmenting a particular parametric model h(.;\u03c8) with a flexible, uninterpretable piece using a modification of semiparametric SDR. We obtain a version of the double robustness result in [28], provided h(.;\u03c8) itself is specified correctly.\nLemma 1. Given \u03c6A(\u03b2) \u2208 \u039b \u22a5\nint, an estimator for \u03b2 which solves E[\u03c6A(\u03b2)] = 0, is consistent and asymptotically normal if h(.;\u03c8) is correctly specified, and either of the models in {r(XTuint\u03b3), E[A(X) | XTuint\u03b3]} is correctly specified.\nLemma 1 allows us to perform consistent inferences for \u03b2 even in settings where a large part of the model likelihood is arbitrarily misspecified, provided h(.) and one of two models are specified correctly. In addition, double robustness implies the bias of the estimator has a product form. This allows parametric ( \u221a n) convergence rates for \u03b2 to be obtained even if flexible machine learning models with slower than parametric convergence rates are used to fit nuisance models. See [5] for details.\nOur semiparametric estimators, derived from Theorem 1, may be extended to arbitrary link functions as well, and the influence functions are presented below. Denote the modelMg,int to be one where Y = g(h(Xint;\u03c8)+r(X T uint\u03b3))+ , where E[ | Xint, Xuint] = 0, and g denotes a known differentiable link function. Theorem 2. The set of all influence functions, i.e. the orthogonal complement of the nuisance tangent space, for \u03b2 inMg,int is given as follows,\n\u039b\u22a5g,int ={A(Xint, Xuint)\u2212 E[A(Xint, Xuint)|XTuint\u03b3]} \u00d7 (g\u2032)\u22121 \u00d7 {Y \u2212 g(h(Xint;\u03c8) + r(Xuint))}\nwhere g\u2032 is the derivative of the link function with respect to its single input.\nChoosing appropriate link functions allows us to consider dichotomous outcomes, often leading to submodels ofMg,int. Nevertheless, elements in \u039b\u22a5g,int remain consistent in such models.\nEstimating equations of the form E[\u03c6A(\u03b2)] = 0 obtained from Theorem 1 and 2 are not linear in \u03b2. As a result, similarly to estimating equations corresponding to Z-estimators [39], they must be solved numerically. We utilize constrained non-linear optimization algorithms to learn our parameters, along with non-parametric kernel regressions to perform prediction using these learned parameters. A detailed description of these algorithms are given in the Supplement.\nIn addition, our results so far assumed the structural dimension d is fixed and known in advance. In practice, this is an unrealistic assumption, and d must be chosen according to some criterion. We adapted a dimension selection procedure described in [28, 9], with details left to the Supplement."
    },
    {
      "heading": "5 Experiments",
      "text": "We now demonstrate the performance of our estimator using various simulations, as well as a data application."
    },
    {
      "heading": "5.1 Simulation Study",
      "text": "In our simulation study, the performance is evaluated using two metrics, the first being the root mean squared error (RMSE) calculated on a held-out testing set. Next, we assess the model on parameter recovery, which is evaluated by the Frobenious norm of \u03b3\u0302(\u03b3\u0302T \u03b3\u0302)\u22121\u03b3\u0302T \u2212 \u03b3(\u03b3T \u03b3)\u22121\u03b3T and \u03c8\u0302(\u03c8\u0302T \u03c8\u0302)\u22121\u03c8\u0302T \u2212 \u03c8(\u03c8T\u03c8)\u22121\u03c8T . This quantity ranges from 0 to 2, and the smaller the number, the better the estimate with 0 denoting a perfect match.\nTo benchmark our model, we compare the performance of our model against a generalized additive model (GAM) [14] and a linear regression model. The GAM implementation used the pygam implementation with the n_splines parameter set to 25. We utilize parametric bootstrap and generate 50 replicates of the dataset, each of size n = 2000. The comparison is given in the tables below.\nTo simulate our data, we closely follow the simulations used in [28]. We set \u03c8 = [0.577,\u22120.577], \u03b31 = [.4082, .4082, .4082, .4082, .4082, .4082] and \u03b32 = [.4082,\u2212.4082, .4082,\u2212.4082, .4082,\u2212.4082]. We generate the covariates X in two different ways, split across case 1 and case 2.\nCase I: Xint is generated from N (0,\u03a3), where \u03a3 is given by 0.5|a\u2212b| where a and b are the row and column indices respectively. Xuint is generated from N (0, 3I). Case II: Similar to [28], Xuint,1, Xuint,2 are jointly generated from a multivariate normal distribution with mean 0 and covariance matrix given as 0.5|a\u2212b|. Xuint,3 = |Xuint,1 + Xuint,2| + |Xuint,1| 1 and Xuint,4 = |Xuint,1 + Xuint,2|2 + |Xuint,2| 2. Xuint,5 comes from a Bernoulli distribution with p =\nexp(Xuint,2) 1+exp(Xuint,2) . Xuint,6 comes from \u03c6(Xuint,2), where \u03c6 denotes the cumulative density function of the standard normal distribution. For the interpretable features, Xint,1, Xuint,2 are generated from a multivariate normal distribution with mean 0 and covariance matrix given as 0.5|a\u2212b|. Then, Xint,2 is transformed as Xint,2|Xuint,3|. Assume the following.\n\u223c N (0, 1),\nh(Xint;\u03c8) \u2261 XTint\u03c8,\nr1(X T uint\u03b3) = (X T uint\u03b31) 2 + (XTuint\u03b32) 2,\nr2(X T uint\u03b3) =\n(XTuint\u03b31)\n(0.5 + (XTuint\u03b32 + 1.5) 2) .\nModel(I) : Y = h(Xint;\u03c8) + r1(XTuint\u03b3) +\nModel(II) : Y = h(Xint;\u03c8) + r1(XTuint\u03b3)\n+ |XTuint\u03b31||Xint,1|\nModel(III) : Y = h(Xint;\u03c8) + r2(XTuint\u03b3) +\nModel(IV) : Y = h(Xint;\u03c8) + r2(XTuint\u03b3) + |XTuint\u03b31| .\nThe models we use in this simulation study belong to the class of multiple-index models [44, 15], a flexible class of models that represent common models such as the partially linear model [37, 40] and the single index model [15]. Parameters of models in this class are known to be difficult to estimate[26].\nWe used scipy.optimize, which supports non-convex optimization with non-linear constraints. All simulations were run on the cluster at our institution, and took 50 hours for 50 bootstrap replicates at n = 2000.\nTables 1 and 3 represent the results. The IML column lists the results from our interpretable model, the LR column lists the results from a Gaussian linear regression and the GAM columns lists the results from a generalized additive model. As we can see, our model outperforms both Gaussian linear regression as well as a GAM on the RMSE, except for in Table 2 model III, where the GAM is marginally better. Since the GAM is a more flexible model than the Gaussian linear regression, it performs better on the data. In addition to comparing performance on the mean squared error, we also measure our algorithm on parameter recovery and demonstrate the results in Figure 1. The quality of the learned parameters is reasonable, given the sample size (n = 2000), and the fact that the data generating process belongs to the class of multiple index models, known to be challenging[26]."
    },
    {
      "heading": "5.2 Data Application",
      "text": "In this section, we are interested in predicting ICU length of stay, as motivated by discussion in Section 2."
    },
    {
      "heading": "5.2.1 Partitioning Between Interpretable and Uninterpretable Features",
      "text": "An existing approach utilized for this problem is to compute a Parsonnet score [19], which calculates post-operative risk based on commonly available variables, and utilize it to predict LOS [20]. Variables utilized in this scoring system include gender, obesity, diabetes, hypertension, ejection fraction, age, number of previous operations, use of intra-aortic balloon pump, previous left ventricular aneurysm, dialysis, previous valve surgery, previous catastrophic state (cardiogenic shock, renal failure). The features used for this score were hand picked by clinicians from available EHR sources, and represent features that are of interest to clinicians in this domain. Hence, we utilized a subset of these features as the interpretable features in our model.\n[8] found that factors associated with prolonged ICU stays in patients undergoing coronary artery bypass grafts (CABGs) also include recent myocardial infarction, smoking, diseased arteries, and preoperative left-ventricular diastolic pressure, as well as postoperative factors such as arrhythmias, respiratory complications, and renal insufficiency. This motivated us to pick uninterpretable features such as - various measures of blood transfusions at different phases of the clinical stay, reintubation status, postoperative creatinine level (a proxy for kidney function), perfusion time, ICU readmission, hematocrit level prior to surgery and platelet count.\nNote that some of our uninterpretable features may have scientific interpretations and could in theory be assigned as interpretable features. However, we have restricted the set of interpretable features to those that are clinically interpretable according to the Parsonnet score, which includes features that clinicians are used to interpreting in the context of ICU stay prediction [8]. Our set of uninterpretable features consists of features which are associated with prolonged ICU stays, but are not part of the Parsonnet feature set. Hence, the interpretable feature set acts as a modified (yet interpretable) Parsonnet score, and the uninterpretable features act to improve the Parsonnet prediction performance."
    },
    {
      "heading": "5.2.2 Data Preprocessing",
      "text": "The electronic health records of 6189 cardiac surgery patients at a major research hospital were queried. The outcome variable is defined as the initial duration of the initial ICU stay, measured in hours from admittance to discharge from ICU. Patients with ICU stays in the top 2.5% were excluded (as these patients are likely systematically different rom those normally entering the ICU), as were patients that did not enter the ICU at all. then, we discarded features and rows with missing data. This left us with a dataset of 5665 rows and 268 features. 9 interpretable features were selected based on their utilization in the Parsonnet score. An additional 10 uninterpretable features were selected based on discussion in Section 5.2.1. A detailed description of each feature is provided in the Supplement. The Supplement also demonstrates the performance on the prediction task using a different partition of the feature set."
    },
    {
      "heading": "5.2.3 Benchmarking Performance",
      "text": "We benchmarked our method against linear regression, random forests (RFs), and GAMs, and predictive performance was measured by root mean squared error (RMSE). To compare interpretability, we compared the coefficients from the linear regression model with the coefficients from our IML model. The random forest regressor from sklearn was run with various tuning parameters, with the number after RF indicating the n_trees hyperparameter settings. The GAM from pygam was fitted with n_splines parameter set to 25. For our IML model, we utilized \u03b4 = 0.05 and the structural dimension d = 1. Additional models of RFs and GAMs with different hyperparameter settings can be found in the Supplement, as well as details with the training and validation accuracy.\nThe dataset was trained on a training dataset consisting of 3965 rows and 19 features, and a validation dataset of 851 rows was utilized. The performance of the various algorithms was compared using the predictions on a held-out testing set of size 849. The table above gives the train, validation and test RMSEs. As seen in Table 1, we outperform all the different methods when it comes to RMSE, with RFs Forests coming in second."
    },
    {
      "heading": "5.2.4 Performance of Parametric and IML Models",
      "text": "IML outperforms all of the methods it is benchmarked against on the testing set, whilst keeping the coefficients of the interpretable features close to that of a linear regression. Figure 2a compares the performance of linear regression against IML. In most cases, we see that the IML prediction (blue) improves upon the linear regression prediction (red), as evidenced by the number of long blue arrows. The IML prediction only marginally worsens some of the linear regression predictions, evidenced by the number of small red arrows.\nWhile the IML model delivers greater predictive power while maintaining interpretability for some features, it is natural to consider the impact of the uninterpretable r() function on the overall prediction. Figure 2b considers the impact of the h() function alone (in red) compared to the h() + r() function in blue. Primarily, the r() function appears to improve upon the h() function prediction for the lower and higher ICU durations, where a great number of blue arrows are evidenced. Predictions for ICU durations close to the median were equal or slightly worse on average, with only a few instances with larger error. Overall, the r() function clearly improves the overall fit, as shown in Figure 3, and Table 3."
    },
    {
      "heading": "6 Conclusion",
      "text": "In this paper we presented a novel approach to interpretable machine learning based on semiparametric statistics and sufficient dimension reduction. Our approach began with an interpretable parametric model that used interpretable features as inputs, and added to it an unrestricted low dimensional function of a large set of uninterpretable features in a way that best mimicked the underlying regression surface.\nThis problem was posed as a target parameter learning problem in a semiparametric model. The estimator for needed parameters was obtained by deriving the space of all influence functions for the target parameter. The resulting estimators enjoyed a double robustness property, provided the parametric form of the interpretable part of the regression is known. We have demonstrated, via simulation studies and a data application, the performance of our method, as well as its ability to retain much of the interpretable structure of a parametric regression model.\nDeriving the efficient influence function for our problem, as well as adapting ideas from the sparsity literature to generalize this work to very high dimensional problems are promising areas of future work."
    },
    {
      "heading": "7 Supplement",
      "text": ""
    },
    {
      "heading": "7.1 Inference in Semiparametric Models",
      "text": "Let Z1, . . . , Zn, be iid samples from a general class of probability densities p(Z; \u03b8) parameterized by \u03b8T = (\u03b2T , \u03b7T ), where \u03b2 \u2208 Rq denotes the (finite dimensional) set of target parameters, and \u03b7 denotes a possibly infinite dimensional set of nuisance parameters. This type of model is termed semiparametric, since it has both a parametric and a non-parametric component. The goal of statistical inference in semiparametric models is to find \u201cbest\" (lowest asymptotic variance) estimator of \u03b2 in the model, denoted by \u03b2\u0302. We will consider regular asymptotically linear (RAL) estimators, which are estimators of the form\n\u221a n(\u03b2\u0302 \u2212 \u03b2) = 1\u221a\nn n\u2211 i=1 \u03c6(Zi) + op(1),\nwhere \u03c6(Zi) is the influence function (IF) of the ith observation for the parameter vector \u03b2, and op(1) denotes a term that approaches to zero in probability. The influence function for the parameter \u03b2 is a random function of the same dimension as \u03b2, i.e., \u03c6(Z) \u2208 Rq. Moreover, the IF is always mean zero, with certain regularity assumptions on the model ensuring that the IF has finite variance. RAL estimators are consistent and asymptotically normal, with the variance of the estimator given by the variance of its IF.\n\u221a n(\u03b2\u0302 \u2212 \u03b2) D\u2212\u2192 N (0, \u03c6\u03c6T ).\nThus, there is a bijective correspondence between RAL estimators and IFs. In fact, IFs provide a geometric view of the behavior of RAL estimators.\nConsider a Hilbert space H of all mean-zero q\u2212dimensional functions, equipped with an inner product. Define the inner product of two arbitrary elements of the Hilbert space, h1 and h2, as E[hT1 h2]. Define a parametric submodel to be a subset of densities in the semiparametric model parameterized by \u03b8T\u03b3 = (\u03b2\nT , \u03b3T ), where \u03b3T \u2208 Rr, such that the subset contains the density p(Z; \u03b80) in the semiparametric model evaluated at the true parameter values \u03b80. The nuisance tangent space \u039b in the semiparametric model is defined to be the mean square closure of elements of the nuisance tangent spaces \u039b\u03b3 = {Bq\u00d7rS\u03b3(Z; \u03b8)} of every parametric submodel. The space \u039b is important because it is known that all influence functions lie in the orthogonal complement of \u039b, denoted by \u039b\u22a5, with respect toH (H = \u039b\u2295 \u039b\u22a5, where \u2295 is the direct sum). For this reason, recovering \u039b\u22a5 is often the first step for constructing RAL estimators in semiparametric models. Out of all IFs in \u039b\u22a5 there exists a unique one which lies in the tangent space, and which yields the most efficient RAL estimator by recovering the semiparametric efficiency bound; see [38] for details.\nA well-known property of semiparametric models is that all elements of \u039b\u22a5 are mean 0 under the true distribution. Consequently, given an arbitrary element U(\u03b2) \u2208 \u039b\u22a5, we get an estimating equation of the form E[U(\u03b2)] = 0 which upon solving, yields a consistent and asymptotically linear estimator for \u03b2."
    },
    {
      "heading": "7.2 Sufficient Dimension Reduction",
      "text": "The sparsity literature [13] places strong assumptions on the regression surface allowing procedures that pick a small subset of the overall feature set to optimize prediction, even with very few samples relative to the size of the feature set. Sparsity approaches to regression problems are generally parametric.\nA common approach to reducing a high-dimensional feature set to a low dimensional one is dimension reduction approaches such as principal component analysis (PCA), that aims to select a set of features that captures major axes of variation given by the feature covariance matrix [33]. The difficulty with methods based on the PCA for regression problems is that they either ignore the outcome entirely, or take no special precautions to preserve the feature outcome relationship. This means that regression models built on top of the output of PCA type procedures may perform significantly worse compared to those built on the original set of high dimensional features. A popular class of methods that may be viewed as a dimension-reduction strategy that take the feature outcome relationships into\naccount, such as linear discriminant analysis (LDA) and generalizations often make strong parametric assumptions.\nA powerful strategy that avoids the problems described above, and allows the reduction of the dimension of the features while preserving a given relationship between features and the outcome exactly has been developed in the sufficient dimension reduction (SDR) literature in statistics.\nLet X be a p-dimensional covariate vector and Y be a univariate response variable. The goal of SDR is to find a known function r(.; \u03b3), with a much smaller range than the domain, parameterized by \u03b3 such that E0[Y | X] = E[Y | r(X; \u03b3)], where E0 is the true regression surface.\nOften this function is assumed to be linear, in which case the goal is to find \u03b3 \u2208 Rp\u00d7d, where d < p, such that Y depends on X only through XT \u03b3. That is,\nE0[Y | X] = E[Y | XT \u03b3]. (2)\nThere are various effective methods developed over the course of decades for estimating the set of matrices \u03b3.\nExamples include sliced inverse regression [23], sliced average variance estimation [7], and directional regression [22]. However, all of these approaches rely on strong parametric assumptions that are unlikely to hold in practical applications. Commonly used in the literature are assumptions such as the linearity assumption -E[X | XT \u03b3] is a linear function of X , or the constant variance assumption - cov(X | XT \u03b3) is a constant rather than a function of X . In a seminal paper, [28] recast the estimation problem in SDR as an estimation problem in a semiparameteric model. This yielded a set of estimators of \u03b3 that do not rely on strong assumptions on the observed data distribution. This approach has since been extended to causal inference problems with high dimensional treatments [30]. [28] derived the orthocomplement of the nuisance tangent space for the model in (2):\n\u039b\u22a5 = {( Y \u2212 E[Y | XT\u03b2] ) \u00d7 ( \u03b1(X)\u2212 E[\u03b1(X) | XT\u03b2] )} , (3)\nwhere \u03b1(X) is an arbitrary function of X of an appropriate dimension. Thus, a consistent family of estimators for \u03b2 (for different \u03b1(X)) for semiparametric sufficient dimension reduction is:\nE [( Y \u2212 E[Y | XT\u03b2] ) \u00d7 ( \u03b1(X)\u2212 E[\u03b1(X) | XT\u03b2] )] = 0. (4)\n[28] illustrated how other parametric SDR methods are special cases of the above family of semiparametric estimators. For example, ordinary least squares (OLS) [25] can be viewed as a special case of the above estimator. To obtain this, set \u03b1(X) = X and take advantage of the double robustness of the above estimator to set E[Y | XT\u03b2] = 0. This combined with the linearity assumption of the OLS estimator yields the estimating equations for OLS.\nThe estimator in (4) is doubly robust with respect to models for E[Y | XT\u03b2] and E[\u03b1(X) | XT\u03b2], meaning that the estimator remains consistent if any one of these two models is correctly specified (even if the other model is arbitrarily misspecified).\nIf the influence function is linear in \u03b2, then \u03b2 can be estimated in closed form after all nuisance models are estimated.\nHowever, estimating equations such as (4) entail solving for \u03b2 using iterative methods, such as variants of the Newton-Raphson algorithm."
    },
    {
      "heading": "7.3 Proofs For Section 4",
      "text": ""
    },
    {
      "heading": "7.3.1 Proof of Theorem 1",
      "text": "For our model where\nY = h(Xint;\u03c8) + l(X T uint\u03b3) + E[ | Xint, Xuint] = 0\nand we observe i.i.d data in the form Z = (Y,Xint, Xuint), the goal is to find estimators for \u3008\u03c8, \u03b3\u3009. The semiparametric model is {p(z;\u03b2, \u03b7) \u03b2, \u03b7} where \u03b2 is a finite dimensional parameter and\n\u03b7 = \u3008\u03c8, \u03b3\u3009 is an infinite dimensional parameter. We let p0(z) denote the true data distribution, and \u03b20, \u03b70 denote the true value of the parameters.\nThe likelihood for our model is given as: p(Y,Xint, Xuint) = p(Y | Xint, Xuint)p(Xuint, Xint)\n= p( | Xint, Xuint)p(Xuint, Xint) = p( | Xint, Xuint; \u03b72)p(Xuint, Xint; \u03b71)\nwhere = Y \u2212 h(Xint;\u03c8)\u2212 l(XTuint\u03b3). Here \u03b71, \u03b72, l are infinite dimensional nuisance parameters. The nuisance tangent space \u039b is the space spanned the nuisance score vectors.\n\u039b = {B \u00d7 S\u03b7\u2200B}\nS\u03b7 = \u2202 log p(z;\u03b2, \u03b7)\n\u2202\u03b7\n= {\u2202 log p(Xuint, Xint; \u03b71) \u2202\u03b71 , \u2202 log p( | Xint, Xuint; \u03b72) \u2202\u03b72 , \u2202 log p( | Xint, Xuint; \u03b72) \u2202l }\nS\u03b71 and S\u03b72 are score vectors, they must be mean zero, and we have the added restriction E[ | Xint, Xuint] = 0. Following an argument similar to [38], we obtain:\n\u039b\u03b71 = {A(Xint, Xuint) : E[A(Xint, Xuint)] = 0} \u039b\u03b72 = {\u03b1( ,Xint, Xuint) : E[\u03b1( ,Xint, Xuint) | Xuint, Xint] = 0,\nE[\u03b1( ,Xint, Xuint) T | Xuint, Xint] = 0}\n\u039bl = { \u2202p( | Xint, Xuint; \u03b72)/\u2202 p( | Xint, Xuint; \u03b72) m(XTuint\u03b3) : \u2200m}\nA detailed description of the derivation of \u039b\u03b71 can be found in Theorem 4.6 in [38]. Similarly, the derivation of derivation of \u039b\u03b72 can be found in Theorem 4.7 in [38]. The derivation of \u039bl follows a similar argument to [30], with a brief overview given below:\nSl = \u2202 log p(y \u2212 h\u2212 l | Xint, Xuint; \u03b72)\n\u2202l\n= \u2202p( = y \u2212 h\u2212 l | Xint, Xuint; \u03b72)/\u2202 p( = y \u2212 h\u2212 l | Xint, Xuint; \u03b72) \u2202 \u2202l\n= \u2202p( = y \u2212 h\u2212 l | Xint, Xuint; \u03b72)/\u2202 p( = y \u2212 h\u2212 l | Xint, Xuint; \u03b72) \u2202l \u2202l\n\u039bl = \u2202p( | Xint, Xuint; \u03b72)/\u2202 p( | Xint, Xuint; \u03b72) m(XTuint\u03b3) : \u2200m}\nSince l is allowed to belong to the unrestricted space of functions, it follows that its derivative will belong to the unrestricted space of functions as well. Since \u03b71, \u03b72, l are variationally independent:\n\u039b = \u039b\u03b71 \u2295 \u039b\u03b72 \u2295 \u039bl \u039b\u22a5 = \u039b\u22a51 \u2229 \u039b\u22a52 \u2229 \u039b\u22a5l\nAs \u039b\u22a5 is the intersection of 3 spaces, \u039b\u22a5 \u2282 (\u039b\u22a5\u03b71 \u2229 \u039b \u22a5 \u03b72) = (\u039b\u03b71 \u2295 \u039b\u03b72) \u22a5, and \u039b\u22a5 \u2282 \u039b\u22a5l . Based on Theorem 4.8 of [28]:\n(\u039b1 \u2295 \u039b2)\u22a5 = {A(Xint, Xuint) : \u2200A(Xint, Xuint)}\nSo any element of \u039b\u22a5 must have the form above with additional restrictions being placed on it by the intersection with \u039b\u22a5l . Taking any element of \u039b\n\u22a5 of the form {A(Xint, Xuint) }, this must be orthogonal to \u039bl. This yields:\nE[A(Xint, Xuint) \u2202p( | Xint, Xuint)/\u2202 p( | Xint, Xuint) m(XTuint\u03b3)] = 0\nWhich implies that E[A(Xint, Xuint)m(XTuint\u03b3)] = 0,\u2200m. This only holds if E[A(Xint, Xuint) | X\u03b3uint] = 0. Hence, any element of \u039b\u22a5 can be written as:\n\u039b\u22a5 = {A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3]}{Y \u2212 h(Xint;\u03c8)\u2212 l(XTuint\u03b3)}"
    },
    {
      "heading": "7.3.2 Proof of Theorem 2",
      "text": "The derivation of the influence function in the presence of an arbitrary known link function follows a similar outline, except the \u039bl space is different.\n\u039bl = { \u2202p( | Xint, Xuint)/\u2202 p( | Xint, Xuint) g\u2032(h(Xint;\u03c8) + l(X T uint\u03b3))m(X T uint\u03b3) : \u2200m}\nSimilar to before, using the orthogonality condition between \u039b\u22a5 and \u039bl:\nE[A(Xint, Xuint) \u2202p( | Xint, Xuint)/\u2202 p( | Xint, Xuint) g\u2032(h(Xint;\u03c8) + l(X T uint\u03b3))m(X T uint\u03b3)] = 0\nThis gives us the additional restriction on A,\nE[A(Xint, Xuint)g\u2032(h(Xint;\u03c8) + l(XTuint\u03b3))m(XTuint\u03b3)] = 0 Taking this into account, \u039b\u22a5 is given below.\n\u039b\u22a5 = {A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | X T uint\u03b3]\ng\u2032 }{Y \u2212 g(h(Xint;\u03c8)\u2212 l(Xuint))}"
    },
    {
      "heading": "7.3.3 Proof of Lemma 1",
      "text": "Let E\u2217[A(Xint, Xuint) | XTuint\u03b3] denoted the incorrectly specified model, yielding the following estimating equation:\nE[{A(Xint, Xuint)\u2212 E\u2217[A(Xint, Xuint) | XTuint\u03b3]} \u00d7{Y \u2212 h(Xint;\u03c8)\u2212 r(XTuint\u03b3)}]\nUtilizing the law of iterated expectation, we have EX [EY |X [{A(Xint, Xuint)\u2212 E\u2217[A(Xint, Xuint) | XTuint\u03b3]}\n\u00d7 {Y \u2212 h(Xint;\u03c8)\u2212 r(XTuint\u03b3)} | Xint, Xuint]]\n= EX [{A(Xint, Xuint)\u2212 E\u2217[A(Xint, Xuint) | XTuint\u03b3]}{E[Y | X]\u2212 h(Xint;\u03c8)\u2212 r(XTuint\u03b3)}]\nBut E[Y | X] = h(Xint;\u03c8) + r(XTuint\u03b3), so the above expectation will evaluate to 0, despite the incorrectly specified model.\nInstead, now assume that the r(XTuint\u03b3) model is incorrectly specified, denoted by r \u2217. The estimating equation is then given as:\nE[{A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3]} \u00d7{Y \u2212 h(Xint;\u03c8)\u2212 r\u2217(XTuint\u03b3)}]\nUsing iterated expectation, we obtain: EX [EY |X [{A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3]}{Y \u2212 h(Xint;\u03c8)\u2212 r\u2217(XTuint\u03b3)} | X]]\n= EX [{A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3]}{EY |X [Y ]\u2212 h(Xint;\u03c8)\u2212 r\u2217(XTuint\u03b3)}]\n= EX [{A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | XTuint\u03b3]}{r(XTuint\u03b3)\u2212 r\u2217(XTuint\u03b3)}] Now taking iterated expectation again:\nEXTuint\u03b3 [EXint|XTuint\u03b3 [{A(Xint, Xuint)\u2212 E[A(Xint, Xuint) | X T uint\u03b3]}\n\u00d7{r(XTuint\u03b3)\u2212 r\u2217(XTuint\u03b3)} | XTuint\u03b3]]\n= EXTuint\u03b3 [{EXint|XTuint\u03b3 [A(Xint, Xuint) | X T uint\u03b3]\u2212 E[A(Xint, Xuint) | XTuint\u03b3]}\n\u00d7{r(XTuint\u03b3)\u2212 r\u2217(XTuint\u03b3)}]\nThis will also evaluate to 0, as long as the model E[A(Xint, Xuint) | XTuint\u03b3] is correct, even if r\u2217 is not specified correctly.\nWe have shown that as long as the parametric form of h is known, the estimating equation for \u03b2 evaluates to 0 with respect to the observed data distribution, as long as either E[A(Xint, Xuint) | XTuint\u03b3] or r is specified correctly. This establishes double robustness."
    },
    {
      "heading": "7.4 Fitting Procedure",
      "text": "In this section, we describe in detail our procedure for estimating \u03b2 by solving the empirical version of the estimating equation, E\u0302[\u03c6A(\u03b2)] = 0, where \u03c6A(\u03b2) \u2208 \u039b \u22a5 int.\nWithout loss of generality, assume \u03c8 \u2208 Rp\u00d71 and \u03b3 \u2208 Rq\u00d7d,where d denotes the structural dimension of the lower dimensional representation of Xuint (we delay the discussion on the choice of d to further sections.) For a given choice of A(X) \u2261 A(Xint, Xuint) and h(Xint;\u03c8),\n1. Pick starting values for \u03b2(1) = {\u03c8(1), \u03b3(1)}. To initialize \u03c8, we fit a linear regression of Y on X and use the coefficients learned for Xint. To initialize \u03b3, we use an SDR procedure called principal Hessian directions described in [24].\n2. At jth iteration, given a fixed \u03b2(j) = {\u03c8(j), \u03b3(j)}, fit the following models.\nE[Y | XTk,uint\u03b3 (j) ] =\n\u2211n i=1 Yk \u00d7Kh(X T i,uint\u03b3\n(j) \u2212XTuint\u03b3 (j))\u2211n\ni=1Kh(X T i,uint\u03b3 (j) \u2212XTuint\u03b3(j))\nE[A(Xuint, Xint) | XTk, uint\u03b3 (j) ]\n=\n\u2211n i=1 A(Xk,uint, Xk,int)\u00d7Kh(X T i,uint\u03b3\n(j) \u2212XTuint\u03b3 (j))\u2211n\ni=1Kh(X T i,uint\u03b3 (j) \u2212XTuint\u03b3(j))\nE[h(Xint;\u03c8(j)) | XTk,uint\u03b3]\n=\n\u2211n i=1 h(Xk,int;\u03c8 (j))\u00d7Kh(XTi,uint\u03b3 (j) \u2212XTuint\u03b3\n(j))\u2211n i=1Kh(X T i,uint\u03b3 (j) \u2212XTuint\u03b3(j)) ,\nr(X T k,uint\u03b3 (j) ) = E[Y | XTk,uint\u03b3 (j) ]\u2212 E[h(Xk,int;\u03c8(j)) | XTk,uint\u03b3 (j) ],\nwhere Kh(.) denotes a kernel function with bandwidth h. We use a Gaussian kernel in our experiments. We estimate the bandwidth h using the Silverman\u2019s Rule of Thumb [18].\n3. Form the empirical evaluation of E[\u03c6A(\u03b2(j))] as,\ne(X;\u03c8(j), \u03b3(j))\n\u2261 1 n n\u2211 i=1 { A(Xi)\u2212 E[A(X) | XTi,uint\u03b3(j)] } \u00d7 { Yi \u2212 h(Xi,int;\u03c8(j))\u2212 r(XTi,uint\u03b3(j)) } ,\n4. Using a non-convex optimizer along with the supporting non-linear constraints, minimize the Frobenius norm of e(X;\u03c8(j), \u03b3(j)), subject to the following constraints. (Given a matrix \u03b2, Frobenius norm is defined as \u03b2(\u03b2T\u03b2)\u22121\u03b2T )\n(a) \u03b3T \u03b3 \u2212 I = 0, s.t. \u2212 1 \u2264 \u03b3 \u2264 1,\n(b) |\u03c8 \u2212 \u03c8init|max \u2264 \u03b4, where \u03b4 is a non-negative tuning parameter chosen by the analyst.\nThis restriction on \u03b3 put forth in 4(a) is to ensure that among possible choices for \u03b3 we prefer those that do well on the optimization objective while not leading to drastically different values of \u03c8 from those in the initial parametric model. The restriction in 4(b) allows control between a model which is more interpretable (where \u03b4 is close to 0) or which has better prediction performance (where \u03b4 is set away from 0).\nA commonly used choice for A(Xint, Xuint) is a simple function of the appropriate dimension, e.g. Xint, Xuint, X 2 uint . . . . This is what we use for our simulations and data application. There exists an optimal choice of A (in the sense of minimizing the variance of the estimated parameters \u03b2) that can be obtained by projecting \u039b\u22a5 on to the tangent space. We leave the choice of optimal A to future work.\nIn practice, it is recommended to standardize the features Xint, Xuint to have mean zero and unit variance."
    },
    {
      "heading": "7.4.1 Using the Learned Parameters for Prediction",
      "text": "Having discussed the method to estimate the parameters, we now outline the procedure to use these estimated parameters for prediction on new data. Let \u03b2\u0302 = {\u03c8\u0302, \u03b3\u0302} be the estimated parameters, and Xj = {Xj,int \u222aXj,uint} be the new datapoint. In order to get a prediction of Y for Xj , we use the following.\nE[Y | Xj ; {\u03c8\u0302, \u03b3\u0302}] = h(Xj,int; \u03c8\u0302) + r(Xj,uint; \u03b3\u0302),\nwhere the form of h(Xj,int; \u03c8\u0302) is known and\nr(XTj,uint\u03b3\u0302) = E[Y | XTk,uint\u03b3\u0302]\u2212 E[h(Xj,int; \u03c8\u0302) | XTj,uint\u03b3\u0302], The contribution of the uninterpretable features to the prediction is not as straightforward, since r is a complex function learned from the data using non-parametric methods (kernels in our case). We learn the r(.) function from the data by fitting the following non-parametric kernel regressions with i ranging over the training data.\nE[Y | XTj,uint\u03b3\u0302] = \u2211n i=1 Yi \u00d7Kh(X T i,uint\u03b3\u0302 \u2212XTj,uint\u03b3\u0302)\u2211n\ni=1Kh(X T i,uint\u03b3\u0302 \u2212XTj,uint\u03b3\u0302)\nE[h(Xint; \u03c8\u0302) | XTj,uint\u03b3\u0302]\n=\n\u2211n i=1 h(Xi,int; \u03c8\u0302)\u00d7Kh(X\nT i,uint\u03b3\u0302 \u2212XTj,uint\u03b3\u0302)\u2211n\ni=1Kh(X T i,uint\u03b3\u0302 \u2212XTj,uint\u03b3\u0302)\nEvaluating the r function gives the contribution of the uninterpretable features to the prediction. The prediction for the new point is the sum of the h and r function."
    },
    {
      "heading": "7.4.2 Choosing the Dimension",
      "text": "In the description of the fitting procedure above, the structural dimension of our estimator d (the rank of \u03b3) was considered fixed and known in advance. In practice, d is a meta-parameter that must be determined from data. For this purpose, we modified the dimension selection procedure outlined in (author?) [28, 9].\nLet \u03bb1, . . . , \u03bbk be the non-zero eigenvalues of\nvar(u)\u22121/2 cov(u, vT ) var(v)\u22121 cov(u, vT ) var(u)\u22121/2\nfor generic random vectors u, v. Then, define\nr2(u, v) = 1\nk k\u2211 i=1 \u03bbi\nFor any structural dimension k, define \u03b3\u0302k to be the estimate based on X , and \u03b3\u0302k,b to be the estimate based on the b-th bootstrap sample of Xuint for b = 1, . . . , B. This returns a score\nr\u03042k = 1\nB B\u2211 b=1 r2(\u03b3\u0302Tk Xuint, \u03b3\u0302 T k,bXuint),\nwhich is to be maximized over candidate dimensions k, in order to determine the optimal dimension d."
    },
    {
      "heading": "7.5 Data Application Details",
      "text": ""
    },
    {
      "heading": "7.5.1 Feature Descriptions",
      "text": "Given the prediction task of ICU length of stay prediction, the first step is to motivate a split of features between those deemed interpretable, versus uninterpretable. To motivate the interpretable features, we rely on those involved in the Parsonnet score [31], and label others as uninterpretable. Thus, the proposed IML model can be interpreted as an improved Parsonnet score.\nThe Parsonnet scoring system relies the following 17 features: gender, obesity, diabetes, hypertension, ejection fraction, age, reoperation status, preoperative IABP, left ventricular aneurysm, emergent status, dialysis, catastrophic state (proxied by cardiogenic shock), other rare circumstances (assortment\nof rare conditions such as paraplegia, severe asthma, etc.), past valve surgery, mitral valve disease, aortic valve disease, and previous CABGs.\nOf these, our institutional database contained information on all above variables except left ventricular aneurysm, reoperation status, other rare circumstances, and mitral/aortic valve diseases/pressures. Hence, we are able to evaluate approximately the Parsonnet score on our database.\nDue to reasons of computational resources, we selected from the Parsonnet score 9 interpretable features: gender, diabetes, hypertension, pre-operative intra-aortic balloon pump usage, emergent status, dialysis, cardiogenic shock, previous valve operation, and previous coronary artery bypass. The 10 uninterpretable features, selected from other non-Parsonnet EHR features, were: postoperative platelet units used, postoperative red blood cell units used, reintubation status, postoperative creatinine level, perfusion time, hematocrit, intraoperative blood products used, preoperative white blood cell count, previous cardiac intervention, and whether an ICU readmission occurred during the visit."
    },
    {
      "heading": "7.5.2 Benchmark Model Details",
      "text": "We benchmark our model against a Random Forest and a GAM. For the Random Forest, we utilized the sklearn.ensemble package and set the max depth to 5 and number of trees to 100. For the GAM, we used the pygam package and we utilize 25 splines along with the grid search option."
    },
    {
      "heading": "7.6 Alternative Analysis in Data Application",
      "text": "Instead of selecting interpretable features based directly on the Parsonnet score, we can instead select interpretable features from those known to be associated with the target [1], and uninterpretable features from those suspected of being associated with the target. 6 interpretable features were selected based on their appearance in previous scoring systems and relevance to the domain, and 10 additional uninterpretable features were selected based on feature information as determined by a random forest model.\nThe interpretable features include measures of hypertension, previous cardiac interventions, weight, gender, age, and white blood cell count (a proxy for immune system performance). Uninterpretable features included various measures of blood transfusions at different phases of the clinical stay, reintubation status, postoperative creatinine level (a proxy for kidney function), perfusion time, use of an intra-aortic balloon pump, hematocrit level prior to surgery, use of antibiotics, and platelet count.\nWe used root mean squared error (RMSE) was used to benchmark our estimator against linear regression, random forests, and GAMs. The random forest regressor had tuning parameter n_trees set to 25. The GAM implementation used the pygam implementation with the n_splines parameter set to 25, along with the use of the grid search option. The dataset was trained on a training dataset consisting of 3965 rows and 16 features, and a validation dataset of 851 rows was utilized. The performance of the various algorithms was compared using the predictions on a held-out testing set of size 849. The table above gives the train, validation and test RMSEs."
    }
  ],
  "title": "A Semiparametric Approach to Interpretable Machine Learning",
  "year": 2020
}
