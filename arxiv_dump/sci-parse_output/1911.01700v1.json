{"abstractText": "We construct realistic equity option market simulators based on generative adversarial networks (GANs). We consider recurrent and temporal convolutional architectures, and assess the impact of state compression. Option market simulators are highly relevant because they allow us to extend the limited real-world data sets available for the training and evaluation of option trading strategies. We show that network-based generators outperform classical methods on a range of benchmark metrics, and adversarial training achieves the best performance. Our work demonstrates for the first time that GANs can be successfully applied to the task of generating multivariate financial time series.", "authors": [{"affiliations": [], "name": "Magnus Wiese"}, {"affiliations": [], "name": "Lianjun Bai"}, {"affiliations": [], "name": "Ben Wood"}, {"affiliations": [], "name": "J.P. Morgan"}, {"affiliations": [], "name": "Hans Buehler"}], "id": "SP:ce7c256a8052c8d210dd8b82a1467b7cd585f691", "references": [{"authors": ["Martin Arjovsky", "Soumith Chintala", "L\u00e9on Bottou"], "title": "Wasserstein Generative Adversarial Networks", "venue": "Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning,", "year": 2017}, {"authors": ["Fischer Black", "Myron Scholes"], "title": "The Pricing of Options and Corporate Liabilities", "venue": "Journal of Political Economy,", "year": 1973}, {"authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "title": "Large Scale GAN Training for High Fidelity", "venue": "Natural Image Synthesis. CoRR,", "year": 2018}, {"authors": ["Hans Buehler", "Lukas Gonon", "Josef Teichmann", "Ben Wood"], "title": "Deep Hedging", "venue": "Quantitative Finance,", "year": 2019}, {"authors": ["Hans Buehler", "Evgeny Ryskin"], "title": "Discrete Local Volatility for Large Time Steps (Extended Version)", "venue": "Available at SSRN", "year": 2017}, {"authors": ["Rama Cont", "Jose\u00e9 Da Fonseca"], "title": "Dynamics of Implied Volatility Surfaces", "venue": "Quantitative Finance,", "year": 2002}, {"authors": ["Bruno Dupire"], "title": "Pricing with a smile", "venue": "Risk, 7:18\u201320,", "year": 1994}, {"authors": ["Christian Francq", "Jean-Michel"], "title": "Zako\u00efan. GARCH Models: Structure", "venue": "Statistical Inference and Financial Applications. Wiley,", "year": 2010}, {"authors": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville"], "title": "Deep Learning", "venue": "http://www.deeplearningbook.org", "year": 2016}, {"authors": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "title": "Generative Adversarial Nets", "venue": "Advances in Neural Information Processing Systems", "year": 2014}, {"authors": ["Ishaan Gulrajani", "Faruk Ahmed", "Martin Arjovsky", "Vincent Dumoulin", "Aaron C Courville"], "title": "Improved Training of Wasserstein GANs", "venue": "Advances in Neural Information Processing Systems", "year": 2017}, {"authors": ["Steven Heston"], "title": "A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options", "venue": "The Review of Financial Studies,", "year": 1993}, {"authors": ["S\u00f8ren Johansen"], "title": "Likelihood-based inference in cointegrated vector autoregressive models", "venue": "Oxford University Press on Demand,", "year": 1995}, {"authors": ["Adriano Soares Koshiyama", "Nick Firoozye", "Philip C. Treleaven"], "title": "Generative Adversarial Networks for Financial Trading Strategies Fine-Tuning and Combination", "year": 1901}, {"authors": ["Lars M. Mescheder"], "title": "On the convergence properties of GAN training", "venue": "CoRR, abs/1801.04406,", "year": 2018}, {"authors": ["Takeru Miyato", "Toshiki Kataoka", "Masanori Koyama", "Yuichi Yoshida"], "title": "Spectral Normalization for Generative", "venue": "Adversarial Networks. CoRR,", "year": 2018}, {"authors": ["Aaron van den Oord", "Sander Dieleman", "Heiga Zen", "Karen Simonyan", "Oriol Vinyals", "Alex Graves", "Nal Kalchbrenner", "Andrew Senior", "Koray Kavukcuoglu"], "title": "Wavenet: A generative model for raw audio", "venue": "arXiv preprint arXiv:1609.03499,", "year": 2016}, {"authors": ["Gordon Ritter", "Petter N Kolm"], "title": "Dynamic Replication and Hedging: A Reinforcement Learning Approach", "venue": "Journal of Financial Data Science,", "year": 2019}, {"authors": ["Casper Kaae S\u00f8nderby", "Jose Caballero", "Lucas Theis", "Wenzhe Shi", "Ferenc Husz\u00e1r"], "title": "Amortised MAP Inference for Image Super-resolution", "year": 2016}, {"authors": ["Dougal J. Sutherland", "Hsiao-Yu Tung", "Heiko Strathmann", "Soumyajit De", "Aaditya Ramdas", "Alexander J. Smola", "Arthur Gretton"], "title": "Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy", "venue": "In 5th International Conference on Learning Representations,", "year": 2017}, {"authors": ["Shuntaro Takahashi", "Yu Chen", "Kumiko Tanaka-Ishii"], "title": "Modeling financial time-series with generative adversarial networks", "venue": "Physica A: Statistical Mechanics and its Applications,", "year": 2019}, {"authors": ["Johannes Wissel"], "title": "Arbitrage-free market models for option prices", "venue": "Technical report, FINRISK,", "year": 2007}, {"authors": ["Kang Zhang", "Guoqiang Zhong", "Junyu Dong", "Shengke Wang", "Yong Wang"], "title": "Stock Market Prediction Based on Generative Adversarial Network", "venue": "Procedia computer science,", "year": 2019}], "sections": [{"heading": "1 Introduction", "text": "There is growing interest in applying reinforcement learning techniques to the problem of managing a portfolio of derivatives [4, 19]. This involves buying and selling not only the relevant underlying assets, but also the available exchange-traded options. In order to train an option trading model, we therefore require time-series data that includes option prices.\nUnfortunately, the amount of useful real-life data available is limited; if we take a sampling interval of one day, ten years of option prices translates into only a few thousand samples. This motivates the need for a realistic simulator: we can generate much larger volumes of data for training and evaluation while preserving the key distributional properties of the real samples, thus helping to avoid overfitting.\nIn this article, we build and test a collection of simulators based on neural networks (NNs). We begin by transforming the option prices to an equivalent representation in the form of discrete local volatilities (DLVs) [5, 24] with less complicated no-arbitrage constraints; we then formalize the role of the simulator as a mapping from a state and input noise to a new set of (transformed) option prices. Next, we define a series of benchmark scores based on the key distributional features of the transformed prices. We construct a set of generative models, varying the network architecture, training method, and state compression scheme. Finally, we evaluate these models against our proposed benchmark scores, and compare with a classical baseline."}, {"heading": "2 Financial time series simulation", "text": "There is a wide range of existing literature on the generation of synthetic time series for asset prices (see, e.g., [9]). Classical derivative pricing models (e.g., [2, 7, 13]) also require path generators, but \u2217Corresponding author: ben.wood@jpmchase.com \u2020Opinions expressed in this paper are those of the authors, and do not necessarily reflect the view of J.P. Morgan.\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nar X\niv :1\n91 1.\n01 70\n0v 1\n[ q-\nfi n.\nC P]\n5 N\nov 2\nthese are not designed to be realistic; they describe diffusion in the risk-neutral measure Q, rather than the real-world measure P, and are typically limited to a small number of driving factors, for ease of computation.\nRecently, generative adversarial networks (GANs) [11] have been successfully used to create realistic synthetic time series for asset prices [15, 22, 23, 25, 26]. Zhang et al. [25] and Zhou et al. [26] reported on using the objective function of GANs to predict spot prices. Koshiyama et al. [15] trained a conditional GAN to generate spot log-returns and provided a study of using generated paths to fine-tune trading strategies, and showed that the autocorrelation function (ACF) and partial autocorrelation function (PACF) could be generated accurately by using a two-layer perceptron. Takahashi et al. [22] also reported on being able generate various stylised facts [6] found in the historical series, but did not provide a detailed description of the methodology used. An unconditional approach to the generation of spot price log-returns, using Temporal Convolutional Networks (TCNs) [18], was first presented by Wiese et al. [23]; they also reproduce the relevant stylised facts, including volatility clustering and the leverage effect.\nIn contrast, generative models for time series of option prices are much less common: Cont [6] performs a principal component analysis (PCA) on implied volatility data; Wissel [24] provides a scheme to build a risk-neutral market model, focusing on ensuring the martingale property rather than realism. As far as we are aware, neural networks have not previously been applied to option market generation.\nOur work extends the conditional modelling framework of [15] to the multivariate setting by using GANs and other calibration techniques."}, {"heading": "3 Option prices", "text": "Our aim in this article is to simulate the prices of standard \u201cvanilla\u201d equity index options, of the type commonly traded on exchanges in large volumes3. An option is characterized by: the underlying index; the type (call or put); the strike, K; and the maturity, T . The maturity is the expiry date of the option; on that date, the option holder receives an amount max ( 0, s(IT \u2212K) ) , where IT is the prevailing level of the underlying index, and s = 1 for a call and \u22121 for a put. At any given time, not all strike/maturity/type combinations are tradable; market makers quote bid and/or offer prices for only the most relevant combinations, which broadly means those with strike closest to the current index level, and maturity closest to today. We will work with a representative grid of strikes and maturities.\nMarket participants commonly express option prices in terms of implied volatilities. The implied volatility is the number one must use in the standard Black-Scholes formula [2] to obtain the option price. The other inputs to the formula are the discount factor and the index forward price. All three\n3Eurex [8] reports an average of more than one million option contracts traded daily on EURO STOXX 50 in August 2019, corresponding to almost e 650MM in premiums paid.\ninputs to the price are stochastic, but the short-term price dynamics are primarily driven by changes in the implied volatility; in this paper, we focus on this contribution.\nOption prices are subject to strict ordering constraints because of no-arbitrage considerations. For example, since the call option payoff is a non-increasing function of strike, the option price must also be non-increasing; violation of this rule would constitute an arbitrage opportunity4, i.e. the possibility of making a profit while guaranteeing no loss. True arbitrage opportunities are rare, fleeting, and small; an option price simulator is more useful if it does not generate arbitrageable market states.\nFor this reason, it is not convenient to work with option prices directly; the ordering constraints are too complicated. The equivalent constraints on implied volatilities are even more awkward. Instead, we transform the prices to DLVs [5, 24], for which the absence of arbitrage corresponds to a simple requirement of positivity. In the absence of arbitrage, this mapping is bijective; an NK \u00d7NM grid of option prices is converted into an NK \u00d7NM grid of DLVs. In this article we will focus on one of the largest option markets, namely options on the EURO STOXX 50 index. An overview of the distributional and dependence properties of DLVs is provided in Appendix B. The implied volatilities of the EURO STOXX 50 for the relevant sets of strikes and maturities are displayed in Figure 1."}, {"heading": "4 Problem formulation", "text": "Throughout this paper N0 is the time set, (\u2126, (Ft)t\u2208N0 ,P) the filtered probability space and L2(RN ) denotes the space of RN -valued measurable functions for which the Euclidean norm \u2016\u00b7\u20162 is Lebesgue integrable.\nWe assume a set of NK equispaced strikes\nK = {K1,K1 + \u2206K, . . . ,K1 + (NK \u2212 1)\u2206K} and a set of NM maturities M = {M1, . . . ,MNM } for which we obtain the (NK \u00b7NM )-dimensional process of DLVs\n\u03c3t := [\u03c3t(K,M)](K,M)\u2208K\u00d7M, for t \u2208 N0.\nFurthermore, we assume that the historical process (\u03c3t, t \u2208 N0) evolves through a conditional model which can be constructed by feeding in a state St, which we would like to condition on, and noise Zt+1 which drives the process. Particularly, we describe the evolution of (\u03c3t, t \u2208 N0) by a unkown mapping g : L2(RNZ )\u00d7 L2(RNS )\u2192 L2(RNK \u00b7NM ) which relates noise and state to the next time step, such that our process takes the form\n\u03c3t+1 = g(Zt+1, St), for t \u2208 N0 (1) where Zt+1 \u223c N (0, I) isNZ -dimensional Gaussian noise and the state St a function of the processes history, i.e. St = f(\u03c3t, . . . , \u03c30). An example of f is a projection onto the most current component, i.e. St = \u03c3t, the last L realisations, St = [\u03c3t, . . . , \u03c3t\u2212L] or an exponentially weighted moving average.\nThe objective is to approximate the mapping (Zt+1, St) 7\u2192 \u03c3t+1 which ideally allows us to generate more data from a given state St. In this paper our approach is to represent this mapping through a deep neural network\ng : L2 ( RNZ ) \u00d7 L2 ( RNS ) \u00d7\u0398\u2192 L2 ( RNK \u00b7NM ) which is defined as a function of noise, state and its parameters \u03b8 \u2208 \u0398. For a given parameter vector \u03b8 \u2208 \u0398 the generated process (\u03c3\u0303t,\u03b8, t \u2208 N0) is defined as\n\u03c3\u0303t+1,\u03b8 = g\u03b8(Zt+1, S\u0303t,\u03b8) (2)\nwhere S\u0303t,\u03b8 = f(\u03c3\u0303t,\u03b8, . . . , \u03c3\u03030,\u03b8). The optimal outcome is to approximate a parameter vector \u03b8ML \u2208 \u0398 such that (\u03c3t, t \u2208 N0) and (\u03c3\u0303t,\u03b8ML , t \u2208 N0) inherit the same dynamics in terms of distributional and dependence properties.\n4Strictly, there is an arbitrage opportunity when the bid price of the higher-strike call option exceeds the offer price of the lower-strike option."}, {"heading": "5 Models", "text": "We now turn to the problem of modeling the process of DLV levels (\u03c3t, t \u2208 N0) and consider from now on log-DLV levels Xt := log(\u03c3t) for t \u2208 N0 to ensure non-negativity of the generated time series.\nThe first (naive) approach to model log-DLVs is to approximate (2) directly and generate all DLVs yielding the generated time-series\nX\u0303t+1,\u03b8 = g\u03b8(Zt+1, S\u0303t,\u03b8) (3)\nwhere S\u0303t,\u03b8 = [X\u0303t,\u03b8, . . . , X\u0303t\u2212L,\u03b8] includes current and past log-DLV levels for tuneable L \u2208 N. However, this approach suffers from having to model an arbitrarily high-dimensional process when it is necessary to generate a fine grid of DLVs yielding NX 1 for NX := NK \u00b7NM . Consequently, we also explore a compressed version of our generator.\nThe compressed version is motivated from the observation that log-DLV levels have high crosscorrelations indicating that log-DLVs live on a lower-dimensional manifold. Figure 2 illustrates the cross-correlation matrix of log-DLVs and DLV log-returns for the set of relative strikes K\u0304 := {0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15} and maturities M\u0304 := {20, 40, 60, 120}. Both cross-correlation matrices show high cross-correlations between groups of different maturities as well as within a specific maturity.\nWe therefore apply PCA to the set of log-DLV levels (Xt, t \u2208 N0) and compress theNX -dimensional process into an NP -dimensional one. The compressed process is defined for t \u2208 N0 as Pt = WXt, where W \u2208 RNP\u00d7NX denotes the compression matrix obtained through PCA. The generated process now takes the form\nP\u0303t+1,\u03b8 = g\u03b8(Zt+1, S\u0303t,\u03b8)\nX\u0303t+1,\u03b8 = W \u2020P\u0303t+1,\u03b8\nwhere S\u0303t,\u03b8 = [P\u0303t,\u03b8, . . . , P\u0303t\u2212L,\u03b8] is the state of current and past compressed log-DLVs - again for tuneable L \u2208 N. We also explored compressing DLV log-returns Rt := Xt \u2212Xt\u22121, t \u2208 N0 as they are also highly correlated (see Figure 2). However, we discarded this approach since it involves taking the cumulative sum of the compressed DLV log-returns which causes a lossy compression for a small number of principle components.\nFigure 3 illustrates the cumulative sum of variance explained as a function of the number of principle components for the grid K\u0304 \u00d7 M\u0304. In section 8 we report our results for NP = 5 principle components which explain \u2248 96% of the variance yielding a good trade-off between dimensionality reduction and preserving information."}, {"heading": "6 Optimization", "text": "The next step is to obtain a close approximation of \u03b8ML. Various training procedures exist ranging from conventional parametric methods such as quasi maximum likelihood estimation (qMLE) to\nnovel non-parametric ones such as GANs and the mean maximum discrepancy (MMD) [21]. In this paper, we explore the performance of qMLE, GANs and Wasserstein GANs (WGAN-GP) [12]. Following, we provide a brief explaination of the qMLE and GANs in the context of our explicit conditional model (3).\nIn qMLE we assume that the distribution of Xt+1|(Zt+1, St) can be described by a family of distributions P = {P\u03b3 | \u03b3 \u2208 \u0393} for some parameter space \u0393. The objective is to maximize the likelihood of our generated data under our family P [10, Chapter 5]. Here, we assume that Xt+1|(Zt+1, St) follows a Gaussian distribution where we constrain our covariance matrix to be diagonal. Our parametric family thus takes the form\nP = {N (\u00b5,\u03a3) | \u00b5 \u2208 RNX ,\u03a3 \u2208 D}.\nwhere D := {diag(a1, . . . , aNX ) | a1, . . . , aNX \u2208 R\u22650} is the set of (NX \u00d7 NX)-dimensional diagional matrices with non-negative components.\nA challenge in qMLE is the correct specification of P and the intractability of likelihood functions. GANs try to address this issue by introducing a min-max two-player game between the generator g\u03b8 and the discriminator d\u03b7 . The discriminator aims to discriminate between real samples from the data distribution and synthetic ones generated by the generator. The objective function proposed by the original paper from Goodfellow [11] adapted to our setting is of the form\nL(\u03b8, \u03b7) = E (log(d\u03b7([St, Xt+1]))) + E ( log(1\u2212 d\u03b7([S\u0303t,\u03b8, X\u0303t+1,\u03b8])) )\nwhere X\u0303t+1,\u03b8 is defined as in (3).\nA drawback of GANs is that they are notoriously hard to train which lead to the introduction of various regularization techniques to stabilize training [1, 3, 12, 16, 17, 20]. In our numerical results, we grid search over spectral normalization [17] imposed on the discriminator and generator [3] and gradient penalities proposed by Mescheder [16]. Furthermore, we also train our generative model by using WGAN-GP proposed by [12] and report on these results separately in section 8."}, {"heading": "7 Evaluating the generated paths", "text": "In GANs the objective function cannot be used to evaluate the performance of the generator. Equally, using the likelihood of a qMLE-trained model can give a distorted image. To measure the goodness and performance of a generative model we define and introduce various metrics and scores. These scores allow us to capture whether the generator is able to generate dynamics that are similar to those found in the historical DLV series such as highly cross-correlated log-DLVs and DLV log-returns, bimodal distributions or persistence in the autocorrelation.\nDuring training we intentionally evaluate log-DLVs instead of implied volatilities due two reasons. First, a close approximation of the generating mechanism of DLVs yields a close approximation of the generating mechanism of implied volatilities. Second, transforming DLVs to implied volatilities is costly. Once a close approximation of \u03b8ML is obtained we transform the generated DLVs to implied volatilities and compute metrics and scores for the generated implied volatilities and report on those.\nWe denote the historical dataset of log-DLVs by Dh = {[x0, . . . , xT ]} and likewise the generated dataset containing M \u2208 N paths of length T through\nDg = { [x\u0303 (i) 0,\u03b8, . . . , x\u0303 (i) T,\u03b8] }M i=1\nwhere [x\u0303(i)0,\u03b8, . . . , x\u0303 (i) T,\u03b8] denotes for any i \u2208 {1, . . . ,M} a time series obtained through recursive sampling from an initial state sampled from the historical dataset Dh. We begin by introducing a distributional metric and distributional scores, then define dependence scores and at last two scores that take into account the cross-correlation structure."}, {"heading": "7.1 Distributional metric", "text": "Naturally, we want the unconditional distribution of the generated and historical to match closely. For this purpose, let Bh = {B1, . . . , BK} be a binning such that approximately 20 elements of\nthe historical series x \u2208 Dh fall into each bin; # {t \u2208 {0, . . . , T} : xt \u2208 B} \u2248 20 for any B \u2208 Bh. With respect to the binning the empirical probability density function (epdf) of the historical f\u0302h : Bh \u2192 R\u22650 and the generated f\u0302g : Bh \u2192 R\u22650 can be defined. During training we track the absolute difference of the epdf \u2211\nB\u2208Bh\n|f\u0302h(B)\u2212 f\u0302g(B)|."}, {"heading": "7.2 Distributional scores", "text": "In financial applications higher order moments such as the skewness and kurtosis are of interest as they determine the propensity to generate extremal values. We therefore define the skewness score\n1\nNX NX\u2211 j=1 \u2225\u2225\u2225skew(x:,j)\u2212 skew ([x\u0303(1):,\u03b8,j , . . . , x\u0303(M):,\u03b8,j ])\u2225\u2225\u2225 2\nwhere x\u0303(i):,\u03b8,j for i \u2208 {1, . . . ,M} denotes the j-th dimension of the i-th generated time series and likewise the kurtosis score\n1\nNX NX\u2211 j=1 \u2225\u2225\u2225kurtosis(x:,j)\u2212 kurtosis([x\u0303(1):,\u03b8,j , . . . , x\u0303(M):,\u03b8,j ])\u2225\u2225\u2225 2 ."}, {"heading": "7.3 Dependence scores", "text": "Since DLVs are persistent we adopted ACF score proposed in [23]. It is defined by taking the Euclidean norm of the difference of the historical and the mean generated autocorrelation function\nACFX := \u2016ACF(x)\u2212 1 |Dg| \u2211\nx\u0303:,\u03b8\u2208Dg\nACF(x\u0303:,\u03b8)\u20162.\nSimilarly, we define the ACF score for the log-return process rt = xt \u2212 xt\u22121, t \u2208 {1, . . . , T}\nACFR := \u2016ACF(r)\u2212 1 |Dg| \u2211\nr\u0303:,\u03b8\u2208Dg\nACF(r\u0303:,\u03b8)\u20162.\nIn section 8 we report the ACFX score for the first 32 lags and the ACFR score for the first lag."}, {"heading": "7.4 Cross-correlation scores", "text": "To capture whether the generator generates cross-correlated log-DLVs and DLV log-returns we introduce two more scores. The cross-correlation score of log-DLVs is defined by taking the Euclidean norm of the cross-correlation matrix of log-DLVs \u2016\u03a3\u0302Xh \u2212 \u03a3\u0302Xg \u20162 where \u03a3\u0302Xh , \u03a3\u0302Xg denote the cross-correlation matrix of the historical and generated respectively. Likewise, the cross-correlation score of DLV log-returns is defined \u2016\u03a3\u0302Rh \u2212 \u03a3\u0302Rg \u20162 where \u03a3\u0302Rh , \u03a3\u0302Rg denote the cross-correlation matrix of the historical and generated DLV log-returns respectively."}, {"heading": "8 Numerical results", "text": "In this section we evaluate the performance of qMLE-, GAN- and WGAN-GP-trained models for the compressed and explicit version."}, {"heading": "8.1 Dataset", "text": "We use call option prices of the EURO STOXX 50 from 2011-01-03 to 2019-08-30 and consider the set of relative strikes and maturities\nK\u0304 := {0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15} , M\u0304 := {20, 40, 60, 120} .\nFor those option prices we compute the path of DLVs which we use for training (see Figure B.1). The total length of the time series is T\u0304 := 2257."}, {"heading": "8.2 Benchmarks", "text": "For comparison we apply the vector autoregressive model VAR(p) [14] and GAN-trained TCNs [23] to the same data. VAR(p) is a standard model for multivariate time series and assumes that Xt+1 is an affine function of the past p observations and some Gaussian noise Zt+1 \u223c N (0,\u03a3):\nXt+1 = A1Xt + \u00b7 \u00b7 \u00b7+ ApXt\u2212p + b + Zt+1. TCNs model log-DLVs unconditionally. Here, the generated process takes the form\nX\u0303t+1,\u03b8 = g\u03b8(Zt+1, . . . , Zt+1\u2212L)\nwhere (Zt, t \u2208 Z) is an i.i.d. Gaussian process and L \u2208 N0 denotes the TCN\u2019s receptive field size (see [23])."}, {"heading": "8.3 Training and evaluation time", "text": "We split the the historical series into a training and validation set through random sampling. The training set holds 85% of the data and is used to calibrate the parameters of the model. During training we compute the scores for M\u0304 := 40 generated paths of length T\u0304 . GAN- and WGAN-GP-trained models are evaluated every 100 generator gradient updates. qMLE-trained models are trained through early stopping and are only evaluated once after the criterion has been reached. The VAR model is also only evaluated once after the parameters are obtained through regression."}, {"heading": "8.4 Results", "text": "Table 1 summarises the best scores obtained for each of the generative models for a fixed parameter vector. For all except the ACFX score the explicit GAN-trained model achieves to generate the best paths.\nThe model that performs worst in terms of distributional properties is the VAR(2) - PCA(5) model. There the the fit of density and kurtosis is widely off. Notably, the ACFX scores fit least for the VAR(2) and qMLE-trained models, independent whether they were trained on all or the compressed log-DLVs. Overall, we can also conclude from Table 1 that GAN- and WGAN-GP-calibrated models give the best fit. For TCNs we do not report on a compressed version as no good approximation could be obtained.\nAlthough GAN-trained TCNs give a fairly good approximation in terms of distributional and crosscorrelation scores the ACFR score is far off. This makes the generated paths look very noisy. From this observation we concluded that TCNs have difficulties generating time series with high persistence from a pure i.i.d. noise process."}, {"heading": "8.5 Explicit GAN-trained model", "text": "We presented numerical results for a wide range of models and optimization algorithms. Now, we will take a look at the properties of the explicit GAN-trained model since it performed best across most benchmark scores.\n5The number in brackets specifies the receptive field size that was used; here 256.\nAs can be seen in Figure 4 the epdfs of the historical and generated log-implied volatilities match closely for most maturities and relative strikes. Arguably, the fit of the bimodal distribution for long-dated (M = 120 days) out of the money implied volatilies could be better. Taking a look at the historical and generated kurtosis in Figure 5 we can conclude that for most implied volatilities the approximation is accurate.\n0.5\n0.0\n0.5\n1.0\n1.5\nKu rto\nsis\nFigure 6 and Figure 7 illustrate the generated and historical cross-correlation matrices for log-implied volatilities and implied volatility log-returns. In both cases the historical is approximated accurately confirming the scores in Table 1.\nLast viewing the dependence properties Figure A.1 shows that for short lags the approximation of the ACF is very good. However, for longer lags the ACF of the historical decays slower than the generated. Figure A.2 displays the ACF of implied volatility log-returns and shows that the explicit GAN-trained model is able to approximate short dependencies quiet well. However, to model longer lags a larger history is necessary.\nFigure A.3 and Figure A.4 display two synthetic paths generated by the explicit GAN-trained model. Notably, the model is able to generate long-lasting periods of low volatility and periods of stress and high volatility phases. When comparing visually the synthetic paths to the historical (see Figure 1) it is difficult to discriminate them from being synthetic."}, {"heading": "9 Conclusion", "text": "In this paper, we demonstrated that the generating mechanism of implied volatilities can be closely approximated by employing adversarial training techniques. To measure the proximity of our synthetic paths to the historical we introduced a variety of scores that capture different features of implied volatilities. In section 8 we developed a benchmark and compared the performance of GANs against a wide range of models, training algorithms and explored the effects of compressing DLVs by using PCA. There we concluded that adversarial training outperforms conventional approaches such as the VAR model and qMLE training.\nFinally, our work shows for the first time that network-based models can be successfully applied to the context of generative modelling of multivariate financial time series; opening new avenues for future research and applications."}, {"heading": "A Explicit GAN-trained model", "text": "A.1 Dependence properties\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K80% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K85% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K90% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K95% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K100% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K105% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K110% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K115% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K80% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K85% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K90% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K95% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K100% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K105% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K110% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K115% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K80% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K85% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K90% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K95% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K100% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K105% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K110% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K115% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K80% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K85% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K90% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K95% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K100% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K105% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K110% generated\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K115% generated\nFigure A.2: ACF of implied volatility logreturns of the historical (blue) and generated (orange).\nA.2 Generated paths"}, {"heading": "B Discrete local volatilities", "text": "DLVs define an arbitrage-free surface that is globally closest to the surface of implied volatilities. We work with DLVs instead of implied volatilities in order to satisfy arbitrage constraints. This eliminates the issue of generating option prices that contain butterfly, calendar or spread arbitrage. Having synthetic options prices that contain arbitrage is highly undesirable. An algorithm trained on these prices could potentially learn to exploit these synthetic arbitrage opportunities which do not occure in reality; yielding an unworldly algorithm that performs well on synthetic but not real data.\nIn this paper, we consider the option prices of the EURO STOXX 50 from 2011-01-03 to 2019-08-30 and for the sets of relative strikes and maturities\nK\u0304 := {0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15} , M\u0304 := {20, 40, 60, 120} .\nThe historical time series of DLVs is obtained by transforming the EURO STOXX 50 implied volatilities and displayed in Figure B.1.\nFigure B.2 shows the empirical densities of log-DLVs. Each row represents a specific maturity and columns the moneyness. Similiar to implied volatilities (see Figure 4) long-dated (M \u2208 {60, 120}) out of the money (OTM) (K \u2208 {105%, 110%, 115%}) DLVs are characterised by bimodal distributions. The large buckets in the epdfs of the short-dated OTM DLVs (M = 20, K \u2208 {110%, 115%}) represent the floor which is defined at 0.01.\n1.5 1.0 0.5 0.0 0.5 0.00\n0.25 0.50\n0.75 1.00\n1.25 1.50\n1.75 M20-K80% 2 1 0 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 M20-K85% 2.0 1.5 1.0 0.5 0.0 0.5 1.0 1.5 2.0 M20-K90% 2.0 1.5 1.0 0.5 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 M20-K95% 2.0 1.5 1.0 0.5 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 M20-K100% 4 3 2 1 0.0 0.2 0.4 0.6 0.8 M20-K105% 4 3 2 1 0.0 0.2 0.4 0.6 0.8 1.0 1.2 M20-K110% 4 3 2 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 M20-K115%\n0.6 0.4 0.2 0.0 0\n1\n2\n3\n4 M40-K80%\n1.4 1.2 1.0 0.8 0.6 0.4 0.0\n0.5 1.0\n1.5 2.0\n2.5 3.0 M40-K85%\n1.6 1.4 1.2 1.0 0.8 0.6 0.0\n0.5\n1.0\n1.5\n2.0\n2.5 M40-K90%\n1.75 1.50 1.25 1.00 0.75 0.00 0.25\n0.50 0.75\n1.00 1.25\n1.50 1.75\n2.00 M40-K95%\n2.00 1.75 1.50 1.25 1.00 0.75 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 M40-K100% 2.5 2.0 1.5 1.0 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 M40-K105% 3.5 3.0 2.5 2.0 1.5 1.0 0.0 0.2 0.4 0.6 0.8 1.0\n1.2 M40-K110%\n4 3 2 1 0.0\n0.2\n0.4\n0.6\n0.8\n1.0 M40-K115%\n0.6 0.4 0.2 0\n1\n2\n3\n4\n5 M60-K80%\n1.4 1.2 1.0 0.8 0.6 0.0 0.5\n1.0 1.5\n2.0 2.5\n3.0 3.5\n4.0 M60-K85%\n1.6 1.4 1.2 1.0 0.8 0.0\n0.5 1.0\n1.5 2.0\n2.5 3.0 M60-K90%\n1.8 1.6 1.4 1.2 1.0 0.8 0.0\n0.5\n1.0\n1.5\n2.0\n2.5 M60-K95%\n2.0 1.8 1.6 1.4 1.2 1.0 0.0\n0.5\n1.0\n1.5\n2.0 M60-K100%\n2.5 2.0 1.5 1.0 0.00\n0.25 0.50\n0.75 1.00\n1.25 1.50\n1.75 M60-K105%\n3.0 2.5 2.0 1.5 0.0 0.2\n0.4 0.6\n0.8 1.0\n1.2 1.4\n1.6 M60-K110%\n3.5 3.0 2.5 2.0 1.5 0.0\n0.2 0.4\n0.6 0.8\n1.0 1.2\n1.4 M60-K115%\n0.7 0.6 0.5 0.4 0.3 0\n1 2\n3 4\n5 6 M120-K80%\n1.4 1.2 1.0 0.8 0\n1 2\n3 4\n5 M120-K85%\n1.6 1.4 1.2 1.0 0.8 0.0\n0.5 1.0\n1.5 2.0\n2.5 3.0\n3.5 M120-K90%\n1.6 1.4 1.2 1.0 0.0\n0.5 1.0\n1.5 2.0\n2.5 M120-K95%\n1.8 1.6 1.4 1.2 1.0 0.0\n0.5\n1.0\n1.5\n2.0\nM120-K100%\n2.25 2.00 1.75 1.50 1.25 0.0\n0.5\n1.0\n1.5\n2.0\nM120-K105%\n2.5 2.0 1.5 0.00 0.25\n0.50 0.75\n1.00 1.25\n1.50 1.75\n2.00 M120-K110%\n2.5 2.0 1.5 0.00 0.25\n0.50 0.75\n1.00 1.25\n1.50 1.75\n2.00 M120-K115%\nFigure B.2: Empirical densities of log-DLV levels. M2\n1.0\n0.5\n0.0\n0.5\n1.0\n1.5\n2.0\nKu rto\nsis\nThe ACFs of log-DLVs and DLV log-returns are displayed in Figure B.4 and Figure B.5. Visually one can detect in Figure B.4 that the ACFs of short-dated in the money DLVs decay faster than long-dated OTM ones.\n0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K80% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K85% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K90% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K95% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K100% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K105% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K110% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M20-K115% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K80% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K85% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K90% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K95% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K100% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K105% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K110% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M40-K115% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K80% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K85% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K90% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K95% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K100% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K105% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K110% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M60-K115% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K80% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K85% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K90% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K95% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K100% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K105% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K110% 0 25 50 75 100 125 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 M120-K115%\nFigure B.4: ACF of log-DLVs.\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K80%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K85%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K90%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K95%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K100%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K105%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K110%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M20-K115%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K80%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K85%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K90%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K95%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K100%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K105%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K110%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M40-K115%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K80%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K85%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K90%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K95%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K100%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K105%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K110%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M60-K115%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K80%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K85%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K90%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K95%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K100%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K105%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K110%\n0 5 10 15 20\n0.2\n0.1\n0.0\n0.1\n0.2 M120-K115%\nFigure B.5: ACF of DLV log-returns."}, {"heading": "C Disclaimer", "text": "Opinions and estimates constitute our judgement as of the date of this Material, are for informational purposes only and are subject to change without notice. It is not a research report and is not intended as such. Past performance is not indicative of future results. This Material is not the product of J.P. Morgan\u2019s Research Department and therefore, has not been prepared in accordance with legal requirements to promote the independence of research, including but not limited to, the prohibition on the dealing ahead of the dissemination of investment research. This Material is not intended as research, a recommendation, advice, offer or solicitation for the purchase or sale of any financial product or service, or to be used in any way for evaluating the merits of participating in any transaction. Please consult your own advisors regarding legal, tax, accounting or any other aspects including suitability implications for your particular circumstances. J.P. Morgan disclaims any responsibility or liability whatsoever for the quality, accuracy or completeness of the information herein, and for any reliance on, or use of this material in any way. Important disclosures at: www.jpmorgan.com/disclosures."}], "title": "Deep Hedging: Learning to Simulate Equity Option Markets", "year": 2019}