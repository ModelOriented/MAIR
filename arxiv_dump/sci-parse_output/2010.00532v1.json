{"abstractText": "Machine learning for nanoporous materials design and discovery has emerged as a promising alternative to more time-consuming experiments and simulations. The challenge with this approach is the selection of features that enable universal and interpretable materials representations across multiple prediction tasks. We use persistent homology to construct holistic representations of the materials structure. We show that these representations can also be augmented with other generic features such as word embeddings from natural language processing to capture chemical information. We demonstrate our approach on multiple metal\u2013organic framework datasets by predicting a variety of gas adsorption targets. Our results show considerable improvement in both accuracy and transferability across targets compared to models constructed from commonly used manually curated features. Persistent homology features allow us to locate the pores that correlate best to adsorption at different pressures, contributing to understanding atomic level structure-property relationships for materials design.", "authors": [{"affiliations": [], "name": "Aditi S. Krishnapriyan"}, {"affiliations": [], "name": "Joseph Montoya"}, {"affiliations": [], "name": "Jens Hummelsh\u00f8j"}, {"affiliations": [], "name": "Dmitriy Morozov"}], "id": "SP:9ac6900644d0c65db1a7418ab0dac6ebe85e0044", "references": [{"authors": ["Jesse L.C. Rowsell", "Elinor C. Spencer", "Juergen Eckert", "Judith A.K. Howard", "Omar M. Yaghi"], "title": "Gas adsorption sites in a large-pore metal\u2013organic framework", "year": 2005}, {"authors": ["Jian-Rong Li", "Julian Sculley", "Hong-Cai Zhou"], "title": "metal\u2013organic frameworks for separations", "venue": "Chemical Reviews,", "year": 2012}, {"authors": ["Dong Yang", "Bruce C. Gates"], "title": "Catalysis by metal organic frameworks: Perspective and suggestions for future research", "venue": "ACS Catalysis,", "year": 2019}, {"authors": ["Samuel O. Odoh", "Christopher J. Cramer", "Donald G. Truhlar", "Laura Gagliardi"], "title": "Quantum-chemical characterization of the properties and reactivities of metal\u2013organic frameworks", "venue": "Chemical Reviews,", "year": 2015}, {"authors": ["Kevin Maik Jablonka", "Daniele Ongari", "Seyed Mohamad Moosavi", "Berend Smit"], "title": "Big-data science in porous materials: Materials genomics and machine learning", "venue": "Chemical Reviews,", "year": 2520}, {"authors": ["Sanggyu Chong", "Sangwon Lee", "Baekjun Kim", "Jihan Kim"], "title": "Applications of machine learning in metal\u2013organic frameworks", "venue": "Coordination Chemistry Reviews,", "year": 2020}, {"authors": ["Yabing He", "Wei Zhou", "Guodong Qian", "Banglin Chen"], "title": "Methane storage in metal\u2013organic frameworks", "venue": "Chem. Soc. Rev.,", "year": 2014}, {"authors": ["Kenji Sumida", "David L. Rogow", "Jarad A. Mason", "Thomas M. McDonald", "Eric D. Bloch", "Zoey R. Herm", "Tae-Hyun Bae", "Jeffrey R. Long"], "title": "Carbon dioxide capture in metal\u2013organic frameworks", "venue": "Chemical Reviews,", "year": 2012}, {"authors": ["Shuji Himeno", "Toshiya Komatsu", "Shoichi Fujita"], "title": "High-pressure adsorption equilibria of methane and carbon dioxide on several activated carbons", "venue": "Journal of Chemical & Engineering Data,", "year": 2005}, {"authors": ["Michael Fernandez", "Amanda S. Barnard"], "title": "Geometrical properties can predict co2 and n2 adsorption performance of metal\u2013organic frameworks (mofs) at low pressure", "venue": "ACS Combinatorial Science,", "year": 2016}, {"authors": ["Maryam Pardakhti", "Ehsan Moharreri", "David Wanik", "Steven L. Suib", "Ranjan Srivastava"], "title": "Machine learning using combined structural and chemical descriptors for prediction of methane adsorption performance of metal organic frameworks (mofs)", "venue": "ACS Combinatorial Science,", "year": 2017}, {"authors": ["George S. Fanourgakis", "Konstantinos Gkagkas", "Emmanuel Tylianakis", "George E. Froudakis"], "title": "A universal machine learning algorithm for large-scale screening of materials", "venue": "Journal of the American Chemical Society,", "year": 2017}, {"authors": ["Seyed Mohamad Moosavi", "Aditya Nandy", "Kevin Maik Jablonka", "Daniele Ongari", "Jon Paul Janet", "Peter G. Boyd", "Yongjin Lee", "Berend Smit", "Heather J. Kulik"], "title": "Understanding the diversity of the metal\u2013organic framework ecosystem", "venue": "Nature Communications,", "year": 2020}, {"authors": ["Ryther Anderson", "Jacob Rodgers", "Edwin Argueta", "Achay Biong", "Diego A. G\u00f3mez-Gualdr\u00f3n"], "title": "Role of pore chemistry and topology in the co2 capture capabilities of mofs: From molecular simulation to machine learning", "venue": "Chemistry of Materials,", "year": 2018}, {"authors": ["Herbert Edelsbrunner", "John Harer"], "title": "Persistent homology \u2013 a survey", "venue": "Contemp. Math.,", "year": 2007}, {"authors": ["Aditi S. Krishnapriyan", "Maciej Haranczyk", "Dmitriy Morozov"], "title": "Topological descriptors help predict guest adsorption in nanoporous materials", "venue": "The Journal of Physical Chemistry C,", "year": 2020}, {"authors": ["Yongjin Lee", "Senja D. Barthel", "Pawe l D lotko", "S. Mohamad Moosavi", "Kathryn Hess", "Berend Smit"], "title": "Quantifying similarity of pore-geometry in nanoporous materials", "venue": "Nature Communications,", "year": 2017}, {"authors": ["Giorgos Borboudakis", "Taxiarchis Stergiannakos", "Maria Frysali", "Emmanuel Klontzas", "Ioannis Tsamardinos", "George E. Froudakis"], "title": "Chemically intuited, large-scale screening of MOFs by machine learning techniques", "venue": "npj Computational Materials,", "year": 2017}, {"authors": ["Christopher E. Wilmer", "Michael Leaf", "Chang Yeon Lee", "Omar K. Farha", "Brad G. Hauser", "Joseph T. Hupp", "Randall Q. Snurr"], "title": "Large-scale screening of hypothetical metal\u2013organic frameworks", "venue": "Nature Chemistry,", "year": 2012}, {"authors": ["Yongchul G. Chung", "Emmanuel Haldoupis", "Benjamin J. Bucior", "Maciej Haranczyk", "Seulchan Lee", "Hongda Zhang", "Konstantinos D. Vogiatzis", "Marija Milisavljevic", "Sanliang Ling", "Jeffrey S. Camp", "Ben Slater", "J. Ilja Siepmann", "David S. Sholl", "Randall Q. Snurr"], "title": "Advances, updates, and analytics for the computation-ready, experimental metal\u2013organic framework database: Core mof 2019", "venue": "Journal of Chemical & Engineering Data,", "year": 2019}, {"authors": ["Peter G. Boyd", "Tom K. Woo"], "title": "A generalized method for constructing hypothetical nanoporous materials of any net topology from graph theory", "venue": "CrystEngComm,", "year": 2016}, {"authors": ["T.F. Willems", "C.H. Rycroft", "M. Kazi", "J.C. Meza", "M. Haranczyk"], "title": "Algorithms and tools for highthroughput geometry-based analysis of crystalline porous materials", "venue": "Microporous and Mesoporous Materials, 149:134\u2013141", "year": 2012}, {"authors": ["Henry Adams", "Tegan Emerson", "Michael Kirby", "Rachel Neville", "Chris Peterson", "Patrick Shipman", "Sofya Chepushtanova", "Eric Hanson", "Francis Motta", "Lori Ziegelmeier"], "title": "Persistence images: A stable vector representation of persistent homology", "venue": "J. Mach. Learn. Res,", "year": 2017}, {"authors": ["H. Edelsbrunner", "D. Letscher", "A. Zomorodian"], "title": "Topological persistence and simplification", "venue": "Discrete Comput. Geom., 28:511\u2013533", "year": 2002}, {"authors": ["Logan Ward", "Alexander Dunn", "Alireza Faghaninia", "Nils E.R. Zimmermann", "Saurabh Bajaj", "Qi Wang", "Joseph Montoya", "Jiming Chen", "Kyle Bystrom", "Maxwell Dylla", "Kyle Chard", "Mark Asta", "Kristin A. Persson", "G. Jeffrey Snyder", "Ian Foster", "Anubhav Jain"], "title": "Matminer: An open source toolkit for materials data mining", "venue": "Computational Materials Science,", "year": 2018}, {"authors": ["L. Breiman"], "title": "Random forests", "venue": "Int. J. Mach. Learn. Cybern., 20:273\u2013297", "year": 1995}, {"authors": ["Shyue Ping Ong", "William Davidson Richards", "Anubhav Jain", "Geoffroy Hautier", "Michael Kocher", "Shreyas Cholia", "Dan Gunter", "Vincent L. Chevrier", "Kristin A. Persson", "Gerbrand Ceder"], "title": "Python materials genomics (pymatgen): A robust, open-source python library for materials analysis", "venue": "Computational Materials Science,", "year": 2013}, {"authors": ["Iwan Sumirat", "Y. Ando", "S. Shimamura"], "title": "Theoretical consideration of the effect of porosity on thermal conductivity of porous materials", "venue": "Journal of Porous Materials,", "year": 2006}, {"authors": ["Hasan Babaei", "Alan J.H. McGaughey", "Christopher E. Wilmer"], "title": "Effect of pore size and shape on the thermal conductivity of metal\u2013organic frameworks", "venue": "Chem. Sci.,", "year": 2017}, {"authors": ["Francois-Xavier Coudert"], "title": "Responsive metal\u2013organic frameworks and framework materials: Under pressure, taking the heat, in the spotlight, with friends", "venue": "Chemistry of Materials,", "year": 2015}], "sections": [{"heading": "1 Introduction", "text": "Metal\u2013organic frameworks (MOFs), and the family of nanoporous materials in general, have exceptional properties beneficial for a number of applications. They have played an important role in natural gas storage and delivery, as adsorbents for separation, and in catalysis applications [1, 2, 3]. The number of MOF structures is massive: there are many experimentally synthesized structures, but also many more hypothesized structures. Accordingly, there have been increasing efforts to employ computational approaches to navigate the vast space of MOFs and to choose promising candidates for various applications. These computational approaches have played an important role in the field by creating more guided directions for experiments and by providing some of the underlying theory to explain experimental results. Molecular simulations and ab initio calculations have allowed computation of key properties such as gas adsorption, Henry\u2019s coefficients, and diffusion [4]. They belong to the wider toolbox of high-throughput screening tools aimed at accelerating materials property prediction and design.\nMore recently, machine learning techniques have entered this toolbox [5, 6]. An ML model learns a function fitted on a set of known properties that represent a material. This model is then used to accurately predict a target value for a new material that was not included in the learning process. The computational cost of machine learning algorithms is appealing: they are often several orders of magnitude faster than the conventional simulation approaches.\nFor nanoporous materials, one of the most desired properties to predict is the adsorption capacity of a gas at given temperature-pressure conditions. Different gas adsorptions have different applications: for example, adsorption of methane is relevant to novel on-board vehicular fuel storage technologies [7], while adsorption of carbon dioxide at low pressure is important for capture and storage of emissions from flue gases [8]. Often, multiple physical models are necessary to capture adsorption across the full range of pressures\nar X\niv :2\n01 0.\n00 53\n2v 1\n[ co\nnd -m\nat .m\ntr l-\nsc i]\n1 O\n[9]. Creating a universal material representation, suitable for all different prediction tasks, is incredibly complicated. Typically, domain experts select specific material features as the model input: these features are usually context specific, used for making predictions about a particular property of interest.\nThe construction of descriptors that are able to achieve good prediction performance on different properties, as well as at different conditions, is a challenging task. For example, in the case of gas adsorption at high pressure, guest molecules tend to occupy the entire void space in a material. Thus, accessible surface area is commonly used in predictive models. In contrast, for gas adsorption at low pressures, the guest molecules aggregate in the strongly binding regions of the material\u2019s pore \u2014 standard structural descriptors are not able to capture this information as well. Additionally, chemical interactions of the system are important in determining some gas adsorption properties; this information also needs to be encoded in material descriptors.\nThe current state of the field suggests a significant need and potential payoff for the development of robust generic descriptors that would support machine learning models across many targets. Much of the previous work in this area has focused on using basic porosity descriptors such as accessible surface area (ASA), largest cavity diameter (LCD), and pore limiting diameter (PLD) [10, 11, 12, 13, 14]. Although these features perform well for some target properties, there is a lot of room for improvement in capturing finer description of the pore structures. Moreover, it is hard to interpret these features in terms of the specific porous frameworks that make up nanoporous materials.\nIn this paper, we use an alternative to these standard structural descriptors. We apply topological data analysis, specifically, persistent homology [15], to compute signatures of the channels and voids in the pores of the material, recording their number and size. These topological signatures are then converted to vector representations, allowing supervised machine learning algorithms to use them as input for predicting target material properties. The topological features we compute are generic, not tailored to a specific application. Instead, the labels in the training data allow machine learning algorithms to decide which subset of the features is important to a particular target prediction. As we demonstrate, these topological descriptors beat the standard structural descriptors in predicting a variety of materials properties.\nWe previously introduced this approach with an application to learning zeolite methane adsorption across different pressures [16], where we showed that topological descriptors consistently outperformed conventional structural descriptors. In this paper, we extend this technique to MOFs and demonstrate its merit for more complicated structures with significantly more diverse elemental compositions.\nThere has been previous work applying topological data analysis to nanoporous materials [17]. This work used standard metrics for unsupervised clustering of crystal structures based on their topological signatures. We instead use topological signatures with supervised machine learning to predict a material property, allowing us to identify the parts of the signature (and thus, the material structure) important for the prediction.\nBesides geometry and topology, chemical information is key for predicting MOF properties. Chemistry is especially important for predicting adsorption capacities at low pressures, as well as chemical properties like the Henry\u2019s coefficient, corresponding to the infinite dilution region. Previous approaches have constructed chemical descriptors by incorporating information from MOF building blocks, such as functional groups [14, 18]. These approaches have resulted in some improvements in predictive capabilities, however, as Fanourgakis et al. [12] noted, since the number of building blocks used to create a MOF is large, using these as descriptors for machine learning results in low transferability of the model and the need for a much larger training database. To combat this, Fanourgarkis et al. created chemical descriptors by identifying atom types using force fields. These atom types were created to account for different elements, as well as different hybridization and connectivities in different atoms. In this paper, we capture chemical information by using word embeddings constructed from a large corpus of abstracts with the word2vec algorithm [19]. The only input required is the elemental composition of the MOFs. By using word embeddings over elementproperty features we maintain the quasi-unsupervised nature of our machine learning pipeline. While the use of word embeddings to featurize composition do represent an implicit knowledge that the chemical elements are distinct, they use no explicit element-specific properties and are themselves derived from an unsupervised learning procedure on raw text. In addition, word embeddings are equally or more effective as other methods\nof composition featurization for capturing the necessary information to accurately predict material properties in other contexts [19], further motivating our use.\nWe demonstrate the combined machine learning framework by predicting different targets across three datasets. The targets include methane and carbon dioxide adsorption at different pressures, as well as Henry\u2019s coefficients. We show that the topological descriptors outperform standard porosity descriptors. Furthermore, we augment the topological features with word embeddings and show that this model improves prediction performance and compares favorably to prior work.\nThe key advantage of our approach is interpretability. It identifies channels and voids in a MOF that correlate best with adsorption at different pressures, further contributing to an atomic-level understanding of structure-property relationships."}, {"heading": "2 Methods", "text": ""}, {"heading": "2.1 Datasets", "text": "We demonstrate our approaches on three different datasets. The first dataset we consider is the hypothetical MOFs (hMOFs) database generated by Wilmer et al. [20] to predict gas uptakes in carbon dioxide at different pressures. This database consists of MOFs constructed by using a \u201cTinkertoy\u201d algorithm to combine different MOF building blocks. We use the hMOF structures from MOFDB,1 which has adsorption capacities (determined using grand canonical Monte Carlo simulations) for carbon dioxide at five different pressures ranging from 0.05 bar to 2.5 bar.\nWe also use the 2019 CoREMOF dataset [21] to predict methane and carbon dioxide adsorption capacities, and methane and carbon dioxide Henry\u2019s coefficients (determined using grand canonical Monte Carlo and Widom insertion simulations). This dataset consists of a selection of experimentally synthesized MOFs. The other dataset we consider is the Boyd-Woo database [22] to predict the same targets as for the CoREMOF dataset (also determined using grand canonical Monte Carlo and Widom insertion simulations). These reflect gas adsorption in a low pressure, high pressure, and infinite dilution context. Similar to Moosavi et al. [13], we use a subset of approximately 20,000 structures from this database for our studies \u2014 we call this the BW dataset.\nFor each structure in our dataset, as in our previous work [16], we have determined the values of the following commonly used geometric descriptors. We call these structural descriptors, and use them as a baseline to compare against topological descriptors: (a) pore limiting diameter (PLD), in (A\u030a), the diameter of the largest sphere to percolate through a material; (b) largest cavity diameter (LCD), in (A\u030a), the diameter of the largest sphere than can fit inside the material\u2019s pore system; (c) crystal density (\u03c1), in (kg/m3); (d) accessible volume (AV), in (cm3/g); (e) accessible surface area (ASA), in (m2/cm3). The values for these descriptors were computed using the Zeo++ software package [23]."}, {"heading": "2.2 Persistent homology", "text": "We describe the topological structure of the MOFs using persistent homology and follow the approach introduced in our earlier paper [16], where it was applied to zeolites. We review it briefly here.\nTo normalize the size of each MOF, expressed as (periodic) base cells of different sizes, we fill a (100A\u030a)3 cell with the atoms of the MOF. The size is chosen to be large enough to capture the statistics of the distribution of the topological features in every structure.\nWe represent a MOF as a union of balls centered on its atoms. We increase the radii of these balls and keep track of the changes in the topology of their union. The changes come in two types: a topological feature, such as a loop or a void, either appears or disappears. An important consequence of the algebraic formulation of this process is that these events can be paired uniquely, resulting in a set of birth\u2013death pairs of radii, called a persistence diagram; see Figure 1. There are two persistence diagrams relevant to us: a diagram that tracks births and deaths of loops that we interpret as tunnels in the MOF (we call\n1http://hmofs.northwestern.edu\nthese 1-dimensional features), and a diagram that tracks voids that we think of as pockets in the MOF (2- dimensional features). The difference in birth\u2013death values is called persistence of the pair. Pairs of larger persistence capture more prominent pores in the MOF. We compute persistence diagrams using Dionysus library.2\nTo translate persistence diagrams into vectors suitable as input for machine learning algorithms, we construct persistence images introduced by Adams et al. [24]. The birth\u2013death pairs (b, d) are transformed into birth\u2013persistence pairs (b, d \u2212 b). They are then convolved with Gaussians and discretized onto a grid of a fixed size, by integrating the resulting mixture of Gaussians in the cells of the grid. We use a modified version of the PersIm package3 to compute persistence images. We use the resolution of 50 \u00d7 50 and a Gaussian spread of \u03c3 = 0.15."}, {"heading": "2.3 Representative cycles", "text": "The algorithm used to compute persistence [25] tracks cycles that represent the topological features summarized in the persistence diagram. The cycles are not unique, but they reveal the atomic structures responsible for particular birth\u2013death pairs. In a crystal structure, representative cycles correspond to channels or voids in the material. We visualize the cycles to better understand the topological features that appear in the MOFs. We choose which cycle to visualize using the feature importances found by the machine learning algorithms. We compute the representative cycles using Dionysus.4"}, {"heading": "2.4 Word embeddings", "text": "To capture the MOF\u2019s chemical information, we use word embeddings of the chemical elements to represent a given MOF\u2019s stoichiometric formula. The chosen embeddings were constructed from a large corpus of abstracts with the word2vec algorithm [19]. We construct feature vectors based on the composition of each MOF structure that represent word embeddings for the different elements in the MOF using the\n2https://github.com/mrzv/dionysus 3persim.scikit-tda.org 4github.com/mrzv/dionysus\n\u201cmatscholar el\u201d preset ElementProperty featurizer in matminer [26]. The feature vectors correspond to 200 embedding dimensions, with the minimum, maximum, range, mean, and standard deviation for each dimension, for a total of 1000 values. We note that the different datasets have different numbers of unique elements, ranging from eight in the hMOF dataset to 72 in the CoREMOF dataset."}, {"heading": "2.5 Machine learning", "text": "We use random forest [27] regression to predict various targets across the different datasets, including carbon dioxide and methane adsorption at different pressures, as well as the Henry\u2019s coefficient for carbon dioxide and methane. One of our motivations for using the random forest is the ability to determine the feature importances in the model. The random forest algorithm builds an ensemble of decision trees and chooses a random subset of features for each one. The frequency with which a particular feature is chosen for a split is an estimate for the importance of the said feature.\nWe build trees for different groups of features: topological features, standard structural features, word embeddings, a combined model of topological features and word embeddings, a combined model of topological and structural features, and a combined model of topological features, structural features, and word embeddings. The topological features consist of both the 1D and 2D persistence images. We train the random forest on the specific target prediction of each material. Each of the forests consists of 500 trees, and the final prediction is the average of the prediction of all trees in the forest. After training the random forest on a training set, predictions are made on an unseen test set. For most of the predictions, we use an 80%/20% training-test split. The quality of the prediction is evaluated by comparing the predicted adsorption values and the correct adsorption values. We quantify our predictions by computing the root-mean-square deviation, \u221a\u2211 (y\u0302i \u2212 yi)2/n, and the coefficient of determination (R2), 1 \u2212 \u2211 (yi \u2212 y\u0302i)2)/ \u2211 (yi \u2212 y\u0304)2."}, {"heading": "3 Results", "text": "We evaluate the accuracy of the machine learning models by predicting a number of different targets across the different datasets. For each target, we calculate the root-mean-square deviation (RMSD) and coefficient of determination (R2 score). For each target and each dataset, we include results from models trained on only the topological features, only the word embeddings, and both the topological features and the word embeddings (T + WE). We also include results from the structural descriptors, described in Section 2.1, as a baseline. Finally, we incorporate the standard structural descriptors by including models combining topological and structural descriptors (T + S), as well as topological descriptors, structural descriptors, and word embeddings (T + S + WE)."}, {"heading": "3.1 hMOF dataset", "text": "For the hMOF dataset, we predict carbon dioxide adsorption capacities at different pressures, as shown in Figure 2. The RMSD is low at lower pressures because the distribution of carbon dioxide adsorption capacity has low variance in this regime. While the topology-based model outperforms the word embeddings, the model combining the two performs even better. We also see that the topological features always outperform the structural features. The word embeddings do not perform as well here. This is likely due to the hMOF dataset lacking compositional diversity: the hMOF data set contains only eight unique elements; other datasets, like the CoREMOF dataset, have 72. Nevertheless, word embeddings help boost the overall model performance when combined with the topological features.\nWe achieve the best performance by combining all three features together, but the accuracy achieved by subsets of the features is revealing. Adding structural to topological features slightly improves the performance, but doesn\u2019t match that of all three features combined. On the other hand, the T + WE model performs only slightly worse than the T + S + WE model, indicating that the topological features capture most of the information that the structural features provide.\nWe compare our results to Fanourgakis et al. [12], who used standard structural features and a featurization based on atom types to predict CO2 adsorption capacity in the hMOF dataset. Table 1 shows results for each of our models at different pressures, along with the best model from Fanourgakis et al. [12].\nOur model does particularly well at low pressures, achieving an R2 score of 0.86 at 0.05 bar, compared to 0.65 from [12]. Carbon dioxide adsorption at low pressure has an important application: carbon capture from flue gases. Thus, it is particularly promising to have a generalized framework for accurate prediction of these targets. In general, our model transfers well across different pressures, as demonstrated by consistently high performance."}, {"heading": "3.2 BW and CoREMOF datasets", "text": "We evaluate the accuracy of the machine learning predictions on the BW and CoREMOF datasets. We predict six targets grouped into three categories: the Henry\u2019s coefficient (log(KH)) for CO2 and CH4, the gas uptakes for CO2 at 0.15 and 16 bar, and the gas uptakes for CH4 at 5.8 and 65 bar. Since each category has different units, to make them easier to compare, we normalize each of the three categories with respect to the maximum RMSD in that category.\nFigure 3 shows the results of these predictions for the BW dataset. As a general trend, topological features outperform the structural features. This is especially apparent for the Henry\u2019s coefficient predictions and the CO2 and CH4 gas uptakes at low pressure. Although word embeddings are the least accurate in all categories, they boost performance when combined with the topological features. This observation reinforces the idea that adding chemical information can improve performance, particularly for targets like the Henry\u2019s coefficient.\nAs with the hMOF dataset, we see that the model combining the three features performs best across all targets. The T + S model typically performs only slightly better than the topological features, and usually much better than the structural features. This corroborates that the topological features capture almost all the information in the structural features, and much more.\nFigure 4 shows the results of the machine learning predictions for the CoREMOF dataset. For predictions of the Henry\u2019s coefficient for both CO2 and CH4, as well as the CO2 adsorption capacity at low pressure, the structural features perform especially poorly in comparison to the other models. For these three targets, unlike in the BW dataset, the word embeddings outperform the topological features. This confirms that these properties depend more on chemical information. The reason why this is especially noticeable in the CoREMOF dataset is its higher composition diversity. The CoREMOF dataset has 72 unique elements, while our subset of the BW dataset has only 16. The one target where structural descriptors outperform the topological descriptors is the CO2 gas uptake at 16 bar. In general, structural (geometric) information is more important at higher pressures.\nFor low pressure adsorption targets like 0.15 bar CO2, the T + S model performs about the same as the topological features, but considerably better than the structural features. This suggests that there is a lot of relevant geometric information that the conventional structural descriptors don\u2019t capture. For low pressure and infinite dilution gas adsorption predictions, to our knowledge, these topological descriptors are currently the best-performing descriptors that only take into account geometric information about the MOF.\nOverall, across all three datasets, the model combining all three feature types (T + S + WE) has the highest predictive capability."}, {"heading": "3.3 Feature analysis", "text": "The random forest algorithm infers the importance of individual features by measuring how frequently they are used by the decision trees to make a prediction about a MOF. In our methodology, there are three distinct types of features: topological, structural, and word embeddings. Further, topological features come in two types, 1-dimensional features that capture the distribution of channels in the MOF and 2-dimensional features that describe the voids. Each of those consists of 2500 individual features (pixels in the persistence image), but we combine them to infer the aggregate importance of the different feature types. In this section, we analyze contributions from the topological and word embedding features, since the structural features contribute little extra information.\nFigure 5 shows the relative importance of topological descriptors and word embeddings. For the BW dataset, 2D features are most important for the prediction, with word embeddings playing a larger role in the predictions of the Henry\u2019s coefficient. For the CoREMOF dataset, word embeddings are more important, especially for the Henry\u2019s coefficient and CO2 adsorption at low pressure, where they account for 40-60% of the decisions, with topological features dominating the importance of predictions at higher pressure. For the hMOF dataset, 1D topological features are most important at low pressures, with 2D being more important at higher pressure, and word embeddings used in \u223c 30% of the decisions.\nThese results reveal the importance of different properties for different tasks. They support the claim that chemical information is more important for infinite dilution and low-pressure CO2 adsorption. In these conditions, the electrostatic interactions between the gas and the MOF framework play an important role in adsorption capacity \u2014 the word embeddings capture this non-structural information. On the other hand, methane adsorption at higher pressure is mostly described by 2D topology, a trend that we also observed in zeolites [16].\nOur results also suggest why the conventional structural descriptors perform especially poorly when predicting CO2 adsorption in hMOFs at low pressure. The standard structural features describe the pore geometry by the largest sphere to percolate through the materials and the largest sphere that can fit inside its pore system. In contrast, topological features record the widths of the channels that criss-cross the MOF as well as the sizes of different cavities. They also distinguishing between the distribution of channels and voids, by separating 1D and 2D topological features, and record other finer information about their shape.\nAs Figure 5 shows, topological features play a major role in predicting gas adsorption, with the 1- dimensional channels being especially important for adsorption at low pressures in the CoREMOF and hMOF datasets, and 2-dimensions voids being important for the predictions with the BW dataset. The differences in feature importances can also be linked back to the data: for example, the CoREMOF MOFs tend to have smaller pores than the BW MOFs. Ultimately, there is at least some complementary information being captured by the structural and topological features, as the best models across all the datasets include both.\nOur results also suggest guiding principles for developing MOFs with high adsorption capacity. Channels in the material are important for adsorption at lower pressures, while adsorption at higher pressures is more influenced by voids in the material. For a MOF to have high adsorption capacity across pressures, a structure with diverse pore geometry, with both channels and voids, may be important."}, {"heading": "4 Interpretability", "text": ""}, {"heading": "4.1 Topological features and representative cycles", "text": "Nanoporous materials, and especially MOFs, are known for how tunable they are: experimentalists can synthesize materials with precisely sized pores. Understanding how structure influences a particular material property helps guide this process. Persistent homology is especially helpful here. The features it defines have an immediate interpretation that can be incorporated into synthesis.\nThe points in a persistence diagram correspond to voids and channels of specific sizes. A point (b, d) in a\n2-dimensional diagram is generated by a cavity that can fit the largest sphere of radius d; the largest sphere that can escape from the cavity (and move to a larger cavity) has radius b. A point (b, d) in a 1-dimensional diagram is produced by a channel in the material, specifically, by its narrowest \u201cbottleneck.\u201d The death value, d, records the radius of the largest sphere that can pass through this bottleneck. The birth value, b, records how close the atoms of the bottleneck are to each other.\nFor each dataset and each target property, the most important 1D and 2D birth-death points, as identified by the random forest algorithm, are listed in Tables 2, 3, and 4. We note a few patterns. In the case of methane adsorption in all three regimes (infinite dilution, low pressure, and high pressure), the 2D birth and death values are similar for both the BW and CoREMOF datasets \u2014 in fact, almost identical for the infinite dilution and high pressure cases. Specifically, birth values are around 2.3 \u2013 2.4 A\u030a for high pressure methane adsorption, and 3.4 \u2013 3.8 A\u030a for low pressure and infinite dilution methane adsorption. Death values are 3.2 A\u030a for high pressure methane adsorption, and 4 \u2013 4.6 A\u030a for low pressure and infinite dilution methane adsorption. Another pattern to note in the hMOF dataset is that 1D death values get larger as CO2 adsorption increases, meaning the size of the largest sphere able to pass through the channel increases.\nWe can dissect topological representations further and extract representative cycles for each point. Although these cycles are not unique \u2014 we are at the mercy of certain choices persistent homology calculation makes \u2014 they are helpful in visualizing the cavities and channel bottlenecks represented by the points in the persistence diagram.\nSince we train our machine learning algorithm on persistence images, we have to take an extra step to identify the points in a persistence diagrams with relevant representative cycles. We illustrate our steps on the following example. Figure 6(b) shows the feature importances for predicting CO2 adsorption at low pressure in the BW dataset. We identify the birth and persistence values of the most important pixel in the\npersistence image and highlight its center in orange in Figure 6(c), which also shows in blue the persistence diagram for str-m3-o10-o15-pcu-sym.49, a MOF with high CO2 adsorption at low pressures. Figure 6(d) shows a representative cycle for the point in the persistence diagram that falls within the Gaussian spread factor used to construct the persistence image.\nWe extracted the representative cycles from the high gas adsorption MOFs from different databases. Four examples, including both 1D topology (channels) and 2D topology (voids), appear in Figure 7. One notable trend is that the loop in Figure 7(c) is present in many of the materials in the hMOF dataset that have high CO2 adsorption at low pressure. Similarly, the void size seen in Figure 7(a) is present in many of the MOFs with high CO2 adsorption."}, {"heading": "4.2 Word embeddings and material properties", "text": "We explore the interpretability of the word embeddings by relating their importances in predicting MOF properties and in predicting chemical properties of individual elements. The former we obtain from the random forests just as the importances of the topological features. To calculate the importances for individual elements, we retrieve word embeddings for all the elements in the matscholar database [19] and use these as features to train models to predict various chemical properties \u2014 electronegativity, atomic radius, electrical resistivity, melting point, etc. \u2014 of the pure elements contained in pymatgen\u2019s \u2018periodic table\u2019 module [28]. We extract the feature importances for each of these models. Because each MOF has 1000 features, summarizing the distribution of 200 features over its elements, as described in Section 2.4, we sum up the MOF feature importances corresponding to the same elemental feature.\nWe take the subset of feature importances that account for 90% of the random forest decisions. By definition, these features describe the subspace of our input where most of the decisions are made to make a prediction about the given target property. Given a MOF target property and a chemical target property,\nwe compute the Jaccard similarity between the two subsets of features. This metric measures the relative size of the subspace, important for the random forest decisions for both targets.\nTable 5 lists the top three materials properties by similarity to each MOF target property; all of them have a Jaccard similarity greater than 0.4. Following this procedure, we identify the chemical property with the strongest informational relevance to a given MOF target property. We focus on interpreting the\nresults from a MOF design perspective. The word-embedding features play a bigger role than topology in predicting 0.15 bar CO2 adsorption, log(KH) CO2, and log(KH) CH4 (Figure 4). For these three targets, the machine learning model trained on electronegativity was the most or second most similar to the model trained on the word embeddings for each MOF. This suggests that local electrostatic interactions are more significant in carbon dioxide adsorption at low pressure, which is consistent with qualitative descriptions of low pressure or dilute-limit profiles of absorptivity in porous materials from literature [13]. Thermal conductivity also appears multiple times, and is the most relevant elemental property for high pressure CO2 and CH4 adsorption.\nThe relevance of thermal conductivity at higher pressures is more difficult to interpret, given that thermal conductivity contains an electronic and vibrational component. However, a relationship between thermal conductivity and MOF geometry has been suggested previously. Specifically, thermal conductivity correlates with pore size and porosity [29, 30], which in turn affects adsorption. Thus, when designing a MOF, choosing metal elements that decrease the thermal conductivity of a MOF could be one way to increase adsorption.\nAnother materials property that appeared multiple times for multiple MOF targets was the Poisson\u2019s ratio, which reflects elasticity of a material. This is another property that fits in the existing paradigm of MOF design: namely, flexibility. MOFs with flexible frameworks often are better adsorbents [31], since they can accommodate a larger space to fit a gas molecule with less stress.\nIn summary, the latent information contained in the word embeddings overlaps with known descriptors for MOF gas adsorption, pointing to important chemical features for designing high adsorption MOFs."}, {"heading": "5 Conclusions", "text": "We have developed a machine learning framework for MOFs, and nanoporous materials in general, using persistent homology and word embeddings. Our approach builds a holistic representation of the materials, requiring less handcrafting and domain expert guidance than the currently widely used porosity and chemical descriptors. Our topological representation is a vectorized persistence diagram, obtained from the atomic coordinates of the normalized supercell representation of a materials\u2019 crystal structure. It can be used in any machine learning algorithm. We augment the topological information with element embeddings, constructed from a large set of scientific abstracts via the word2vec algorithm [19]. They provide a generalized representation of the MOF composition. We have tested this approach on three different datasets, predicting several gas adsorption targets at various pressures. These experiments show a significantly improved\nperformance compared to standard structural descriptors. The topological features we compute are generic and transferable across different property targets. As the topological descriptors consistently outperform standard structural descriptors, they provide a simple way to boost the performance of any machine learning algorithm. Additionally, to our knowledge, these descriptors are the best purely geometric descriptors for predicting gas adsorption at low pressures and in the infinite dilution regime. Moreover, these descriptors are interpretable: their components can be traced to specific channels and voids in the crystal structure, which contributes to a greater understanding of structure-property relationships in MOFs.\nWe conclude by highlighting the key strengths of our approach. 1) It provides a way to quickly screen any dataset to find the top MOFs for a particular task without the need to handcraft specific features. 2) It augments existing features for accurate performance predictions. 3) It helps guide materials design by directly connecting property predictions to the crystal structure."}, {"heading": "6 Acknowledgements", "text": "This work was supported by the U.S. Department of Energy under Contract Number DE-AC02-05CH11231 at Lawrence Berkeley National Laboratory. A.S.K. is an Alvarez Fellow in the Computational Research Division at LBNL. A.S.K. also acknowledges support from the TRI-AMDD internship program and further support from TRI-AMDD for cloud computing resources and initial project planning. The authors acknowledge helpful discussions with Muratahan Aykol, John Dagdelen, Aayush Singh, Santosh Suram, and Ram Seshadri."}, {"heading": "7 Competing interests", "text": "The authors declare no competing interests."}], "title": "Persistent homology advances interpretable machine learning for nanoporous materials", "year": 2020}