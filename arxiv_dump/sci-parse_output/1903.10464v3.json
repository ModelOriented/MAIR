{
  "abstractText": "Explaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from a complex machine learning model by learning simple, interpretable explanations. Shapley values is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent, which may give very wrong explanations. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values. We also propose a method for aggregating individual Shapley values, such that the prediction can be explained by groups of dependent variables.",
  "authors": [
    {
      "affiliations": [],
      "name": "KJERSTI AAS"
    },
    {
      "affiliations": [],
      "name": "MARTIN JULLUM"
    },
    {
      "affiliations": [],
      "name": "ANDERS L\u00d8LAND"
    }
  ],
  "id": "SP:56e8d4ab417861cda42ea99b4a7f830e716947f8",
  "references": [
    {
      "authors": [
        "D. Baehrens",
        "T. Schroeter",
        "S. Harmeling",
        "M. Kawanabe",
        "K. Hansen",
        "M\u00fcller",
        "K.-R"
      ],
      "title": "How to explain individual classification descisions",
      "venue": "Journal of Machine Learning Research",
      "year": 2010
    },
    {
      "authors": [
        "K. Bertin",
        "C. Lacour",
        "V. Rivoirard"
      ],
      "title": "Adaptive pointwise estimation of conditional density function",
      "venue": "Ann. Inst. H. Poincar Probab. Statist",
      "year": 2016
    },
    {
      "authors": [
        "H.J. Bierens"
      ],
      "title": "The Nadaraya-Watson kernel regression function estimator",
      "venue": "Topics in Advanced Econometrics. Cambridge University Press.",
      "year": 1994
    },
    {
      "authors": [
        "R.P. Browne",
        "P.D. McNicholas"
      ],
      "title": "A mixture of generalized hyperbolic distributions",
      "venue": "Canadian Journal of Statistics",
      "year": 2015
    },
    {
      "authors": [
        "A. Charnes",
        "B. Golany",
        "M. Keane",
        "J. Rousseau"
      ],
      "title": "Extremal Principle Solutions of Games in Characteristic Function Form: Core, Chebychev and Shapley Value Generalizations",
      "year": 1988
    },
    {
      "authors": [
        "J. Chen",
        "L. Song",
        "M.J. Wainwright",
        "M.I. Jordan"
      ],
      "title": "L-shapley and c-shapley: Efficient model interpretation for structured data",
      "venue": "CoRR abs/1808.02610",
      "year": 2018
    },
    {
      "authors": [
        "T. Chen",
        "C. Guestrin"
      ],
      "title": "XGBoost: A scalable tree boosting system",
      "venue": "In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). ACM",
      "year": 2016
    },
    {
      "authors": [
        "A.R. de Leon",
        "K.C. Carriere"
      ],
      "title": "A generalized mahalanobis distance for mixed data",
      "venue": "Journal of Multivariate Analysis 92,",
      "year": 2005
    },
    {
      "authors": [
        "European Union"
      ],
      "title": "Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)",
      "venue": "Official Journal of the European Union 59.",
      "year": 2016
    },
    {
      "authors": [
        "T. Gneiting",
        "A.E. Raftery"
      ],
      "title": "Strictly proper scoring rules, prediction, and estimation",
      "venue": "Journal of the American Statistical Association",
      "year": 2007
    },
    {
      "authors": [
        "I.J. Good"
      ],
      "title": "The population frequencies of species and the estimation of population",
      "venue": "parameters. Biometrika",
      "year": 1953
    },
    {
      "authors": [
        "M.P. Holmes",
        "A.G. Gray",
        "C.L. Isbell"
      ],
      "title": "Fast kernel conditional density estimation: A dual-tree monte carlo approach",
      "venue": "Computational Statistics & Data Analysis",
      "year": 2010
    },
    {
      "authors": [
        "Z. Huang"
      ],
      "title": "Clustering large data sets with mixed numeric and categorical variables",
      "venue": "Proceedings of the First Pacific Asia Knowledge Discovery and Data Mining Conference.",
      "year": 1997
    },
    {
      "authors": [
        "Z. Huang"
      ],
      "title": "Extensions to the k-Means Algorithm for Clustering Large Data sets with Categorical variables",
      "venue": "Data Mining and Knowledge Discovery 2, 283\u2013304.",
      "year": 1998
    },
    {
      "authors": [
        "C.M. Hurvich",
        "J.S. Simonoff",
        "Tsai",
        "C.-L"
      ],
      "title": "Smoothing parameter selection in nonparametric regression using an improved akaike information criterion",
      "venue": "Journal of the Royal Statistical Society. Series B (Statistical Methodology)",
      "year": 1998
    },
    {
      "authors": [
        "R. Izbicki",
        "A.B. Lee"
      ],
      "title": "Converting high-dimensional regression to high-dimensional conditional density estimation",
      "venue": "Electron. J. Statist",
      "year": 2017
    },
    {
      "authors": [
        "R. Izbicki",
        "A.B. Lee"
      ],
      "title": "Converting high-dimensional regression to high-dimensional conditional density estimation",
      "venue": "Electronical Journal of Statistics",
      "year": 2017
    },
    {
      "authors": [
        "L.A. Kelley",
        "S.P. Gardner",
        "M.J. Sutcliffe"
      ],
      "title": "An automated approach for clustering an ensemble of NMR-derived protein structures into conformationally related subfamilies",
      "venue": "Protein Engineering, Design and Selection",
      "year": 1996
    },
    {
      "authors": [
        "M.G. Kendall"
      ],
      "title": "A new measure of rank correlation",
      "venue": "Biometrika 30, 81\u201393.",
      "year": 1938
    },
    {
      "authors": [
        "H. Kvamme",
        "N. Sellereite",
        "K. Aas",
        "S. Sjursen"
      ],
      "title": "Predicting mortgage default using convolutional neural networks",
      "venue": "Expert Systems with Applications",
      "year": 2018
    },
    {
      "authors": [
        "X. Li",
        "N.C. Dvornek",
        "Y. Zhou",
        "J. Zhuang",
        "P. Ventola",
        "J.S. Duncan"
      ],
      "title": "Efficient interpretation of deep learning models using graph structure and cooperative game theory: Application to ASD biomarker discovery",
      "venue": "CoRR abs/1812.06181",
      "year": 2018
    },
    {
      "authors": [
        "S.M. Lundberg",
        "Lee",
        "S.-I"
      ],
      "title": "A Unified Approach to Interpreting Model Predictions",
      "venue": "In Advances in Neural Information Processing Systems. Curram Associates Inc",
      "year": 2017
    },
    {
      "authors": [
        "S.M. Lundberg",
        "Lee",
        "S.-I"
      ],
      "title": "Consistent feature attribution for tree ensembles",
      "venue": "In Proceedings of the 34 th International Conference on Machine Learning. JMLR: W&CP",
      "year": 2017
    },
    {
      "authors": [
        "P.C. Mahalanobis"
      ],
      "title": "On the generalised distance in statistics",
      "venue": "Proceedings of the National Institute of Sciences of India.",
      "year": 1936
    },
    {
      "authors": [
        "A.J. McNeil",
        "R. Frey",
        "P. Embrechts"
      ],
      "title": "Quantitative Risk Management: Concepts, Techniques and Tools",
      "year": 2006
    },
    {
      "authors": [
        "C. Molnar"
      ],
      "title": "Interpretable Machine Learning - A Guide for Making Black Box Models explainable",
      "venue": "https://christophm.github.io/interpretable-ml-book/.",
      "year": 2019
    },
    {
      "authors": [
        "D. M\u00fcllner"
      ],
      "title": "fastcluster: Fast hierarchical, agglomerative clustering routines for R and Python",
      "venue": "Journal of Statistical Software 53, 1\u201318.",
      "year": 2013
    },
    {
      "authors": [
        "Z. Obermeyer",
        "E.J. Emanuel"
      ],
      "title": "Predicting the Future \u2013 Big Data, Machine Learning, and Clinical Medicine",
      "venue": "New England Journal of Medicine",
      "year": 2016
    },
    {
      "authors": [
        "A.B. Owen"
      ],
      "title": "Sobol indices and Shapley value",
      "venue": "SIAM/ASA Journal on Uncertainty Quantification 2, 245\u2013251.",
      "year": 2014
    },
    {
      "authors": [
        "A.B. Owen",
        "C. Prieur"
      ],
      "title": "On Shapley value for measuring importance of dependent inputs",
      "venue": "SIAM/ASA Journal on Uncertainty Quantification",
      "year": 2017
    },
    {
      "authors": [
        "M.T. Ribeiro",
        "S. Singh",
        "C. Guestrin"
      ],
      "title": "Why should I trust you? Explaining predictions of any classifier",
      "venue": "In Proceeedings of te 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). ACM",
      "year": 2016
    },
    {
      "authors": [
        "M. Rosenblatt"
      ],
      "title": "Remarks on Some Nonparametric Estimates of a Density Function",
      "venue": "The Annals of Mathematical Statistics 27, 832\u2013837.",
      "year": 1956
    },
    {
      "authors": [
        "L.S. Shapley"
      ],
      "title": "A Value for N-Person Games",
      "venue": "Contributions to the Theory of Games 2, 307\u2013317.",
      "year": 1953
    },
    {
      "authors": [
        "A. Sklar"
      ],
      "title": "Fonctions de r\u00e9partition \u00e0 n dimensions et leurs marges",
      "venue": "Publ. Inst. Stat. Univ. Paris 8, 229\u2013231.",
      "year": 1959
    },
    {
      "authors": [
        "E. Song",
        "B.L. Nelson",
        "J. Staum"
      ],
      "title": "Shapley effects for global sensitivity analysis: Theory and computation",
      "venue": "SIAM/ASA Journal on Uncertainty Quantification",
      "year": 2016
    },
    {
      "authors": [
        "A. Sudjianto",
        "S. Nair",
        "M. Yuan",
        "A. Zhang",
        "D. Kern",
        "F. Cela-D\u0301\u0131az"
      ],
      "title": "Statistical methods for fighting financial crimes",
      "year": 2010
    },
    {
      "authors": [
        "E. \u0160trumbel",
        "I. Kononenko"
      ],
      "title": "An Efficient Explanation of Individual Classifications using Game Theory",
      "venue": "Journal of Machine Learning Research",
      "year": 2010
    },
    {
      "authors": [
        "E. \u0160trumbel",
        "I. Kononenko"
      ],
      "title": "Explaining prediction models and individual predictions with feature contributions",
      "venue": "Knowledge and Information Systems",
      "year": 2014
    },
    {
      "authors": [
        "Y. Wei",
        "Y. Tang",
        "P.D. McNicholas"
      ],
      "title": "Mixtures of generalized hyperbolic distributions and mixtures of skew-t distributions for model-based clustering with incomplete data",
      "venue": "Computational Statistics & Data Analysis 130,",
      "year": 2019
    },
    {
      "authors": [
        "D. White",
        "R.B. Gramacy"
      ],
      "title": "maptree: Mapping, pruning, and graphing tree models. R package version 1.4-7",
      "year": 2012
    },
    {
      "authors": [
        "H.P. Young"
      ],
      "title": "Monotonic solutions of cooperative games",
      "venue": "International Journal of Game Theory 14, 65\u201372.",
      "year": 1985
    }
  ],
  "sections": [
    {
      "heading": "1. Introduction",
      "text": "Interpretability is crucial when a complex machine learning model is to be applied in areas such as medicine (Obermeyer & Emanuel, 2016), fraud detection (Sudjianto et al., 2010) or credit scoring (Kvamme et al., 2018). In many applications, complex hard-to-interpret machine learning models like deep neural networks, random forests and gradient boosting machines, are currently outperforming the traditional, and to some extent interpretable, linear/logistic regression models. However, often there is a clear trade-off between model complexity and model interpretability, meaning that it is often hard to understand why these sophisticated models perform so well. This lack of explanation constitutes a practical issue \u2013 can I trust the model? (Ribeiro et al., 2016), and a legal issue\u2014those who develop the model can be required by law to explain what the model does to those who are exposed to automated decisions \u2013 GDPR (European Union, 2016). In response, a new line of research has emerged that focuses on helping users to interpret the predictions from advanced machine learning methods.\nExisting work on explaining complex models may be divided into two main categories; global and local explanations. The former tries to describe the model as whole, in terms of which variables/features influenced the general model the most. Two common methods for such an overall explanation is some kind of permutation feature importance or partial dependence plots (Molnar, 2019). Local explanations, on the other hand, tries to identify how the different input variables/features influenced a specific prediction/output from the model, and are often referred to as individual prediction explanation methods. Such explanations are particularly useful for complex models which behave rather different for different feature combinations, meaning that the global explanation is not representative for the local behavior.\nLocal explanation methods may further be divided into two categories: model-specific and model-agnostic (general) explanation methods. In this paper the focus is on the latter. The methods in this category usually try to explain individual predictions by learning simple, interpretable explanations of the model specifically for a given prediction. Three examples are Explanation Vectors (Baehrens et al., 2010), LIME (Local Interpretable Model-agnostic Explanations (Ribeiro et al., 2016) and Shapley values (S\u030ctrumbel & Kononenko, 2010, 2014; Lundberg\n1,2,3Norwegian Computing Center, P.O. Box 114, Blindern, N-0314 Oslo, Norway. E-mail addresses: kjersti.aas@nr.no, martin.jullum@nr.no, anders.loland@nr.no.\n1\nar X\niv :1\n90 3.\n10 46\n4v 3\n[ st\nat .M\nL ]\n6 F\neb 2\n02 0\n& Lee, 2017a). The latter approach, which builds on concepts from cooperative game theory (Shapley, 1953), has a series of desirable theoretical properties (Lundberg & Lee, 2017a).\nThe Shapley value is a method originally invented for assigning payouts to players depending on their contribution towards the total payout. In the explanation setting, the features are the players and the prediction is the total payout. In this framework, the difference between the prediction and the average prediction is perfectly distributed among the features. This property distinguishes Shapley values from other methods like for example LIME, which does not guarantee perfectly distributed effects. It should be noted that LIME and the Shapley values actually explain two different things. For instance, if the prediction to be explained is the probability of person A crashing his car, the sum of the Shapley values for all features is equal to the difference between this prediction and the mean probability of a person crashing his car, where the mean is taken over all persons having a driver license. The sum of the LIME values is also equal to the difference between this prediction and a mean probability, but here the mean is taken over all persons \u201csimilar to\u201d person A. That is, Shapley values explain the difference between the prediction and the global average prediction, while LIME explains the difference between the prediction and a local average prediction. Appropriate model explanations should be consistent with how humans understand that model. In their study, Lundberg & Lee (2017a) found a much stronger agreement between human explanations and Shapley values than with LIME.\nShapley values have also been used for measuring global feature importance. For instance, it has been used to partition the R2 quantity among the d features in a linear regression model (\u201cShapley regression values\u201d), both assuming independent features (Owen, 2014), and more recently also for dependent features (Song et al., 2016; Owen & Prieur, 2017).\nThe main disadvantage of the Shapley value is that the computational time grows exponentially and becomes intractable for more than say ten features. This has led to approximations like the Shapley Sampling Values (S\u030ctrumbel & Kononenko, 2010, 2014) and Kernel SHAP (Lundberg & Lee, 2017a). The latter requires less computational power to obtain a similar approximation accuracy. Hence, in this paper, the focus is on the Kernel SHAP method. While having many desirable properties, this method assumes feature independence. In observational studies and machine learning problems, it is very rare that the features are statistically independent. If there is high degree of dependence/correlation among some or all the features, the resulting explanations might be very wrong. This is the case even if a simple linear model is used. Recently, Lundberg & Lee (2017b) have proposed a method based on Shapley Values denoted Tree SHAP, which is said to assume \u201cless\u201d feature independence in the sense that it accounts for some of the dependence, but not all. As we be apparent from our simulations experiments, this method does not deliver in terms of accuracy, being potentially highly inaccurate when the features are dependent. Moreover, it is not universally applicable, but specially designed for tree ensemble methods like XGBoost (Chen & Guestrin, 2016).\nIn this paper, we extend the Kernel SHAP method to handle dependent features, using some of the ideas from the latter. To the best of our knowledge, there has been no previous research on what dependency between the features means for the Shapley values in the explanation setting, nor a suggestion on how to handle such dependence. Hence, we regard this paper to be the first to account for dependence within Shapley value based individual prediction explanation. Moreover, we propose a method for clustering Shapley values corresponding to dependent features, improving the presentation of feature contribution for individual predictions in the presence of feature dependence. Our methodology has been implemented in an R-package currently available at: https://github.com/NorskRegnesentral/shapr.\nThe rest of this paper is organized as follows. Section 2 reviews the Shapley values and the Kernel SHAP method. In Section 3 we describe our proposed approaches for capturing dependence, while Section 4 gives the results from several experiments validating these methods. An approach for clustering of Shapley values corresponding to feature dependence is described in Section 5 and, finally, Section 6 contains some concluding remarks."
    },
    {
      "heading": "2. The exact Shapley value and the Kernel SHAP approximation",
      "text": "In this section we first give the definition of the Shapley Value from game theory in Section 2.1, explain its use in the context of explaining individual predictions in Section 2.2, and then we describe the Kernel SHAP method in Section 2.3.\n2.1. The exact Shapley value and cooperative game theory. Consider a cooperative game with M players aiming at maximizing a payoff, and let S \u2286 M = {1, . . . ,M} be a subset consisting of |S| players. Assume that we have a \u201ccontribution\u201d function v(S) that maps subsets of players to the real numbers, called the worth or contribution of coalition S. It describes the total expected sum of payoffs the members of S can obtain by cooperation. The Shapley value (Shapley, 1953) is one way to distribute the total gains to the players, assuming that they all collaborate. It is a \u201dfair\u201d distribution in the sense that it is the only distribution with certain desirable properties listed below. According to the Shapley value, the amount that player j gets is\n(1) \u03c6j(v) = \u03c6j = \u2211\nS\u2286M\\{j}\n|S|!(M \u2212 |S| \u2212 1)! M ! (v(S \u222a {j})\u2212 v(S)), j = 1, . . . ,M,\nthat is, a weighted mean over all subsets S of players not containing player j. Note that the empty set S = \u2205 is also part of this sum. The formula can be interpreted as follows: Imagine the coalition being formed for one player at a time, with each player demanding their contribution v(S \u222a {j}) \u2212 v(S) as a fair compensation. Then, for each player, compute the average of this contribution over all possible combinations in which the coalition can be formed, yielding a weighted mean.\nTo illustrate the application of (1), let us consider a game with three players such that M = {1, 2, 3}. Then, there are 8 possible subsets; \u2205, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, and {1, 2, 3}. Using (1), the Shapley values for the three players are given by\n\u03c61 = 13 ( v({1,2,3})\u2212v({2,3}) ) + 1 6 ( v({1,2})\u2212v({2}) ) + 1 6 ( v({1,3})\u2212v({3}) ) + 1 3 ( v({1})\u2212v(\u2205) ) ,\n\u03c62 = 13 ( v({1,2,3})\u2212v({1,3}) ) + 1 6 ( v({1,2})\u2212v({1}) ) + 1 6 ( v({2,3})\u2212v({3}) ) + 1 3 ( v({2})\u2212v(\u2205) ) ,\n\u03c63 = 13 ( v({1,2,3})\u2212v({1,2}) ) + 1 6 ( v({1,3})\u2212v({1}) ) + 1 6 ( v({2,3})\u2212v({2}) ) + 1 3 ( v({3})\u2212v(\u2205) ) .\nLet us also define the non-distributed gain \u03c60 = v(\u2205), that is, the fixed payoff which is not associated to the actions of any of the players, although this is often zero for coalition games.\nBy summarizing the right hand sides above, we easily see that they add up to the total worth of the game: \u03c60 + \u03c61 + \u03c62 + \u03c63 = v({1, 2, 3}).\nThe Shapley value has the following desirable properties\nEfficiency:: The total gain is distributed:\nM\u2211 j=0 \u03c6j = v(M)\nSymmetry:: If i and j are two players who contribute equally to all possible coalitions, i,e.\nv(S \u222a {i}) = v(S \u222a {j}) for every subset S which contains neither i nor j, then their Shapley values are identical:\n\u03c6i = \u03c6j .\nDummy player:: If v(S \u222a {j}) = v(S) for a player j and all coalitions S \u2286 M \\ {j}, then \u03c6j = 0. Linearity:: If two coalition games described by gain functions v and w are combined, then the distributed gains correspond to the gains derived from v and the gains derived from w:\n\u03c6i(v + w) = \u03c6i(v) + \u03c6i(w),\nfor every i. Also, for any real number a we have that\n\u03c6i(a v) = a\u03c6i(v).\nThe Shapley values is the only set of values satisfying the above properties, see Shapley (1953) and Young (1985) for proofs.\n2.2. Shapley values for prediction explanation. Consider a classical machine learning scenario where a training set {yi,xi}i=1,...,ntrain of size ntrain has been used to train a predictive model f(x) attempting to resemble a response value y as closely as possible. Assume now that we want to explain the prediction from the model f(x\u2217), for a specific feature vector x = x\u2217. S\u030ctrumbel & Kononenko (2010, 2014) and Lundberg & Lee (2017a) suggest to do this using Shapley values. By moving from game theory to decomposing an individual prediction into feature contributions, the single prediction takes the place of the payout, and the features take the place of the players. We have that the prediction f(x\u2217) is decomposed as follows\nf(x\u2217) = \u03c60 + M\u2211 j=1 \u03c6\u2217j ,\nwhere \u03c60 = E[f(x)] and \u03c6 \u2217 j is the \u03c6j for the prediction x = x \u2217. That is, the Shapley values explain the difference between the prediction y\u2217 = f(x\u2217) and the global average prediction. A model of this form is an additive feature attribution method, and it is the only additive feature attribution method that adhers to the properties listed in Section 2.1 (Lundberg & Lee, 2017a). In Appendix A we discuss why these properties are useful in the prediction explanation setting. Note that LIME, another well-known additive feature attribution method, does not satisfy the four properties, which may lead to inconsistent explanations.\nTo be able to compute the Shapley values in the prediction explanation setting, we need to define the contribution function v(S) for a certain subset S. This function should resemble the value of f(x\u2217) when we only know the value of the subset S of these features. To quantify this, we follow Lundberg & Lee (2017a) and use the expected output of the predictive model, conditional on the feature values xS = x \u2217 S of this subset: (2) v(S) = E[f(x)|xS = x\u2217S ].\nOther measures, such as the conditional median, may also be appropriate. However, the conditional expectation summarises the whole probability distribution and it is the most common estimator in prediction applications. When viewed as a prediction for f(x\u2217), it is also the minimiser of the commonly used squared error loss function.\nIf the predictive model is a linear regression model f(x) = \u03b20+ \u2211M j=1 \u03b2j xj , where all features xj , j = 1, . . . ,M are independent, we show in Appendix B that under (2), the Shapley values take the simple form: (3) \u03c60 = \u03b20 + M\u2211 j=1 \u03b2jE[xj ], and \u03c6j = \u03b2j (x \u2217 j \u2212 E[xj ]), j = 1, . . . ,M.\nNote, that for ease of notation, we have here and in the rest of the paper dropped the superscript * for the \u03c6j values. Every prediction f(x\n\u2217) to be explained will result in different sets of \u03c6j values.\nTo the best of our knowledge, no explicit formula like (3) exists for the general case of dependent features with non-linear models. With M features, the number of possible subsets involved in (1) is 2M . Hence, the number of possible subsets increases exponentially when M increases, meaning that the exact solution to this problem becomes computationally intractable when we have more than a few features. In Section 2.3, we shall see how a clever approximation method may be used to (partly) overcome this issue.\nIn addition to a computationally tractable approximation for computing the Shapley values, applying the above method in practice requires an estimate of the expectation in (2) for all xS . The main methodological contribution of this paper is describing, developing, and comparing methodology to appropriately estimate these expectations. In Section 2.3.2 we describe the state-of-art method for determining the expectations before we describe our proposed approaches in Section 3.\n2.3. Kernel SHAP. The Kernel SHAP method of Lundberg & Lee (2017a) aims at estimating Shapley values under (2) in practical situations. The method may be divided in two separate parts:\n(i) A clever computationally tractable approximation for computing the Shapley values of (1) (ii) A simple method for estimating v(S) In Lundberg & Lee (2017a), the method is presented in a somewhat limited form without full detail. In order to facilitate the understanding of the method and our consecutive improvements to the method, we shall therefore in this section carefully re-state the Kernel SHAP method. We will first present part i), assuming v(S) is known, and then present the method for estimating v(S) used by Kernel SHAP.\n2.3.1. Approximated weighted least squares. There are several alternative equivalent formulas for the Shapley values. Charnes et al. (1988) and later Lundberg & Lee (2017a) define the Shapley values as the optimal solution of a certain weighted least squares (WLS) problem.\nIn its simplest form, the WLS problem can be stated as the problem of minimizing (4) \u2211 S\u2286M (v(S)\u2212 (\u03c60 + \u2211 j\u2208S \u03c6j)) 2k(M,S),\nwith respect to \u03c60, . . . , \u03c6M , where k(M,S) = (M \u2212 1)/( ( M |S| ) |S| (M \u2212 |S|)), are denoted the Shapley kernel weights. Let us write Z for the 2M \u00d7 (M + 1) binary matrix representing all possible combinations of inclusion/exclusion of the M features, where the first column is 1 for every row, while entry j+1 of row l is 1 if feature j is included in combination l, and 0 otherwise. Let also v be a vector containing v(S), and W be the 2M \u00d7 2M diagonal matrix containing k(M, |S|), where S in both cases resembles the feature combinations of the corresponding row in Z. Then (4) may be rewritten to\n(5) (v \u2212Z\u03c6)TW (v \u2212Z\u03c6), for which the solution is\n(6) \u03c6 = ( ZTWZ )\u22121 ZTWv.\nIn practice, the infinite Shapley kernel weights k(M,M) = k(M, 0) = \u221e may be set to a large constant C, for example C = 106, or imposing the constraints that \u03c60 = v(\u2205) and\u2211M\nj=0 \u03c6j = v(M) into the problem. When the model contains more than a few features M , computing the right hand side of (6) is still computationally expensive. However, the trick is to use the weighted least squares formulation to approximate (6). The Shapley kernel weights have very different sizes, meaning that the majority of the subsets S, that is, the rows in Z, contributes very little to the Shapley value. Hence, assuming that we have an proper approximation for the elements in v, a consistent approximation may be obtained by sampling (with replacement) a subset D of M from a probability distribution following the Shapley weighting kernel, and using only those rows ZD of Z and elements vD of v in the computation. As the Shapley kernel weights are used in the sampling, the sampled subsets are weighted equally in the new least squares problem. Note that S = \u2205 and S = M are excluded from the sampling procedure. As above, their corresponding Z-rows are appended to ZD, their v(S)-elements are appended to vD, and the diagonal matrix WD is extended with two diagonal elements equal to C. This procedure gives the following approximation to (6):1\n(7) \u03c6 = [( ZTDWDZD )\u22121 ZTDWD ] vD = RDvD.\nA practical consequence of using (7) as opposed to (1) is that when explaining several predictions, which typically is the case, the matrix operations producing the (M + 1) \u00d7 |D| matrix\n1The bulk of information regarding the approximation of the WLS problem was obtained through personal communication with Scott Lundberg.\nRD only has to be carried out once. All that is needed to explain different predictions from the same model (provided vD is pre-computed) is to perform the matrix multiplication of RD and vD for the different vD.\n2.3.2. Estimating the contribution function under feature independence. When computing the vector v, we need the v(S) values for all possible feature subsets represented by the matrix Z. As stated in Section 2.1, the contribution value v(S) for a certain subset S is defined as\nv(S) = E[f(x)|xS = x\u2217S ].\nLet S\u0304 denote the complement of S, such that xS\u0304 is the part of x not in xS . Then, the expected value may be computed as follows\nE[f(x)|xS = x\u2217S ] = E[f(xS\u0304 ,xS)|xS = x\u2217S ] = \u222b f(xS\u0304 ,x \u2217 S) p(xS\u0304 |xS = x\u2217S)dxS\u0304 ,(8)\nwhere p(xS\u0304 |xS = x\u2217S) is the conditional distribution of xS\u0304 given xS = x\u2217S . Hence, to be able to compute the exact v(S) values we need the conditional distribution p(xS\u0304 |xS = x\u2217S), which seldom is known. In this step of the procedure, the Kernel SHAP method assumes feature independence, replacing p(xS\u0304 |xS) by p(xS\u0304). Using the training set, that is, the data used to train the model f(\u00b7), as the empirical distribution of x, the integral in (8) can be approximated by\n(9) vKerSHAP(S) = 1\nK K\u2211 k=1 f(xkS\u0304 ,x \u2217 S),\nwhere xkS\u0304 , k = 1, . . . ,K are samples from the training data. Due to the independence assumption, they are sampled independently of xS ."
    },
    {
      "heading": "3. Incorporating dependence into the Kernel SHAP method",
      "text": "If the features in a given model are highly dependent, the Kernel SHAP method may give a completely wrong answer. As stated in Section 1, it is very rare that features in real datasets are statistically independent. The only place in the Kernel SHAP method where the independence assumption p(xS\u0304 |xS) = p(xS\u0304) is used, is when approximating the integral in (8). Apart from this rough assumption, the Kernel SHAP framework stands out as a clever and fruitful way to approximate the Shapley values. It would therefore be desirable to incorporate dependence into the Kernel SHAP method by relaxing the independence assumption. This can be done by estimating/approximating p(xS\u0304 |xS = x\u2217S) directly and generate samples from this distribution, instead of generating them independently from xS as in Section 2.3.2. We propose four approaches for estimating p(xS\u0304 |xS = x\u2217S); (i) assuming a Gaussian distribution for p(x), (ii) assuming a Gaussian copula distribution for p(x), (iii) approximating p(xS\u0304 |xS = x\u2217S) by an empirical (conditional) distribution and (iv) a combination of the empirical approach and either the Gaussian or the Gaussian copula approach.\n3.1. Multivariate Gaussian distribution. If we assume that the feature vector x stems from a multivariate Gaussian distribution with some mean vector \u00b5 and covariance matrix \u03a3, the conditional distribution p(xS\u0304 |xS = x\u2217S) is also multivariate Gaussian. In particular, writing p(x) = p(xS ,xS\u0304) = NM (\u00b5,\u03a3) with \u00b5 = (\u00b5S ,\u00b5S\u0304) > and\n\u03a3 = [ \u03a3SS \u03a3SS\u0304 \u03a3S\u0304S \u03a3S\u0304S\u0304 ] ,\ngives p(xS\u0304 |xS = x\u2217S) = N|S\u0304|(\u00b5S\u0304|S ,\u03a3S\u0304|S), with\n(10) \u00b5S\u0304|S = \u00b5S\u0304 + \u03a3S\u0304S \u03a3 \u22121 SS(x \u2217 S \u2212 \u00b5S)\nand\n(11) \u03a3S\u0304|S = \u03a3S\u0304S\u0304 \u2212\u03a3S\u0304S \u03a3\u22121SS\u03a3SS\u0304 .\nHence, instead of sampling from the marginal distribution of xS\u0304 , we can sample from the Gaussian distribution with expectation vector and covariance matrix given by (10) and (11), where the full expectation vector \u00b5 and the full covariance matrix \u03a3 are estimated by the sample mean and covariance matrix of the training data, respectively. Using the samples xkS\u0304 , k = 1, . . . ,K from the conditional distribution, the integral in (8) is finally approximated by (9).\n3.2. Gaussian copula. When the features are far from multivariate Gaussian distributed, one may instead represent the marginals by their empirical distributions, and model the dependence structure by a Gaussian copula. The definition of a d-dimensional copula is a multivariate distribution, C, with uniformly distributed marginals U(0,1) on [0,1]. Sklar\u2019s theorem (Sklar, 1959) states that every multivariate distribution F with marginals F1, F2,. . . ,Fd can be written as\n(12) F (x1, . . . , xd) = C(F1(x1), F2(x2), ...., Fd(xd)),\nfor some appropriate d-dimensional copula C. In fact, the copula from (12) has the expression\nC(u1, . . . , ud) = F (F \u22121 1 (u1), F \u22121 2 (u2), . . . , F \u22121 d (ud)),\nwhere the F\u22121j s are the inverse distribution functions of the marginals. While other copulas may be used, the Gaussian copula has the benefit that we may use the analytical expressions for the conditionals in (10) and (11).\nAssuming a Gaussian copula, we may thus use the following procedure for generating samples from p(xS\u0304 |xS = x\u2217S):\n\u2022 Convert each marginal Xj of the feature distribution X to a Gaussian feature Vj by Vj = \u03a6\n\u22121(F\u0302j(Xj)), where F\u0302j is the empirical distribution function of marginal j. \u2022 Assume that V is distributed according to a multivariate Gaussian2, and sample from\nthe conditional distribution p(vS\u0304 |vS = v\u2217S) using the method described in Section 3.1. \u2022 Convert the margins Vj in the conditional distribution to the original distribution using X\u0302j = F\u0302 \u22121 j (\u03a6(Vj)).\nWith a series of samples generated as described above, the integral in (8) is finally approximated by (9).\n3.3. Empirical conditional distribution. If both the dependence structure and the marginal distributions of x are very far from the Gaussian, neither of the two aforementioned methods will work very well. For such situations, we propose a non-parametric approach. The classical method for non-parametric density estimation is the kernel estimator (Rosenblatt, 1956), which in the decades following its introduction has been refined and developed in many directions, see for example Holmes et al. (2010); Bertin et al. (2016); Izbicki & B. Lee (2017). However, the kernel estimator suffers greatly from the curse of dimensionality, which quickly inhibits its use in multivariate problems. Moreover, very few methods exist for the non-parametric estimation of conditional densities, especially when either xS or xS\u0304 are not one-dimensional. Finally, most kernel estimation approaches gives a non-parametric density estimate, only, while we need to be able to generate samples from the estimated distribution.\nHence, we have developed an empirical conditional approach, inspired by the NadarayaWatson estimator (Bierens, 1994), to sample approximately from p(xS\u0304 |x\u2217S). The method, which is motivated by the idea that samples (xS\u0304 ,xS) with xS close to x \u2217 S are informative about the conditional distribution p(xS\u0304 |x\u2217S), consists of the following steps: (1) Compute the distance between the instance x\u2217 to be explained and all training instances\nxi, i = 1, . . . , ntrain. The distance between x \u2217 and instance i is computed as\n(13) DS(x \u2217,xi) =\n\u221a (x\u2217S \u2212 xiS)T\u03a3 \u22121 S (x \u2217 S \u2212 xiS)\n|S| ,\n2The quality of this assumption will depend on how close the Gaussian copula is to the true copula.\nwhere \u03a3S is the sample covariance matrix for the ntrain instances of xS . That is, when we compute the distance we only use the elements in the subset S. (13) may be viewed as a scaled version of the Mahalanobis distance (Mahalanobis, 1936). (2) Compute weights for all training instances xi, i = 1, . . . , ntrain from the distances similarly to a Gaussian distribution kernel:\nwS(x \u2217,xi) = exp ( \u2212DS(x \u2217,xi)2\n2\u03c32\n) ,\nwhere \u03c3 may be viewed as a smoothing parameter or bandwidth that needs to be specified. (3) Sort the weights wS(x \u2217,xi) in increasing order, and let x[k] be the training instance\ncorresponding to the kth largest weight. (4) Approximate the integral in (8) with a weighted version of (9):\nvcondKerSHAP(S) = \u2211K k=1wS(x \u2217,x[k])f(x [k] S\u0304 ,x \u2217 S)\u2211K\nk=1wS(x \u2217,x[k])\n.\nNote that we could have used (9), with the xkS\u0304 sampled (with replacement) from the training data with weights wS(x i), i = 1, . . . , ntrain. Our approach is, however, more sampling effective as it uses each training observation only once, and uses their weights in the integral computation, rather than as input for the sampling only.\nThe number of samples K to be used in the approximate prediction in step 4 can for instance be chosen such that most of the total sum of weights is accounted for by the K largest weights:\nK = min L\u2208N\n{\u2211L k=1wS(x\n\u2217,x[k])\u2211ntrain i=1 wS(x \u2217,xi) > \u03b7\n} ,(14)\nwhere \u03b7 is set to for instance 0.9. If K in (14) exceeds a certain limit, for instance 5,000, it might be set to that limit.\nEssentially all kernel based estimation procedures (such as kernel density estimation) requires selection of one or more bandwidth parameters. Our method is no exception. The choice of the bandwidth parameter \u03c3 may be viewed as a bias-variance trade-off. A small \u03c3 puts most of the weight to a few of the closest training observations and thereby gives low bias, but high variance. A large \u03c3 spreads the weight to a higher number of (more distant) training observations and thereby gives high bias, but low variance. Typically, when the features are highly dependent, a small \u03c3 is needed such that the bias does not dominate. When the features are essentially independent, there is no bias and a larger \u03c3 is preferable. As \u03c3 \u2192\u221e our method approximates the original Kernel SHAP method in Section 2.3.2.\nBy viewing the estimation of E[f(x)|xS = x\u2217S ] as a regression problem with response f(xiS\u0304 ,x \u2217 S) and covariates x i S , i = 1, . . . , ntrain, it turns out that our empirical conditional distribution approach (with K = ntrain) is equivalent to the Nadaraya-Watson estimator (Bierens, 1994). Hurvich et al. (1998) have developed a small-sample-size corrected version of Akaike information criterion (AICc) to select bandwidth parameters in such nonparametric regression problems. The connection to the Nadaraya-Watson estimator allows us to apply the AICc directly to select \u03c3.\nThe strategy used in AICc to find a suitable smoothing parameter is to choose the \u03c3 which is the minimizer of\nAICc = log(\u03c4\u03022) + \u03a6(H),(15)\nwhere\n\u03c4\u03022 = 1\nntrain ntrain\u2211 i=1 ( f(xiS\u0304 ,x \u2217 S)\u2212 \u2211ntrain j=1 wS(x j ,xi)f(xjS\u0304 ,x \u2217 S)\u2211ntrain j=1 wS(x j ,xi) )2 ,\nand\n\u03a6(H) = 1 + tr(H)/ntrain\n1\u2212 (tr(H) + 2)/2 .\nHere H is the ntrain \u00d7 ntrain matrix with indexes\nHi,j = wS(x j ,xi)\u2211ntrain l=1 wS(x l,xi)\ncommonly called the smoother or hat matrix. Thus, to select \u03c3 we compute the AICc in (15) for various \u03c3 values and select the \u03c3 corresponding to the smallest AICc value. This should be done for all subsets S and every new observation x\u2217 to be explained, meaning that it is a computationally intensive approach. To reduce the computational burden, we have experimented with different approximations, and ended up with one where \u03c3 is assumed to have the same value for all subsets S of the same size |S|. In this approach, which is denoted the approximate AICc method in Section 4, the sum of the AICc values for all subsets of the same size is minimized instead of the AICc values for each subset.\nEven the approximate AICc method is quite time consuming. Hence, in Section 4 we have also experimented with a fixed \u03c3 = 0.1 for all subsets S.\n3.4. A combined approach. When performing the experiments to be described in Section 4, it turned out that the empirical conditional distribution method works very well if the dimension of xS \u2264 D\u2217, where D\u2217 is a small number, while it is outperformed by the multivariate Gaussian method and the Gaussian copula method if we condition on more features. This is in accordance with previous literature, see for instance Izbicki & Lee (2017) and references therein. Very few papers attempt to estimate f(z|x) when x has more than D = 3 dimensions, even if z is onedimensional. In higher dimensions, the previously proposed methods typically rely on a prior dimension reduction step, which can result in significant loss of information. Hence, it might be wise to combine the empirical approach with either the multivariate Gaussian or the Gaussian copula approach, simulating the conditional distributions for which dim(xS) \u2264 D\u2217 using the empirical method, and all other conditional distributions using the parametric method. In this combined approach we at least partly avoid the curse of dimensionality, since the empirical approach is used only when conditioning on a few features and the conditional distributions can be analytically computed for the Gaussian approach. To determine D\u2217, one may use for instance cross validation. In our experiments we have, however, determined D\u2217 using an ad-hoc procedure."
    },
    {
      "heading": "4. Experiments",
      "text": "A problem with evaluating prediction explanation methods is that there generally is no ground truth. Hence, to verify that our approaches are more accurate than the original Kernel SHAP method described in Section 2.3.2 when we have dependent features, we have to turn to simulated data for which we may compute the true Shapley values.\nAs computing the exact Shapley values for a single prediction requires solving O(2M ) integrals of the type in (8), which are of dimension 1 to M \u2212 1, we cannot perform accurate experiments in high dimensional settings. We will however perform experiments in a low dimensional (M = 3) and moderate dimensional (M = 10) setting, using various multivariate distributions for the features x, sampling models for y|x, and forms of the predictive model f(). The experiments with M = 3 and M = 10 are treated in Sections 4.2 and 4.3, respectively. Due to the low/moderate dimension of the features in these experiments, it is computationally tractable to use the exact version of Kernel SHAP in (6). Hence, we do not have to turn to the approximation in (7).\nAs the AICc dependent approximation methods are directly dependent on the sampled training set, we run the experiments in 10 batches. In each batch, we sample a new training set of size ntrain = 2, 000, and use the model fitted to those training data to explain predictions in a test set of size 100. These means that the quality of the conditional expectation approximations is measured based on a total of ntest = 10\u00b7100 = 1, 000 test observations. Sampling new training data for each batch also reduces the influence of the exact form of the fitted predictive model, compared to using a single training set across all simulations.\nThe Shapley value approximations we compare with the original Kernel SHAP method (original) are:\n\u2022 The Kernel SHAP with the Gaussian conditional distribution (Gaussian) \u2022 The Kernel SHAP with the Gaussian copula and empirical margins (copula) \u2022 The Kernel SHAP with the empirical conditional distribution determining \u03c3 with exact\nAICc (empirical-AICc-exact) \u2022 The Kernel SHAP with the empirical conditional distribution determining \u03c3 with ap-\nproximate AICc (empirical-AICc-approx) \u2022 The Kernel SHAP with the empirical conditional distribution setting \u03c3 = 0.1 for all\nconditional distributions (empirical-0.1) \u2022 The Kernel SHAP with the combined approach using the empirical approach for subsets\nwith dimension \u2264 3 and the Gaussian approach otherwise (empirical-0.1+Gaussian and empirical-AICc-approx+Gaussian) \u2022 The Kernel SHAP with the combined approach using the empirical approach for subsets\nwith dimension \u2264 3 and the copula approach otherwise (empirical-0.1+copula and empirical-AICc-approx+copula)\nDue to computational complexity, the empirical-AICc-exact method is only used in the 3 dimensional experiments. Furthermore, the combined approaches are only used in the 10 dimensional experiments. For the experiments where XGBoost is used to fit the predictive model, we will also include the so-called TreeSHAP method (Lundberg & Lee, 2017b) in the comparison.\n4.1. Evaluation measures. To quantify the accuracy of the different methods, we rely on the mean absolute error (MAE) of the Shapley value approximations, averaged over all features and all test samples, that is\nMAE(method q) = 1\nMntest M\u2211 j=1 ntest\u2211 i=1 |\u03c6(i)j,true \u2212 \u03c6 (i) j,q|,\nwhere \u03c6 (i) j,q denotes the Shapley value of feature j, for prediction i, and computed with approximation method q, while \u03c6 (i) j,true is the corresponding true value. In order to determine the superiority of the various proposed methods over the original Kernel SHAP method, we rely on the so-called skill score (Gneiting & Raftery, 2007) associated with the aforementioned MAE. The skill score for method q takes the form\nSkill(MAE, method q) = MAE(method q)\u2212MAE(original) MAE(optimal)\u2212MAE(original) = 1\u2212 MAE(method q) MAE(original) ,\nwhere MAE(optimal) is the MAE of an optimal method, being equal to zero. The skill score measures the superiority of a method compared to the reference method (here the original Kernel SHAP). It is standardized in such a way that it takes the value 1 for a perfect approximation and 0 for the reference method. When the approximation method is worse than the reference method, the skill score becomes negative.\nTo compare the methods on equal terms, all methods are restricted to use K = 1000 samples from the training set for each feature combination and test observation.\n4.2. Dimension 3. For the three dimensional setting, we will use two different sampling models for y|x (linear and piecewise constant), and combine these with three different multivariate distributions for the features x (Gaussian, Generalized Hyperbolic distribution and Gaussian mixture), such that we get a total of six experimental setups A-F. In Sections 4.2.1\u20144.2.3 we describe the multivariate feature distributions, while the sampling models are discussed in Sections 4.2.4 and 4.2.5. Finally, Section 4.2.6 contains the results.\nThe noise term \u03b5i is common for all experients and assumed to follow the distribution \u03b5i d. = \u03b5 \u223c N(0, 0.12). Due to the low dimension, the exact Shapley value in (8) can be computed using numerical integration.\n4.2.1. Gaussian distributed features. The first feature distribution p(x) we shall consider is a multivariate Gaussian distribution p(x) = N3(0,\u03a3(\u03c1)), where the covariance matrix \u03a3(\u03c1) takes the form\n\u03a3(\u03c1) = 1 \u03c1 \u03c1\u03c1 1 \u03c1 \u03c1 \u03c1 1  .(16) In the various experiments, the correlation coefficient \u03c1 varies between 0 and 0.98, representing an increasing positive correlation among the features.\n4.2.2. Skewed and heavy-tailed distributed features. The second feature distribution p(x) to be considered is the Generalized Hyperbolic(GH)-distribution. Following Browne & McNicholas (2015), a random vector X is said to follow a GH-distribution with index parameter \u03bb, concentration parameter \u03c9, location vector \u00b5, dispersion matrix \u03a3, and skewness vector \u03b2, denoted by X \u223c GH(\u03bb, \u03c9,\u00b5,\u03a3,\u03b2), if it can be represented by\nX = \u00b5+W \u03b2 + \u221a W U ,\nwhere W \u223c GIG(\u03bb, \u03c9, \u03c9), U \u223c N(0,\u03a3) and W is independent of U . GIG is the Generalised Inverse Gaussian distribution introduced by Good (1953). Appendix C contains more details on this distribution. We use the following parameter values in our experiments:\n\u03bb = 1\n\u03c9 = 0.5\n\u03a3 = \u03a3(0) = diag(1)\n\u03b2 = (1/4)\u03ba \u2217 1 \u00b5 = 0\u2212 E[W ](1/4)\u03ba,\nwhere the skewness coefficient \u03ba varies from 1 to 10 in different experiments, resulting in an increasingly more skewed, heavy-tailed and positively correlated distribution. E[W ] denotes the mean of the GIG distribution, equal to approximately 4.56 for the above parameter values. The special form of \u00b5 is chosen such that the GH distribution has mean zero.\n4.2.3. Multi-modal distributed features. The last feature distribution is a mixture of two Gaussian distribution with different means. That is,\np(x) = 2\u2211\nk=1\n\u03c0kN(\u00b5k(\u03b3),\u03a3(0.2)),\nwith mixture probabilities \u03c01 = \u03c02 = 0.5 and mean functions \u00b51(\u03bb) = \u2212\u00b52(\u03bb) = \u03b3 \u00b7(1,\u22120.5, 1)>. The covariance matrix \u03a3 is assumed to be on the form in (16). The \u03b3 parameter represents the distance between the two Gaussian distributions, and will range from 0.5 to 10 in the different experiments.\n4.2.4. Linear model. The first sampling model y|x is a simple linear model:\ny = g(x) = x1 + x2 + x3 + \u03b5.\nData from such a distribution will be modelled by fitting the parameters \u03b2j , j = 0, . . . , 3 in the linear model\nf(x) = \u03b20 + \u03b21 x1 + \u03b22 x2 + \u03b23 x3 + \u03b5,\nusing ordinary linear regression.\n4.2.5. Piecewise constant model. The second sampling model y|x is a piecewise constant model constructed by summing three different piecewise constant functions:\ny = g(x) = fun1(x1) + fun2(x2) + fun3(x3) + \u03b5.\nThe functions fun1, fun2, and fun3 are displayed in Figure 1. We fit the model g(x) with the XGBoost framework (Chen & Guestrin, 2016) using default values of all hyperparameters, the histogram tree learning method (tree_method=\"hist\") and 50 boosting iterations.\n4.2.6. Results. The results from the 3D-experiments are visualized in Figures 2\u20147. In experiment A we have used a linear sampling model and Gaussian features. As seen from Figure 2, the original Kernel SHAP method works well when the features are independent, but it is outperformed by all other methods when \u03c1 is greater than 0.05. The Gaussian model generally shows the best performance. It should also be noted that the AICc methods for determining \u03c3 works better than using the fixed value of 0.1.\nIn experiment B, we still have the linear sampling model, but now we have skewed and heavy-tailed features. Like for the previous experiment, the original Kernel SHAP method is outperformed by all other approaches. As shown in Figure 3, when \u03ba increases, the MAE of the copula and Gaussian methods is reduced. This might be due to the increased variance of the features that comes as a by-product of increasing the \u03ba parameter. For this experiment, the empirical approach with a fixed \u03c3 = 0.1 performs uniformly better than those based on AICc.\nIn experiment C, we have the same sampling model, but now with bimodal Gaussian mixture distributed features. Again, all our methods perform uniformly better than the original Kernel SHAP method. Figure 4 further shows that the empirical methods outperform the Gaussian and copula methods, especially when \u03b3 (that is, the distance between the modes of the feature distribution) is large.\nIn experiments D-F we use the same feature distributions as in A-C, but for these experiments we use a piecewise constant model instead of the linear. The results are largely the same as in the linear model case. The original Kernel SHAP method is outperformed by all other approaches. Further the Gaussian model is best when we have Gaussian features, while the empirical approaches are best when the feature distribution is bi-modal. In the case with skewed and heavy-tailed features, the Gaussian and copula methods again seem to be preferable for larger values of \u03ba.\nFor the experiments with the piecewise constant model, we have used the TreeSHAP method in addition to the other ones. As shown in Figures 5-7, the performance of this method is just slightly better than that of the original kernel SHAP method for experiments D and E, and\nworse in experiment F. This is surprising, since the TreeSHAP method is supposed to handle dependence better than the original kernel SHAP method.\nOverall, our 3 dimensional experiments clearly shows that it is important to account for the dependence between the features when computing the Shapley values. Which of the suggested methods that is best, depends on the underlying feature distribution, Further, since the results for our empirical method using the approximate AICc version are fairly similar (and in some cases even better) to those using the slower exact version, we recommend the former.\nResults experiment A Sampling model: Linear, feature distribution: Gaussian, dimension: 3\nResults experiment B Sampling model: Linear, feature distribution: Generalized Hyperbolic, dimension: 3\nResults experiment C Sampling model: Linear, feature distribution: Gaussian mixture, dimension: 3\nResults experiment D Sampling model: Piecewise constant, feature distribution: Gaussian, dimension: 3\nResults experiment E Sampling model: Piecewise constant, feature distribution: Generalized Hyperbolic, dimension: 3\nResults experiment F Sampling model: Piecewise constant, feature distribution: Gaussian mixture, dimension: 3\n4.3. Dimension 10. In the 10 dimensional case we have restricted ourselves to three types of experiments. In the first two, we use Gaussian distributed features on the same form as described for the 3 dimensional case in Section 4.2.1. That is, p(x) = N10(0,\u03a3(\u03c1)), where \u03a3(\u03c1) is the 10 dimensional extension of (16) such that all features have variance 1 and the pairwise correlation between any two features is \u03c1.\nThe first experiment uses a sampling model y|x directly extending the 3 dimensional linear model in Section 4.2.4, that is,\ny = g(x) = 9\u2211 j=1 xj + \u03b5,\nwhere we use the same error term \u03b5i d. = \u03b5 \u223c N(0, 0.12) as in the 3 dimensional experiments. Analogous to the 3 dimensional case, y is modelled by ordinary linear regression\nf(x) = 10\u2211 j=1 \u03b2jxj + \u03b5.\nNote that even though we have 10 features, one of them has no influence on y. The second experiment extends the 3 dimensional experiment described in Section 4.2.5, taking the form\ny = g(x) = \u2211\nj \u2208{1,2,3}\nfun1(xj) + \u2211\nj \u2208{4,5,6}\nfun2(xj) + \u2211\nj \u2208{7,8,9}\nfun3(xj) + \u03b5,\nagain excluding the effect of the 10th feature. As for the 3 dimensional case, the model g(x) is fitted using the XGBoost framework, using the same settings.\nIn the last experiment, we simulate data from a 10 dimensional GH-distribution with the following parameter values\n\u03bb = 1\n\u03c9 = 0.5\n\u00b5 = (3, 3, 3, 3, 3, 3, 3, 3, 3, 3)\n\u03a3 = diag(1, 2, 3, 1, 2, 3, 1, 2, 3, 3)\n\u03b2 = (1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5).\nThe parameter values are chosen as to resemble the feature distribution in our real data example to be described in Section 4.4. As sampling model, we use the piecewise constant model described above.\nWe didn\u2019t use the empirical-AICc-exact approach for any of the 10 dimensional experiments. As previously stated, this approach is computationally intensive. Moreover, the 3 dimensional experiments showed that the performance of the empirical-AICc-exact and the empirical-AICcapprox approaches were very similar. For the 3 dimensional experiment with the Generalized Hyperbolic features and piecewise constant model, the MAE and skill scores for the three empirical approches were almost equal, meaning that it is not necessary to use the significantly more computational heavy AICc approach. Hence, the only empirical approach used in the last experiment was the empirical-0.1 method. In the combined approaches, we use the empirical approach for subsets with dimension \u2264 3, with the bandwidth parameter \u03c3 either determined by the approximate AICc method (in the linear case, only) or fixed to 0.1.\nThe results from the simulation experiments are shown in Figures 8 and 9 and Table 1. While numerical integration was used to compute the exact Shapley values in the 3 dimensional experiments, we have to turn to Monte Carlo integration for the 10 dimensional case. From the figures, we see that the results with Gaussian distributed features in dimension 10 are mostly the same as for the 3 dimensional counterparts in Figures 2 and 3, with the Gaussian method generally showing the best performance. The combined empirical and Gaussian/copula approaches also works well. For the piecewise constant model, the TreeSHAP method behaves\nas in the 3 dimensional case: slightly better than the original kernel SHAP method for small and medium sized dependence, but worse when there is high dependence between the features.\nFor the skewed and heavy-tailed data, Table 1 shows that the empirical-0.1+Gaussian method gives the best performance, having slightly better MAE values and skill scores than the empirical-0.1+copula method. Finally, like for the other experiments, all our suggested approaches outperform the original Kernel SHAP and the TreeSHAP method.\nResults experiment G Sampling model: Linear, feature distribution: Gaussian, dimension: 10\nResults experiment H Sampling model: Piecewise constant, feature distribution: Gaussian, dimension: 10\n4.4. Real data example. In our last example, we use a real data set. The data set consists of 28 features extracted from 6 transaction time series. It has previously been used for predicting mortgage default, relating probability of default to transaction information (Kvamme et al.,\n2018). The transaction information consists of the daily balances on consumers\u2019 credit (kk), checking (br), and savings (sk) accounts, in addition to the daily number of transactions on the checking account (tr), the amount transferred into the checking account (inn), and the sum of the checking, savings, and credit card accounts (sum). For each of these time series, which were of length 365 days, the mean (mean), maximum (max), minimum (min), standard deviation (std), and the standard deviation scaled by the mean (std mean) were computed, resulting in 28 features. These are scaled to have mean 0 and standard deviation 1 before they are used in our computations. Figure 10 shows histograms for nine of the features (the remaining features have similar distributions). The feature distributions are skewed and heavy-tailed. The pairwise rank correlations (measured by Kendall\u2019s \u03c4 , see Section 5.1 for more information) are shown in Figure 11. Most correlations are close to 0, but as can be seen from the figure, there are groups of features with high mutual correlations.\nThe data set was divided into a training set and a test set, containing 12,696 and 1,921 observations respectively. We fitted an XGBoost model with 50 trees to the training data, using default parameter settings. The resulting AUC for the test data was 0.88.\nThe last example in Section 4.3 showed that for the case with skewed and heavy-tailed features and a piecewise constant model, the combined approaches were superior to the other, with the empirical-0.1+Gaussian approach as the best performing method. We assume that this is also the case for the real data set, and compare the performance of this method with the original Kernel SHAP approach. Figure 12 shows plots of Shapley values estimated with the original Kernel SHAP approach against those estimated with the empirical-0.1+Gaussian method for four of the features. For the features inn std mean and sk std mean there is a high degree of correspondence, while for tr std and br max, the Shapley values for the two methods are very different. These results may at least partly be explained by Figure 11. The features inn std mean and sk std mean are almost independent from all other features, while tr std, and especially br max, have a high degree of dependence with many other features. Hence, the original Kernel SHAP method is likely to perform well for inn std mean and sk std mean and poor for tr std and br max."
    },
    {
      "heading": "5. Clustering of Shapley values corresponding to feature dependence",
      "text": "Using any of our suggested Shapley value approximations, the dependencies between features are handled in a proper way. One way to then visually present the explanation of a particular prediction could be to rank the absolute Shapley values and present them and their corresponding features in descending order, for example for the ten most important features. However, if some or many of the features are dependent, a grouping or clustering of dependent features may ease the interpretation and use of the Shapley values.\nAssume that we have many features that are highly correlated, but none of them is among the ten most important features. If presented as a group, however, their combined Shapley value might turn out to be on the top ten list. Even when the individual Shapley values are well approximated, clustering can therefore aid in presenting the model explanation more correctly.\nThis clustering of features can in principle be different for each individual, but that would make model explanations across individuals opaque. We therefore suggest to cluster the features once on 1) the training data, or 2) test data, given that the test data set is large enough for reliable clustering to be done. We are then left with the choice of dependence measure and clustering method. Our preferred choices are not canonical in any sense and other choices may suit your particular application better.\n5.1. Dependence measure. The Pearson correlation coefficient measures the linear correlation. As our Shapley values are not restricted to linear dependence, we suggest to apply a more robust measure of dependence with fewer implicit assumptions, namely the rank correlation, more specifically as measured by Kendall\u2019s \u03c4 (Kendall, 1938). Kendall\u2019s \u03c4 for two random features xj and xk is defined as\nTj,k = 1 n(n\u2212 1) \u2211 i 6=l sign(xij \u2212 xlj) sign(xik \u2212 xlk),\nwhere i, l = 1, . . . n are the samples we use to compute this measure.\n5.2. Clustering method and cluster size. First, we define a dissimilarity matrix, that is distances between pairs of features. Since we would like to group features together that are strongly correlated, regardless of whether this correlation is positive or negative, we define a dissimilarity matrix D having indicies\n(17) Dj,k = 1\u2212 |Tj,k|, j, k = 1, . . . ,M, where |(\u00b7)| denotes the absolute value. Hence, two features that are perfectly correlated will have a dissimilarity value of 0, while a pair of independent features will have a dissimilarity value of 1. We then do hierarchical, agglomerative clustering with the agglomeration method commonly denoted as \u201ccomplete\u201d (Mu\u0308llner, 2013) and D in (17) as dissimilarity matrix. This\nmeans that when merging of two clusters J and K is considered, the cluster dissimilarity is given as\ndJ,K = max j\u2208J,k\u2208K Dj,k.\nFurther, suppose now that J and K are clusters that are joined into a new cluster, and C is a any other cluster. The distance between the joined cluster J \u222aK and cluster C is then defined as\nmax(dJ,C , dK,C).\nThe number of clusters can be chosen either by a user chosen dissimilarity level or some sort of optimal choice of clusters. We used the minimum value of the Kelley-Gardner-Sutcliffe penalty function for a hierarchical cluster tree (Kelley et al., 1996). In the implementation of this method in White & Gramacy (2012), there is an additional tuning parameter \u03b1 with default value equal to 1 that can be used to scale the optimal number of clusters.\n5.3. Real data example continued. Here, we continue with the example from Section 4.4. Using the Kelley-Gardner-Sutcliffe penalty function with \u03b1 = 0.1, the features were clustered into twelve groups, denoted g1, g2, . . . , g12 from left to right in Figure 11. Hence, g1 contains the features tr mean, tr max and tr std and g3 contains br std mean only, etc. Figure 13 shows the combined Shapley values for the twelve groups for two example predictions. In both examples it is apparent from the top panels that the original Kernel SHAP method has a ranking of groups that is very different from the empiricial-0.1+Gaussian method, which we believe is more correct. Further, as indicated by the lower panels, the Shapley values obtained by the original Kernel SHAP method and the empiricial-0.1+Gaussian method are very different for the majority of the groups. Take for instance example 2. For this person, group 12 is considered to be the one providing the highest increase in probability by the empirical0.1+Gaussian approach, while according to the original Kernel SHAP, group 12 is the one reducing the probability the most. This means that the original Kernel SHAP approach give completeley different explanations from our approach, which is regarded to be more trustworthy according to our simulation experiments in Section 4. In real data settings it is crucial to get a correct explanation, as an incorrect explanation may cause wrong conclusions and actions. Hence, it is very important to take the feature dependence into account."
    },
    {
      "heading": "6. Summary and discussion",
      "text": "Shapley values is a model-agnostic method for explaining individual predictions with a solid theoretical foundation. The main disadvantage with this method is that the computational time grows exponentially. This has led to approximations, of which the Kernel SHAP method is the most known. A key ingredient of the Kernel SHAP method is the conditional distribution of a subset S\u0304 of the features, conditional on the features in S that are not in this subset. It\nis assumed that the features in the two subsets are independent, meaning that the conditional distribution may be replaced by the marginal distribution of the features in S\u0304. If there is a high degree of dependence among some or all the features, the resulting explanations might be very wrong. This paper introduces a modified version of the Kernel SHAP method, which handles dependent features. We have proposed four different approaches for estimating the\nconditional distribution; assuming a Gaussian multivariate distribution for all features, assuming a Gaussian copula with empirical margins, using an empirical approach and a combination of the empirical approach and either the Gaussian or the Gaussian copula approach.\nWe have performed a comprehensive simulation study with linear and non-linear models, Gaussian and non-Gaussian distributions, and dimensions 3 and 10, where our methods give more accurate approximations to the true Shapley values than the original Kernel SHAP approach. For the non-linear models, these methods clearly outperformed the Tree SHAP method, which, to the best of our knowledge, is the only Shapley approach which tries to handle dependence between features in the prediction explanation setting. When performing our experiments, it turned out that the non-parametric approach was superior when conditioning on a small number of the features, while it was outperformed by the Gaussian and copula methods if we condition on more variables. Hence, we regard the combined approach to be the most promising of our proposed methods. This approach was applied to a real case with 28 variables, where the predictions to be explained were produced by a XGBoost classifier designed to predict mortgage default. In this case, the true Shapley values are not known. However, we provide results, which indicate that our combined approach provides more sensible approximations than the Tree SHAP and original Kernel SHAP methods.\nIf features are dependent, it is more challenging to interpret the resulting Shapley values. We have therefore proposed a method for aggregating individual Shapley values. Using hierarchical agglomerative clustering of the training data, the features are divided into a number of clusters. Having obtained the individual Kernel SHAP values using one of the approaches above, we compute the sum of these values for each cluster and visually present these sums instead of the individual values.\nWhile having many desirable properties, our method has one obvious drawback: the computational time. The most time-consuming part is the AICc computation of the bandwidth parameter in the non-parametric approach. Using a fixed bandwidth parameter instead, the computational time of the combined approach is the same as that of the original Kernel SHAP method. Very recently, there has been some attempts at using the underlying graph structure of the input data to reduce the computational complexity (Chen et al., 2018; Li et al., 2018). If several conditional independence requirements are satisfied, the full graph may first be divided into separate communities and then the Kernel SHAP method may be applied to each community individually. The methods proposed by Chen et al. (2018); Li et al. (2018) were tested on predictions obtained from text and image classification. In such settings the data often has a graph structure, enabeling factorization into separate communities. The main challenge with using this method for tabular data is the potentially huge number of tests for conditional dependence which has to be performed. However, it is definitely worth a closer look.\nIn this paper, we assume that the aim is to explain the actual predictions from the model. For some models, the prediction is a probability. If the Shapley framework is used to decompose probabilities, summing over a subset of the \u03c6i-values is likely to produce values that are not in the range [0,1]. Hence, in such cases it might be more natural to assume that the importance of features is additive in the log odds space rather than in the space of probabilities. There are however problems even with this solution, since it is not straightforward for a human to interpret a log odds contribution to the probability. Hence, what to decompose seems to be more a practical than a mathematical question.\nTabular data often contain ordered or even non-ordered categorical data. The proposed nonparametric approach may still be used if the categorical variables are converted into numerical ones. The simplest solution is to use one-hot-encoding. However, large data sets often handle categorical features with hundreds of categories, meaning that a such method needs to handle a large number of binary attributes. An alternative approach is to use ideas from the clustering literature (Huang, 1997, 1998) defining distance functions that handle both categorical and mixed-type features. There are also generalizations of the Mahalanobis distance treating data with a mixture of nominal, ordinal and continuous variables that might be used instead of the approach described above, see for instance de Leon & Carriere (2005). When it comes to the parametric approaches, categorical data represents a greater challenge. The most promising\nalternative might be to use entity embedding (Guo & Berkhahn, 2016) to convert the categorical features into numerical ones, and then treat these features similarly to the other numerical features."
    },
    {
      "heading": "Acknowledgement",
      "text": "The authors are grateful to Scott Lundberg for valuable advice concerning the Kernel SHAP method. We also want to thank Ingrid Hob\u00e6k Haff for suggesting the copula approach, Nikolai Sellereite for major contributions to the implementation of the methods in the R-package shapr (https://github.com/NorskRegnesentral/shapr). This work was supported by the Norwegian Research Council grant 237718 (Big Insight)."
    },
    {
      "heading": "Appendix A. Shapley properties in the prediction explanation setting",
      "text": "When using Shapley values for prediction explanation, \u03c60 = v(\u2205) = E[f(x)] actually plays an important role, quantifying how much of a prediction which is not due to any of the features, but merely to the global average prediction. If \u03c60 is large (in absolute value) compared to \u03c6j , j 6= 0, the features are said to be \u2019not important\u2019 for that specific prediction. Moreover, in the prediction explanation setting, the interpretation of the properties of the Shapley value discussed in Section 2.1 are as follows:\nEfficiency:: The sum of the Shapley values for the different features is equal to the difference between the prediction and the global average prediction: \u2211M j=1 \u03c6j = f(x\n\u2217)\u2212 E[f(x)]. This property ensures that the part of the prediction value which is not explained by the global mean prediction, is fully devoted and explained by the features, and that the \u03c6j , j = 1, . . . ,M can be compared across different predictions f(x\n\u2217). Symmetry:: The Shapley values for two features are equal if, when combined with any other\nsubsets of features, they contribute equally to the prediction. Failure to fulfill such a criterion, that is, that the same contribution from two different features does not give the same explanation, would be inconsistent and give untrustworthy explanations.\nDummy player:: A feature that does not change the prediction, no matter which other features it is combined with, has a Shapley value of 0. Assigning a nonzero explanation value to a feature that has no influence on the prediction would be very odd, so this is a natural requirement. Linearity:: When a prediction function consists of a sum prediction functions, the Shapley value for a feature is identical to the sum of that feature\u2019s Shapley values from each of the individual prediction functions. This also holds for linear combinations of prediction functions. This property ensures that models on this form, such as Random Forest or other structurally simple ensemble models, can be explained and interpreted individually.\nFailure to fulfill any of these basic and advantageous properties gives an odd, undesirable or inconsistent explanation framework. There is no other additive explanation method than Shapley values which satisfy all these criteria (Lundberg & Lee, 2017a)."
    },
    {
      "heading": "Appendix B. Shapley values when the model is linear",
      "text": "In this section we first give a proof for the explicit formula for the Shapley values when the predictive model is a linear regression model, and all features are independent. Then, we show how to obtain the contribution function v(S) when the model still is linear, but the features might be dependent.\nB.1. Linear model and independent features. When v(S) = E[f(x)|xS = x\u2217S ], the predictive model is a linear regression model, and all features are independent, then the Shapley values take the simple form\n\u03c6j = \u03b2j (x \u2217 j \u2212 E[xj ]), j = 1, . . . ,M.\nProof: First, we derive the expression for v(S) in this case:\nv(S) = E[f(x)|xS = x\u2217S ]\n= \u222b f(xS\u0304 ,x \u2217 S) p(xS\u0304 |xS = x\u2217S) dxS\u0304 ,(18)\n= \u222b \u2211 i\u2208S\u0304 \u03b2i xi + \u2211 i\u2208S \u03b2i x \u2217 i  p(xS\u0304 |xS = x\u2217S) dxS\u0304(19) = \u2211 i\u2208S\u0304 \u03b2i \u222b xi p(xi) dxi + \u2211 i\u2208S \u03b2i x \u2217 i \u222b p(xS\u0304) dxS\u0304(20)\n= \u2211 i\u2208S\u0304 \u03b2iE[xi] + \u2211 i\u2208S \u03b2i x \u2217 i\nThe transition from step (18) to (19) follows from the assumption of a linear model, while the transition from (19) to (20) follows from the independent features assumption.\nHaving computed v(S), the expression for v(S \u222a {j}) can be simply found as\nv(S \u222a {j}) = v(S) + \u03b2j x\u2217j \u2212 \u03b2j E[xj ],\nmeaning that\nv(S \u222a {j})\u2212 v(S) = \u03b2j ( x\u2217j \u2212 E[xj ] ) .\nFrom the above, we see that in this case, the difference v(S \u222a {j})\u2212 v(S) is independent of S. Hence, the Shapley formula may be written as\n\u03c6j = \u03b2j ( x\u2217j \u2212 E[xj ] ) \u2211 S\u2286M\\{j} |S|!(M \u2212 |S| \u2212 1)! M ! .\nSince the sum of the Shapley weights is 1, we have \u03c6j = \u03b2j ( x\u2217j \u2212 E[xj ] ) ,\nfor j = 1, . . . ,M.\nB.2. Linear model and dependent features. If the model is linear, but the features are not independent, v(S) instead may be derived as follows\nv(S) = E[f(x)|xS = x\u2217S ]\n= \u222b f(xS\u0304 ,x \u2217 S) p(xS\u0304 |xS = x\u2217S) dxS\u0304 ,(21)\n= \u222b \u2211 i\u2208S\u0304 \u03b2i xi + \u2211 i\u2208S \u03b2i x \u2217 i  p(xS\u0304 |xS = x\u2217S) dxS\u0304(22) = \u2211 i\u2208S\u0304 \u03b2i \u222b xi p(xi|xS = x\u2217S) dxi + \u2211 i\u2208S \u03b2i x \u2217 i \u222b p(xS\u0304) dxS\u0304(23)\n= \u2211 i\u2208S\u0304 \u03b2iE[xi|xS = x\u2217S ] + \u2211 i\u2208S \u03b2i x \u2217 i\n= f(xS\u0304 = E[xS\u0304 |xS = x\u2217S ],xS = x\u2217S)(24)\nIn this case, one may therefore avoid time-consuming simulations if one is able to analytically obtain a proper estimate of E[xS\u0304 |xS = x\u2217S ]. This is not straightforward in general."
    },
    {
      "heading": "Appendix C. Generalized Hyperbolic Distribution",
      "text": "The density of a d-dimensional Generalized Hyperbolic random vector X is\np(x) =\n[ \u03c9 + \u03b4(x,\u00b5,\u03a3)\n\u03c9 + \u03b2T\u03a3\u22121\u03b2\n]\u03bb\u2212d/2 2 K\u03bb\u2212d/2 (\u221a (\u03c9 + \u03b4(x,\u00b5,\u03a3))(\u03c9 + \u03b2T\u03a3\u22121\u03b2) ) (2\u03c0)d/2|\u03a3|1/2K\u03bb(\u03c9) exp {\u2212(x\u2212 \u00b5)T\u03a3\u22121\u03b2} ,\nwhere \u03b4(x,\u00b5,\u03a3) = (x \u2212 \u00b5)T\u03a3\u22121(x \u2212 \u00b5) is the squared Mahalanobis distance between x and \u00b5, and K\u03bb is the modified Bessel function of the third kind with index \u03bb. The mean vector and covariance matrix of X are\nE(X) = \u00b5+ E(W )\u03b2 and Var(X) = E(W )\u03a3 + Var(W )\u03b2\u03b2T .\nIt can be shown (Wei et al., 2019) that if X is partitioned as (XT1 ,X T 2 ) T , where X1 is d1dimensional and X2 is d2-dimensional, the conditional distribution of X2 given that X1 = x1 is Generalized Hyperbolic distributed, that is,X2|X1 = x1 \u223c GH\u2217(\u03bb2|1, \u03c72|1, \u03c82|1,\u00b52|1,\u03a32|1,\u03b22|1), where\n\u03bb2|1 = \u03bb\u2212 d1/2, \u00b52|1 = \u00b52 + \u03a3T12\u03a3\u2212111 (x1 \u2212 \u00b51), \u03c72|1 = \u03c9 + (x1 \u2212 \u00b51)T\u03a3\u2212111 (x1 \u2212 \u00b51), \u03a32|1 = \u03a322 \u2212\u03a3 T 12\u03a3 \u22121 11 \u03a312, \u03c82|1 = \u03c9 + \u03b2 T 1 \u03a3 T 11\u03b21, \u03b22|1 = \u03b22 \u2212\u03a3T12\u03a3\u2212111 \u03b21.\nNote that GH* means that a slightly different parameterization of the GH distribution is used for the conditional distribution. Here, due to technical reasons, we use the parameterization proposed by McNeil et al. (2006):\np(x) =\n[ \u03c7+ \u03b4(x,\u00b5,\u03a3)\n\u03c8 + \u03b2T\u03a3\u22121\u03b2\n]\u03bb\u2212d/2 2 (\u03c8/\u03c7) \u03bb/2K\u03bb\u2212d/2 (\u221a (\u03c7+ \u03b4(x,\u00b5,\u03a3))(\u03c8 + \u03b2T\u03a3\u22121\u03b2) ) (2\u03c0)d/2|\u03a3|1/2K\u03bb( \u221a \u03c7\u03c8) exp {\u2212(x\u2212 \u00b5)T\u03a3\u22121\u03b2} ."
    }
  ],
  "title": "EXPLAINING INDIVIDUAL PREDICTIONS WHEN FEATURES ARE DEPENDENT: MORE ACCURATE APPROXIMATIONS TO SHAPLEY VALUES",
  "year": 2020
}
