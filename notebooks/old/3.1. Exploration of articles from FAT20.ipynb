{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mair import papers_processing_utils\n",
    "import mair\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy.lang.en\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import gensim.summarization\n",
    "from pprint import pprint\n",
    "import pyLDAvis\n",
    "from gensim.models import ldamodel\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "PICKLED_PATH = \"parserd_pdfs.pkl\"\n",
    "PDFS_PATH = \"../data/FAT_20/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PICKLED_PATH):\n",
    "    pdfs = mair.pdf_parsing.parse_all_files_from_path()\n",
    "    with open(PICKLED_PATH, \"wb+\") as f:\n",
    "        pickle.dump(pdfs, f)\n",
    "else:\n",
    "    with open(PICKLED_PATH, \"rb\") as f:\n",
    "        pdfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pdfs)\n",
    "df['pages_num']=df.pages.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pages_num.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing papers with only one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.pages_num!=1]\n",
    "df.pages_num.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing references and bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    position = text.lower().rfind(\"references\")\n",
    "    text = text[:position]  # removing bibliography\n",
    "    text = text.replace(\"\\n\", \" \")  # removing newlines\n",
    "    text = re.sub(\"\\[[^\\[^\\]]*\\]\", \"\", text)  # removing references\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df.full_text.apply(papers_processing_utils.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en=spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.lang.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df.cleaned_text.apply(lambda x: en(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = tokenized.apply(\n",
    "    lambda doc: \n",
    "        [word.lemma_.lower() for word in doc if not word.is_stop if word.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemas = []\n",
    "for l in lemmas:\n",
    "    all_lemas+=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = nltk.FreqDist(all_lemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "unigrams.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lemmas = lemmas.apply(dictionary.doc2bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(list(bow_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_lemmas], num_features=12)\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = lemmas.apply(\" \".join).apply(gensim.summarization.keywords).str.split('\\n')\n",
    "\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = []\n",
    "for k in keywords:\n",
    "    all_keywords+=k\n",
    "\n",
    "nltk.FreqDist(all_keywords).plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = ldamodel.LdaModel(list(bow_lemmas), num_topics=5, id2word=dictionary)\n",
    "\n",
    "pprint(lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda, texts=list(lemmas), dictionary=dictionary, coherence='c_v')\n",
    "\n",
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = list(ParameterGrid({\n",
    "    \"num_topics\": [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"alpha\": list(np.arange(0.01, 1, 0.3)) + [\"auto\", \"asymmetric\"],\n",
    "}))\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "for params in tqdm(grid):\n",
    "    lda_model = ldamodel.LdaModel(list(bow_lemmas),id2word=dictionary,**params)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=list(lemmas), dictionary=dictionary, coherence='c_v')\n",
    "    scores.append(coherence_model_lda.get_coherence())\n",
    "    models.append(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_id = np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[best_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_id].print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
