{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SOURCE_DIR = '../data/arxiv_dump/sources'\n",
    "sources = [f for f in os.listdir(SOURCE_DIR) if not f.endswith(\"tar.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(s):\n",
    "    paper_dir = os.path.join(SOURCE_DIR, s)\n",
    "    return [os.path.join(paper_dir, f) for f in os.listdir(paper_dir)]\n",
    "\n",
    "\n",
    "def get_tex_files(s):\n",
    "    return [f for f in get_all_files(s) if f.endswith(\".tex\")]\n",
    "\n",
    "def clean_text(text, prune_document=True):\n",
    "    pos = text.find(\"\\\\begin{abstract}\")\n",
    "    if pos >= 0:\n",
    "        text = text[:pos]\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if not line.startswith(\"%\")]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def get_text(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        try:\n",
    "            return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            # print('Failed to read the file {}'.format(path))\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mail_domains(s):\n",
    "    emails = []\n",
    "    tex_files = get_tex_files(s)\n",
    "    for f in tex_files:\n",
    "        text = clean_text(get_text(f))\n",
    "        emails += re.findall('@[a-z-_\\.]+\\.[a-z-_\\.]+', text)\n",
    "    emails = [m[1:] for m in emails]\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.shuffle(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_set = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_affiliations_entry(name_version):\n",
    "    d = dict()\n",
    "    d['names'] = []\n",
    "    d['mail_domains'] = extract_mail_domains(name_version)\n",
    "    d['dbpedia_ids'] = []\n",
    "    d['types'] = []\n",
    "    return d\n",
    "\n",
    "def generate_entry(name, name_version):\n",
    "    entry = dict()\n",
    "    entry['id'] = name\n",
    "    entry['versioned_id'] = name_version\n",
    "    entry['manually_annotated'] = False\n",
    "    entry['affiliations'] = generate_affiliations_entry(name_version)\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sources:\n",
    "    pruned_version = s.split('v')[0]\n",
    "    annotated_set[pruned_version] = generate_entry(pruned_version, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babelpy import babelfy\n",
    "API_KEY = '62cb486d-98aa-4f4b-b0cc-f1b6430491b4'\n",
    "babelfy_params = {\n",
    "    'lang': 'EN'\n",
    "    }\n",
    "babel_client = babelfy.BabelfyClient(API_KEY, babelfy_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbpedia_links(text):\n",
    "    babel_client.babelfy(text)\n",
    "    ents_info = babel_client.merged_entities\n",
    "    return [ent['DBpediaURL'] for ent in ents_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_phrases = {\n",
    "    \"universit\",\n",
    "    \"school\",\n",
    "    \"college\",\n",
    "    \"institut\",\n",
    "    \"academ\",\n",
    "    \"universidad\",\n",
    "    \"polyte\",\n",
    "    \"schule\",\n",
    "    \"ecole\",\n",
    "    \"escuela\",\n",
    "}\n",
    "\n",
    "def detect_type(aff_name):\n",
    "    for uni in uni_phrases:\n",
    "        if uni in str.lower(aff_name):\n",
    "            return 'academic'\n",
    "    return 'company'\n",
    "\n",
    "def annotate_types(aff):\n",
    "    if aff['types'] == []:\n",
    "        return [detect_type(aff_name) for aff_name in aff['names']]\n",
    "    else:\n",
    "        return aff['types']\n",
    "    \n",
    "def flatten(ls):\n",
    "    return [el for l in ls for el in l]\n",
    "    \n",
    "def link_dbpedia(aff):\n",
    "    return flatten([get_dbpedia_links(name) for name in aff['names']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://dbpedia.org/resource/University_of_Warsaw',\n",
       " 'http://dbpedia.org/resource/Google']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_dbpedia({'names': ['University of Warsaw', 'Google Research']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['academic']\n",
      "['Universidad Autonoma de Madrid']\n",
      "['http://dbpedia.org/resource/Autonomous_University_of_Madrid']\n",
      "['academic', 'academic', 'academic', 'company', 'academic', 'academic']\n",
      "['TU Berlin', 'MPII', 'Korea University', 'Google Research, Brain Team', 'RIKEN AIP', 'TU Kaiserslautern']\n",
      "['http://dbpedia.org/resource/Technical_University_of_Berlin', 'http://dbpedia.org/resource/Max_Planck_Institute_for_Informatics', 'http://dbpedia.org/resource/Korea_University', 'http://dbpedia.org/resource/Google', 'http://dbpedia.org/resource/Brain', 'http://dbpedia.org/resource/Musical_ensemble', 'http://dbpedia.org/resource/RIKEN', 'http://dbpedia.org/resource/AH_receptor-interacting_protein', 'http://dbpedia.org/resource/Kaiserslautern_University_of_Technology']\n",
      "['company']\n",
      "['Diveplane Corporation']\n",
      "['http://dbpedia.org/resource/Corporation']\n",
      "['academic', 'academic', 'academic']\n",
      "['Manchester Metropolitan University', 'Chinese Academy of Sciences', 'Tongji University']\n",
      "['http://dbpedia.org/resource/Manchester_Metropolitan_University', 'http://dbpedia.org/resource/Chinese_Academy_of_Sciences', 'http://dbpedia.org/resource/Tongji_University']\n",
      "['academic', 'company']\n",
      "['University of Cagliari', 'Pluribus One']\n",
      "['http://dbpedia.org/resource/University_of_Cagliari', 'http://dbpedia.org/resource/Pluribus']\n",
      "['academic', 'academic']\n",
      "['University of Dhaka', 'United International University']\n",
      "['http://dbpedia.org/resource/University_of_Dhaka', 'http://dbpedia.org/resource/United_International_University']\n",
      "['academic', 'academic']\n",
      "['Hong Kong University of Science and Technology', 'Tsinghua University']\n",
      "['http://dbpedia.org/resource/University_of_Hong_Kong', 'http://dbpedia.org/resource/Korea_University_of_Science_and_Technology', 'http://dbpedia.org/resource/Tsinghua_University']\n",
      "['academic', 'academic', 'academic']\n",
      "['Universitat Heidelberg', 'ExtreMe Matter Institute EMMI', 'Fraunhofer Heinrich Hertz Institute']\n",
      "['http://dbpedia.org/resource/Heidelberg_University', '', 'http://dbpedia.org/resource/Matter', 'http://dbpedia.org/resource/Institute', 'http://dbpedia.org/resource/Emmi_(singer)', 'http://dbpedia.org/resource/Fraunhofer_(crater)', 'http://dbpedia.org/resource/Heinrich_Hertz', 'http://dbpedia.org/resource/Institute']\n",
      "['academic', 'academic']\n",
      "['University of Sao Paulo', 'Federal University of Sao Carlos']\n",
      "['http://dbpedia.org/resource/University_of_São_Paulo', 'http://dbpedia.org/resource/Federal_University_of_São_Carlos']\n",
      "['academic', 'academic', 'academic']\n",
      "['University of Texas at Austin', 'Open University of Israel', 'Yale University']\n",
      "['http://dbpedia.org/resource/University_of_Texas_at_Austin', 'http://dbpedia.org/resource/Open_University_of_Israel', 'http://dbpedia.org/resource/Yale_University']\n",
      "['academic']\n",
      "['Maastricht University']\n",
      "['http://dbpedia.org/resource/Maastricht_University']\n",
      "['company']\n",
      "['Worldline']\n",
      "['http://dbpedia.org/resource/World_line']\n",
      "['academic', 'company']\n",
      "['Warsaw University of Technology', 'Samsung']\n",
      "['http://dbpedia.org/resource/Warsaw_University_of_Technology', 'http://dbpedia.org/resource/Samsung']\n",
      "['academic', 'academic', 'academic']\n",
      "['Centrum Wiskunde & Informatica', 'Delft University of Technology', 'University of Amsterdam']\n",
      "['', 'http://dbpedia.org/resource/Informatica', 'http://dbpedia.org/resource/Delft_University_of_Technology', 'http://dbpedia.org/resource/University_of_Amsterdam']\n",
      "['academic', 'company', 'academic', 'academic', 'academic']\n",
      "['Fraunhofer Heinrich Hertz Institute', 'ISTD Pillar', 'Singapore University of Technology and Design', 'Berlin Institute of Technology', 'Korea University']\n",
      "['http://dbpedia.org/resource/Fraunhofer_(crater)', 'http://dbpedia.org/resource/Heinrich_Hertz', 'http://dbpedia.org/resource/Institute', '', 'http://dbpedia.org/resource/Singapore_University_of_Technology_and_Design', 'http://dbpedia.org/resource/Technical_University_of_Berlin', 'http://dbpedia.org/resource/Korea_University']\n",
      "['academic', 'company']\n",
      "[\"King's College London\", 'Turing Intelligence Technology Limited']\n",
      "['', '', 'http://dbpedia.org/resource/Greater_London', 'http://dbpedia.org/resource/Intelligence', 'http://dbpedia.org/resource/Engineering', '']\n",
      "['academic']\n",
      "['Georgia Institute of Technology']\n",
      "['http://dbpedia.org/resource/Georgia_Institute_of_Technology']\n",
      "['academic']\n",
      "['Stanford University']\n",
      "['http://dbpedia.org/resource/Stanford_University']\n",
      "['academic']\n",
      "['University of Maryland']\n",
      "['http://dbpedia.org/resource/University_of_Maryland,_College_Park']\n",
      "['academic']\n",
      "['Duke University']\n",
      "['http://dbpedia.org/resource/Duke_University']\n",
      "['academic', 'academic']\n",
      "['Politecnico di Torino', 'Fondazione Bruno Kessler']\n",
      "['http://dbpedia.org/resource/Polytechnic_University_of_Turin', 'http://dbpedia.org/resource/Bruno_Kessler']\n",
      "['company', 'company']\n",
      "['UC San Diego', 'SRI International']\n",
      "['http://dbpedia.org/resource/University_of_California,_San_Diego', 'http://dbpedia.org/resource/SRI_International']\n",
      "['academic']\n",
      "['Duke University']\n",
      "['http://dbpedia.org/resource/Duke_University']\n",
      "['company']\n",
      "['IBM Research']\n",
      "['http://dbpedia.org/resource/IBM_Research']\n",
      "['academic', 'academic', 'company', 'company', 'company']\n",
      "['Polytech Nice', \"Universite Cote d'Azur\", 'INRIA', 'CNRS', 'LJAD']\n",
      "['', 'http://dbpedia.org/resource/Nice', '', 'http://dbpedia.org/resource/Azur,_Landes', 'http://dbpedia.org/resource/French_Institute_for_Research_in_Computer_Science_and_Automation', 'http://dbpedia.org/resource/CNR_(software)']\n",
      "['academic', 'academic', 'academic']\n",
      "['Worcester Polytechnic Institute', 'Howard University', 'New York University']\n",
      "['http://dbpedia.org/resource/Worcester_Polytechnic_Institute', 'http://dbpedia.org/resource/Howard_University', 'http://dbpedia.org/resource/New_York_University']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['academic']\n",
      "['University of Konstanz']\n",
      "['http://dbpedia.org/resource/University_of_Konstanz']\n",
      "['academic', 'company', 'academic', 'academic']\n",
      "['Technische Universitat Berlin', 'Google Research, Brain Team', 'Max Planck Institut', 'Korea University']\n",
      "['http://dbpedia.org/resource/Technical_University_of_Berlin', 'http://dbpedia.org/resource/Google', 'http://dbpedia.org/resource/Brain', 'http://dbpedia.org/resource/Musical_ensemble', 'http://dbpedia.org/resource/Max_Planck_Society', 'http://dbpedia.org/resource/Korea_University']\n",
      "['company', 'company']\n",
      "['VanBerlo Consulting', 'The Corporation of the City of London']\n",
      "['', 'http://dbpedia.org/resource/City_of_London_Corporation']\n",
      "['company']\n",
      "['Otto Group Solution Provider']\n",
      "['http://dbpedia.org/resource/Otto_Group', 'http://dbpedia.org/resource/Solution', 'http://dbpedia.org/resource/Provider_(song)']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['academic']\n",
      "['Kyoto University']\n",
      "['http://dbpedia.org/resource/Kyoto_University']\n",
      "['academic', 'company']\n",
      "['The University of Hong Kong', 'Wells Fargo']\n",
      "['http://dbpedia.org/resource/University_of_Hong_Kong', 'http://dbpedia.org/resource/Wells_Fargo']\n",
      "['academic', 'academic']\n",
      "['University of Exeter', 'University of Manitoba']\n",
      "['http://dbpedia.org/resource/University_of_Exeter', 'http://dbpedia.org/resource/University_of_Manitoba']\n",
      "['academic']\n",
      "['Syracuse University']\n",
      "['http://dbpedia.org/resource/Syracuse_University']\n",
      "['company', 'academic']\n",
      "['Academia Sinica', 'National Chiao Tung University']\n",
      "['http://dbpedia.org/resource/Academia_Sinica', 'http://dbpedia.org/resource/National_Chiao_Tung_University']\n",
      "['academic']\n",
      "['Drexel University']\n",
      "['http://dbpedia.org/resource/Drexel_University']\n",
      "['company']\n",
      "['KAIST']\n",
      "['http://dbpedia.org/resource/KAIST']\n",
      "['academic']\n",
      "['University of Eastern Finland']\n",
      "['http://dbpedia.org/resource/University_of_Eastern_Finland']\n",
      "['academic']\n",
      "['Georgia Institute of Technology']\n",
      "['http://dbpedia.org/resource/Georgia_Institute_of_Technology']\n",
      "['academic']\n",
      "['Carnegie Mellon University']\n",
      "['http://dbpedia.org/resource/Carnegie_Mellon_University']\n",
      "['academic', 'academic']\n",
      "['University College London', 'University of British Columbia']\n",
      "['http://dbpedia.org/resource/University_College_London', 'http://dbpedia.org/resource/University_of_British_Columbia']\n",
      "['academic', 'academic']\n",
      "['Shenzhen University', 'The Chinese University of Hong Kong']\n",
      "['http://dbpedia.org/resource/Shenzhen_University', 'http://dbpedia.org/resource/Chinese_University_of_Hong_Kong']\n",
      "['academic', 'academic', 'academic']\n",
      "['Machine Intelligence and Data Science (MINDS) Lab', 'Universidade Federal de Minas Gerais', 'Universidade Federal de Ouro Preto']\n",
      "['http://dbpedia.org/resource/Artificial_intelligence', 'http://dbpedia.org/resource/Data_science', '', 'http://dbpedia.org/resource/Laboratory', 'http://dbpedia.org/resource/Universidade_Federal_de_Minas_Gerais', 'http://dbpedia.org/resource/Universidade_Federal_de_Ouro_Preto']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['academic', 'company']\n",
      "['Human-Centered Computing Freie Universitat Berlin', 'Wikimedia Foundation']\n",
      "['http://dbpedia.org/resource/Human-centered_computing', 'http://dbpedia.org/resource/Free_University_of_Berlin', 'http://dbpedia.org/resource/Wikimedia_Foundation']\n",
      "['company']\n",
      "['Wells Fargo']\n",
      "['http://dbpedia.org/resource/Wells_Fargo']\n",
      "['academic', 'academic', 'company']\n",
      "['University of Waterloo', 'Waterloo Artificial Intelligence Institute', 'DarwinAI Corp.']\n",
      "['http://dbpedia.org/resource/University_of_Waterloo', '', 'http://dbpedia.org/resource/Artificial_intelligence', 'http://dbpedia.org/resource/Institute', 'http://dbpedia.org/resource/Corporation']\n",
      "['company']\n",
      "['Lumiata Inc.']\n",
      "['http://dbpedia.org/resource/Lumia_(citrus)', 'http://dbpedia.org/resource/Inc._(magazine)']\n",
      "Manually labelled: 50/587\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset = '../data/affiliations_annotated.json'\n",
    "try:\n",
    "    with open(dataset, 'r') as f:\n",
    "        old_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    old_data = dict()\n",
    "    \n",
    "new_data = old_data.copy()\n",
    "manual_count = 0\n",
    "\n",
    "for k, v in annotated_set.items():\n",
    "    if k not in old_data or old_data[k]['manually_annotated'] == False:\n",
    "        new_data[k] = v\n",
    "    else:\n",
    "        affiliation_dict = new_data[k][\"affiliations\"]\n",
    "        types = annotate_types(affiliation_dict)\n",
    "        dbpedia_ids = link_dbpedia(affiliation_dict)\n",
    "        print(types)\n",
    "        print(affiliation_dict[\"names\"])\n",
    "        print(dbpedia_ids)\n",
    "        new_data[k][\"affiliations\"][\"types\"] = types\n",
    "        new_data[k][\"affiliations\"][\"dbpedia_ids\"] = dbpedia_ids\n",
    "        manual_count += 1\n",
    "    \n",
    "print('Manually labelled: {}/{}'.format(manual_count, len(sources)))\n",
    "        \n",
    "        \n",
    "with open('../data/affiliations_annotated.json', 'w') as f:\n",
    "    json.dump(new_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(s):\n",
    "    tex_files = get_tex_files(s)\n",
    "    for f in tex_files:\n",
    "        text = clean_text(get_text(f))\n",
    "        print(text)\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of affiliation\n",
    "* academic\n",
    "* company\n",
    "* government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009.10990v1\n",
      "\\documentclass[letterpaper]{article} % DO NOT CHANGE THIS\n",
      "\\usepackage{aaai21}  % DO NOT CHANGE THIS\n",
      "\\usepackage{times}  % DO NOT CHANGE THIS\n",
      "\\usepackage{helvet} % DO NOT CHANGE THIS\n",
      "\\usepackage{courier}  % DO NOT CHANGE THIS\n",
      "\\usepackage[hyphens]{url}  % DO NOT CHANGE THIS\n",
      "\\usepackage{graphicx} % DO NOT CHANGE THIS\n",
      "\\urlstyle{rm} % DO NOT CHANGE THIS\n",
      "\\def\\UrlFont{\\rm}  % DO NOT CHANGE THIS\n",
      "\\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT\n",
      "\\usepackage{lipsum}\n",
      "\\usepackage{booktabs}\n",
      "\\usepackage{amsmath}\n",
      "\\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT\n",
      "\\frenchspacing  % DO NOT CHANGE THIS\n",
      "\\setlength{\\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS\n",
      "\\setlength{\\pdfpageheight}{11in}  % DO NOT CHANGE THIS\n",
      "\\usepackage{endnotes}\n",
      "\\let\\footnote=\\endnote\n",
      "\\usepackage{etoolbox}\n",
      "\\makeatletter\n",
      "\\patchcmd{\\@verbatim}\n",
      "  {\\verbatim@font}\n",
      "  {\\verbatim@font\\tiny}\n",
      "  {}{}\n",
      "\\makeatother\n",
      "\n",
      "\\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.\n",
      "\n",
      "\n",
      "\\title{Accurate and Interpretable Machine Learning for Transparent Pricing of Health Insurance Plans}\n",
      "\\author {\n",
      "    % Authors\n",
      "\\parbox{\\linewidth}{\\centering\n",
      "        Rohun Kshirsagar,\n",
      "        Li-Yen Hsu,\n",
      "        Charles H. Greenberg, \n",
      "        Matthew McClelland,\n",
      "        Anushadevi Mohan,\n",
      "        Wideet Shende,\n",
      "        Nicolas P. Tilmans,\n",
      "        Min Guo,\n",
      "        Ankit Chheda,\n",
      "        Meredith Trotter,\n",
      "        Shonket Ray,\n",
      "        Miguel Alvarado\n",
      "        }\n",
      "}\n",
      "\\affiliations{\n",
      "   Lumiata Inc. 489 S. El Camino Real, San Mateo, CA 94402 USA\n",
      "    \n",
      "    Corresponding Author: Rohun Kshirsagar - rohun@lumiata.com\n",
      "}\n",
      "\n",
      "\\begin{document}\n",
      "\\nocopyright\n",
      "\\maketitle\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no = 49\n",
    "print(sources[no])\n",
    "display(sources[no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
