{
  "abstractText": "Motivated by the sequence form formulation of Koller et al. [19], this paper defines bilinear games, and proposes efficient algorithms for its rank based subclasses. Bilinear games are two-player non-cooperative single-shot games with compact polytopal strategy sets and two payoff matrices (A, B) such that when (x, y) is the played strategy profile, the payoffs of the players are xT Ay and xTBy respectively. We show that bilinear games are very general and capture many interesting classes of games like bimatrix games, two player Bayesian games, polymatrix games, two-player extensive form games with perfect recall etc. as special cases, and hence are hard to solve in general. Existence of a (symmetric) Nash equilibrium for (symmetric) bilinear games follow directly from the known results. For a given bilinear game, we define its Best Response Polytopes (BRPs) and characterize the set of Nash equilibria as fully-labeled pairs in the BRPs. We consider a rank based hierarchy of bilinear games, where rank of a game (A, B) is defined as rank(A+ B). In this paper, we give polynomial time algorithms to compute Nash equilibrium for special classes of bilinear games: \u2013 Rank-1 games (i.e., rank(A + B) = 1). \u2013 FPTAS for constant rank games (i.e., rank(A + B) is constant). \u2013 When rank(A) or rank(B) is constant. This improves the results by Lipton et al. [22] and Kannan et al. [17], for bimatrix games with low rank matrices.",
  "authors": [
    {
      "affiliations": [],
      "name": "Jugal Garg"
    },
    {
      "affiliations": [],
      "name": "Albert Xin Jiang"
    },
    {
      "affiliations": [],
      "name": "Ruta Mehta"
    }
  ],
  "id": "SP:2d46c65a10217800af9a194565f72d19691a58a2",
  "references": [
    {
      "authors": [
        "B. Adsul",
        "J. Garg",
        "R. Mehta",
        "M. Sohoni"
      ],
      "title": "Rank-1 bimatrix games: A homeomorphism and a polynomial time algorithm",
      "venue": "STOC. pp. 195\u2013204",
      "year": 2011
    },
    {
      "authors": [
        "D. Avis",
        "G.D. Rosenberg",
        "R. Savani",
        "B. von Stengel"
      ],
      "title": "Enumeration of Nash equilibria for twoplayer games",
      "venue": "Economic Theory 42, 9\u201337",
      "year": 2010
    },
    {
      "authors": [
        "A. Charnes"
      ],
      "title": "Constrained games and linear programming",
      "venue": "Proceedings of the National Academy of Sciences of the USA 39, 639\u2013641",
      "year": 1953
    },
    {
      "authors": [
        "X. Chen",
        "X. Deng"
      ],
      "title": "Settling the complexity of 2-player Nash-equilibrium",
      "venue": "FOCS",
      "year": 2006
    },
    {
      "authors": [
        "X. Chen",
        "X. Deng",
        "S.H. Teng"
      ],
      "title": "Computing Nash equilibria: Approximation and smoothed complexity",
      "venue": "FOCS. pp. 603\u2013612. IEEE Computer Society, Los Alamitos, CA, USA",
      "year": 2006
    },
    {
      "authors": [
        "G.B. Dantzig"
      ],
      "title": "Linear Programming and Extensions",
      "venue": "Princeton University Press",
      "year": 1963
    },
    {
      "authors": [
        "C. Daskalakis",
        "P.W. Goldberg",
        "C.H. Papadimitriou"
      ],
      "title": "The complexity of computing a Nash equilibrium",
      "venue": "STOC. pp. 71\u201378",
      "year": 2006
    },
    {
      "authors": [
        "C. Daskalakis",
        "C. Papadimitriou"
      ],
      "title": "On a network generalization of the minmax theorem",
      "venue": "ICALP, pp. 423\u2013434",
      "year": 2009
    },
    {
      "authors": [
        "D. Fudenberg",
        "J. Tirole"
      ],
      "title": "Game Theory",
      "venue": "MIT Press",
      "year": 1991
    },
    {
      "authors": [
        "I.L. Glicksberg"
      ],
      "title": "A further generalization of the Kakutani fixed point theorem, with application to Nash equilibrium points",
      "venue": "American Mathematical Society 3(1), 170\u2013174",
      "year": 1952
    },
    {
      "authors": [
        "P.W. Goldberg",
        "C.H. Papadimitriou"
      ],
      "title": "Reducibility among equilibrium problems",
      "venue": "STOC. pp. 61\u201370",
      "year": 2006
    },
    {
      "authors": [
        "V. Goyal",
        "L. Genc-Kaya",
        "R. Ravi"
      ],
      "title": "An fptas for minimizing the product of two non-negative linear cost functions",
      "venue": "Mathematical Programming 126(2), 401\u2013405",
      "year": 2011
    },
    {
      "authors": [
        "J. Harsanyi"
      ],
      "title": "Games with incomplete information played by \u201cBayesian\u201d players, i-iii",
      "venue": "part i. the basic model. Management science 14(3), 159\u2013182",
      "year": 1967
    },
    {
      "authors": [
        "J. Howson Jr"
      ],
      "title": "Equilibria of polymatrix games",
      "venue": "Management Science pp. 312\u2013318",
      "year": 1972
    },
    {
      "authors": [
        "J. Howson Jr",
        "R. Rosenthal"
      ],
      "title": "Bayesian equilibria of finite two-person games with incomplete information",
      "venue": "Management Science pp. 313\u2013315",
      "year": 1974
    },
    {
      "authors": [
        "N. Immorlica",
        "A.T. Kalai",
        "B. Lucier",
        "A. Moitra",
        "A. Postlewaite",
        "M. Tennenholtz"
      ],
      "title": "Dueling algorithms",
      "venue": "STOC",
      "year": 2011
    },
    {
      "authors": [
        "R. Kannan",
        "T. Theobald"
      ],
      "title": "Games of fixed rank: A hierarchy of bimatrix games",
      "venue": "Economic Theory pp. 1\u201317",
      "year": 2009
    },
    {
      "authors": [
        "D. Koller",
        "N. Megiddo",
        "B. von Stengel"
      ],
      "title": "Fast algorithms for finding randomized strategies in game trees",
      "venue": "STOC. pp. 750\u2013759",
      "year": 1994
    },
    {
      "authors": [
        "D. Koller",
        "N. Megiddo",
        "B. von Stengel"
      ],
      "title": "Efficient computation of equilibria for extensive twoperson games",
      "venue": "Games and economic behavior 14, 247\u2013259",
      "year": 1996
    },
    {
      "authors": [
        "S. Kontogiannis",
        "P. Spirakis"
      ],
      "title": "Exploiting concavity in bimatrix games: new polynomially tractable subclasses",
      "venue": "APPROX. pp. 312\u2013325",
      "year": 2010
    },
    {
      "authors": [
        "C.E. Lemke"
      ],
      "title": "Bimatrix equilibrium points and mathematical programming",
      "venue": "Management Science 11(7), 681\u2013689",
      "year": 1965
    },
    {
      "authors": [
        "R. Lipton",
        "E. Markakis",
        "A. Mehta"
      ],
      "title": "Playing large games using simple strategies",
      "venue": "EC. pp. 36\u201341. ACM New York, NY, USA",
      "year": 2003
    },
    {
      "authors": [
        "J.F. Nash"
      ],
      "title": "Non-cooperative games",
      "venue": "The Annals of Mathematics 54(2), 286\u2013295",
      "year": 1951
    },
    {
      "authors": [
        "N. Nisan",
        "T. Roughgarden",
        "E. Tardos",
        "Vazirani",
        "V. (eds."
      ],
      "title": "Algorithmic Game Theory",
      "venue": "Cambridge University Press, Cambridge, UK",
      "year": 2007
    },
    {
      "authors": [
        "J.P. Ponssard",
        "S. Sorin"
      ],
      "title": "The LP formulation of finite zero-sum games with incomplete information",
      "venue": "International Journal of Game Theory 9, 99\u2013105",
      "year": 1980
    },
    {
      "authors": [
        "Y. Shoham",
        "K. Leyton-Brown"
      ],
      "title": "Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations",
      "venue": "Cambridge University Press, New York",
      "year": 2009
    },
    {
      "authors": [
        "B. von Stengel"
      ],
      "title": "Equilibrium computation for two-player games in strategic and extensive form",
      "venue": "Chapter 3, Algorithmic Game Theory, eds. N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani pp. 53\u201378",
      "year": 2007
    },
    {
      "authors": [
        "S. Vavasis"
      ],
      "title": "Approximation algorithms for indefinite quadratic programming",
      "venue": "Mathematical Programming 57, 279\u2013311",
      "year": 1992
    }
  ],
  "sections": [
    {
      "text": "ar X\niv :1\n10 9.\n61 82\nv1 [\ncs .G\nT ]\n2 8\nSe p\n20 11\nExistence of a (symmetric) Nash equilibrium for (symmetric) bilinear games follow directly from the known results. For a given bilinear game, we define its Best Response Polytopes (BRPs) and characterize the set of Nash equilibria as fully-labeled pairs in the BRPs. We consider a rank based hierarchy of bilinear games, where rank of a game (A, B) is defined as rank(A+ B). In this paper, we give polynomial time algorithms to compute Nash equilibrium for special classes of bilinear games:\n\u2013 Rank-1 games (i.e., rank(A + B) = 1). \u2013 FPTAS for constant rank games (i.e., rank(A + B) is constant). \u2013 When rank(A) or rank(B) is constant. This improves the results by Lipton et al. [22]\nand Kannan et al. [17], for bimatrix games with low rank matrices."
    },
    {
      "heading": "1 Introduction",
      "text": "In the last decade, there has been much research at the interface of computer science and game theory (see e.g. [24,26]). One fundamental class of computational problems in game theory is the computation of solution concepts of finite games. Nash [23] proved that in any finite game there always exists a steady state, from where no player gains by unilateral deviation. Such a steady state has since been named Nash equilibrium (NE) and is perhaps the most well-known and well-studied game-theoretic solution concept. However, computing a Nash equilibrium is nontrivial, and indeed the recent series of papers [4,7,11] established that the problem is PPAD-complete for finite games in the standard normal form representation, even for games with only two players. Furthermore it is PPAD-complete to even find a 1\nn\u03b8(1) -approximate Nash equilibrium [5]. In light of these negative\nresults, one direction is to identify subclasses of games for which the problem is tractable. A two-player normal form game can be represented by two payoff matrices, say A and B, one for each player, and hence is also known as bimatrix game [24]. For bimatrix games, polynomial time NE computation algorithms are known for many subclasses, including zero-sum games [6], (quasi-) concave games [20], and games with low rank payoff matrices [22]. A line of work focuses\n\u22c6 Work done while the author was an intern at Microsoft Research India\non games of small rank, defined as rank(A + B) by Kannan and Theobald [17]. They gave a fully polynomial time approximation scheme (FPTAS) for fixed rank games and recently Adsul et al. [1] gave a polynomial time algorithm for computing an exact Nash equilibrium for rank-1 games. Specifying the two payoff matrices of a bimatrix game requires a polynomial number of entries in the numbers of pure strategies available to the players. This is adequate when the set of pure strategies are explicitly given. However, there are situations where the natural description gives the set of pure strategies implicitly, and as a result they may be exponential in the description of the game. For example, normal form (bimatrix) representation of two player extensive-form game may have exponentially many strategies in the size of the extensive-form description [9]. In such a case, even if the resulting bimatrix game has a fixed rank, the above results may not be applied for efficient computation.\nNevertheless, certain types of extensive-form games have some combinatorial structure which can be exploited. Koller, Megiddo and von Stengel [19] converted an arbitrary two-player, perfectrecall, extensive form game into a payoff-equivalent two-player game with continuous strategy sets. In this derived formulation, which they call the sequence form, there is a pair of payoff matrices A and B, one for each player. Further, their strategy sets turn out to be compact polytopes in Euclidean space of polynomial dimension. Given a pair of strategies (x, y), utilities of the players are xT Ay and xTBy respectively. Interestingly, the sequence form requires only a polynomial number of bits to specify.\nMotivated by the sequence form of Koller et al., we define bilinear games, which are two-player, non-cooperative, single shot games represented by two payoff matrices, say A and B, of dimension M \u00d7 N and two polytopal compact strategy sets X = {x \u2208 RM | Ex = e, x \u2265 0} and Y = {y \u2208 RN | Fy = f , y \u2265 0}. If (x, y) \u2208 X \u00d7 Y is the played strategy profile, then xT Ay and xTBy are the utilities derived by player one and player two respectively. In other words, the payoffs are bilinear functions of strategies, hence the name bilinear games. The scope of bilinear games is large enough to capture many interesting classes of games besides two-player extensive form games with perfect recall. For example, for two-player Bayesian games [15,25], polymatrix games [14], and various classes of optimization duels [16], researchers have proposed polynomial-sized payoff-equivalent formulations which (either explicitly or implicitly) turn out to be bilinear games (see Section 2.1 for details). Intuitively the polytopal strategy sets are concise representations of the original sets of mixed strategies as marginal probabilities, and xT Ay and xTBy express the expected utilities of the original game in terms of these marginal probabilities.\nRemark 1. Note that our formulation can express arbitrary polytopes as strategy space, for example if the strategy set of a player is expressed as {x : Gx \u2264 g}, i.e., the intersection of a set of half-spaces, it can be transformed to an equivalent game with strategy set {x\u2032 : Ex\u2032 = e, x\u2032 \u2265 0} using standard techniques (i.e., by adding slack variables, substituting unbounded xi with x + i \u2212 x \u2212 i , x + i , x \u2212 i \u2265 0, and modifying the payoff matrices accordingly).\nAs we have seen that many different types of games can be concisely described as bilinear games, designing efficient algorithms for the more general bilinear games seem to be important as well as challenging. Since bimatrix games is a subclass of bilinear games (see Section 2.1), all the hardness results of bimatrix games automatically apply to bilinear games as well. Therefore, the only hope is to design efficient algorithms or FPTAS for the special subclasses. There are many similarities between bilinear and bimatrix games, for example, payoffs are represented by two matrices, and utilities are bilinear functions of strategy vectors, hence it is natural to try to adapt algorithms for bimatrix games to bilinear games. However, a technical challenge is that the polytopal strategy sets of bilinear games are generally much more complex than the bimatrix case; in particular the number\nof vertices may be exponential, while the set of mixed strategies is just a simplex. Recently, we were pointed to the constrained games, similar to bilinear games, considered by Charnes [3]. The linear programming technique by Charnes [3] also works for zero-sum bilinear games, i.e., those with (A + B) = 0 (see also [18] for sequence form, [16] for another derivation, [25] for zero-sum Bayesian games and [8] for zero-sum polymatrix games). Further, it is easy to show that the linear complementarity program (LCP) characterization for the set of NE of a sequence form game [19] works for bilinear games as well. However the Lemke-Howson algorithm may not be directly applied to the general bilinear games. There are results for certain subclasses of bilinear games with specific structure in their strategy sets, e.g., Howson and Rosenthal [15] adapted the Lemke-Howson algorithm to two-player Bayesian games and Koller et al.[19] adapted Lemke\u2019s algorithm [21] to two-player extensive-form games.\nOur Contribution. In Section 2, we define the bilinear game and show that the existence of a (symmetric) Nash equilibrium in a (symmetric) bilinear game directly follows from the known results. Note that given a strategy of a player, the other player would like to play a utility maximizing strategy. We formulate this problem as a primal-dual LP, similar to the Koller et al. formulation. Using the complementarity conditions of the primal-dual, we characterize the Nash equilibria and then define Best Response Polytopes (BRPs) and the notion of fully-labeled pairs in BRPs. Further, we show one-to-one correspondence between the Nash equilibria and fully-labeled pairs. This in turn gives a quadratic programming (QP) formulation for the NE computation problem.\nNext, we extend Kannan and Theobald\u2019s [17] rank-based hierarchy for bimatrix games to bilinear games, by defining the rank of a bilinear game with payoff matrices (A, B) as the rank of (A + B). Zero-sum games are rank-0 games and a NE for these games can be computed efficiently, as discussed above. In Section 3, we show that in spite of a very general structure of the strategy sets in bilinear games, the basic approach given by Adsul et al. [1] to compute a NE of a rank-1 bimatrix game, can be generalized to compute a NE of a rank-1 bilinear game by solving a rank-1 QP. While solving a rank-1 general QP is NP-hard [12], those arising from the bilinear games can be solved in polynomial time. In Section 4, we discuss two FPTAS algorithms for the fixed rank bilinear games, which are generalization of the algorithms by Kannan and Theobald [17] for the bimatrix games. Finally, in Section 5, using the structure of BRPs, we obtain a polynomial time algorithm for the case when the rank of either A or B is a constant, and rank of E and F are also constant. Since, a bimatrix game can be thought of as a bilinear game with E and F being a single row of 1s (see Example 1 of Section 2.1), this algorithm improves upon a result by Lipton et al. [22] and Kannan et al. [17] for bimatrix games, where they require the rank of both A and B to be constant. This approach also gives an enumeration algorithm for extreme equilibria, which runs in polynomial time under the above assumption and exponential time for the general bilinear games.\nThe following table summarizes all the NE computation results while keeping the bimatrix games in perspective.\nResults Bimatrix games Bilinear games\nExistence of (symmetric) NE Nash [23] Easy to show using ([23]) [10]\nLCP formulation for NE Known [24] Koller et al. [19]\nNE as fully-labeled pairs of BRPs Known [27] This paper\nZero-sum games Linear programming [6] Linear programming [18]\nRank-1 games Adsul et al. [1] This paper\nFPTAS for fixed rank games Kannan and Theobald [17] This paper Games with low rank matrices Lipton et al. [22] This paper"
    },
    {
      "heading": "2 Bilinear Games and Nash Equilibria",
      "text": "Notations. We consider a vector x as a column vector by default and for the row vector, we use transpose (i.e., xT). A \u201c0\u201d in the block representation of a matrix, is the matrix with all zero entries of appropriate dimension, and \u201c1k\u201d is a vector of all 1s of length k. Let x \u2208 R\nn be a vector and c \u2208 R be a scalar, then by x \u2264 c we mean, \u2200i \u2264 n, xi \u2264 c. For a given matrix X, Xi denotes the ith row of X, X j denotes the jth column of X and |X| denotes the maximum absolute entry in X, i.e., |X| = maxij |Xij|. For a set S, \u2206(S) denotes the set of probability distribution vectors over the elements of S, i.e., \u2206(S) = {x \u2208 R|S| | x \u2265 0, \u2211i\u2208S xi = 1}. Bilinear games are two-player non-cooperative, single shot games. A bilinear game is represented by two M \u00d7 N dimensional payoff matrices A and B, one for each player, and two compact polytopal strategy sets. Let S1 = {1, . . . , M} be the set of rows and S2 = {1, . . . , N} be the set of columns of the matrices. Let E \u2208 Rk1\u00d7M and F \u2208 Rk2\u00d7N be the matrices, and e \u2208 Rk1 and f \u2208 Rk2 be the vectors. The strategy set of the first-player is X = {x \u2208 RM | Ex = e, x \u2265 0} and the secondplayer is Y = {y \u2208 RN | Fy = f , y \u2265 0}. Sets X and Y are assumed to be compact. From a strategy profile (x, y) \u2208 X \u00d7 Y, the payoffs obtained by the first and the second player are xT Ay and xTBy respectively.\nFrom a Nash equilibrium (NE) strategy profile, no player gains by unilateral deviation. Formally,\nDefinition 1. A strategy profile (x, y) \u2208 X \u00d7 Y is a NE of the game (A, B) iff xT Ay \u2265 x\u2032T Ay, \u2200x\u2032 \u2208 X and xTBy \u2265 xTBy\u2032, \u2200y\u2032 \u2208 Y.\nAs a direct corollary of Glicksberg\u2019s [10] result that there always exists a Nash equilibrium in a game whose players\u2019 strategy spaces are convex and compact, and whose utility function for each player i is continuous in all players\u2019 strategies and quasi-concave in i\u2019s strategy, we have\nProposition 1. Every bilinear game has at least one Nash equilibrium.\nA bilinear game is completely represented by a six-tuple (A, B, E, F, e, f ) in general. However, for ease of notation we represent it by (A, B) fixing (E, F, e, f ). Given a strategy y \u2208 Y of the secondplayer, the objective of the first player is to play x \u2208 X such that xT(Ay) is maximized, i.e., solve the following linear program [19].\nmax : xT(Ay) s.t. Ex = e\nx \u2265 0 Dual\u2212\u2212\u2192\nmin : eT p s.t. ET p \u2265 Ay\n(1)\nNote that pi is the dual variable of the equation Eix = ei in the above program. At the optimal point (x, p) of (1), we get xi > 0 \u21d2 Aiy = p\nTEi, \u2200i \u2208 S1 from the complementarity. A similar condition can be obtained for the second-player, given an x \u2208 X. At a Nash equilibrium both the conditions are satisfied, and these characterize the NE strategies as follows: A strategy pair (x, y) \u2208 X \u00d7 Y is a Nash equilibrium of the game (A, B) iff it satisfies the following conditions.\n\u2203p \u2208 Rk1 s.t. Ay \u2264 ET p and \u2200i \u2208 S1, xi > 0 \u21d2 Aiy = p TEi \u2203q \u2208 Rk2 s.t. xTB \u2264 qTF and \u2200j \u2208 S2, yj > 0 \u21d2 x TBj = qT Fj\n(2)\nThe above characterization implies that, a player plays a strategy with non-zero probability only if it gives the maximum payoff with respect to (w.r.t.) the opponent\u2019s strategy in some sense. Such\nstrategies are called the best response strategies (w.r.t. the opponent\u2019s strategy). Using this fact, we define best response polytopes (BRPs), similar to the best response polytopes of a bimatrix game [27].\nIn the following expression, x, y, p and q are vector variables.\nP = { (y, p) \u2208 RN+k1 | Aiy \u2212 p TEi \u2264 0, \u2200i \u2208 S1; yj \u2265 0, \u2200j \u2208 S2; Fy = f} Q = { (x, q) \u2208 RM+k2 | xi \u2265 0, \u2200i \u2208 S1; x TBj \u2212 qTFj \u2264 0, \u2200j \u2208 S2; Ex = e}\n(3)\nThe polytope P in (3) is closely related to the best response strategies of the first-player for any given strategy of the second-player and it is called the best response polytope of the first-player. Similarly Q is called the best response polytope of the second-player. Note that, in both the polytopes the first set of inequalities corresponds to the first-player, and the second set corresponds to the second-player. Since |S1| = M and |S2| = N, let the inequalities be numbered from 1 to M, and M+ 1 to M + N in both the polytopes. Let the label L(v) of a point v in the polytope be the set of indices of the tight inequalities at v. If a pair (v, w) \u2208 P \u00d7 Q is such that L(v) \u222a L(w) = {1, . . . , M + N}, then it is called a fully-labeled pair. The proof of the next lemma follows using (2).\nLemma 1. A strategy profile (x, y) is a NE of the game (A, B) iff ((y, p), (x, q)) \u2208 P \u00d7 Q is a fully-labeled pair, for some p and q.\nA game is called non-degenerate if both the polytopes are non-degenerate. Note that a fullylabeled pair of a non-degenerate game has to be a vertex-pair. Lemma 1 implies that a NE strategy profile has to satisfy the following linear complementarity conditions (LCP) over P \u00d7 Q [19].\n((y, p), (x, q)) \u2208 P \u00d7 Q corresponds to a NE \u21d4 xT(Ay \u2212 ET p) = 0 and\n(xTB \u2212 qTF)y = 0 (4)\nClearly, xT(Ay \u2212 ET p) \u2264 0 and (xTB \u2212 qTF)y \u2264 0 over P \u00d7 Q and hence xT(Ay\u2212 ET p) + (xTB\u2212 qTF)y \u2264 0. Simplifying the expression using Ex = e and Fy = f we get xT(A+ B)y \u2212 eT p \u2212 f Tq \u2264 0 over P \u00d7 Q and equality holds iff (x, y) is a NE (using (4)). This gives the following QP formulation which captures all the NE of game (A, B) at its optimal points.\nmax: xT(A + B)y \u2212 eT p \u2212 f Tq s.t. ((y, p), (x, q)) \u2208 P \u00d7 Q\n(5)\nSymmetric Bilinear Games. Nash [23] proved that any symmetric finite game has a symmetric Nash equilibrium. The concept of symmetry can be straightforwardly adapted to the bilinear games: We say a bilinear game is symmetric if B = AT, E = F, and e = f . A strategy profile (x, y) is symmetric if x = y. A straightforward adaptation of Nash\u2019s [23] proof yields the following proposition.\nProposition 2. Any symmetric bilinear game has a symmetric NE.\nNote that for a symmetric game (A, AT), strategy sets X and Y are the same. From (2) and (4), it is clear that a symmetric NE x \u2208 X must satisfy q = p, Ax \u2264 ET p, xT(Ax \u2212 ET p) = 0. This gives the following QP formulation to capture all symmetric NE of a symmetric game (A, E, e).\nmax: xT Ax \u2212 eT p s.t. Ax \u2264 ET p; Ex = e; x \u2265 0\n(6)\nA bilinear game (A, B, E, F, e, f ) can be converted to an equivalent symmetric game (A\u2032, E\u2032, e\u2032), where\nA\u2032 =\n[\n0 A BT 0\n]\n, E\u2032 =\n[\nE 0 0 F\n]\n, e\u2032 =\n[\ne f\n]\n, with strategy vector z =\n[\nx y\n]\nIt is easy to check that any symmetric NE of the derived game corresponds to a NE of the original game and vice-versa. In the next section, we discuss reductions of different games to polynomial size bilinear games, which do not seem to be possible with the bimatrix games."
    },
    {
      "heading": "2.1 Examples of Bilinear Games",
      "text": "The simplest subclass of bilinear games is the set of two-player normal-form games (bimatrix games).\nExample 1. Bimatrix Games A bimatrix game (A, B) with A, B \u2208 RM\u00d7N can be straightforwardly transformed to the bilinear game (A, B, E, F, e, f ) where ET = 1M, e = 1 and similarly F T = 1N , f = 1. \u2293\u2294\nMany other interesting classes of finite games may be formulated as bilinear games. In this section, we provide a few examples where the bilinear formulation are exponentially smaller than a direct bimatrix formulation.\nExample 2. Two-player Bayesian Games In a Bayesian game [13], there is a type set associated with each player, which is her private information. The nature draws the type for each player from a joint distribution, which is a common knowledge, and each player gets to know only her own type before choosing an action. The final utilities of the game is determined by types of all the players, and hence are uncertain.\nHere we consider the two-player case, where Tis are the type sets and Sis are the strategy sets. The joint probability distribution is denoted by pts for the type profile (t, s) \u2208 T1 \u00d7 T2. Let S = S1 \u00d7 S2, T = T1 \u00d7 T2, |Ti| = ti and |Si| = mi. The utilities are the functions of actions and types, i.e., ui : S \u00d7 T \u2192 R, hence for every type profile they can be represented by the two matrices. For a type profile (t, s) let Ats and Bts denote the respective m1 \u00d7 m2 dimensional payoff matrices. The strategy of a player is to decide her play for each of her type so that her expected payoff is maximized, i.e., x : T1 \u2192 \u2206(S1) for player one and y : T2 \u2192 \u2206(S2) for player two. For a t \u2208 T1, let x\nt denote the mixed strategy given type t.\nThe induced normal form of this game is a bimatrix game in which each pure strategy of a player prescribes an action for each of her types. Thus the size of the induced normal form is exponential in the number of types. However, it can be formulated as a polynomial sized bilinear game as follows\nA =\n\n \np11 A 11 \u00b7 \u00b7 \u00b7 p1t2 A 1t2\n... . . . ... pt11A t11 \u00b7 \u00b7 \u00b7 pt1t2 A t1t2\n\n  , B =\n\n \np11B 11 \u00b7 \u00b7 \u00b7 p1t2 B 1t2\n... . . . ... pt11B t11 \u00b7 \u00b7 \u00b7 pt1t2 B t1t2\n\n  , E =\n\n  1Tm 0 \u00b7 \u00b7 \u00b7 0 1Tm ... . . .\n\n  , F =\n\n  1Tn 0 \u00b7 \u00b7 \u00b7 0 1Tn ... . . .\n\n \nand e = 1t1 , f = 1t2 . Given mixed strategies x 1, . . . , xt1 , y1, . . . , yt2 of the Bayesian game, define x = [x1 T , \u00b7 \u00b7 \u00b7 , xt T 1 ]T and y = [y1 T , \u00b7 \u00b7 \u00b7 , yt T 2 ]T. Then xT Ay and xTBy are exactly the expected utilities of the Bayesian game. This transformation is implicit in Howson and Rosenthal\u2019s [15] adaptation of Lemke-Howson algorithm to two-player Bayesian games. \u2293\u2294\nExample 3. Polymatrix Games [14] A polymatrix game is an n-player game in which each player\u2019s utility is the sum of the utilities resulting from her bilateral interactions with each of the n \u2212 1 other players. Let Si be player i\u2019s set of pure strategies. The game is represented by the payoff matrices Aij \u2208 R|Si|\u00d7|Sj| for all pairs of\nplayers (i, j). Let xi \u2208 \u2206(Si) denote a mixed strategy of player i. Given a strategy profile (x 1, . . . , xn), the expected utility of player i is,\nui(x 1, . . . , xn) = \u2211\nj 6=i\n(xi)T Aijxj\nWe show that any polymatrix game can be transformed to a symmetric bilinear game such that any symmetric NE of the bilinear game corresponds to a NE of the polymatrix game. Our derivation is adapted from Howson\u2019s [14] formulation of NE of polymatrix games as solutions of an LCP. Formally, given a polymatrix game, we define the induced symmetric bilinear game as (A, AT, E, E, e, e), where\nA =\n\n   \n0 A12 \u00b7 \u00b7 \u00b7 A1n A21 0 A2n\n... . . .\nAn1 An2 0\n\n    , E =\n\n    \n1T|S1 | 0 \u00b7 \u00b7 \u00b7 0\n0 1T|S2| \u00b7 \u00b7 \u00b7 0 ... . . . 0 0 \u00b7 \u00b7 \u00b7 1T|Sn|\n\n     ,\nand e = 1n. The space of strategy vectors is x = [x1 T \u00b7 \u00b7 \u00b7 xn T ]T .\nProposition 3. Consider a polymatrix game of n players. The strategy (x1, x2, . . . , xn) is an NE of the game if and only if (x, x) is a symmetric NE of its induced bilinear game.\nProof. The proof is relatively straightforward, by observing that the respective incentive constraints are equivalent. Thus the problem of finding a NE of a polymatrix game reduces to the problem of finding a symmetric NE of a symmetric bilinear game. Note that an asymmetric NE doesn\u2019t correspond to a NE of the polymatrix game. \u2293\u2294\nImmorlica et al. [16] analyzed several classes of games between two optimization algorithms whose objectives are to outperform each other. The space of pure strategies are the possible outputs of the algorithm which are exponential, however the authors were able to formulate some of these games as zero-sum bilinear games (which they call bilinear duels). We describe one example from [16].\nExample 4. Ranking Duels [16] Each player chooses a ranking over m elements. Thus the number of pure strategies is exponential in m. Such a ranking can be represented as a m \u00d7 m permutation matrix. By the Birkoff-von Neumann theorem, the space of mixed strategies corresponds to the space of m \u00d7 m doubly-stochastic matrices with each row and each column sum to 1. This space can be described by the polytope {x \u2208 Rm 2 | x \u2265 0; \u2200i, \u2211j xij = 1; \u2200j, \u2211i xij = 1}. Viewing x and y as column vectors, the sizes of the corresponding E, e are polynomial in m. Immorlica et al. [16] constructed matrices A \u2208 Rm 2\u00d7m2 such that the players\u2019 expected utilities are equal to xT Ay and \u2212xT Ay respectively. \u2293\u2294\nExample 5. Two-player Perfect-recall Extensive-form Games Extensive-form represents a dynamic game as a tree [26], where every pure strategy of a player prescribes a move at each of the player\u2019s information sets. As a result the number of pure strategies may be exponential in the size of the extensive-form description. Fortunately, if we assume perfect recall\u2014roughly, that each player remembers all her past decisions and observations\u2014then there always exists a Nash equilibrium in behavior strategies, where each player independently chooses a distribution over actions at each of her information sets. Representation of a behavior strategy\nrequires space linear in the extensive form. However, the expected utilities of the two-player perfectrecall extensive-form games are not bilinear functions of the behavior strategies. Koller et al. [19] proposed the sequence form, which is a bilinear game formulation for these games. The number of rows and columns of the matrices A and B, in the bilinear form, are the number of feasible sequences of plays of the first and second player respectively. If a play sequence pair (i, j) leads to a leaf node then the ijth entry of A and B are the payoffs of the first and second player at that leaf node, otherwise it is zero \u22c6. A strategy x of the first player is such that, x(root) = 1, and if a sequence \u03c3 ends at an information node C, then \u2211a\u2208Actions(C) x\u03c3a \u2212 x\u03c3 = 0. Similar conditions hold for a strategy y of the second player. Such a strategy may be transformed to a behavior strategy and vice versa. This gives E, F, e and f . Note that the reduction is polynomial sized and xT Ay and xTBy are exactly the expected payoffs under the corresponding behavior strategies. We refer readers to [19] for more details. \u2293\u2294\nRemark 2. Lemke\u2019s algorithm on the LCP formulation of bilinear games terminates with a solution (i.e., not at a ray) if the only non-negative solutions x and y to Ex = 0 and Fy = 0 are x = 0 and y = 0, and the payoff matrices are non-positive, i.e., A \u2264 0 and B \u2264 0. This result directly follows from [19]. Note that games of all the above examples satisfy these requirements, without loss of generality.\nThe rank of a game (A, B) is defined as rank(A + B), and we consider the rank based hierarchy of the bilinear games. The set of rank-k games consists of all (A, B) such that rank(A + B) \u2264 k. Zero-sum games are rank-0 games, the smallest set in the hierarchy. Koller et al. [18] gave an LP formulation for zero-sum bilinear games, derived from two-player extensive form games with perfect recall. However, their formulation works for general bilinear games as well. Beyond rank-0 games, no polynomial time algorithm is known for NE computation (even for the reduction specific formulations). In the next section, we extend the polynomial time solvability of Nash equilibrium for the rank-1 bilinear games.\nFor all the algorithms that follow, we make the following assumptions (without loss of generality): 1) The entries of A, B, E, F, e and f are integers, since scaling them by a positive number does not change the set of NE. 2) The equalities Ex = e and Fy = f are all linearly independent because even if we discard the dependent equalities, X and Y do not change. 3) The letter L denotes the bit length of the input game."
    },
    {
      "heading": "3 Rank-1 Games and Polynomial Time Algorithm",
      "text": "The approach used in this section is motivated by the paper [1]. Given a rank-1 game (A, B), it is easy to find \u03b1 \u2208 RM and \u03b2 \u2208 RN such that A + B = \u03b1 \u00b7 \u03b2T , since any two rows of A + B are multiple of each other. In that case B = \u2212A + \u03b1 \u00b7 \u03b2T . Let G(\u03b1) = (A,\u2212A + \u03b1 \u00b7 \u03b2T) be a parametrized game for a fixed A \u2208 RM\u00d7N and \u03b2 \u2208 RN . For any game G(\u03b1) the BRP of first-player is fixed to P(\u03b1) = P (of (3)) since A is fixed. However, the BRP of second-player Q(\u03b1) changes with the parameter. Now, consider the following polytope with x, q as vector variables and \u03bb as a scalar variable:\nQ\u2032 = { (x, \u03bb, q) \u2208 RM+1+k2 | xi \u2265 0, \u2200i \u2208 S1; x T(\u2212Aj) + \u03bb\u03b2 j \u2212 q TFj \u2264 0, \u2200j \u2208 S2; Ex = e} (7)\nIt is easy to see that Q(\u03b1) is the projection of {(x, \u03bb, q) \u2208 Q\u2032 | \u03bb = xT\u03b1} on (x, q)-space. In other words, Q(\u03b1) is a section of Q\u2032 obtained by hyper-plane \u03bb = xT\u03b1. Clearly, Q\u2032 covers Q(\u03b1), \u2200\u03b1 \u2208 RM. Number the equations of Q\u2032 in a similar way as the equations of Q. Let N be the set of fully-labeled\n\u22c6 Due to chance moves, the entry may correspond to multiple leaf nodes. In that case the entry stores the expected payoff.\npairs of P \u00d7 Q\u2032, i.e., N = {(v, w) \u2208 P \u00d7 Q\u2032 | L(v) \u222a L(w) = {1, . . . , M + N}}. Using the definition of fully-labeled pairs, it is easy to check that for a given ((y, p), (x, \u03bb, q)) \u2208 P \u00d7 Q\u2032,\n((y, p), (x, \u03bb, q)) \u2208 N \u21d4 xT(Ay \u2212 ET p) = 0 and (xT(\u2212A) + \u03bb\u03b2T \u2212 qTF)y = 0 (8)\nLemma 2. Let (v, w) \u2208 N , v = (y, p) and w = (x, \u03bb, q).\n\u2013 For all \u03b1 such that \u03bb = xT\u03b1, (x, y) is a NE of G(\u03b1). \u2013 For every NE (x, y) of a game G(\u03b1), there exists a (v, w) \u2208 N , where \u03bb = xT\u03b1.\nProof. Since (v, w) is fully-labeled it satisfies, xT(Ay \u2212 ET p) = 0 and (xT(\u2212A) + \u03bb\u03b2T \u2212 qT F)y = 0. Let \u03b1 be such that \u03bb = xT\u03b1 then we get (xT(\u2212A) + (xT\u03b1)\u03b2T \u2212 qTF)y = 0 \u21d2 (xT(\u2212A + \u03b1\u03b2T) \u2212 qTF)y = 0. This implies that (x, y) is a NE of the game (A,\u2212A + \u03b1\u03b2T) (i.e., G(\u03b1)), since it satisfies the complementarity condition of (4).\nGiven a (x, y) of G(\u03b1), from (2) and (4) it is clear that \u2203p, q such that xT(Ay \u2212 ET p) = 0 and (xT(\u2212A + \u03b1\u03b2T) \u2212 qTF)y = 0. Let \u03bb = xT\u03b1, then we get (xT(\u2212A) + \u03bb\u03b2T \u2212 qTF)y = 0. Therefore, ((y, p), (x, \u03bb, q)) \u2208 N . \u2293\u2294\nThe above lemma establishes strong relation between the set of NE of all the G(\u03b1)s and the set N . Next we discuss the structure of N , and later use it to design a polynomial time algorithm to find a NE of a given game G(\u03b1).\nThe polytopes P and Q\u2032 are assumed to be non-degenerate3, and let k1 = k2 = k for simplicity. As there are k linearly independent equalities in P and Q\u2032, they are of dimension N and M + 1 respectively. Therefore, \u2200(v, w) \u2208 N , |L(v)| \u2264 N and |L(w)| \u2264 M + 1. Since, M + N labels are required for a pair (v, w) to be part of N , N \u2282 1-skeleton of P\u00d7 Q\u2032. Further, if (v, w) \u2208 N is a vertex pair then |L(v) \u2229 L(w)| = 1. Let the label in the intersection be called the duplicate label of (v, w). Relaxing the inequality corresponding to the duplicate label at (v, w) in P and Q\u2032 respectively gives its two adjacent edges in N . Therefore, every vertex of N has degree two. This implies that N is a set of cycles and infinite paths (unbounded edges at both the ends). We will show that N forms a single infinite path. The next lemma follows directly from the definition of P (3) and Q\u2032 (7), and expression (8).\nLemma 3. For all (v, w) = ((y, p), (x, \u03bb, q)) \u2208 P\u00d7Q\u2032, we have \u03bb(\u03b2Ty)\u2212 eT p\u2212 f Tq \u2264 0, and the equality holds iff (v, w) \u2208 N .\nLemma 3 implies that N is captured by \u03bb(\u03b2Ty)\u2212 eT p \u2212 f Tq = 0 over P \u00d7 Q\u2032. Using this fact and Lemma 3, we define the following parametrized LP.\nLP(\u03b4) \u2212 max: \u03b4(\u03b2Ty)\u2212 eT p \u2212 f Tq s.t. P \u00d7 Q\u2032; \u03bb = \u03b4\nFor an a \u2208 R, let OPT(a) be the set of optimal solutions of LP(a) and N (a) be the set of points of N with \u03bb = a, i.e., N = {(v, w) \u2208 N | w = (x, \u03bb, q) and \u03bb = a}.\nLemma 4. For an a \u2208 R, N (a) 6= \u2205 and OPT(a) = N (a)\nProof. Consider a game G(\u03b1) where \u03b1 = [a, . . . , a]. Clearly, for any Nash equilibrium (x, y) of G(\u03b1) the corresponding point in N has \u03bb = xT\u03b1 = a (Lemma 2). Therefore, N (a) 6= \u2205. The feasible set of LP(a) is all points of P \u00d7 Q\u2032 with \u03bb = a. Further, function \u03bb(\u03b2Ty) \u2212 eT p \u2212 f Tq achieves maximum only at points on N (Lemma 3). Therefore, OPT(a) = N (a) follows. \u2293\u2294\n3 Degeneracy may be handled using standard techniques as done in [1].\nLemma 5. The set N forms an infinite path, with \u03bb being monotonic on it.\nProof. To the contrary suppose there are cycles and multiple paths in N . Let C be a cycle in N . It is easy to see that N (a) = intersection of N with the hyper-plane \u03bb = a. Therefore, \u2203a \u2208 R, such that either C is contained in \u03bb = a or it cuts the cycle at exactly two points. This contradicts that N (a) is a convex set in both the cases (Lemma 4).\nNow let P1 and P2 be two paths in N . Since, N (a) is a convex set \u2200a \u2208 R, \u03bb is monotonic on both the paths. Suppose, the range of \u03bb covered by P1 and P2 be (\u2212\u221e, a] and (a, inf). However, this contradicts the fact that P2 is a closed set. Monotonicity of \u03bb follows from the convexity of N (a). \u2293\u2294"
    },
    {
      "heading": "3.1 Algorithm",
      "text": "Let (A, B) be a given rank-1 game and A + B = \u03b3 \u00b7 \u03b2T . Let \u03b3min = minx\u2208X \u2211i\u2208S1 \u03b3ixi and \u03b3max = maxx\u2208X \u2211i\u2208S1 \u03b3ixi. The \u03b3min and \u03b3max exists since X is a bounded polytope. From Lemma 2 it is clear that every point in the intersection of the set N and hyper-plane H\u03b3 : \u03bb\u2212\u2211i\u2208S1 \u03b3ixi = 0 corresponds to a NE of the given game (A, B). Note that for any point in the intersection, corresponding \u03bb is between \u03b3min and \u03b3max. Let H \u2212 \u03b3 and H + \u03b3 be the negative and positive half spaces of the hyper-plane H\u03b3 respectively, then clearly N (\u03b3min) \u2208 H \u2212 \u03b3 and N (\u03b3max) \u2208 H + \u03b3 . All the points in the intersection of N and H\u03b3 are between N (\u03b3min) and N (\u03b3max). The following algorithm does binary search on N between N (\u03b3min) and N (\u03b3max) to find a point in the intersection using the fact that \u03bb monotonically increases (similar to the algorithm in [1]).\nS1 Initialize a1 = \u03b3min and a2 = \u03b3max. S2 If the edge containing N (a1) or N (a2) intersects H\u03b3, then output the intersection and exit. S3 Let a = a1+a2 2 . Let u, v be the edge containing N (a). S4 If u, v intersects H\u03b3, then output the intersection and exit. S5 Else if u, v \u2208 H\u2212\u03b3 , then set a1 = a else set a2 = a and continue from step S3.\nCorrectness. Since the feasible set of LP(a) is a section of P \u00d7 Q\u2032, where \u03bb = a, the OPT(a) is on an edge of P \u00d7 Q\u2032 (assuming non-degeneracy of LP(a)). It is easy to construct this edge from the tight equations of P \u00d7 Q\u2032 at OPT(a). Clearly, this entire edge should be part of the set N , hence if this edge intersects the hyper-plane H\u03b3 then we get a Nash equilibrium of the given game. Since, all the points in the intersection of N and H\u03b3 are between N (\u03b3min) and N (\u03b3max), and \u03bb monotonically increases between these two (Lemma 5), the algorithm does a simple binary search between \u03b3min and \u03b3max to find an a, such that the edge containing N (a) = OPT(a) intersects H\u03b3 (Lemma 4).\nTime Complexity. Recall that L is the bit length of the input game. Since, \u03b3min and \u03b3max are optimal points of two LPs on set X = {Ex = e, x \u2265 0}, they can be represented in poly(L, M, N) bits. Let Z = max{|A|, |E|, |F|, |e|, | f |, |\u03b3|, |\u03b2|}, l = M + N + k1 + k2 + 1, and \u2206 = l!Zl .\nTheorem 1. The above algorithm finds a NE of game (A, B) in time poly(L, M, N).\nProof. One round of steps S3 to S5 can be done in polynomial time since computation of N (a) requires solving LP(a) (Lemma 4), and computation of u, v \u2229 H\u03b3 requires checking the feasibility of a polytope. Now, to show polynomial time complexity, we need to bound the number of rounds of steps S3 to S5.\nNote that the denominator of any co-ordinate of a vertex of P \u00d7 Q\u2032 is at most \u2206, and if \u03bb is not constant on an edge of N , then the difference in its value between the two end points of the edge is\nat least 1 \u22062 . Therefore, if a2 \u2212 a1 < 1 \u22062 the algorithm terminates. After k rounds a2 \u2212 a1 = \u03b3max\u2212\u03b3min 2k . In round k if a2 \u2212 a1 = \u03b3max\u2212\u03b3min\n2k > 1 \u22062 , then k < log(\u03b3max \u2212 \u03b3min) + 2 log \u2206. Therefore, the algorithm is guaranteed to terminate after log(\u03b3max \u2212 \u03b3min) + 2 log \u2206 + 1 = poly(L, M, N) many rounds. \u2293\u2294\n4 FPTAS for Rank-k Games\nIn this section, we discuss fully polynomial time approximation schemes for fixed rank games (i.e., rank(A+ B) is constant). The approximation notion in bilinear games can be defined in a similar way to that of bimatrix games given by Kannan et al. [17]. Let xmax = maxx\u2208X \u2211i xi, ymax = maxy\u2208Y \u2211j yj and D = |A + B|. Clearly the total payoff derived from a strategy profile (x, y) \u2208 X \u00d7 Y is at most xmaxDymax. Using this we define an \u01eb-approximate NE for a bilinear game (A, B) as follows.\nDefinition 2. For a strategy profile (x, y) \u2208 X \u00d7Y, let u = maxx\u2032\u2208X x \u2032T Ay and v = maxy\u2032\u2208Y x TBy\u2032. Then (x, y) is an \u01eb-approximate NE of the game (A, B) if u + v \u2212 xT(A + B)y \u2264 \u01eb(xmaxDymax).\nFor a bimatrix game xmaxDymax = D, since x and y are probability distributions, which is compatible with the definition of [17]. Next we define a stronger notion of \u01eb-approximate NE called relative \u01eb-approximate NE, where the error is relative to the maximum achievable payoff from the given strategy.\nDefinition 3. For a strategy profile (x, y) \u2208 X \u00d7Y, let u = maxx\u2032\u2208X x \u2032T Ay and v = maxy\u2032\u2208Y x TBy\u2032. Then (x, y) is a relative \u01eb-approximate NE of the game (A, B) if u + v \u2212 xT(A + B)y \u2264 \u01eb(u + v), i.e., the total error is relatively small.\nSince the value of u + v is at most xmaxDymax, if (x, y) is relative \u01eb-approximate NE, then it is also \u01eb-approximate NE. For all the examples mentioned in Section 2.1, a (relative) approximate NE of the bilinear game formulation can be straightforwardly turned into a (relative) approximate NE of the corresponding finite game under standard definitions. Without loss of generality we assume that A, B, E, F, e and f are integer matrices, since scaling them by a positive value does not change the set of (relative) \u01eb-approximate NE. Next we discuss two FPTAS to solve QP of (5), one for each definition of approximation. The approaches used in these algorithms are generalization of the ones in [17]."
    },
    {
      "heading": "4.1 FPTAS for Approximate NE",
      "text": "We show that the result by Vavasis [28] can be applied to get an \u01eb-approximate Nash equilibrium (Definition 2). The following proposition states the result by Vavasis.\nProposition 4. Let min{ 12 x TQx + qTx : Ax \u2264 b} be a quadratic optimization problem with compact polytope {x \u2208 Rn : Ax \u2264 b}, and let the rank of Q be a fixed constant. If x\u2217 and x# denote points minimizing and maximizing the objective function f (x) = 12 x TQx + qT x in the feasible region, respectively, then one can find in time poly(L, 1\u01eb ) a point x \u22c4 satisfying\nf (x\u22c4)\u2212 f (x\u2217) \u2264 \u01eb( f (x#)\u2212 f (x\u2217)).\nNow consider the following QP formulation of (5), which captures all the NE of (A, B) at its optimal.\nmin: eT p + f Tq \u2212 xT(A + B)y s.t. Ay \u2212 ET p \u2264 0; Fy = f ; y \u2265 0\nxTB \u2212 qTF \u2264 0; Ex = e; x \u2265 0\nTheorem 2. Let (A, B) be a rank-k game, then for every \u01eb > 0, an \u01eb-approximate Nash equilibrium can be computed in time poly(L, 1\u01eb ), where L is the bit length of the game and k is a constant.\nProof. The objective function of the above QP can be easily transformed to the standard QP form 1 2 x\nTQx + qT x, where rank(Q) = 2k. To apply Proposition 4 on this QP, we need to bound its feasible set. Since, {x : Ex = e, x \u2265 0} and {y : Fy = f , y \u2265 0} are compact, the only variables to bound are ps and qs. Since, the maximum possible value of xT(A + B)y for any (x, y) \u2208 X \u00d7 Y is xmaxDymax, the value of eT p + f Tq is at most xmaxDymax at any point of the polytope corresponding to NE (by (4)). Therefore, we impose eT p + f Tq \u2264 xmaxDymax. However, this may not bound the ps and qs.\nLet Z = max{|A|, |B|, |E|, |F|, |e|, | f |} and l = M+ N + k1 + k2. Recall that NE of a non-degenerate game correspond to vertices of the polytope. It is easy to see that maximum absolute value of a coordinate of any vertex in the polytope is at most l!Zl . Further, the quantity l!Zl can be represented in poly(L) bits. Therefore, imposing \u2212l!Zl \u2264 p \u2264 l!Zl and \u2212l!Zl \u2264 q \u2264 l!Zl in the above QP incur only a polynomial increase in its representation and does not change its optimal set. The minimum and the maximum objective values of this QP are zero (Lemma 3) and at most 2xmaxDymax respectively. Let ((y\u22c4, p\u22c4), (x\u22c4, q\u22c4)) be the solution given by Vavasis algorithm for \u01eb2 , then from Proposition 4 we get,\neT p\u22c4 + f Tq\u22c4 \u2212 x\u22c4T(A + B)y\u22c4 \u2264 \u01eb(xmaxDymax)\nFrom the primal-dual formulation of (1) it is clear that maxx\u2032\u2208X x \u2032T Ay\u22c4 \u2264 eT p\u22c4 and maxy\u2032\u2208Y x \u22c4TBy\u2032 \u2264 f Tq\u22c4. Therefore, we get maxx\u2032\u2208X x \u2032T Ay\u22c4 + maxy\u2032\u2208Yx \u22c4TBy\u2032 \u2212 x\u22c4T(A + B)y\u22c4 \u2264 \u01eb(xmaxDymax). \u2293\u2294"
    },
    {
      "heading": "4.2 FPTAS for Relative Approximate NE",
      "text": "Let the rank of a game (A, B) be k, then A+ B = \u2211ki=1 \u03b1(i)\u03b2(i) T , where \u2200i, \u03b1(i) \u2208 RM and \u03b2(i) \u2208 RN . We assume that the game is such that \u03b1(i)s and \u03b2(i)s are positive vectors. For all i \u2264 k, let wi = minx\u2208X x T\u03b1(i) and w\u2032i = maxx\u2208X x T\u03b1(i), similarly let zi = miny\u2208Y \u03b2(i) Ty and z\u2032i = maxy\u2208Y \u03b2(i) Ty. Note that wi, w \u2032 i, zi and z \u2032 i can be represented by poly(L, M, N) bits, since X and Y are compact. Given an \u01eb > 0, consider the sub-intervals [wi, (1 + \u01eb)wi], [(1 + \u01eb)wi, (1 + \u01eb) 2wi] of [wi, w \u2032 i] and similarly of [zi, z \u2032 i]. All combinations of these intervals form a grid in 2k-dimensional box B = \u00d7i[wi, w \u2032 i]\u00d7i [zi, z \u2032 i]. Let (x, y) \u2208 X \u00d7 Y be such that \u2200i, xT\u03b1(i) \u2208 [ui, (1 + \u01eb)ui] and \u03b2(i) Ty \u2208 [vi, (1 + \u01eb)vi], then clearly,\nk\n\u2211 i=1\nuivi \u2264 x T(A + B)y \u2264 (1 + \u01eb)2\nk\n\u2211 i=1 uivi (9)\nFor a fixed hyper-cube of the grid, consider the following LP based on the QP of (5)\nmin: eT p + f Tq s.t. Ay \u2264 ET p, Fy = f , y \u2265 0\nxTB \u2264 qTF; Ex = e; x \u2265 0 ui \u2264 x T\u03b1(i) \u2264 (1 + \u01eb)ui; vi \u2264 \u03b2(i) Ty \u2264 (1 + \u01eb)vi, \u2200i\nAlgorithm. Run the above LP for each hyper-cube of the grid, and output an optimal point of the one giving the best approximation. As the number of hyper-cubes in the grid is poly(L, 1/ log(1 + \u01eb)), the running time of the algorithm is poly(M, N,L, 1/ log(1 + \u01eb)).\nCorrectness. Next we show that the above algorithm gives (\n1 \u2212 1 (1+\u01eb)2\n)\n-approximate NE of the\ngame (A, B). Let (x\u2032, y\u2032) be a NE of the given game, and (p\u2032, q\u2032) be such that x\u2032T Ay\u2032 = eT p\u2032 and\nx\u2032TBy\u2032 = f Tq\u2032. Consider the hyper-cube containing (x\u2032T\u03b1(1), . . . , x\u2032T\u03b1(k), \u03b2(1)Ty\u2032, . . . , \u03b2(k)Ty\u2032) of the grid and corresponding LP. Clearly, (x\u2032, y\u2032, p\u2032, q\u2032) is a feasible point of this LP and \u2211ki=1 uivi \u2264 eT p\u2032 + f Tq\u2032 \u2264 (1 + \u01eb)2 \u2211ki=1 uivi, since e\nT p\u2032 + f Tq\u2032 = x\u2032T(A + B)y\u2032. Therefore, at the optimal point (x\u0303, y\u0303, p\u0303, q\u0303) of the LP we get eT p\u0303 + f T q\u0303 \u2264 (1 + \u01eb)2 \u2211ki=1 uivi, and this gives,\nx\u0303T(A + B)y\u0303 \u2265 \u2211ki=1 uivi \u2265 eT p\u0303+ f Tq\u0303 (1+\u01eb)2\n(using (9))\n\u21d2 eT p\u0303 + f T q\u0303 \u2212 x\u0303T(A + B)y\u0303 \u2264 (\n1 \u2212 1 (1+\u01eb)2\n)\n(eT p\u0303 + f T q\u0303)\nLet \u00b5 = (\n1 \u2212 1 (1+\u01eb)2\n)\n, u\u0303 = max\u03b3\u2208X \u03b3 T Ay\u0303, and v\u0303 = max\u03b3\u2208Y x\u0303 TB\u03b3. Clearly, eT p\u0303 \u2265 u\u0303 and f T q\u0303 \u2265 v\u0303\n(using (1)). Let D = eT p\u0303 + f T q\u0303 \u2212 u\u0303 \u2212 v\u0303, then u\u0303 + v\u0303 \u2212 x\u0303T(A + B)y\u0303 = eT p\u0303 + f T q\u0303 \u2212 D \u2212 x\u0303T(A + B)y\u0303 \u2264 \u00b5(eT p\u0303 + f T q\u0303) \u2212 D \u2264 \u00b5(eT p\u0303 + f T q\u0303 \u2212 D) = \u00b5(u\u0303 + v\u0303), since \u00b5 \u2208 (0, 1). Therefore, (x\u0303, y\u0303) is a relative \u00b5-approximate NE of the given game (A, B) (Definition 3).\nTheorem 3. Let (A, B) be a rank-k game, and A + B = \u2211ki=1 \u03b1(i)\u03b2(i) T , such that \u03b1(i)s and \u03b2(j)s are positive vectors. Then given an \u01eb > 0, a relative (\n1 \u2212 1 (1+\u01eb)2\n)\n-approximate NE can be computed in time\npoly(L, 1/ log(1 + \u01eb)), where L is the input bit length. \u2293\u2294\nFor a symmetric game (B = AT, E = F, e = f ), an (relative) \u01eb-approximate symmetric NE can be defined as an (relative) \u01eb-approximate NE with the same strategies, i.e., x = y. It is easy to check that, if we use the QP formulation of (6) instead of (5) in any of these algorithms, then the output strategy is an (relative) \u01eb-approximate symmetric NE strategy."
    },
    {
      "heading": "5 Games with a Low Rank Matrix",
      "text": "In this section we show that if rank of even one payoff matrix (A or B) is constant, then Nash equilibrium computation can be done in polynomial time. Recall the best response polytopes P and Q (3) for the bilinear game (A, B).\nLemma 6. Given a game (A, B), there exists a vertex pair ((y, p), (x, q)) \u2208 P \u00d7 Q such that (x, y) is a NE of (A, B).\nProof. All the solutions of (4) over P \u00d7 Q are the NE of the game, and existence of a solution is guaranteed (Proposition 1). Suppose v \u2208 P \u00d7 Q is a NE of (A, B). It is easy to check that the entire face, formed by the set of tight equations at v, is solution, and it contains at least one vertex, as P\u00d7 Q is bounded from one side. \u2293\u2294\nLemma 7. Let k1 = k2 = k and rank(A) = l. The polytope P has at most O(N l+k) vertices.\nProof. From (3), it is clear that P is in (N + k)-dimensional Euclidean space, however Fy = f gives k linearly independent equalities. Therefore, P is of dimension N, and at a vertex of P, N linearly independent inequalities must be tight. Since A is of rank l, rank([A -E]) \u2264 l + k. Therefore, \u2203!S \u2282 S1, |S| = l + k such that \u2200i \u2208 S1 \\ S, Aiy \u2212 p\nTEi \u2264 0 are not needed in defining the polytope P. At a vertex, if d inequalities are tight from S then rest N \u2212 d must be of type yj = 0, hence for a fixed D \u2282 S, |D| = d, there are at most ( NN\u2212d) = ( N d ) choices to form a vertex. Therefore, the total number of vertices are at most \u2211l+ki=0 ( l+k i )( N i ) \u2264 2 l+kNl+k. \u2293\u2294\nNote that if we remove the assumption k1 = k2 = k then the exponent of N turns out to be a linear function of l, k1 and k2. A similar proof can be worked out for Q.\nTheorem 4. If rank of either A or B is constant then a Nash equilibrium of a bilinear game (A, B) can be computed in polynomial time, assuming k to be a constant.\nProof. Suppose rank(A) = l (a constant) and v = (y, p) \u2208 P be a vertex. We can check in polynomial time whether v corresponds to a NE or not as follows. Let Sx = {i \u2208 S1 | Aiy \u2212 p\nTEi = 0} and Sy = {j \u2208 S2 | yj > 0}. Consider all (x, q) \u2208 R M+k such that\nEx = e; \u2200j \u2208 Sy, xTBj \u2212 qT Fj = 0; \u2200i \u2208 Sx, xi \u2265 0 \u2200j /\u2208 Sy, xTBj \u2212 qT Fj \u2264 0; \u2200i /\u2208 Sx, xi = 0.\nEvery such (x, q) lies in Q and makes a fully-labeled pair with v, and hence forms a NE (Lemma 1). Note that such an (x, q) can be obtained in polynomial time by solving an LP. Now the proof follows from Lemmas 6 and 7. A similar argument proves the other case when rank(B) is constant. \u2293\u2294\nAs the set of bimatrix games is a subclass of the bilinear games (Example 1), where k1 = k2 = 1, Theorem 4 strengthens the results by Lipton, Markakis and Mehta [22] (Corollary 4), and Kannan and Theobald [17] (Theorem 3.2), where they require that the rank of both A and B to be constants. Note that k in Bayesian games depends on the number of types of players and in the sequence form, it depends on the number of information sets of players. Therefore, this result can be applied to these games if in their bilinear representation, a payoff matrix has low rank and k is constant.\nIn fact Theorem 4 gives a polynomial time algorithm to enumerate all the extreme equilibria of a bilinear game with a constant rank matrix, and an exponential time enumeration algorithm for any bilinear game. A similar (exponential time) algorithm was given by Avis et al. [2] to enumerate all Nash equilibria of a bimatrix game."
    },
    {
      "heading": "6 Conclusion",
      "text": "We have defined two-player bilinear games, where payoffs are represented by two matrices (A, B) and strategy sets are compact polytopes. In both bilinear and bimatrix games, the utilities are bilinear functions of strategy vectors. The scope of these games is large enough to capture many interesting classes of games like bimatrix games, two-player Bayesian games, polymatrix games, and two-player extensive-form games with perfect recall. Considering the rank-based hierarchy puts a structure on bilinear games, and by exploiting this structure and the similarity between bilinear and bimatrix games, we extended various combinatorial and algorithmic results, pertaining to the efficient computation of Nash equilibria, from bimatrix games to bilinear games. It will be interesting to know what other results of bimatrix games extend to bilinear games like 1) designing Lemke-Howson type algorithm for NE computation, 2) extending other algorithms for computation of approximate equilibria, etc.\nAcknowledgments. We would like to thank Milind Sohoni for helpful comments and corrections."
    }
  ],
  "title": "Bilinear Games: Polynomial Time Algorithms for Rank Based Subclasses",
  "year": 2020
}
