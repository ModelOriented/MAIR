{
  "abstractText": "An important feature of successful supervised machine learning applications is to be able to explain the predictions given by the regression or classification model being used. However, most state-of-the-art models that have good predictive power lead to predictions that are hard to interpret. Thus, several model-agnostic interpreters have been developed recently as a way of explaining black-box classifiers. In practice, using these methods is a slow process because a novel fitting is required for each new testing instance, and several non-trivial choices must be made. We develop NLS (neural local smoother), a method that is complex enough to give good predictions, and yet gives solutions that are easy to be interpreted without the need of using a separate interpreter. The key idea is to use a neural network that imposes a local linear shape to the output layer. We show that NLS leads to predictive power that is comparable to state-of-the-art machine learning models, and yet is easier to interpret. 1 ar X iv :1 91 0. 05 20 6v 1 [ st at .M L ] 1 1 O ct 2 01 9",
  "authors": [
    {
      "affiliations": [],
      "name": "Victor Coscrato"
    },
    {
      "affiliations": [],
      "name": "Marco Henrique de Almeida In\u00e1cio"
    }
  ],
  "id": "SP:e2e552303e9f926d0a96dccfbaf5a1faf54aba4c",
  "references": [
    {
      "authors": [
        "Werner Vach",
        "Reinhard Ro\u00c3\u00a7ner",
        "Martin Schumacher"
      ],
      "title": "Neural networks and logistic regression",
      "year": 1996
    },
    {
      "authors": [
        "Finale Doshi-Velez",
        "Been Kim"
      ],
      "title": "Towards a rigorous science of interpretable machine learning",
      "venue": "arXiv preprint arXiv:1702.08608,",
      "year": 2017
    },
    {
      "authors": [
        "Victor Coscrato",
        "Rafael Izbicki"
      ],
      "title": "The nn-stacking: Feature weighted linear stacking through neural networks, 2019",
      "year": 2019
    },
    {
      "authors": [
        "Yotam Hechtlinger"
      ],
      "title": "Interpretation of prediction models using the input gradient",
      "venue": "arXiv preprint arXiv:1611.07634,",
      "year": 2016
    },
    {
      "authors": [
        "Pang Wei Koh",
        "Percy Liang"
      ],
      "title": "Understanding black-box predictions via influence functions",
      "venue": "In Proceedings of the 34th International Conference on Machine LearningVolume",
      "year": 2017
    },
    {
      "authors": [
        "Scott M Lundberg",
        "Su-In Lee"
      ],
      "title": "A unified approach to interpreting model predictions",
      "venue": "In Advances in Neural Information Processing Systems,",
      "year": 2017
    },
    {
      "authors": [
        "Riccardo Guidotti",
        "Anna Monreale",
        "Salvatore Ruggieri",
        "Franco Turini",
        "Fosca Giannotti",
        "Dino Pedreschi"
      ],
      "title": "A survey of methods for explaining black box models",
      "venue": "ACM computing surveys (CSUR),",
      "year": 2019
    },
    {
      "authors": [
        "Ruth C Fong",
        "Andrea Vedaldi"
      ],
      "title": "Interpretable explanations of black boxes by meaningful perturbation",
      "venue": "In Proceedings of the IEEE International Conference on Computer Vision,",
      "year": 2017
    },
    {
      "authors": [
        "Tiago Botari",
        "Rafael Izbicki",
        "Andre C.P.L.F. de Carvalho"
      ],
      "title": "Local interpretation methods to machine learning using the domain of the feature space, 2019",
      "year": 2019
    },
    {
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "title": "Anchors: High-precision model-agnostic explanations",
      "venue": "In Thirty-Second AAAI Conference on Artificial Intelligence,",
      "year": 2018
    },
    {
      "authors": [
        "Gregory Plumb",
        "Maruan Al-Shedivat",
        "Eric Xing",
        "Ameet Talwalkar"
      ],
      "title": "Regularizing black-box models for improved interpretability",
      "venue": "arXiv preprint arXiv:1902.06787,",
      "year": 2019
    },
    {
      "authors": [
        "Michael H Kutner",
        "Christopher J Nachtsheim",
        "John Neter",
        "William Li"
      ],
      "title": "Applied linear statistical models, volume 5",
      "year": 2005
    },
    {
      "authors": [
        "Diederik P. Kingma",
        "Jimmy Ba"
      ],
      "title": "Adam: A method for stochastic optimization",
      "venue": "CoRR, abs/1412.6980,",
      "year": 2014
    },
    {
      "authors": [
        "Xavier Glorot",
        "Yoshua Bengio"
      ],
      "title": "Understanding the difficulty of training deep feedforward neural networks",
      "year": 2010
    },
    {
      "authors": [
        "Djork-Arn\u00e9 Clevert",
        "Thomas Unterthiner",
        "Sepp Hochreiter"
      ],
      "title": "Fast and accurate deep network learning by exponential linear units (elus)",
      "year": 2015
    },
    {
      "authors": [
        "Geoffrey E. Hinton",
        "Nitish Srivastava",
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Ruslan R. Salakhutdinov"
      ],
      "title": "Improving neural networks by preventing co-adaptation of feature detectors",
      "year": 2012
    },
    {
      "authors": [
        "Jianqing Fan",
        "Irene Gijbels"
      ],
      "title": "Variable bandwidth and local linear regression smoothers",
      "venue": "The Annals of Statistics,",
      "year": 1992
    },
    {
      "authors": [
        "Jianqing Fan"
      ],
      "title": "Design-adaptive nonparametric regression",
      "venue": "Journal of the American statistical Association,",
      "year": 1992
    },
    {
      "authors": [
        "Dan Ruan",
        "Jeffrey A Fessler",
        "JM Balter"
      ],
      "title": "Real-time prediction of respiratory motion based on local regression methods",
      "venue": "Physics in Medicine & Biology,",
      "year": 2007
    },
    {
      "authors": [
        "Daniel P McMillen"
      ],
      "title": "Geographically weighted regression: the analysis of spatially varying relationships",
      "year": 2004
    },
    {
      "authors": [
        "Shawkat Ali",
        "Kate A Smith-Miles"
      ],
      "title": "A meta-learning approach to automatic kernel selection for support vector",
      "venue": "machines. Neurocomputing,",
      "year": 2006
    },
    {
      "authors": [
        "Reshma Khemchandani",
        "Suresh Chandra"
      ],
      "title": "Optimal kernel selection in twin support vector machines",
      "venue": "Optimization Letters,",
      "year": 2009
    },
    {
      "authors": [
        "Andreas Argyriou",
        "Raphael Hauser",
        "Charles A Micchelli",
        "Massimiliano Pontil"
      ],
      "title": "A dc-programming algorithm for kernel selection",
      "venue": "In Proceedings of the 23rd international conference on Machine learning,",
      "year": 2006
    },
    {
      "authors": [
        "Trevor Hastie",
        "Clive Loader"
      ],
      "title": "Local regression: Automatic kernel carpentry",
      "venue": "Statistical Science,",
      "year": 1993
    },
    {
      "authors": [
        "David Harrison Jr.",
        "Daniel L Rubinfeld"
      ],
      "title": "Hedonic housing prices and the demand for clean air",
      "venue": "Journal of environmental economics and management,",
      "year": 1978
    },
    {
      "authors": [
        "Kam Hamidieh"
      ],
      "title": "A data-driven statistical model for predicting the critical temperature of a superconductor",
      "venue": "arXiv preprint arXiv:1803.10260,",
      "year": 2018
    },
    {
      "authors": [
        "Krisztian Buza"
      ],
      "title": "Feedback prediction for blogs. In Data analysis, machine learning and knowledge discovery, pages 145\u2013152",
      "year": 2014
    },
    {
      "authors": [
        "Julian John McAuley",
        "Jure Leskovec"
      ],
      "title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews",
      "venue": "In Proceedings of the 22nd international conference on World Wide Web,",
      "year": 2013
    },
    {
      "authors": [
        "George Cybenko"
      ],
      "title": "Approximations by superpositions of a sigmoidal function",
      "venue": "Mathematics of Control, Signals and Systems,",
      "year": 1989
    }
  ],
  "sections": [
    {
      "text": "ar X\niv :1\n91 0.\n05 20\n6v 1\n[ st\nat .M"
    },
    {
      "heading": "1 Introduction",
      "text": "Machine learning applications are often focused on maximizing prediction accuracy, leading practitioners to choose highly complex regression estimators [Vach et al., 1996]. In this scenario, neural networks have recently gained much prominence in regression applications due to their high predictive accuracy and their scalability to large datasets [LeCun et al., 2015].\nHowever, in many applications, accuracy is only one of the features that must be considered when choosing which prediction method to use. Another relevant aspect is the easiness in interpreting the outputs of the method at hand. The ability to explain predictions made by a method is important to give insights about the decisions being taken by the learned model, which can increase the trust practitioners have over the ML model [Doshi-Velez and Kim, 2017].\nIn this work, we introduce the Neural Local Smoother (NLS), a one-step approach to fit a neural network that yields predictions that are easy to be explained. The key idea of the method is to combine the architecture of the network with a local linear output [Coscrato et al., 2019]. We show that while NLS keeps the high predictive accuracy of neural networks, it is highly interpretable."
    },
    {
      "heading": "1.1 Related work",
      "text": "Many approaches to interpreting complex machine learning algorithms have been proposed; see Hechtlinger [2016], Koh and Liang [2017], Lundberg and Lee [2017], Guidotti et al. [2019] and references therein for a review of some methods. Typically, these proposals offer model agnostic interpreters to explain the outputs given by a learned model, that is, explanations to a prediction can be taken regardless of the model nature. An example of one solution is LIME [Ribeiro et al., 2016]. LIME uses a kernel smoother to fit a local linear approximation to a (possibly complex) regression function around the instance to be explained. By looking at the coefficients of this approximation, it is then possible to explain why a particular prediction was made.\nLIME and related methods work on demand. That is, every time a new instance, x\u2217, needs to be explained, a local linear estimator is fit on a neighborhood around x\u2217. This process can be too slow to be applied in practice. Moreover, several nontrivial choices on how to define the neighborhood around x\u2217 and how to sample from it need to be made [Fong and Vedaldi, 2017, Botari et al., 2019]Thus, this two-step approach of first learning the regression and then explaining it is not practical in many applications. On the other hand, NLS learns a prediction model that is already locally linear and can, therefore, already be interpreted in the same way as an explanation given by LIME.\nThe remaining of the work is organized as follows: in Section 2, we introduce NLS and show how it outperforms other local linear approaches. In Section 3, we apply the NLS to real data, comparing its performance to other stateof-the-art methods. Finally, Section 4 presents final remarks\nand possible future extensions."
    },
    {
      "heading": "2 The Neuro Local Smoother - NLS",
      "text": "Consider a set of data instances (X1,Y1), . . . ,(Xn ,Yn), where Xi \u2208 R\nd are features and Yi \u2208 R is the target to be predicted. The Neural Local Smoother learns a neural network that ensures a local linear shape to the prediction function. In order to do so, this neural network has input X and output \u0398(x) = (\u03b80,\u03b81(x), . . . ,\u03b8d(x)), where d is the dimension of X. An example of an NLS network containing 4 features and a single hidden layer with 4 neurons is shown in Figure 1. In order to obtain the predictions, these outputs are then combined according to\nG\u0398(x) \u2236= \u03b80+ d\n\u2211 i=1\n\u03b8i (x)xi . (1)\nThe prediction function of Equation 1 is easy to interpret because it is locally linear. Thus, given a new instance, x\u2217, one can interpret the prediction made to x\u2217 by looking at the coefficients \u03b8i (x\n\u2217), similar way as done in LIME. Consider a fixed architecture of a NLS neural network that maps x \u2208 Rd into \u0398(x) \u2208 Rd+1. Let \u0393 be the set of all possible values for the parameters (weights) associated with that network. Each \u03b3 \u2208 \u0393 is then associated with a different choice of\u0398(x). In order to learn the weights of the network, the NLS uses a squares loss function over a given training dataset (X1,Y1), . . . ,(Xn ,Yn), that is,\n\u03b3\u2217 = argmin \u03b3\u2208\u0393\nn\n\u2211 i=1\n[(yi \u2212G\u0398(xi )) 2] (2)\nAs long as the architecture of the network is sufficiently complex, any regression function can be represented by Equation 1. This property is confirmed by the following theorem:\nTheorem 2.1. Let r(x) \u2236= E[Y \u2223x] be the true regression function and let \u00b2 > 0. Assume that the domain of the feature space is [0,1]d . If r(x) is continuous, then there exists an architecture and weights for NLS such that \u2223r(x)\u2212G\u0398(x)\u2223 < \u00b2 for every x \u2208 (0,1)d .\nTheorem 2.1 implies that, for a complex enough architecture, an NLS can fully represent any neural network regression. Furthermore, for a fixed index i \u2208 {1, ...,d}, a NLS with \u03b8 j (x) \u2261 0\u2200 j \u2260 i can still fully represent any neural network regression. Hence, there are infinite choices of \u0398(x), and thus infinite possible NLS fits that lead to the same predictions. In other words, the solution of Equation 2 is not unique. There might be, therefore, a variety of \u03b3 settings leading to similar predictive errors."
    },
    {
      "heading": "2.1 Extending a local interpretation to its neighborhood",
      "text": "A NLS is a local linear method, and thus \u03b8i (x \u2217) can be locally interpreted as a linear coefficient. However, as Ribeiro\nHidden layer Input layer\nOutput layer\net al. [2018] argue, practitioners tend to extend local interpretation to new samples, which can lead to poor inference if \u03b8i (x) varies too much. Thus, to minimize this effect, \u03b8i (x) should vary smoothly with x. Therefore, we define an alternative loss function that penalizes non smooth solutions through the cumulative squared derivative. We choose \u03b3 as follows:\n\u03b3\u2217 = argmin \u03b3\u2208\u0393\nn\n\u2211 i=1\n[(yi \u2212G\u03b3(xi )) 2\n+\u03bb \u2211 k,l\u22650\n( \u2202\u03b8k(x)\n\u2202x(l) \u2223 x=xi )\n2\n]\n(3)\nwhere \u03bb is the penalization strength. This penalization guarantees that the optimization algorithm pursues \u03b3\u2019s for which \u0398 is smooth, leading to more accurate inferences to new samples when interpretations are extended.\nEquation 3 establishes a global interpretability-accuracy trade-off. If \u03bb = 0,\u0398(x) can vary freely, which typically leads to predictive models with better accuracy. As \u03bb\u00d0\u2192\u221e, we recover a standard least squares linear regression (i.e., constant \u03b8i \u2019s), which is highly interpretable, but has low predictive power in most cases. Notice, however, that high values of \u03bb encourage simpler NLS, which tends to increase model bias while decreasing its variance. Thus, accuracy may also increase with\u03bb. We discuss how\u03bb can be chosen in practice in Section 3.2.\nThe approach of introducing a penalty that encourages explainability in prediction methods has also been proposed by Plumb et al. [2019] in a general framework. In our case, we choose a regularizer that is particularly suitable to a neural network because it is easy to compute: the derivatives in Equation 3 come straight from the backpropagation algorithm on the network fit.\nExample 2.2 presents a toy experiment to show the interpretability-accuracy trade-off in practice.\nExample 2.2. In this example, we use a NLS to fit the function y = sin(x) in the interval [0,2\u03c0]. For this, we sampled\n2,000 points in this interval and fit the NLS for \u03bb varying in [0,1] using 80% of the points (randomly selected). For the remaining 20%, we compute the MSE (Mean Squared Error) and the average squared gradient (in this case, as x is unidimensional, this is the cumulative squared derivative) as a function of \u03bb. Figure 2 illustrates the obtained results. For large \u03bb, NLS leads to a simple linear regression with gradients close to zero; for small \u03bb, the true regression function is better approximated."
    },
    {
      "heading": "2.2 Classification",
      "text": "The NLS can also be generalized as a classifier. Assume that Y assumes values in {0,1, ...,L}. Given an instance x, the NLS estimates class probabilities with the shape\nP(Y = y \u2223x)\u221d exp(\u03b8(Y =y)0 + d\n\u2211 i=1\n\u03b8 (Y =y) i (x)xi) .\nHence, the classifier NLS neural network will estimate one vector\u0398 for each label y , that is, the network output has dimension (k+1)(d+1). In order forP(Y = y \u2223x) to be well defined probabilities, we use the log-softmax function. To optimize the network we use the cross entropy loss: we choose\n\u03b3 via\n\u03b3\u2217 = argmin \u03b3\u2208\u0393\nn\n\u2211 i=1\n[\u2212 L\n\u2211 y=0\nI(Yi = y) logP(Yi = yi \u2223xi )\n+\u03bb \u2211 k,l\u22650\n( \u2202\u03b8k(x)\n\u2202x(l) \u2223 x=xi )\n2\n],\nwhere \u03bb controls the penalization strength as in the regression case. The logarithmic scale is used due to numeric optimization. The classifier NLS weights can be interpreted through the log-odds ratios as in standard logistic regression [Kutner et al., 2005]."
    },
    {
      "heading": "2.3 Implementation details",
      "text": "The Python package that implements the methods proposed in this paper is available at github.com/randommm/ nnlocallinear. We work with the following default specifications for the artificial neural networks:\n\u2022 Optimizer: we choose to work with the Adam optimizer [Kingma and Ba, 2014] and decrease its learning rate once no improvement is achieved on the validation loss for a considerable number of epochs.\n\u2022 Initialization: to initialize the network weights, we used the method of initialization proposed by Glorot and Bengio [2010].\n\u2022 Layer activation and regularization: we chose ELU [Clevert et al., 2015] as the activation function and no regularization.\n\u2022 Stop criterion: a 90%/10% split early stopping for small datasets and a higher split factor for larger datasets (increasing the proportion of training instances) and a patience of 50 epochs without improvement on the validation set.\n\u2022 Normalization: batch normalization, as proposed by Ioffe and Szegedy, is used in this work in order to speed-up the training process.\n\u2022 Dropout: We also took advantage of dropout, which is a technique proposed by Hinton et al. [2012].\n\u2022 Software: we chose PyTorch as the deep learning framework."
    },
    {
      "heading": "2.4 Connection to local linear estimators",
      "text": "Local linear smoothing (LLS) methods [Fan and Gijbels, 1992, Fan, 1992, 2018] demonstrated to be a powerful tool for performing nonparametric regression in several applications [Ruan et al., 2007, McMillen, 2004]. Their prediction function has the shape\nG\u0398(x) \u2236= \u03b80(x)+ d\n\u2211 i=1\n\u03b8i (x)xi , (4)\nthat is, LLS also consists of a local linear expression for the regression function. However, rather than estimating the parameters \u03b8i using neural networks, for each new instance x\u2217, \u0398(x\u2217) = (\u03b80(x\u2217), . . . ,\u03b8d(x\u2217)) is estimated using weighted least squares:\n\u0398\u0302(x) = argmin \u03b8\u2208Rd+1\nn\n\u2211 i=1\nK (x,xi )(Yi \u2212\u03b80\u2212 d\n\u2211 i=1\n\u03b8i xi ) 2, (5)\nwhere K is a smoothing kernel function. The solution to such a minimization problem is given by\n\u0398\u0302(x\u2217) = (X T W X )\u22121X T W y, (6)\nwhere W = diag(K (x\u2217,x1),K (x\u2217,x2), ...,K (x\u2217,xn)). Local linear smoothers yield good interpretability by default. One minor interpretability issue happens in LLS: On linear models, the parameter \u03b80 stands for E[Y \u2223x = 0], but when \u03b80(x) is a function of x, there is not a practical meaning for \u03b80(x)\u2223x \u2260 0. We fix this issue in NLS by fixing \u03b80.\nThe LLS calculates pairwise kernels for each new instance, leading to higher calculation effort and memory requirements as training data increases. Also, a new least squares optimization is required for each new instance. Therefore, local smoothers might be slow to generate predictions on high dimensional applications. This is not the case for NLS: once the network is learned, evaluating the prediction on new instances only requires a single feedforward run through the network.\nIn LLS, the kernel plays a key role: it controls the weight each training instance will receive, and thus choosing a suitable kernel is important. In particular, several algorithms to choose a suitable kernel have been developed [Ali and Smith-Miles, 2006, Khemchandani et al., 2009, Argyriou et al., 2006, Hastie et al., 1993]. In practice, these methods require a family of kernel functions to be specified, such as a Gaussian kernel:\nK (xi ,x j ) = exp{\u2212 d 2(xi ,x j )\n\u03c32 }\nwhere d(\u22c5, \u22c5) is the Euclidean distance and\u03c32 a variance parameter that defines the size of the neighborhoods. \u03c3 is usually chosen through cross-validation. Unfortunately, choosing a suitable kernel can be slow, especially because of the slow prediction time for LLS.\nRemark 1. When using a Gaussian kernel on a local linear smoother, the \u03c3 kernel hyper-parameter has a similar role as \u03bb on NLS: when \u03c3\u00d0\u2192\u221e, the weights are the same over the whole sample space, and hence the plain least squares linear regression is recovered. As\u03c3 gets small, the local linear parameters can vary more.\nNotice that the Gaussian kernel (as well as the other most commonly used kernels) does not perform a weighting over the features, that is, every feature is equally relevant to the kernel value. In practice, however, features do not have the\nsame predictive relevance: many of them can have no influence on Y . Therefore, an optimal weighting procedure should consider feature predictive relevance, which is not trivial. On the other hand, NLS creates a local linear estimator that does not depend on a kernel. In particular, as the neural net has x as input, the network architecture automatically allows for feature selection. Example 2.3 shows a simulated example to illustrate this.\nExample 2.3. Consider the regression model E(Y \u2223x) = g(x) = x2. We sampled 2,000 instances with x \u223c U[\u22125,5]. We fitted a NLS (with an architecture of 3 layers of size 500) and a LLS (with a Gaussian kernel, using cross-validation to choose \u03c3). We also added irrelevant features (that is, features that are independent of the label) to the data and refitted the models. Figure 3 illustrates the features relationship with Y . Table 1 shows each model mean squared error on a 20% holdout sample. The NLS is robust to these irrelevant features on the training data, while these can cause major damage to the accuracy of the LLS."
    },
    {
      "heading": "3 Experiments",
      "text": "The NLS is a prediction method that fits a local smoother through neural networks. Therefore, we want to ensure that it gives good predictive accuracy when compared to both standard neural network regression and LLS. In this section, we perform comparisons among these models, as well as with random forests [Breiman, 2001]. We used the following datasets:\n\u2022 The Boston housing dataset [Harrison Jr and Rubinfeld, 1978] (506 instances, 13 features),\n\u2022 The superconductivity dataset [Hamidieh, 2018] (21.263 instances, 80 features),\n\u2022 The blog feedback dataset [Buza, 2014] (60.021 instances, 280 features),\n\u2022 The Amazon fine foods dataset [McAuley and Leskovec, 2013] (100.000 instances, textual data).\nTo evaluate models (on the test dataset), we used a split of 90% for train-validation and 10% test data for each dataset (except for the Boston dataset, for which we used 5-fold cross-validation procedure to split train-validation and test because of the small sample size). On each inner trainvalidation dataset, we used 90% as train data and 10% as validation data to perform a grid search optimized for the mean squared error (except for the Boston dataset, for which we used 2-fold cross-validation procedure to separate train and validation). Moreover, for the neural network methods, early stopping validation is performed on 10% of the training set. We describe below the grid search for each method:\n\u2022 For the NLS and the neural network regression (NN), we tested using 1, 3, and 5 layers, with sizes 100, 300 and 500 (9 combinations). We used no penalization for the NLS (\u03bb = 0),\n\u2022 For the LLS we used a Gaussian kernel and select the kernel variation parameter from {0.1,1,10,100,1000},\n\u2022 For the random forests (RF), we used the Scikit-learn [Pedregosa et al., 2011] implementation and varied the number of trees in {10,50,100}.\nFor the final models obtained, we computed the MSE, the mean absolute error (MAE), and both metrics\u2019 standard deviations. Also, we evaluated the fitting time (in seconds) for every technique (including the cross-validation). These experiments were performed on an AMD Ryzen 7 1800X CPU running at 3.6Gz. Table 2 shows the obtained results.\nNLS either outperforms or has a similar performance against both LLS and NN in all of the datasets. When compared to random forests, NLS was the best in one out of four datasets. As the NLS is estimated through neural networks, one could expect its performance to be poor on small training sets. However, the results for Boston housing data indicate that NLS can also lead to good predictions for small datasets. The training time of NLS is high (especially on high dimensional data), but, contrary to LLS, its predictions are fast to compute. There is also no need to fit an additional interpreter such as LIME to NLS on prediction time."
    },
    {
      "heading": "3.1 Sample size effect and computational time",
      "text": "Next, we use the Amazon fine foods dataset to check how the sample size affects both the quality and the fitting time of the models used in our previous experiments. In this experiment, we selected different sample sizes ranging from\n1,000 to 100,000. For each sample size, we perform the same experiment described earlier in Section 3. Figure 4 (top) shows how the test mean squared error of each method varies as a function of the sample size. While for smaller sample sizes, random forests give better predictions, NLS becomes comparable to the other methods for n > 5000. Figure 4 (bottom) shows how the total fitting time (including cross-validation) of each method varies as a function of the sample size. For small sample sizes, NLS is slow relative to the competing approaches, but for larger sample sizes, it becomes faster than the also easy-to-interpret LLS."
    },
    {
      "heading": "3.2 The choice of \u03bb",
      "text": "In this section we explore the role of the regularization parameter \u03bb from Equation 3.\nIn practice, to have an easy-to-interpret NLS that still yields good predictive performance, we successively increase \u03bb and check how the hold-out MSE varies. To reduce fitting time, for each \u03bb step, we initialize the network with the weights obtained in the last \u03bb that was used. We illustrate this procedure using the Boston housing dataset. We start with the NLS fitted in Section 3 and refit it for \u03bb \u2208 (0,\u221e]. Figure 5 illustrates how the MSE and average squared gradient vary as a function of \u03bb both in the training and testing samples. The figure shows that an accuracyinterpretability trade-off occurs for the training data. On the other hand, in the test set, there is no big loss on in-\ncreasing penalization factor \u03bb in the interval [0,50]; in fact, increasing \u03bb can slightly decrease the MSE: the fit with \u03bb = 5 leads to the best test MSE value (3.61). An explanation for this fact is that the penalization controls\u0398(x) variation, and thus controls over-fitting over the training data. Also notice that \u03bb = 5 leads to substantially smoother solutions (bottom plot). Thus, in practice choosing\u03bb by data-splitting can give good prediction errors while maintaining an interpretable solution."
    },
    {
      "heading": "3.3 NLS interpretation",
      "text": "In machine learning, there is a debate about what a good prediction explanation is [Doshi-Velez and Kim, 2017]. For example, Ribeiro et al. [2018] suggest that good explanations are the ones that allow human users to reproduce the regression function predictions for new samples with high accuracy after analyzing a set of given predictions and their explanations. In this section, we show how high penalization values allows users to reproduce NLS predictions. We use the Boston housing dataset as an example.\nAs \u03bb increases, we want to guarantee that NLS interpretations get more accurate in the sense proposed by Ribeiro et al. [2018]. That is, we want to guarantee that, given a set of predicted instances with their explanations, a naive algorithm can reproduce NLS predictions with high accuracy if \u03bb is large. To test this statement, we use a set of given predictions and their explanations (i.e., the coefficients \u03b8i\nattached to them) to obtain predictions for an unseen instance xe through a 1 nearest neighbor approach. We then compare such predictions to the true prediction for this instance, true_pred(xe) \u2236= \u03b8\u03020+\u2211 d k=1 \u03b8\u0302k(xe)xk . Algorithm 1 describes the procedure for a fixed \u03bb. To ensure that extended predictions through interpretations are accurate, such predictions need to be compared to the ones given by the NLS. That is, we want to have low \u2223extended_pred(xei )\u2212 true_pred(x e i )\u2223 on average. We split the test set (3/4 as prediction instances and the remaining as extension instances) and use Algorithm 1 for \u03bb values in [2,\u221e], and then compute such averages. Figure 6 illustrates the results. The figure corroborates that the penalization strength \u03bb leads to an accuracy-interpretability trade-off in the sense of Ribeiro et al. [2018]."
    },
    {
      "heading": "3.3.1 Comparison to LIME",
      "text": "In this section, we apply NLS to the same religion dataset used to showcase LIME [Ribeiro et al., 2016]. The goal is to verify if NLS leads to similar predictive power and captures similar explanations to the ones found in that paper. Figure 7 shows the most relevant features that explain the predictions for this instance. These are words that appear in the mail header and not on its body. This finding is similar to the one obtained by applying LIME to a SVM model (see Ribeiro et al. 2016, Figure 2, right pannel), and indicates that the dataset has issues. Furthermore, the accuracy obtained by NLS is 95,6%, which is slightly larger than the one obtained by a SVM with RBF kernel (94% according\nto Ribeiro et al. 2016). We conclude that for this example, the NLS (i) has slightly better predictive performance than SVM, and, at the same time, (ii) is able to give meaningful explanations."
    },
    {
      "heading": "4 Conclusion and future work",
      "text": "NLS is a prediction technique that enforces a local linear shape to a neural network. While NLS is able to represent the same functions as the usual predictive networks, it also allows users to make accurate interpretations directly using the estimated coefficients, which are the output of the network. NLS presents some advantages when compared to local linear smoothers, as NLS is more robust to irrelevant features and generates predictions with almost no computation cost. We have also shown that NLS produces easy to interpret and accurate explanations for the given predictions in the sense proposed by [Ribeiro et al., 2018]. Moreover, these explanations were comparable to those made by LIME in our experiments.\nIn future work, we wish to apply the NLS on classification datasets. Also, we will investigate alternative loss functions for NLS that penalize non-sparse solutions. These alterna-\nAlgorithm 1 Extending interpretations to replicate predictions Input: A set of prediction instances {xp1 , ..., x p n}, a set of extension instances {xe1, ..., xen}. Output: Predictions obtained though interpretation extension for the extension instances.\n1: for xei \u2208 {x e 1, ...,x e n} do 2: Obtain xneigh = argminxpj \u2208{x p 1 ,...,x p n)d(x e i ,x p j ) 3: Obtain \u03b8\u03021(xneigh), ..., \u03b8\u0302d(xneigh) through NLS 4: Evaluate\nextended_pred(xei ) \u2236= \u03b8\u03020+ d\n\u2211 k=1\n\u03b8\u0302k(xneigh)x e i ,k\n5: end for\ntive loss functions will ensure that the NLS is still highly interpretable on high dimensional applications."
    },
    {
      "heading": "Acknowledgments",
      "text": "Victor Coscrato and Marco In\u00e1cio are grateful for the financial support of CAPES: this study was financed in part by the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior - Brasil (CAPES) - Finance Code 001. Rafael Izbicki is grateful for the financial support of FAPESP (grants 2017/03363-8 and 2019/11321-9) and CNPq (grant 306943/2017-4). Tiago Botari acknowledges support by Grant 2017/06161-7, S\u00e3o Paulo Research Foundation (FAPESP). This paper partially emanates from research supported by a grant from Science Foundation Ireland under Grant No. 18/CRT/6223 which is co-funded under the European Regional Development Fund. The authors are also grateful for the suggestions given by Derek Bridge, Andr\u00e9 C. P. L. F. Carvalho, Murilo C. Naldi, Marcos O. Prates, Diego F. Silva, and Rafael Stern."
    },
    {
      "heading": "Appendix: proof",
      "text": "Proof of Theorem 2.1. Because h(x) \u2236= r(x)x1 is also continuous, it follows from the universal representation theorem [Cybenko, 1989] that there exists a neural network with output N(x) such that\n\u2223h(x)\u2212N(x)\u2223 < \u00b2\nfor every x \u2208 (0,1)d . Now, let \u03b81(x) = N(x), \u03b80 = 0, and \u03b8i (x) \u2261 0 for every i > 1, and thus G\u0398(x) = \u03b81(x)x1. Because 0 < x1 < 1, it follows that\n\u2223r(x)\u2212G\u0398(x)\u2223 = \u2223r(x)\u2212N(x)x1\u2223 \u2264\n\u2223 r(x)\nx1 \u2212N(x)\u2223 = \u2223h(x)\u2212N(x)\u2223 < \u00b2,\nwhich concludes the proof."
    }
  ],
  "title": "NLS: an accurate and yet easy-to-interpret regression method",
  "year": 2019
}
