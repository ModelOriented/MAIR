{
  "abstractText": "High availability of data is responsible for the current trends in Artificial Intelligence (AI) and Machine Learning (ML). However, high-grade datasets are reluctantly shared between actors because of lacking trust and fear of losing control. Provenance tracing systems are a possible measure to build trust by improving transparency. Especially the tracing of AI assets along complete AI value chains bears various challenges such as trust, privacy, confidentiality, traceability, and fair remuneration. In this paper we design a graph-based provenance model for AI assets and their relations within an AI value chain. Moreover, we propose a protocol to exchange AI assets securely to selected parties. The provenance model and exchange protocol are then combined and implemented as a smart contract on a permission-less blockchain. We show how the smart contract enables the tracing of AI assets in an existing industry use case while solving all challenges. Consequently, our smart contract helps to increase traceability and transparency, encourages trust between actors and thus fosters collaboration between them.",
  "authors": [
    {
      "affiliations": [],
      "name": "Philipp L\u00fcthi"
    },
    {
      "affiliations": [],
      "name": "Marcel Gygli"
    },
    {
      "affiliations": [],
      "name": "Thibault Gagnaux"
    }
  ],
  "id": "SP:f201c27f0e7133669b570a0df02ed191011738fc",
  "references": [
    {
      "authors": [
        "J.A. Bondy",
        "Murty",
        "U.S.R"
      ],
      "title": "Graph Theory with Applications, vol",
      "venue": "290. Macmillan London",
      "year": 1976
    },
    {
      "authors": [
        "P. Buneman",
        "S. Khanna",
        "T. Wang-Chiew"
      ],
      "title": "Why and where: A characterization of data provenance",
      "venue": "International Conference on Database Theory",
      "year": 2001
    },
    {
      "authors": [
        "V Buterin"
      ],
      "title": "A next-generation smart contract and decentralized application platform",
      "venue": "white paper 3, 37",
      "year": 2014
    },
    {
      "authors": [
        "C.D. Clack",
        "V.A. Bakshi",
        "L. Braine"
      ],
      "title": "Smart Contract Templates: Foundations, Design Landscape and Research Directions",
      "venue": "arXiv:1608.00771 [cs]",
      "year": 2016
    },
    {
      "authors": [
        "M. Crosby",
        "P. Pattanayak",
        "S. Verma",
        "V Kalyanaraman"
      ],
      "title": "Blockchain Technology: Beyond Bitcoin",
      "venue": "Applied Innovation 2(6-10), 71",
      "year": 2016
    },
    {
      "authors": [
        "J. Dean",
        "S. Ghemawat"
      ],
      "title": "MapReduce: Simplified data processing on large clusters",
      "venue": "Communications of the ACM",
      "year": 2008
    },
    {
      "authors": [
        "T. Economist"
      ],
      "title": "The world\u2019s most valuable resource is no longer oil, but data",
      "venue": "The Economist: New York, NY, USA",
      "year": 2017
    },
    {
      "authors": [
        "J. Kone\u010dn\u00fd",
        "H.B. McMahan",
        "F.X. Yu",
        "P. Richt\u00e1rik",
        "A.T. Suresh",
        "D. Bacon"
      ],
      "title": "Federated Learning: Strategies for Improving Communication Efficiency",
      "venue": "arXiv:1610.05492 [cs]",
      "year": 2016
    },
    {
      "authors": [
        "A. Labrinidis",
        "H.V. Jagadish"
      ],
      "title": "Challenges and opportunities with big data",
      "venue": "Proceedings of the VLDB Endowment",
      "year": 2012
    },
    {
      "authors": [
        "X. Liang",
        "S. Shetty",
        "D. Tosh",
        "C. Kamhoua",
        "K. Kwiat",
        "L. Njilla"
      ],
      "title": "Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability",
      "venue": "Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",
      "year": 2017
    },
    {
      "authors": [
        "G. Litjens",
        "T. Kooi",
        "B.E. Bejnordi",
        "A.A.A. Setio",
        "F. Ciompi",
        "M. Ghafoorian",
        "van der Laak",
        "J.A.W.M.",
        "B. van Ginneken",
        "C.I. S\u00e1nchez"
      ],
      "title": "A survey on deep learning in medical image analysis",
      "venue": "Medical image analysis",
      "year": 2017
    },
    {
      "authors": [
        "T. Llewellyn",
        "M.F. Carrobles",
        "O. Deniz",
        "S. Fricker",
        "A. Storkey",
        "N. Pazos",
        "G. Velikic",
        "K. Leufgen",
        "R. Dahyot",
        "S Koller"
      ],
      "title": "BONSEYES: Platform for Open Development of Systems of Artificial Intelligence",
      "venue": "ACM International Conference on Computing Frontiers 2017. ACM Digital Library",
      "year": 2017
    },
    {
      "authors": [
        "S. Ma",
        "Y. Aafer",
        "Z. Xu",
        "W.C. Lee",
        "J. Zhai",
        "Y. Liu",
        "X. Zhang"
      ],
      "title": "LAMP: Data provenance for graph based machine learning algorithms through derivative computation",
      "venue": "Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering",
      "year": 2017
    },
    {
      "authors": [
        "R. Maull",
        "P. Godsiff",
        "C. Mulligan",
        "A. Brown",
        "B. Kewell"
      ],
      "title": "Distributed Ledger Technology: Applications and Implications",
      "venue": "Strategic Change 26(5), 481\u2013489",
      "year": 2017
    },
    {
      "authors": [
        "H. Park",
        "R. Ikeda",
        "J. Widom"
      ],
      "title": "Ramp: A system for capturing and tracing provenance in mapreduce workflows",
      "year": 2011
    },
    {
      "authors": [
        "A. Ramachandran",
        "M. Kantarcioglu"
      ],
      "title": "Smartprovenance: A distributed, blockchain based dataprovenance system",
      "venue": "Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy",
      "year": 2018
    },
    {
      "authors": [
        "K. Sarpatwar",
        "R. Vaculin",
        "H. Min",
        "G. Su",
        "T. Heath",
        "G. Ganapavarapu",
        "D. Dillenberger"
      ],
      "title": "Towards Enabling Trusted Artificial Intelligence via Blockchain",
      "venue": "Calo, S., Bertino, E., Verma, D. (eds.) Policy-Based Autonomic Data Governance, vol. 11550, pp. 137\u2013153. Springer International Publishing, Cham",
      "year": 2019
    },
    {
      "authors": [
        "S. Schelter",
        "J.H. Boese",
        "J. Kirschnick",
        "T. Klein",
        "S. Seufert"
      ],
      "title": "Automatically tracking metadata and provenance of machine learning experiments",
      "venue": "Machine Learning Systems Workshop at NIPS",
      "year": 2017
    },
    {
      "authors": [
        "R. Stauder",
        "D. Ostler",
        "T. Vogel",
        "D. Wilhelm",
        "S. Koller",
        "M. Kranzfelder",
        "N. Navab"
      ],
      "title": "Surgical data processing for smart intraoperative assistance systems",
      "venue": "Innovative Surgical Sciences 2(3), 145\u2013152",
      "year": 2017
    },
    {
      "authors": [
        "R.B. Thomas H. Davenport"
      ],
      "title": "Big Data and AI Executive Survey 2019",
      "venue": "Tech. rep., NewVantage Partners (NVP)",
      "year": 2019
    },
    {
      "authors": [
        "G Wood"
      ],
      "title": "Ethereum: A Secure Decentralised Generalised Transaction Ledger",
      "venue": "Ethereum project yellow paper 151, 1\u201332",
      "year": 2014
    },
    {
      "authors": [
        "A. Woodruff",
        "M. Stonebraker"
      ],
      "title": "Supporting fine-grained data lineage in a database visualization environment",
      "venue": "Proceedings 13th International Conference on Data Engineering",
      "year": 1997
    }
  ],
  "sections": [
    {
      "text": "Keywords: Artificial Intelligence \u00b7 Blockchain \u00b7 Transparency \u00b7 Provenance."
    },
    {
      "heading": "1 Introduction",
      "text": "Artificial intelligence (AI) is continuously becoming more critical for businesses. As reported by the Big Data and AI Executive Survey 2019 92% of the firms are increasing their pace of investing in Artificial Intelligence and Big Data [21]. The availability of data drives AI development. Google, for example, surpassed 3 billion searches worldwide per day in 2012 [8]. Moreover, data has replaced oil as the most valuable resource and is becoming the new currency of the digital era [7].\nCreating value from data consists of multiple steps. For Machine Learning (ML), Baylor et al. identified eight steps shown in Figure 1. Between each of these phases, value is passed in the form of assets. Value chains are created by linking these assets together, named AI value chain if all involved assets are relevant for the creation of an AI solution. Machine or deep-learning that are ? equal contribution\nar X\niv :2\n00 2.\n11 00\n0v 1\n[ cs\n.C R\n] 2\n5 Fe\nb 20\nused to solve a defined task such as medical image analysis [12] are examples of AI value chains.\nToday, an AI value chain often involves experts from different organizations. It is also possible that multiple value chains coexist or interact with each other as shown in Figure 2. As a result, AI assets need to be exchanged between actors possibly merging or splitting value chains. The figure shows how three different companies exchange AI assets to create value. Additionally, points of friction are shown where challenges arise. These are the challenges we address within this work.\nParticipants of such AI value chains face several challenges when they try to exchange AI assets:\nTrust is one of the core issues that need to be addressed. Currently, when handing over an AI asset, the provider needs to trust the receiver as well as the medium of transfer because they lose sovereignty and control over the asset. This\nsetting discourages the sharing of AI assets because there are no good systems that allow creating such trust between two parties that do not know each other. Privacy: From a provider\u2019s perspective, it is vital to know how their asset is used to prevent abuse. Especially if personal information is in the data, data regulations such as GDPR1 might apply. We do not aim at providing a solution towards data privacy within this work, but are interested in providing solutions such that data providers can keep track where data is being used. In regards to GDPR, this would potentially enable the retraction of data items from multiple AI value chains at once. Confidentiality: A provider has a key interest in keeping their assets either private or only visible to a selected number of other actors. This allows providers to protect their business interests and for example share sensitive data only with certified companies. Traceability, Transparency & Auditability: If AI assets are exchanged without their provenance, the receiver may not have any possibility to verify their correctness. By verifying the asset\u2019s correctness, errors that otherwise might propagate through the value chain unnoticed can be detected early. Fair Remuneration: A provider wants to know who is making use of their assets to claim their reward. From a receiver\u2019s perspective, it might be of interest to identify the involved actors to fairly compensate them.\nDistributed Ledger Technology (DLT) [15] allows creating a distributed database, spread across many nodes. Blockchain [5] is one of the most prominent concepts for the actual implementation of DLT. In a blockchain all blocks are cryptographically linked with one another, depending on the data that is stored within them. This ensures that data cannot be modified once it has been stored.\nIn this paper, we introduce a smart contract [4] concept that allows tracking the provenance of AI assets along their value chains. The smart contract can be deployed on the Ethereum blockchain [22]. Data providers will be able to register their data using the smart contract and data consumers can register how they used this data and what kind of operations they applied on it. This smart contract creates trust for all involved parties, as it allows for independent auditing of all registered transactions to verify its integrity. We will show how this approach solves the privacy, auditability, and fair remuneration challenges.\nThe rest of the paper is structured as follows: Section 2 describes the approaches and solutions of other provenance systems and identifies a gap that we will address. Section 3 illustrates how we define our provenance model and how it solves the first three challenges privacy, auditability and fair remuneration. Section 4 shows the functionality of the smart contract and the protocol specification that allow us to solve the remaining trust and confidentiality challenges. We validate our solution using a real-world medical use case in Section 5. The paper closes with a discussion and pointers towards future work.\n1 See https://eugdpr.org"
    },
    {
      "heading": "2 Related Work",
      "text": "In the following, we introduce existing approaches for the purpose of tracing the provenance of data in AI, and then existing provenance tracing solutions that are using blockchain technology. We discuss these approaches, introduce the limitations of existing approaches and identify a gap that we address within this work."
    },
    {
      "heading": "2.1 Provenance Tracing for Data in AI Development",
      "text": "With the rise of Big Data, traditional data processing and provenance tracing [23,2] became inapplicable. However, Provenance tracking has been identified as a key requirement for Big Data applications [10]. MapReduce [6] is a specialized framework enabling parallel processing of high volume data. Provenance capturing for MapReduce workflows is possible. Park et al. developed RAMP [16], a provenance capturing system that extends Hadoop2.\nIn the area of machine learning, tracking the provenance of data points and training algorithms can be automated. The importance of single data points can be calculated. Ma et al. designed LAMP [14] to automate the partial derivative calculation of each data point evaluating its importance on the machine learning algorithm\u2019s result. Schelter et al. designed a system [19] that automatically extracts and stores provenance information of common artifacts in machine learning experiments. The system can be integrated into many popular machine learning frameworks to improve the reproducibility and comparability of machine learning experiments."
    },
    {
      "heading": "2.2 Provenance Tracing Using Blockchain",
      "text": "Blockchain technology is well suited in environments where trust between actors is needed as it makes a middleman obsolete. Additionally, storing provenance information on a blockchain is beneficial due to its immutable nature. Liang et al. [11] introduce ProvChain, a cloud architecture that gathers and validates provenance data by inserting them into blockchain transactions. Also, ProvChain provides security features such as tamper-proof provenance and user privacy.\nRamachandran and Kantarcioglu [17] use Ethereum to develop a secure and immutable scientific data provenance management framework called SmartProvenance that validates the provenance data using a use case-tailored verification script. During the verification, involved actors approve or reject proposed changes in a voting process.\nProvChain and SmartProvenance focus on tracking provenance on a single file and solve auditability by storing each file change on the blockchain. As they have only one value chain they do not need to address trust or confidentiality.\nSarpatwar et al. [18] combined blockchain and AI and propose a concept for trusted AI. They illustrate the needed requirements and key blockchain constructs for trusted AI and demonstrate how these can be used to represent 2 See https://hadoop.apache.org\nprovenance using a federated learning [9] use case. For their specific use case, they did not need to address the trust and confidentiality challenges. They also do not address the issue of auditability of data."
    },
    {
      "heading": "2.3 Limitations of State of the Art",
      "text": "Existing solutions allow storing provenance of digital assets on central or distributed databases [23,2]. These databases are controlled by a single authority, making them vulnerable to untruthful modification. This requires the trust of all involved parties into this central authority, which hinders collaboration.\nFor Big Data and machine learning workflows, provenance tracking of individual data points with traditional databases is not feasible. Therefore, specialized frameworks have been developed that allow tracing the provenance using MapReduce.\nBlockchain technology allows storing provenance without the need for a centralized authority. Consequently, all actors can participate equally and validate the transactions of other actors. Furthermore, provenance information stored on the blockchain is immutable and therefore false modifications are impossible.\nExisting blockchain solutions can track the changes applied to single digital assets and AI models trained in a federated learning scenario. They, however, cannot trace all phases of a typical AI development workflow. In particular, the exchange and transformation of AI assets between interacting AI value chains are not supported, as can be seen in Figure 2. For example, it is not possible to track how data is collected or transformed before it is used for AI model training. Furthermore, current blockchain solutions do not address how assets can be shared confidentially and selectively. The models trained in federated learning are directly stored on the blockchain and thus publicly accessible.\nNone of the abovementioned works cover all outlined challenges in a sufficient manner. This calls for further research on how to design a system that addresses all of them. In this work, we generalize the provenance model of Sarpatwar et al. [18] to be able to represent interacting AI value chains of any sort. Additionally, we build a system that stores this provenance model and supports the exchange of confidential assets without the need for a centralized authority."
    },
    {
      "heading": "3 Provenance Model for AI Assets on a Public Permission-less Blockchain",
      "text": "Our provenance model extends the model of Sarpatwar et al. [18], which differentiates between datasets, operations, and models. This existing concept solves the privacy, auditability, and fair remuneration within the federated learning [9] context. Thus, it has several limitations: Datasets and models can exist only with a corresponding operation and the types of operations are finite. Operations always result in a model. Trust is generated by making generated models as well as their coefficients public. Confidentiality is addressed only for private\ndatasets. Besides, their provenance model does not allow to track transformations on datasets and thus does not solve any challenges for general interacting value chains where an exchange of datasets is needed as illustrated in Figure 2.\nOur goal is to generalize this provenance model and support interacting AI value chains and add the ability to track datasets and models without the need for the corresponding operation. Furthermore, the provenance model will allow participants to define their operations. To achieve this goal we redefine the three types of AI assets and their relations as follows:\nOperation: An operation may represent any executable algorithm. In an AI value chain operations might be used for data collection, transformation, combination, reduction, analysis, training, etc. Multiple operations can be combined into one single operation as shown in Figure 3a. Dataset: A dataset represents any composition of digital data. A dataset might be transformed (e.g. an anonymization algorithm) resulting in a new dataset as shown in Figure 3b or multiple datasets might be reduced (e.g. a filtering algorithm) to one dataset as shown in Figure 3c. Model: Combining an operation with a dataset (e.g. a classification algorithm) can result in a model as shown in Figure 3d. Additionally, combining a model, a dataset and an operation might result in a new model (e.g. transfer learning) as shown in Figure 3e. Lastly, multiple models can be combined into one model (e.g., through federated learning) as shown in figure 3f.\nWe represent the provenance model as a directed acyclic graph (DAG) [1] with nodes representing the AI assets. Edges in this graph either represent a Parent Of or Child Of relationship between two assets. Figure 4 shows how the interacting value chains of Figure 4 are transformed into this graph. The \u201cCollection Algorithm\u201d is a parent of \u201cDataset B\u201d, and similarly \u201cAI Model B\u201d is a child of \u201cDataset B\u201d.\nUsing this graph representation, the traceability, fair remuneration, and privacy challenges can be solved using graph traversal algorithms. This will be shown in detail in Section 4.3."
    },
    {
      "heading": "4 Implementation",
      "text": "In this section, we propose the implementation of the provenance model outlined in Section 3 on a public blockchain. Our implementation introduces the possibility to exchange confidential AI assets between different actors, therefore addressing the confidentiality challenges. We use the Ethereum blockchain [22] as a deployment and execution framework. In this framework, code is executed through so-called smart contracts [3]. These smart contracts can write data in two different ways State Storage or Logs. State Storage stores information directly in the state of the smart contract and can be modified by it. Logs are a cheaper form of data storage that can not be read or modified by the smart contract. When Logs are written to the blockchain they emit events on the smart contract, for which client applications are able to listen to.\nAdditionally, we define a protocol to interact with our implementation. Based on this protocol, we will show how we provide solutions for all challenges introduced in Section 1. Every client that implements the protocol accordingly, helps to build and enforce provenance, therefore increasing trust into the registered AI assets."
    },
    {
      "heading": "4.1 System Overview",
      "text": "Our system is comprised of a smart contract and a protocol specification to interact with it as shown in Figure 5. The smart contract writes the results of all actions performed on it into the blockchain. By specifying what information is stored the contract enforces the provenance model from Section 3. The protocol specification defines how to work with the smart contract in such a way that\nthe stored information can be retrieved and the provenance model can be built. Furthermore, the protocol defines the exchange of AI assets between actors. This protocol specification is necessary as otherwise, every actor could use the smart contract differently, making it hard to use the information stored on the blockchain. Finally, a client will be responsible for making these interactions accessible to a human actor. All interactions performed by such a client will use the Ethereum account provided by the actor."
    },
    {
      "heading": "4.2 Smart Contract",
      "text": "The smart contract exposes the functionality that Clients will interact with. For our use, the smart contract will only store information in immutable Logs by executing events. These logs are searchable and remain retrievable forever. All information stored in logs this way is publicly accessible. Additionally, blockchain technology does not allow to store large amounts of data directly on the blockchain. Confidential data should, therefore, be encrypted and stored on an external storage solution as shown in Figure 5. Our protocol will introduce a way for exchanging such encrypted data that is provided through such storage solutions.\nTable 1 shows all functions exposed by the smart contract. A new AI asset is registered using the addAsset function providing the following information: An asset identifier which is generated by computing a hash of the data item that is provided with the asset; The URL through which the data item of the asset can be retrieved; Additional meta-information that describes the contents of the asset; This information needs to be provided as a JSON object. The set of parents that are in a relationship with this asset. When the smart contract is executed, the maintainer of the asset is automatically set to the user that called the function.\nThe execution of this function will trigger several events, which in turn will store the information as logs on the blockchain. Listing 4.1 shows the events related to the provenance tracking of AI assets. When an AI asset is registered, the following events are emitted: A Register event that writes a log with the\nTable 1. Functions exposed on the smart contract, their description and required parameters.\nFunction Description addAsset Register a new AI asset. The caller of the function will automatically be assigned as maintainer. transfer Transfer ownership of an AI asset from one blockchain user to another. This operation can only be performed by the maintainer of the asset. addUrl Add a download URL to an asset. This operation can only be performed by the maintainer of the asset. requestAccess Request access to an AI asset. This operation can be performed by any blockchain user. grantAccess Grant access to an AI asset. This operation can only be performed by the maintainer of the asset. getMaintainer Retrieve maintainer of an AI asset. This operation can be performed by\nany blockchain user.\nmetadata of the asset, as well as a URL event that stores the URL. Lastly, all parents are written using ParentOf events and the inverse ChildOf events to ensure that the provenance graph remains in order and without cycles.\nThe FormerMaintainer event is only used when the ownership of an AI asset changes. Using these events allows us to store the complete provenance model to the blockchain, and therefore solve the privacy, auditability, and fair remuneration challenges.\nevent Register(asset_id, metadata); event URL(asset_id, url); event FormerMaintainer(asset_id, previous_maintainer); event ParentOf(asset_id, parent_id); event ChildOf(asset_id, child_id);\nListing 4.1. Provenance related events of the smart contract\nTo address the trust and confidentiality challenges, the smart contract needs to provide the functionality to exchange AI assets between actors in a confidential manner. This works under the assumption that the data item, that can be downloaded from an AI asset URL, is encrypted. The smart contract provides the two functions requestAccess and grantAccess that facilitate the exchange of the cryptographic information needed to decrypt the asset. Listing 4.2 shows the additional events that store this information on the blockchain in the form of logs. In the following section, we will introduce how the protocol specification facilitates this exchange.\nevent RequestAccess(asset_id, accessor, encryption_algorithm, public_key); event GrantAccess(asset_id, accessor, encrypted_AEK);\nListing 4.2. Event logs on the smart contract for the exchange of AI assets"
    },
    {
      "heading": "4.3 Protocol Specification",
      "text": "The smart contract specification from above defines a set of functionality that can be used by any application. To ensure that all applications use the smart contract in the same fashion, we design an interaction protocol. This will allow all systems implementing this protocol to rebuild the complete provenance of all AI assets stored on the blockchain. Interactions with the smart contract are enabled through the JSON-RPC interface provided by the Ethereum network3.\nRegistration: Registering an AI asset is the key step to enable provenance for any asset. Figure 6a shows a sequence diagram of the protocol. It will insert a new node into the provenance model and make it visible to others. As already outlined, our system only supports assets that are made available through an external file storage provider. Should the asset contain multiple files, it can be compressed into a ZIP file. First, the Client computes a hash of the file to generate the asset identifier, and then encrypts it. We call the encryption key used in this process the Asset Encryption Key (AEK) and it will be later used when access to an asset is granted. Using the addAsset function of the smart contract, the asset is then registered on the blockchain, and the account making this request will automatically become the maintainer of the asset.\nAccessing AI assets: To solve the confidentiality challenge the data files representing an asset are encrypted as shown previously. The smart contract and the protocol need to provide ways for exchanging the cryptographic material in a secure way that is registered on the blockchain. Providing access to an AI asset needs an action of two actors. First, the accessor creates an encryption key pair consisting of a private (PrK) and public key (PuK). Then, they start the access process using the requestAccess method of the smart contract, indicating the asset with its identifier. A Client on the premises of the maintainer will react to the emitted RequestAccess event. If access should be granted the maintainer encrypts the AEK with the provided PuK, and invokes the grantAc3 https://github.com/ethereum/wiki/wiki/JSON-RPC\ncess method on the smart contract. The Client of the accessor listens for the emitted GrantAccess event containing the encrypted AEK that they will be able to decrypt using their PrK. This then will allow them to download the asset from the external storage and decrypt it using the AEK. The sequence diagram of this protocol is provided in Figure 6b. Our system does not prevent misuse of the keys by the involved parties, e.g. the receiver simply providing the AEK to third-parties. But the maintainer at least knows exactly whom they provided access to, limiting the number of potential bad actors. It would also allow for the creation of systems that would automatically take the actual assets offline.\nRetrieve accessors: We solve the outlined privacy challenge by making it possible for a maintainer to retrieve a list of actors who possibly accessed their AI assets. As the smart contract emits the GrantAccess event for all granted access requests, this can be solved easily. A client can retrieve and filter all past events using the Ethereum JSON-RPC API. Using this information, a client can then visualize for each AI asset, which Ethereum accounts currently have access. In the case of Data Erasure requests through the GDPR, the maintainer can then notify all users of such a data item to remove it as well.\nRetrieve Usages & Build Provenance: Finally, we need to provide a solution for the traceability and fair remuneration challenges. We represent the potential usage of an AI asset if it is linked in a ParentOf relationship to any other AI asset. This also means that we can solve both challenges by building the provenance graph. As our provenance model is represented by an acyclic graph, we are able to compute it using existing graph traveling algorithms. A Client can build the provenance graph by retrieving the ParentOf events recursively, starting with the AI asset they are interested in.\nThis shows, that the protocol, combined with our generalized provenance model, addresses all challenges in Section 1."
    },
    {
      "heading": "5 Validation",
      "text": "We validate our implementation by modeling the provenance of the Surgical Workflow Recognition for Collaborative Operation Theatre [20] use case. The use case has been documented within the Bonseyes [13] project and reflects existing real-world use cases. In this section, we first introduce the use case, its actors, actions, and involved AI assets. We then translate this use case into the provenance model introduced in Section 3. For simplicity, we abstract the use case and focus on the provenance affecting actions and the AI assets involved. We show which actors interact with the smart contract and present the resulting provenance model. Furthermore, we look into the costs of registering assets on the blockchain."
    },
    {
      "heading": "5.1 Medical Use Case",
      "text": "In Figure 7a we show the complete use case. It covers all steps of a machine learning workflow from data collection to model deployment. The goal of this use\ncase is to develop AI models that support surgery inside the operation theatre. Data is acquired from different sources in an operation theatre (e.g. cameras, and sensors). The data collected during this phase is processed and managed by the data management action. Different filter and anonymization algorithms support the data management action, all represented in a single action. The result of this action is heterogeneous but anonymized RAW data. Before labeling the data needs to be pre-processed. This is performed by an algorithm that transforms and possibly aggregates the RAW data into a new dataset containing unlabeled data. This data is then fed into a labeling tool where expert labelers annotate the data.\nAs a result, we end up with a dataset viable for model development. Models are generated within the university hospital (e.g. by students) and externally by partners. In order to be able to compare the generated models, the data is split into three parts (training, validation, and testing). Only the training and validation datasets are made available to the development teams such that the testing dataset can be used for final evaluation. For the external partners, the data leaves the network of the hospital for the first time. Each development party uses its training algorithms that use the training data to generate an ML model. These algorithms, as well as the resulting models, need to be registered using the smart contract. Once the external parties provide their models back to the hospital, they again cross network boundaries. For an audit of the training method, also the training algorithm might be exchanged. The developed models will go through the model evaluation activity before they might get integrated into smart services."
    },
    {
      "heading": "5.2 Smart Contract Interactions and Costs for TUM Use Case",
      "text": "Along the outlined value chain, various AI assets are created and need to be registered on the smart contract. As data acquisition and data management are performed in sequence by the same actor, we abstract these two actions into one. In Figure 7b, we show all AI assets identified in the value chain and the corresponding provenance graph. Each of these assets is registered according to our protocol definition. As in the real world, we use separate Ethereum accounts for every involved actor.\nIn Table 2, we list the costs for each action that occurs inside the presented use case. These actions correspond with the smart contract interactions presented in Table 1 using the protocol introduced in Section 4.3. Ether is the currency on the Ethereum blockchain and gas is the execution fee for an operation. Each interaction with the smart contract costs around 0.15 USD. The variations in costs are explained by the different amount of metadata that is provided for each AI asset. Therefore, the complete provenance model of the outlined use case can be stored on the blockchain for less than 3 USD."
    },
    {
      "heading": "5.3 Smart Contract Limitations",
      "text": "As shown above, each execution of a smart contract on the Ethereum Network costs gas. In order to prevent over-complex or non-terminating computations, the network limits the amount of gas a single transaction (or one function call) can use. With the current gas limit, an AI asset can have a maximum of around 1200 parents. In case of tracking complete datasets this might not be an issue, but if one aims at tracking single data points, e.g. for GDPR, this can quickly become an issue. This would force data collectors to create multiple intermediate datasets, where data is incrementally aggregated.\nA second limitation is that the smart contract stores metadata directly on the blockchain, thus making it publicly available. All metadata of registered AI assets are therefore not confidential and accessible by anyone. It remains an open discussion if there is a need for a distinction between required metadata that needs to be publicly available (e.g. for independent audits) and metadata information that can be made private."
    },
    {
      "heading": "6 Discussion",
      "text": "Multiple experts from different companies collaborate in interacting AI value chains by exchanging AI assets. Tracing the provenance of these AI assets from start to finish and especially across different AI value chains bears many challenges including trust, privacy, confidentiality, traceability and fair remuneration as defined in Section 1.\nWe introduce a graph-based provenance model generalizing the federated learning provenance model from Sarpatwar et al. [18] to support interacting value chains by solving the traceability, fair remuneration, and privacy challenges. Furthermore, we provide a smart contract for the Ethereum blockchain implementing the provenance model and removing the need for a middleman, thereby solving the trust challenge. Additionally, the smart contract offers the ability to exchange assets in a confidential manner specified in a protocol fulfilling the confidentiality challenges.\nCombining the provenance model and our protocol definition in a smart contract allowed us to track interacting value chains from start to finish. We validated our smart contract with an industry use case from the Technical University of Munich, covering all phases of a typical machine learning workflow except the model monitoring phase. Our results show that the smart contract is able to sufficiently trace the produced and exchanged AI assets at a low cost, as shown in Table 2.\nComparing our concept to traditional centralized provenance tracing systems, we found that trust is a significant issue when collaborating. Removing the centralized party with a decentralized blockchain increases trust among the participants and encourages collaboration. Other blockchain-based provenance work, such as ProvChain [11] and SmartProvenance [17], exceed at tracking single file changes with sophisticated privacy features but cannot trace AI assets along all phases of value chains and are therefore not addressing the abovementioned challenges. The work of Sarpatwar et al. [18] focuses on enabling trusted AI for interacting value chains performing federated learning. However, as the exchange of datasets is by design not supported, it is not possible to track interacting value chains outside of the federated learning context. This gap is where our contribution steps in providing a solution for all challenges mentioned in Section 1.\nAs every transaction on a blockchain has its cost, our solution has its limitations. We found that, with the current gas limit of ca. 7 \u00d7 106 on Ethereum, we can insert assets referencing up to 1200 other AI assets as parents. We con-\nsider this sufficient for most use cases. Our smart contract was only tested on a local network discarding the waiting time that every transaction generates during block mining. Furthermore, non-deterministic operations such as many AI training algorithms do not allow to reproduce the output asset completely and thus hinder auditability. Finally, every client using our smart contract must implement our protocol to support the confidential exchange of assets as the smart contract is not able to enforce confidentiality without it.\nFor future work, it would be beneficial to test our smart contract with a sophisticated web client on the Ropsten or Ethereum network to include usability related aspects, such as the above mentioned waiting time when registering or exchanging assets. Future extensions of the provenance model\u2019s type definitions, e.g. data streams, might allow increased provenance tracking coverage. Furthermore, a comparison of our solution to a smart contract on a permissioned blockchain such as Hyperledger, which does not need any exchange management in the smart contract would help to decide if the blockchain or the smart contract should be responsible for the management of the AI asset exchange. Finally, zero-knowledge proofs may provide more secure auditability capabilities because access to assets would not be required."
    },
    {
      "heading": "Acknowledgements",
      "text": "The project leading to this application has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 732204 (Bonseyes). This work is supported by the Swiss State Secretariat for Education, Research and Innovation (SERI) under contract numbers 16.0159. The opinions expressed and arguments employed herein do not necessarily reflect the official views of these funding bodies."
    }
  ],
  "title": "Distributed Ledger for Provenance Tracking of Artificial Intelligence Assets",
  "year": 2020
}
