,doc_type,dest_title,source_title,dest_path,source_arxiv_url,match_type,matched_info,matched_text
0,oecd,CIVIL LIABILITY REGIME FOR ARTIFICIAL INTELLIGENCE,"Don't Explain without Verifying Veracity: An Evaluation of Explainable
  AI with Video Activity Recognition",27005.txt,http://arxiv.org/abs/2005.02335v1,by_author_abbreviation,C\. Roy," Dr. soc. 
2001, p. 885, obs. C. Roy-Loustaunau), a lack of informa"
1,oecd,AI AND PRIVACY REPORT,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26958.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"ine-learning-in-the-gdpr/ cf. Sandra Wachter, Brent 
Mittelstadt, Luciano F"
2,oecd,AI AND PRIVACY REPORT,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26958.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"nd 25). 
 
13 See for example Sandra Wachter, Brent Mittelstadt and Chris R"
3,oecd,AI AND PRIVACY REPORT,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26958.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"e for example Sandra Wachter, Brent Mittelstadt and Chris Russel, 
«Counterfac"
4,oecd,MALTA'S NATIONAL AI STRATEGY,Explainable AI for Interpretable Credit Scoring,24994.txt,http://arxiv.org/abs/2012.03749v1,by_author,Alexiei Dingli,"Emanuel Darmanin
Member
Prof. Alexiei Dingli
Member
Dr. Abdalla Kablan
Memb"
5,oecd,MALTA'S NATIONAL AI STRATEGY,Explainable AI for Interpretable Credit Scoring,24994.txt,http://arxiv.org/abs/2012.03749v1,by_author,Alexiei Dingli,"Education and workforce
Prof. Alexiei Dingli (Chair), Carmel Cachia, Gilber"
6,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,X-ToM: Explaining with Theory-of-Mind for Gaining Justified Human Trust,26955.txt,http://arxiv.org/abs/1909.06907v1,by_author_abbreviation,C\. Liu,"019. 
30 
[105]  N. Carlini,  C. Liu,  Ú. Erlingsson,  J. Kos,  and"
7,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explainable Black-Box Attacks Against Model-based Authentication,26955.txt,http://arxiv.org/abs/1810.00024v1,by_author_abbreviation,S\. Jha,", P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami, “P"
8,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explainable Black-Box Attacks Against Model-based Authentication,26955.txt,http://arxiv.org/abs/1810.00024v1,by_author_abbreviation,S\. Jha,"017. 
P. Kiourti, K. Wardega, S. Jha, and W. Li, “TrojDRL: Trojan A"
9,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explainable Black-Box Attacks Against Model-based Authentication,26955.txt,http://arxiv.org/abs/1810.00024v1,by_author_abbreviation,S\. Jha," 
N. Papernot,  P. McDaniel,  S. Jha,  M. Fredrikson,  Z. B.  Celik"
10,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explainable Black-Box Attacks Against Model-based Authentication,26955.txt,http://arxiv.org/abs/1810.00024v1,by_author_abbreviation,S\. Jha,"ernot,  P. McDaniel,  X. Wu,  S. Jha,  and  A. Swami,  “Distillatio"
11,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explainable Black-Box Attacks Against Model-based Authentication,26955.txt,http://arxiv.org/abs/1810.00024v1,by_author_abbreviation,S\. Jha,"2018. 
[106]  M. Fredrikson,  S. Jha, and  T. Ristenpart,  “Model  "
12,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Joint Mind Modeling for Explanation Generation in Complex Human-Robot
  Collaborative Tasks",26955.txt,http://arxiv.org/abs/2007.12803v1,by_author_abbreviation,S\. Wang," 
X. Huang,  M. Kwiatkowska,  S. Wang,  and  M. Wu,  “Safety  verifi"
13,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations,26955.txt,http://arxiv.org/abs/2012.03058v1,by_author_abbreviation,X\. Huang,"n. Springer, 2017, pp. 3–29. 
X. Huang,  M. Kwiatkowska,  S. Wang,  a"
14,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,FairLens: Auditing Black-box Clinical Decision Support Systems,26955.txt,http://arxiv.org/abs/2011.04049v1,by_author_abbreviation,D\. Pedreschi," F. Turini, F. Giannotti, and D. Pedreschi, “A survey of methods for 
[51"
15,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and
  Goals of Human Trust in AI",26955.txt,http://arxiv.org/abs/2010.07487v3,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
16,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,A Grounded Interaction Protocol for Explainable Artificial Intelligence,26955.txt,http://arxiv.org/abs/1903.02409v1,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
17,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Quantitative Evaluations on Saliency Methods: An Experimental Study,26955.txt,http://arxiv.org/abs/2012.15616v1,by_author_abbreviation,X\. Li,"Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classi"
18,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Quantitative Evaluations on Saliency Methods: An Experimental Study,26955.txt,http://arxiv.org/abs/2012.15616v1,by_author_abbreviation,H\. Li,"W), 2018, pp. 1–7. 
B. Liang, H. Li, M. Su, P. Bian, X. Li, and W."
19,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Towards a Grounded Dialog Model for Explainable Artificial Intelligence,26955.txt,http://arxiv.org/abs/1806.08055v1,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
20,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Ada-SISE: Adaptive Semantic Input Sampling for Efficient Explanation of
  Convolutional Neural Networks",26955.txt,http://arxiv.org/abs/2102.07799v1,by_author_abbreviation,H\. Kim,".  Tae,  Y. Roh,  Y. H.  Oh,  H. Kim,  and  S. E.  Whang,  “Data  C"
21,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Explaining Convolutional Neural Networks through Attribution-Based Input
  Sampling and Block-Wise Feature Aggregation",26955.txt,http://arxiv.org/abs/2010.00672v2,by_author_abbreviation,H\. Kim,".  Tae,  Y. Roh,  Y. H.  Oh,  H. Kim,  and  S. E.  Whang,  “Data  C"
22,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Distributed Linguistic Representations in Decision Making: Taxonomy, Key
  Elements and Applications, and Challenges in Data Science and Explainable
  Artificial Intelligence",26955.txt,http://arxiv.org/abs/2008.01499v2,by_author_abbreviation,H\. Zhang,"208–4215. 
M. Cheng,  J. Yi,  H. Zhang,  P.-Y.  Chen,  and  C.-J.  Hs"
23,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Distributed Linguistic Representations in Decision Making: Taxonomy, Key
  Elements and Applications, and Challenges in Data Science and Explainable
  Artificial Intelligence",26955.txt,http://arxiv.org/abs/2008.01499v2,by_author_abbreviation,H\. Zhang,"EE, 2016, pp. 372–387. 
[93] 
H. Zhang,  Y. Yu,  J. Jiao,  E. P.  Xin"
24,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Explanation in Artificial Intelligence: Insights from the Social
  Sciences",26955.txt,http://arxiv.org/abs/1706.07269v3,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
25,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Towards A Rigorous Science of Interpretable Machine Learning,26955.txt,http://arxiv.org/abs/1702.08608v2,by_arxiv_id,1702.08608,"ning: 
[55] 
prints, p. arXiv:1702.08608, 2017. 
F. Doshi-Velez and B."
26,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Towards A Rigorous Science of Interpretable Machine Learning,26955.txt,http://arxiv.org/abs/1702.08608v2,by_author_abbreviation,F\. Doshi-Velez,", p. arXiv:1702.08608, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorou"
27,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Towards A Rigorous Science of Interpretable Machine Learning,26955.txt,http://arxiv.org/abs/1702.08608v2,by_author_abbreviation,B\. Kim,"08, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorous Science o"
28,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Machine Learning: Fundamental Principles and 10 Grand
  Challenges",26955.txt,http://arxiv.org/abs/2103.11251v1,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
29,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for
  Complex Systems",26955.txt,http://arxiv.org/abs/1611.09139v1,by_author_abbreviation,B\. Kim,"08, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorous Science o"
30,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Machine Learning Model for Early Prediction of Mortality
  in Elderly Patients with Multiple Organ Dysfunction Syndrome (MODS): a
  Multicenter Retrospective Study and Cross Validation",26955.txt,http://arxiv.org/abs/2001.10977v1,by_author_abbreviation,C\. Liu,"019. 
30 
[105]  N. Carlini,  C. Liu,  Ú. Erlingsson,  J. Kos,  and"
31,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable machine learning: definitions, methods, and applications",26955.txt,http://arxiv.org/abs/1901.04592v1,by_arxiv_id,1901.04592,"ns,” arXiv e-prints, p. arXiv:1901.04592, Jan. 2019. 
W. J. Murdoch, C"
32,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable machine learning: definitions, methods, and applications",26955.txt,http://arxiv.org/abs/1901.04592v1,by_author_abbreviation,C\. Singh,"2, Jan. 2019. 
W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, an"
33,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable machine learning: definitions, methods, and applications",26955.txt,http://arxiv.org/abs/1901.04592v1,by_author_abbreviation,K\. Kumbier,"19. 
W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu, “In"
34,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable machine learning: definitions, methods, and applications",26955.txt,http://arxiv.org/abs/1901.04592v1,by_author_abbreviation,R\. Abbasi-Asl,"urdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu, “Interpretable mac"
35,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable machine learning: definitions, methods, and applications",26955.txt,http://arxiv.org/abs/1901.04592v1,by_author_abbreviation,B\. Yu,". Kumbier, R. Abbasi-Asl, and B. Yu, “Interpretable machine learni"
36,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Machine Learning Models for the Digital Clock Drawing Test,26955.txt,http://arxiv.org/abs/1606.07163v1,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
37,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"In Pursuit of Interpretable, Fair and Accurate Machine Learning for
  Criminal Recidivism Prediction",26955.txt,http://arxiv.org/abs/2005.04176v1,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
38,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Nothing Else Matters: Model-Agnostic Explanations By Identifying
  Prediction Invariance",26955.txt,http://arxiv.org/abs/1611.05817v1,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
39,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Nothing Else Matters: Model-Agnostic Explanations By Identifying
  Prediction Invariance",26955.txt,http://arxiv.org/abs/1611.05817v1,by_author_abbreviation,C\. Guestrin,"T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  should  I  trust  you?"
40,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"IAIA-BL: A Case-based Interpretable Deep Learning Model for
  Classification of Mass Lesions in Digital Mammography",26955.txt,http://arxiv.org/abs/2103.12308v1,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
41,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Stop Explaining Black Box Machine Learning Models for High Stakes
  Decisions and Use Interpretable Models Instead",26955.txt,http://arxiv.org/abs/1811.10154v3,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
42,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Enriched Annotations for Tumor Attribute Classification from Pathology
  Reports with Limited Labeled Data",26955.txt,http://arxiv.org/abs/2012.08113v1,by_author_abbreviation,B\. Yu,". Kumbier, R. Abbasi-Asl, and B. Yu, “Interpretable machine learni"
43,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,The Doctor Just Won't Accept That!,26955.txt,http://arxiv.org/abs/1711.08037v2,by_author_abbreviation,Z\. C. Lipton,"vol. 1, no. 5, p. 206, 2019. 
Z. C. Lipton, “The mythos of model interpre"
44,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Generalized and Scalable Optimal Sparse Decision Trees,26955.txt,http://arxiv.org/abs/2006.08690v3,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
45,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Re-imagining Algorithmic Fairness in India and Beyond,26955.txt,http://arxiv.org/abs/2101.09995v2,by_author_abbreviation,B\. Hutchinson,"var, P. Barnes, L. Vasserman, B. Hutchinson, E. Spitzer, I. D. Raji, and T"
46,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,M\. Mitchell,", 2018, p. arXiv:1803.09010. 
M. Mitchell, S. Wu, A. Zaldivar, P. Barnes"
47,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,S\. Wu,"Xiv:1803.09010. 
M. Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Va"
48,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,A\. Zaldivar,"3.09010. 
M. Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. H"
49,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,P\. Barnes,"Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. Hutchinson, "
50,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,L\. Vasserman,". Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. Hutchinson, E. Spitzer, I."
51,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,B\. Hutchinson,"var, P. Barnes, L. Vasserman, B. Hutchinson, E. Spitzer, I. D. Raji, and T"
52,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,E\. Spitzer," L. Vasserman, B. Hutchinson, E. Spitzer, I. D. Raji, and T. Gebru, 
[4"
53,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,T\. Gebru,"ol. 36, no. 4, p. 105, 2015. 
T. Gebru, J. Morgenstern, B. Vecchione,"
54,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model Cards for Model Reporting,26955.txt,http://arxiv.org/abs/1810.03993v2,by_author_abbreviation,T\. Gebru,", E. Spitzer, I. D. Raji, and T. Gebru, 
[48] 
“Model cards for model"
55,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,EdNet: A Large-Scale Hierarchical Dataset in Education,26955.txt,http://arxiv.org/abs/1912.03072v3,by_author_abbreviation,B\. Kim,"08, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorous Science o"
56,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Estimating and Improving Fairness with Adversarial Learning,26955.txt,http://arxiv.org/abs/2103.04243v1,by_author_abbreviation,X\. Li,"Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classi"
57,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Good proctor or ""Big Brother""? AI Ethics and Online Exam Supervision
  Technologies",26955.txt,http://arxiv.org/abs/2011.07647v1,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
58,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"PneumoXttention: A CNN compensating for Human Fallibility when Detecting
  Pneumonia through CXR images with Attention",26955.txt,http://arxiv.org/abs/2008.04907v1,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
59,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Fair and Responsible AI: A Focus on the Ability to Contest,26955.txt,http://arxiv.org/abs/2102.10787v1,by_author_abbreviation,T\. Miller,"] 
vol. 267, pp. 1–38, 2019. 
T. Miller, “Explanation in artificial in"
60,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,M\. Brundage,"ystems (NIPS), vol. 27, 2014 
M. Brundage, S. Avin, J. Clark, H. Toner, "
61,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,S\. Avin,", vol. 27, 2014 
M. Brundage, S. Avin, J. Clark, H. Toner, P. Eckers"
62,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,H\. Toner," Brundage, S. Avin, J. Clark, H. Toner, P. Eckersley, B. Garfinkel, A"
63,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,J\. Clark,", 2014 
M. Brundage, S. Avin, J. Clark, H. Toner, P. Eckersley, B. Ga"
64,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,P\. Eckersley," S. Avin, J. Clark, H. Toner, P. Eckersley, B. Garfinkel, A. Dafoe, P. Sc"
65,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,R\. Cammarota,"in 
[112] 
F. Boemer, Y. Lao, R. Cammarota, and C. Wierzynski,  “nGraph-H"
66,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,A\. Dafoe,", P. Eckersley, B. Garfinkel, A. Dafoe, P. Scharre, T. Zeitzoff, and "
67,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,P\. Scharre,"sley, B. Garfinkel, A. Dafoe, P. Scharre, T. Zeitzoff, and 
[43] 
B. Fi"
68,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,Y\. Bengio,"rithms. 
[41] 
I. Goodfellow, Y. Bengio, and A. Courville, Deep learni"
69,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26955.txt,http://arxiv.org/abs/2004.07213v2,by_author_abbreviation,Y\. Bengio,", S. Ozair, A. Courville, and Y. Bengio, 
[42] 
“Generative Adversaria"
70,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Keeping Designers in the Loop: Communicating Inherent Algorithmic
  Trade-offs Across Multiple Objectives",26955.txt,http://arxiv.org/abs/1910.03061v3,by_author_abbreviation,B\. Yu,". Kumbier, R. Abbasi-Asl, and B. Yu, “Interpretable machine learni"
71,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Data Cleaning for Accurate, Fair, and Robust Models: A Big Data - AI
  Integration Approach",26955.txt,http://arxiv.org/abs/1904.10761v1,by_author_abbreviation,Y\. Roh,"), 2019.  
[94] 
K. H.  Tae,  Y. Roh,  Y. H.  Oh,  H. Kim,  and  S."
72,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Data Cleaning for Accurate, Fair, and Robust Models: A Big Data - AI
  Integration Approach",26955.txt,http://arxiv.org/abs/1904.10761v1,by_author_abbreviation,H\. Kim,".  Tae,  Y. Roh,  Y. H.  Oh,  H. Kim,  and  S. E.  Whang,  “Data  C"
73,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Essential requirements for establishing and operating data trusts:
  practical guidance based on a working meeting of fifteen Canadian
  organizations and initiatives",26955.txt,http://arxiv.org/abs/2005.06604v1,by_author_abbreviation,A\. Smith,". McSherry,  K. Nissim,  and  A. Smith,  “Calibrating  noise  to  sen"
74,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"FR-Train: A Mutual Information-Based Approach to Fair and Robust
  Training",26955.txt,http://arxiv.org/abs/2002.10234v2,by_author_abbreviation,Y\. Roh,"), 2019.  
[94] 
K. H.  Tae,  Y. Roh,  Y. H.  Oh,  H. Kim,  and  S."
75,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26955.txt,http://arxiv.org/abs/2005.05906v1,by_author_abbreviation,S\. Wachter,"6, no. 4, pp. 889–911, 2005. 
S. Wachter, B. Mittelstadt, and C. Russel"
76,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26955.txt,http://arxiv.org/abs/2005.05906v1,by_author_abbreviation,B\. Mittelstadt,". 889–911, 2005. 
S. Wachter, B. Mittelstadt, and C. Russell, “Counterfactu"
77,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26955.txt,http://arxiv.org/abs/2005.05906v1,by_author_abbreviation,C\. Russell," Wachter, B. Mittelstadt, and C. Russell, “Counterfactual Explanations "
78,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"A study in Rashomon curves and volumes: A new perspective on
  generalization and model simplicity in machine learning",26955.txt,http://arxiv.org/abs/1908.01755v2,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
79,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Evolving the pulmonary nodules diagnosis from classical approaches to
  deep learning aided decision support: three decades development course and
  future prospect",26955.txt,http://arxiv.org/abs/1901.07858v3,by_author_abbreviation,X\. Li,"Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classi"
80,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms,26955.txt,http://arxiv.org/abs/1908.08619v4,by_author_abbreviation,B\. Li,"lt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Praka"
81,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms,26955.txt,http://arxiv.org/abs/1908.08619v4,by_author_abbreviation,D\. Song,"–42. 
J. Kos, I. Fischer, and D. Song, “Adversarial examples for gen"
82,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms,26955.txt,http://arxiv.org/abs/1908.08619v4,by_author_abbreviation,D\. Song,"ao, A. Prakash, T. Kohno, and D. Song, “Robust 
physical-world  atta"
83,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms,26955.txt,http://arxiv.org/abs/1908.08619v4,by_author_abbreviation,D\. Song,"Ú. Erlingsson,  J. Kos,  and  D. Song,  “The  Secret  Sharer:  Evalu"
84,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Adequate and fair explanations,26955.txt,http://arxiv.org/abs/2001.07578v1,by_author_abbreviation,C\. Russell," Wachter, B. Mittelstadt, and C. Russell, “Counterfactual Explanations "
85,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,The Mythos of Model Interpretability,26955.txt,http://arxiv.org/abs/1606.03490v3,by_author_abbreviation,Z\. C. Lipton,"vol. 1, no. 5, p. 206, 2019. 
Z. C. Lipton, “The mythos of model interpre"
86,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Learning Interpretable Concept-Based Models with Human Feedback,26955.txt,http://arxiv.org/abs/2012.02898v1,by_author_abbreviation,F\. Doshi-Velez,", p. arXiv:1702.08608, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorou"
87,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model-Agnostic Interpretability of Machine Learning,26955.txt,http://arxiv.org/abs/1606.05386v1,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
88,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Model-Agnostic Interpretability of Machine Learning,26955.txt,http://arxiv.org/abs/1606.05386v1,by_author_abbreviation,C\. Guestrin,"T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  should  I  trust  you?"
89,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Classification Models for Recidivism Prediction,26955.txt,http://arxiv.org/abs/1503.07810v6,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
90,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,D\. Pedreschi," F. Turini, F. Giannotti, and D. Pedreschi, “A survey of methods for 
[51"
91,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,F\. Giannotti,"eale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedreschi, “A survey o"
92,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,R\. Guidotti,". IEEE, 2018, pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. "
93,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,A\. Monreale," pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Gi"
94,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,S\. Ruggieri,"5. 
R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and "
95,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1806.09936v1,by_author_abbreviation,F\. Turini,"ti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedresch"
96,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Manipulating and Measuring Model Interpretability,26955.txt,http://arxiv.org/abs/1802.07810v4,by_author_abbreviation,J\. Wortman Vaughan,"J. Morgenstern, B. Vecchione, J. Wortman Vaughan, H. Wallach, I. Daume, Hal, an"
97,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Manipulating and Measuring Model Interpretability,26955.txt,http://arxiv.org/abs/1802.07810v4,by_author_abbreviation,H\. Wallach,"ecchione, J. Wortman Vaughan, H. Wallach, I. Daume, Hal, and 
[47] 
K. "
98,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Optimal Sparse Decision Trees,26955.txt,http://arxiv.org/abs/1904.12847v5,by_author_abbreviation,C\. Rudin,"vol. 51, no. 5, p. 93, 2019. 
C. Rudin, “Stop explaining black box ma"
99,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Veridical Data Science,26955.txt,http://arxiv.org/abs/1901.08152v5,by_author_abbreviation,B\. Yu,". Kumbier, R. Abbasi-Asl, and B. Yu, “Interpretable machine learni"
100,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Veridical Data Science,26955.txt,http://arxiv.org/abs/1901.08152v5,by_author_abbreviation,K\. Kumbier,"19. 
W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu, “In"
101,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Compressive-Sensing Data Reconstruction for Structural Health
  Monitoring: A Machine-Learning Approach",26955.txt,http://arxiv.org/abs/1901.01995v2,by_author_abbreviation,H\. Li,"W), 2018, pp. 1–7. 
B. Liang, H. Li, M. Su, P. Bian, X. Li, and W."
102,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,GLocalX -- From Local to Global Explanations of Black Box AI Models,26955.txt,http://arxiv.org/abs/2101.07685v2,by_author_abbreviation,R\. Guidotti,". IEEE, 2018, pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. "
103,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,GLocalX -- From Local to Global Explanations of Black Box AI Models,26955.txt,http://arxiv.org/abs/2101.07685v2,by_author_abbreviation,A\. Monreale," pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Gi"
104,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,GLocalX -- From Local to Global Explanations of Black Box AI Models,26955.txt,http://arxiv.org/abs/2101.07685v2,by_author_abbreviation,F\. Turini,"ti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedresch"
105,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,GLocalX -- From Local to Global Explanations of Black Box AI Models,26955.txt,http://arxiv.org/abs/2101.07685v2,by_author_abbreviation,D\. Pedreschi," F. Turini, F. Giannotti, and D. Pedreschi, “A survey of methods for 
[51"
106,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,GLocalX -- From Local to Global Explanations of Black Box AI Models,26955.txt,http://arxiv.org/abs/2101.07685v2,by_author_abbreviation,F\. Giannotti,"eale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedreschi, “A survey o"
107,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Convolutional Filters with SincNet,26955.txt,http://arxiv.org/abs/1811.09725v2,by_author_abbreviation,Y\. Bengio,"rithms. 
[41] 
I. Goodfellow, Y. Bengio, and A. Courville, Deep learni"
108,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Convolutional Filters with SincNet,26955.txt,http://arxiv.org/abs/1811.09725v2,by_author_abbreviation,Y\. Bengio,", S. Ozair, A. Courville, and Y. Bengio, 
[42] 
“Generative Adversaria"
109,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explaining Black-box Android Malware Detection,26955.txt,http://arxiv.org/abs/1803.03544v2,by_author_abbreviation,B\. Biggio,", p. arXiv:1702.02284, 2017. 
B. Biggio, B. Nelson, and P. Laskov, “Po"
110,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Predictive and Causal Implications of using Shapley Value for Model
  Interpretation",26955.txt,http://arxiv.org/abs/2008.05052v1,by_author_abbreviation,S\. Ma,". Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Kho"
111,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"""Why Should I Trust You?"": Explaining the Predictions of Any Classifier",26955.txt,http://arxiv.org/abs/1602.04938v3,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
112,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"""Why Should I Trust You?"": Explaining the Predictions of Any Classifier",26955.txt,http://arxiv.org/abs/1602.04938v3,by_author_abbreviation,C\. Guestrin,"T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  should  I  trust  you?"
113,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Neural-Symbolic Reasoning on Knowledge Graphs,26955.txt,http://arxiv.org/abs/2010.05446v3,by_author_abbreviation,L\. Zhang,"n, I. Mironov, K. Talwar, and L. Zhang, “Deep learning with 
differen"
114,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation
  Methods",26955.txt,http://arxiv.org/abs/1911.02508v2,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
115,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Learning Qualitatively Diverse and Interpretable Rules for
  Classification",26955.txt,http://arxiv.org/abs/1806.08716v2,by_author_abbreviation,F\. Doshi-Velez,", p. arXiv:1702.08608, 2017. 
F. Doshi-Velez and B. Kim, “Towards A Rigorou"
116,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Enforcing Interpretability and its Statistical Impacts: Trade-offs
  between Accuracy and Interpretability",26955.txt,http://arxiv.org/abs/2010.13764v2,by_author_abbreviation,S\. Ben-David," 2014. 
S. Shalev-Shwartz and S. Ben-David, Understanding machine learnin"
117,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Sequence Learning for COVID-19 Forecasting,26955.txt,http://arxiv.org/abs/2008.00646v2,by_author_abbreviation,S\. Singh,"014. 
[119]  M. T.  Ribeiro,  S. Singh,  and  C. Guestrin,  “Why  sho"
118,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Interpretable Sequence Learning for COVID-19 Forecasting,26955.txt,http://arxiv.org/abs/2008.00646v2,by_author_abbreviation,L\. Zhang,"n, I. Mironov, K. Talwar, and L. Zhang, “Deep learning with 
differen"
119,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Explaining Deep Learning Models - A Bayesian Non-parametric Approach,26955.txt,http://arxiv.org/abs/1811.03422v1,by_author_abbreviation,S\. Huang,"telligence. 2011, pp. 43–58. 
S. Huang, N. Papernot, I. Goodfellow, Y"
120,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Multimodal Learning for Intelligent Regulation in Online
  Payment Systems",26955.txt,http://arxiv.org/abs/2006.05669v1,by_author_abbreviation,S\. Wang," 
X. Huang,  M. Kwiatkowska,  S. Wang,  and  M. Wu,  “Safety  verifi"
121,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Deep Learning: Interpretations, Interpretability,
  Trustworthiness, and Beyond",26955.txt,http://arxiv.org/abs/2103.10689v1,by_author_abbreviation,X\. Li,"Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classi"
122,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Deep Learning: Interpretations, Interpretability,
  Trustworthiness, and Beyond",26955.txt,http://arxiv.org/abs/2103.10689v1,by_author_abbreviation,X\. Li,"Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classi"
123,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Interpretable Deep Learning: Interpretations, Interpretability,
  Trustworthiness, and Beyond",26955.txt,http://arxiv.org/abs/2103.10689v1,by_author_abbreviation,X\. Wu," 
N. Papernot,  P. McDaniel,  X. Wu,  S. Jha,  and  A. Swami,  “Di"
124,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,R\. Guidotti,". IEEE, 2018, pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. "
125,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,A\. Monreale," pp. 0210–0215. 
R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Gi"
126,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,S\. Ruggieri,"5. 
R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and "
127,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,D\. Pedreschi," F. Turini, F. Giannotti, and D. Pedreschi, “A survey of methods for 
[51"
128,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,F\. Turini,"ti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedresch"
129,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,Local Rule-Based Explanations of Black Box Decision Systems,26955.txt,http://arxiv.org/abs/1805.10820v1,by_author_abbreviation,F\. Giannotti,"eale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedreschi, “A survey o"
130,oecd,THE ROBUSTNESS AND EXPLAINABILITY OF ARTIFICIAL INTELLIGENCE,"Explaining Vulnerabilities of Deep Learning to Adversarial Malware
  Binaries",26955.txt,http://arxiv.org/abs/1901.03583v2,by_author_abbreviation,B\. Biggio,", p. arXiv:1702.02284, 2017. 
B. Biggio, B. Nelson, and P. Laskov, “Po"
131,oecd,CDEI SNAPSHOT PAPER: FACIAL RECOGNITION TECHNOLOGY,"What does it mean to solve the problem of discrimination in hiring?
  Social, technical and legal perspectives from the UK on automated hiring
  systems",26709.txt,http://arxiv.org/abs/1910.06144v2,by_author,Lilian Edwards,"I & University of Winchester)
Lilian Edwards (Professor of Law, Innovation "
132,oecd,CDEI SNAPSHOT PAPER: FACIAL RECOGNITION TECHNOLOGY,Model Cards for Model Reporting,26709.txt,http://arxiv.org/abs/1810.03993v2,by_author,Margaret Mitchell," 
Life, Bangor University)
•  Margaret Mitchell (Senior 
Research Engineer, Go"
133,oecd,TOWARDS TRUSTWORTHY AI: MALTAS ETHICAL AI FRAMEWORK 2019,Explainable AI for Interpretable Credit Scoring,24993.txt,http://arxiv.org/abs/2012.03749v1,by_author,Alexiei Dingli,"manuel Darmanin 
Member
Prof. Alexiei Dingli 
Member
Dr. Abdalla Kablan 
Me"
134,oecd,LEADING THE WAY INTO THE AGE OF ARTIFICIAL INTELLIGENCE,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",24199.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ased on them compiled by: 
•  Samuel Kaski, Academy Professor at Aalto Un"
135,oecd,LEADING THE WAY INTO THE AGE OF ARTIFICIAL INTELLIGENCE,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",24199.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ent)
Sonja Ängeslevä (Zynga) 
Samuel Kaski (Aalto University)
Antti Vasar"
136,oecd,LEADING THE WAY INTO THE AGE OF ARTIFICIAL INTELLIGENCE,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",24199.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"scher, Leadership Akatemia
•  Samuel Kaski, Aalto University
•  Ilkka Kiv"
137,oecd,LEADING THE WAY INTO THE AGE OF ARTIFICIAL INTELLIGENCE,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",24199.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ieto
•  Topi Järvinen, PwC
•  Samuel Kaski, Aalto University
•  Outi Kesk"
138,oecd,LEADING THE WAY INTO THE AGE OF ARTIFICIAL INTELLIGENCE,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",24199.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"  Antti Karjaluoto, DIMECC
•  Samuel Kaski, Aalto University 
•  Ilkka Ki"
139,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,"Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of
  Key Ideas and Publications, and Bibliography for Explainable AI",26746.txt,http://arxiv.org/abs/1902.01876v1,by_arxiv_id,1902.01876,"hy for Explainable AI.  arXiv:1902.01876 [cs].  arXiv: 
1902.01876. 
["
140,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,"Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of
  Key Ideas and Publications, and Bibliography for Explainable AI",26746.txt,http://arxiv.org/abs/1902.01876v1,by_arxiv_id,1902.01876,"Xiv:1902.01876 [cs].  arXiv: 
1902.01876. 
[62]  Nisbett,  R.  E.,  Wi"
141,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,Towards A Rigorous Science of Interpretable Machine Learning,26746.txt,http://arxiv.org/abs/1702.08608v2,by_arxiv_id,1702.08608,"earning. arXiv preprint arXiv:1702.08608. 
[17]  Edmond, G., Towler, A"
142,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,Manipulating and Measuring Model Interpretability,26746.txt,http://arxiv.org/abs/1802.07810v4,by_arxiv_id,1802.07810,"Model Interpretability. arXiv:1802.07810 [cs]. 
arXiv: 1802.07810. 
[7"
143,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,Manipulating and Measuring Model Interpretability,26746.txt,http://arxiv.org/abs/1802.07810v4,by_arxiv_id,1802.07810,"rXiv:1802.07810 [cs]. 
arXiv: 1802.07810. 
[70]  Pronin,  E. (2009).  "
144,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,"The Role of Individual User Differences in Interpretable and Explainable
  Machine Learning Systems",26746.txt,http://arxiv.org/abs/2009.06675v1,by_author,Reva Schwartz,"authors thank Kristen Greene, Reva Schwartz, Brian Stanton, Amy Yates, and"
145,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,"The Role of Individual User Differences in Interpretable and Explainable
  Machine Learning Systems",26746.txt,http://arxiv.org/abs/2009.06675v1,by_author,David A. Broniatowski,"na A. Hahn 
Peter C. Fontana 
David A. Broniatowski 
Mark A. Przybocki 
This draft"
146,oecd,NIST PRINCIPLES FOR EXPLAINABLE AI,"The Role of Individual User Differences in Interpretable and Explainable
  Machine Learning Systems",26746.txt,http://arxiv.org/abs/2009.06675v1,by_author,David A. Broniatowski,"mation Technology Laboratory 
David A. Broniatowski 
Information Technology Labora"
147,oecd,WHITE HOUSE SUMMIT ON AI IN GOVERNMENT,"Don't Explain without Verifying Veracity: An Evaluation of Explainable
  AI with Video Activity Recognition",25002.txt,http://arxiv.org/abs/2005.02335v1,by_author_abbreviation,C\. Roy," Dr. soc. 
2001, p. 885, obs. C. Roy-Loustaunau), a lack of informa"
148,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Ground Truth Evaluation of Neural Network Explanations with CLEVR-XAI,26961.txt,http://arxiv.org/abs/2003.07258v2,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
149,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"How Much Can I Trust You? -- Quantifying Uncertainties in Explaining
  Neural Networks",26961.txt,http://arxiv.org/abs/2006.09000v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
150,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards Best Practice in Explaining Neural Network Decisions with LRP,26961.txt,http://arxiv.org/abs/1910.09840v3,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
151,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning,26961.txt,http://arxiv.org/abs/1912.08881v3,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
152,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning,26961.txt,http://arxiv.org/abs/1912.08881v3,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
153,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"On the Explanation of Machine Learning Predictions in Clinical Gait
  Analysis",26961.txt,http://arxiv.org/abs/1912.07737v2,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
154,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,The Clever Hans Effect in Anomaly Detection,26961.txt,http://arxiv.org/abs/2006.10609v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
155,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards Explainable Artificial Intelligence,26961.txt,http://arxiv.org/abs/1909.12072v1,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
156,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards Explainable Artificial Intelligence,26961.txt,http://arxiv.org/abs/1909.12072v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
157,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models",26961.txt,http://arxiv.org/abs/1708.08296v1,by_arxiv_id,1708.08296,"(2017), https://arxiv.org/abs/1708.08296.
For instance, advances in co"
158,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models",26961.txt,http://arxiv.org/abs/1708.08296v1,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
159,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models",26961.txt,http://arxiv.org/abs/1708.08296v1,by_author,Thomas Wiegand,"1-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explain"
160,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explainable Artificial Intelligence: Understanding, Visualizing and
  Interpreting Deep Learning Models",26961.txt,http://arxiv.org/abs/1708.08296v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
161,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Representation, Justification and Explanation in a Value Driven Agent:
  An Argumentation-Based Approach",26961.txt,http://arxiv.org/abs/1812.05362v2,by_author_abbreviation,M\. Anderson,"te 
7.
20 See generally James M. Anderson et al., Autonomous Vehicle Tec"
162,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards A Rigorous Science of Interpretable Machine Learning,26961.txt,http://arxiv.org/abs/1702.08608v2,by_arxiv_id,1702.08608,"2017), https://
arxiv.org/abs/1702.08608. For visualization techniques"
163,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards A Rigorous Science of Interpretable Machine Learning,26961.txt,http://arxiv.org/abs/1702.08608v2,by_author,Finale Doshi-Velez,"mputing 
Syss. Procs. (2018); Finale Doshi-Velez & Been Kim, Towards a Rigorous"
164,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards A Rigorous Science of Interpretable Machine Learning,26961.txt,http://arxiv.org/abs/1702.08608v2,by_author,Finale Doshi-Velez,"es with similar outcomes. See Finale Doshi-Velez et al., Accountability 
of AI "
165,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Towards A Rigorous Science of Interpretable Machine Learning,26961.txt,http://arxiv.org/abs/1702.08608v2,by_author,Been Kim," (2018); Finale Doshi-Velez & Been Kim, Towards a Rigorous 
Science o"
166,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for
  Complex Systems",26961.txt,http://arxiv.org/abs/1611.09139v1,by_author,Been Kim," (2018); Finale Doshi-Velez & Been Kim, Towards a Rigorous 
Science o"
167,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"""What is Relevant in a Text Document?"": An Interpretable Machine
  Learning Approach",26961.txt,http://arxiv.org/abs/1612.07843v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
168,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"""What is Relevant in a Text Document?"": An Interpretable Machine
  Learning Approach",26961.txt,http://arxiv.org/abs/1612.07843v1,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
169,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Variable Selection via Thompson Sampling,26961.txt,http://arxiv.org/abs/2007.00187v2,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
170,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Variable Selection via Thompson Sampling,26961.txt,http://arxiv.org/abs/2007.00187v2,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
171,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Nothing Else Matters: Model-Agnostic Explanations By Identifying
  Prediction Invariance",26961.txt,http://arxiv.org/abs/1611.05817v1,by_author,Marco Tulio Ribeiro,"ill.pub/2018/building-blocks; Marco Tulio Ribeiro et 
al., “Why Should I Trust Y"
172,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Model Cards for Model Reporting,26961.txt,http://arxiv.org/abs/1810.03993v2,by_author,Inioluwa Deborah Raji,"ine 
Learning Res. 77 (2018).
Inioluwa Deborah Raji & Joy Buolamwini, Actionable A"
173,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Model Cards for Model Reporting,26961.txt,http://arxiv.org/abs/1810.03993v2,by_author,Timnit Gebru,"matched-28; Joy 
Boulamwini & Timnit Gebru, Gender Shades: Intersectional"
174,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Model Cards for Model Reporting,26961.txt,http://arxiv.org/abs/1810.03993v2,by_author,Timnit Gebru,"8.00023.
90  Joy Boulamwini & Timnit Gebru, Gender Shades: Intersectional"
175,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Online Decision Trees with Fairness,26961.txt,http://arxiv.org/abs/2010.08146v1,by_author,Liang Zhao,"019); 
Xiajing Gong, Meng Hu, Liang Zhao, Big Data Toolsets to Pharmaco"
176,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26961.txt,http://arxiv.org/abs/2004.07213v2,by_author,Peter Henderson,"
Contributors: Matthew Agnew, Peter Henderson, Geet Sethi, 
Stephen Tang
For"
177,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",26961.txt,http://arxiv.org/abs/2004.07213v2,by_author,Peter Henderson,"Alex Duran, 
Michael Fischer, Peter Henderson, David Hoyt, Caroline Jo, 
Sun"
178,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Welfare and Distributional Impacts of Fair Classification,26961.txt,http://arxiv.org/abs/1807.01134v1,by_author,Yiling Chen,"g 390–409 (2009); Ben Green & Yiling Chen, The Principles and 
Limits of"
179,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Interpretable Artificial Intelligence through the Lens of Feature
  Interaction",26961.txt,http://arxiv.org/abs/2103.03103v1,by_author,Yan Liu,"re is meant to represent. See Yan Liu et al., Review of Chart 
Recog"
180,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Interpretable Artificial Intelligence through the Lens of Feature
  Interaction",26961.txt,http://arxiv.org/abs/2103.03103v1,by_author,Yan Liu,"what a figure represents. See Yan Liu et 
al., Review of Chart Recog"
181,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Interpretable Artificial Intelligence through the Lens of Feature
  Interaction",26961.txt,http://arxiv.org/abs/2103.03103v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
182,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Interpretable Artificial Intelligence through the Lens of Feature
  Interaction",26961.txt,http://arxiv.org/abs/2103.03103v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
183,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",26961.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"le, supra 
note 48, at 55-59; Sandra Wachter, Brent Mittlestadt & Luciano F"
184,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Learning Interpretable Concept-Based Models with Human Feedback,26961.txt,http://arxiv.org/abs/2012.02898v1,by_author,Finale Doshi-Velez,"mputing 
Syss. Procs. (2018); Finale Doshi-Velez & Been Kim, Towards a Rigorous"
185,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Learning Interpretable Concept-Based Models with Human Feedback,26961.txt,http://arxiv.org/abs/2012.02898v1,by_author,Finale Doshi-Velez,"es with similar outcomes. See Finale Doshi-Velez et al., Accountability 
of AI "
186,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Model-Agnostic Interpretability of Machine Learning,26961.txt,http://arxiv.org/abs/1606.05386v1,by_author,Marco Tulio Ribeiro,"ill.pub/2018/building-blocks; Marco Tulio Ribeiro et 
al., “Why Should I Trust Y"
187,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explaining NonLinear Classification Decisions with Deep Taylor
  Decomposition",26961.txt,http://arxiv.org/abs/1512.02479v1,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
188,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explaining NonLinear Classification Decisions with Deep Taylor
  Decomposition",26961.txt,http://arxiv.org/abs/1512.02479v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
189,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"How does this interaction affect me? Interpretable attribution for
  feature interactions",26961.txt,http://arxiv.org/abs/2006.10965v1,by_author,Yan Liu,"re is meant to represent. See Yan Liu et al., Review of Chart 
Recog"
190,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"How does this interaction affect me? Interpretable attribution for
  feature interactions",26961.txt,http://arxiv.org/abs/2006.10965v1,by_author,Yan Liu,"what a figure represents. See Yan Liu et 
al., Review of Chart Recog"
191,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"How does this interaction affect me? Interpretable attribution for
  feature interactions",26961.txt,http://arxiv.org/abs/2006.10965v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
192,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"How does this interaction affect me? Interpretable attribution for
  feature interactions",26961.txt,http://arxiv.org/abs/2006.10965v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
193,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Evaluating the visualization of what a Deep Neural Network has learned,26961.txt,http://arxiv.org/abs/1509.06321v1,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
194,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Evaluating the visualization of what a Deep Neural Network has learned,26961.txt,http://arxiv.org/abs/1509.06321v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
195,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explaining Deep Neural Networks and Beyond: A Review of Methods and
  Applications",26961.txt,http://arxiv.org/abs/2003.07631v2,by_author,Wojciech Samek,"ons,” see id., 41-43.
14 
13  Wojciech Samek, Thomas Wiegand & Klaus-Robert"
196,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Explaining Deep Neural Networks and Beyond: A Review of Methods and
  Applications",26961.txt,http://arxiv.org/abs/2003.07631v2,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
197,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Assessing the Local Interpretability of Machine Learning Models,26961.txt,http://arxiv.org/abs/1902.03501v2,by_author,Sorelle A. Friedler,"ents, 5 Big Data 153 (2017); 
Sorelle A. Friedler, Carlos Scheidegger & Suresh V"
198,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Assessing the Local Interpretability of Machine Learning Models,26961.txt,http://arxiv.org/abs/1902.03501v2,by_author,Carlos Scheidegger,"(2017); 
Sorelle A. Friedler, Carlos Scheidegger & Suresh Venkatasubramanian, 
"
199,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Can I trust you more? Model-Agnostic Hierarchical Explanations,26961.txt,http://arxiv.org/abs/1812.04801v1,by_author,Yan Liu,"re is meant to represent. See Yan Liu et al., Review of Chart 
Recog"
200,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Can I trust you more? Model-Agnostic Hierarchical Explanations,26961.txt,http://arxiv.org/abs/1812.04801v1,by_author,Yan Liu,"what a figure represents. See Yan Liu et 
al., Review of Chart Recog"
201,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Can I trust you more? Model-Agnostic Hierarchical Explanations,26961.txt,http://arxiv.org/abs/1812.04801v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
202,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Can I trust you more? Model-Agnostic Hierarchical Explanations,26961.txt,http://arxiv.org/abs/1812.04801v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
203,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"""Why Should I Trust You?"": Explaining the Predictions of Any Classifier",26961.txt,http://arxiv.org/abs/1602.04938v3,by_author,Marco Tulio Ribeiro,"ill.pub/2018/building-blocks; Marco Tulio Ribeiro et 
al., “Why Should I Trust Y"
204,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"A game method for improving the interpretability of convolution neural
  network",26961.txt,http://arxiv.org/abs/1910.09090v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
205,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"A game method for improving the interpretability of convolution neural
  network",26961.txt,http://arxiv.org/abs/1910.09090v1,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
206,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Interpretation of Neural Networks is Fragile,26961.txt,http://arxiv.org/abs/1710.10547v2,by_author,James Zou,"nt, and 
Disparate Impact
85  James Zou & Londa Schiebinger, AI Can Be"
207,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Feature Importance Measure for Non-linear Learning Algorithms,26961.txt,http://arxiv.org/abs/1611.07567v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
208,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Learning Qualitatively Diverse and Interpretable Rules for
  Classification",26961.txt,http://arxiv.org/abs/1806.08716v2,by_author,Finale Doshi-Velez,"mputing 
Syss. Procs. (2018); Finale Doshi-Velez & Been Kim, Towards a Rigorous"
209,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Learning Qualitatively Diverse and Interpretable Rules for
  Classification",26961.txt,http://arxiv.org/abs/1806.08716v2,by_author,Finale Doshi-Velez,"es with similar outcomes. See Finale Doshi-Velez et al., Accountability 
of AI "
210,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Why an Android App is Classified as Malware? Towards Malware
  Classification Interpretation",26961.txt,http://arxiv.org/abs/2004.11516v2,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
211,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,"Why an Android App is Classified as Malware? Towards Malware
  Classification Interpretation",26961.txt,http://arxiv.org/abs/2004.11516v2,by_author_abbreviation,Y\. Liu,"n-Nader, Daniel E. Ho & Larry Y. Liu, Deep Learning 
with Satellite"
212,oecd,GOVERNMENT BY ALGORITHM: ARTIFICIAL INTELLIGENCE IN FEDERAL ADMINISTRATIVE AGENCIES,Building and Interpreting Deep Similarity Models,26961.txt,http://arxiv.org/abs/2003.05431v1,by_author,Klaus-Robert Müller,"ciech Samek, Thomas Wiegand & Klaus-Robert Müller, Explainable 
Artificial Intel"
213,oecd,WELSH LANGUAGE TECHNOLOGY ACTION PLAN,"An Experimentation Platform for Explainable Coalition Situational
  Understanding",26880.txt,http://arxiv.org/abs/2010.14388v2,by_author,Alun Preece,"rgh University. 
  Professor Alun Preece, Deputy Head of School of Comp"
214,oecd,WELSH LANGUAGE TECHNOLOGY ACTION PLAN,"Interpretable to Whom? A Role-based Model for Analyzing Interpretable
  Machine Learning Systems",26880.txt,http://arxiv.org/abs/1806.07552v1,by_author,Alun Preece,"rgh University. 
  Professor Alun Preece, Deputy Head of School of Comp"
215,oecd,WELSH LANGUAGE TECHNOLOGY ACTION PLAN,Stakeholders in Explainable AI,26880.txt,http://arxiv.org/abs/1810.00184v1,by_author,Alun Preece,"rgh University. 
  Professor Alun Preece, Deputy Head of School of Comp"
216,oecd,NATIONAL ETHICAL GUIDELINES FOR BIOMEDICAL AND HEALTH RESEARCH INVOLVING HUMAN PARTICIPANTS,"Don't Explain without Verifying Veracity: An Evaluation of Explainable
  AI with Video Activity Recognition",24955.txt,http://arxiv.org/abs/2005.02335v1,by_author_abbreviation,C\. Roy," Dr. soc. 
2001, p. 885, obs. C. Roy-Loustaunau), a lack of informa"
217,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,"Symbolic AI for XAI: Evaluating LFIT Inductive Programming for Fair and
  Explainable Automatic Recruitment",facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2012.00360v1,by_author_abbreviation,J\. Fierrez,"website, and A. Morales, A., 
J. Fierrez, J., and R. Vera-Rodriguez, R."
218,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,"Symbolic AI for XAI: Evaluating LFIT Inductive Programming for Fair and
  Explainable Automatic Recruitment",facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2012.00360v1,by_author_abbreviation,A\. Morales,"he SensitiveNets website, and A. Morales, A., 
J. Fierrez, J., and R. V"
219,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,Bias in Multimodal AI: Testbed for Fair Automatic Recruitment,facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2004.07173v1,by_author_abbreviation,A\. Morales,"he SensitiveNets website, and A. Morales, A., 
J. Fierrez, J., and R. V"
220,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,Bias in Multimodal AI: Testbed for Fair Automatic Recruitment,facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2004.07173v1,by_author_abbreviation,J\. Fierrez,"website, and A. Morales, A., 
J. Fierrez, J., and R. Vera-Rodriguez, R."
221,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,Learning Emotional-Blinded Face Representations,facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2009.08704v1,by_author_abbreviation,J\. Fierrez,"website, and A. Morales, A., 
J. Fierrez, J., and R. Vera-Rodriguez, R."
222,nesta,Facial recognition technology: fundamental rights considerations in the context of law enforcement,Learning Emotional-Blinded Face Representations,facial-recognition-technology-fundamental-rights-considerations-in-the-context-of-law-enforcement.txt,http://arxiv.org/abs/2009.08704v1,by_author_abbreviation,A\. Morales,"he SensitiveNets website, and A. Morales, A., 
J. Fierrez, J., and R. V"
223,nesta,AV Code of Practice,"What does it mean to solve the problem of discrimination in hiring?
  Social, technical and legal perspectives from the UK on automated hiring
  systems",av-code-of-practice.txt,http://arxiv.org/abs/1910.06144v2,by_author,Lilian Edwards,"ash. L. Rev. 85 (2007): 1249; Lilian Edwards and 
Michael Veale, “Slave to "
224,nesta,AV Code of Practice,Manipulating and Measuring Model Interpretability,av-code-of-practice.txt,http://arxiv.org/abs/1802.07810v4,by_author,Hanna Wallach," Crawford, Aaron Shapiro and 
Hanna Wallach, “The Problem with Bias: From "
225,nesta,AI - Shaping the Future of New Zealand,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-shaping-the-future-of-new-zealand.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
226,nesta,AI - Shaping the Future of New Zealand,Interpretable Convolutional Filters with SincNet,ai-shaping-the-future-of-new-zealand.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
227,nesta,Positively Shaping the Future of Austria with Robotics and AI,"An Experimentation Platform for Explainable Coalition Situational
  Understanding",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2010.14388v2,by_author_abbreviation,H\. Taylor,"tegration with AI.
7  Russell H. Taylor, “A Perspective on Medical Rob"
228,nesta,Positively Shaping the Future of Austria with Robotics and AI,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"s that are investing in AI.
- Yoshua Bengio, Director, Montreal Institute "
229,nesta,Positively Shaping the Future of Austria with Robotics and AI,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"d some words of 
caution from Yoshua Bengio, Director of the 
Montréal Ins"
230,nesta,Positively Shaping the Future of Austria with Robotics and AI,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"er perspective was offered by Yoshua Bengio. 
As discussed above, Dr. Beng"
231,nesta,Positively Shaping the Future of Austria with Robotics and AI,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"m. 
Element AI, co-founded by Yoshua Bengio, is part 
research lab and par"
232,nesta,Positively Shaping the Future of Austria with Robotics and AI,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"itute for Learning Algorithms Yoshua Bengio, Director, Professor, Universi"
233,nesta,Positively Shaping the Future of Austria with Robotics and AI,"`Why didn't you allocate this task to them?' Negotiation-Aware Task
  Allocation and Contrastive Explanation Generation",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2002.01640v3,by_author,Subbarao Kambhampati," research in Canada. In fact 
Subbarao Kambhampati of the Association for the 
Ad"
234,nesta,Positively Shaping the Future of Austria with Robotics and AI,"`Why didn't you allocate this task to them?' Negotiation-Aware Task
  Allocation and Contrastive Explanation Generation",positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/2002.01640v3,by_author,Subbarao Kambhampati,"botics (by 
video conference)
Subbarao Kambhampati, Professor, Arizona State 
Uni"
235,nesta,Positively Shaping the Future of Austria with Robotics and AI,Interpretable Convolutional Filters with SincNet,positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"s that are investing in AI.
- Yoshua Bengio, Director, Montreal Institute "
236,nesta,Positively Shaping the Future of Austria with Robotics and AI,Interpretable Convolutional Filters with SincNet,positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"d some words of 
caution from Yoshua Bengio, Director of the 
Montréal Ins"
237,nesta,Positively Shaping the Future of Austria with Robotics and AI,Interpretable Convolutional Filters with SincNet,positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"er perspective was offered by Yoshua Bengio. 
As discussed above, Dr. Beng"
238,nesta,Positively Shaping the Future of Austria with Robotics and AI,Interpretable Convolutional Filters with SincNet,positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"m. 
Element AI, co-founded by Yoshua Bengio, is part 
research lab and par"
239,nesta,Positively Shaping the Future of Austria with Robotics and AI,Interpretable Convolutional Filters with SincNet,positively-shaping-the-future-of-austria-with-robotics-and-ai.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"itute for Learning Algorithms Yoshua Bengio, Director, Professor, Universi"
240,nesta,AI Sector Deal,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-sector-deal.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"né and leading AI 
researcher Yoshua Bengio. With deep domain expertise an"
241,nesta,AI Sector Deal,Interpretable Convolutional Filters with SincNet,ai-sector-deal.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"né and leading AI 
researcher Yoshua Bengio. With deep domain expertise an"
242,nesta,Action Plan Against Disinformation,Model Cards for Model Reporting,action-plan-against-disinformation.txt,http://arxiv.org/abs/1810.03993v2,by_author,Timnit Gebru,"See, e.g., Joy Buolamwini and Timnit Gebru “Gender Shades: Intersectional"
243,nesta,Action Plan Against Disinformation,"""The Human Body is a Black Box"": Supporting Clinical Decision-Making
  with Deep Learning",action-plan-against-disinformation.txt,http://arxiv.org/abs/1911.08089v2,by_author,Madeleine Elish,"with-it-4622ec1566d5.
26
 See Madeleine Elish and danah boyd, Situating Meth"
244,nesta,Malta - Towards an AI Strategy - High-level policy document for public consultation,Explainable AI for Interpretable Credit Scoring,malta-towards-an-ai-strategy-high-level-policy-document-for-public-consultation.txt,http://arxiv.org/abs/2012.03749v1,by_author,Alexiei Dingli,"E
Wayne Grixti
Chairman
Prof. Alexiei Dingli
Member
Dr. Angelo Dalli
Member"
245,nesta,Data Ethics Framework,"What does it mean to solve the problem of discrimination in hiring?
  Social, technical and legal perspectives from the UK on automated hiring
  systems",data-ethics-framework.txt,http://arxiv.org/abs/1910.06144v2,by_author,Lilian Edwards,"ash. L. Rev. 85 (2007): 1249; Lilian Edwards and 
Michael Veale, “Slave to "
246,nesta,Data Ethics Framework,Manipulating and Measuring Model Interpretability,data-ethics-framework.txt,http://arxiv.org/abs/1802.07810v4,by_author,Hanna Wallach," Crawford, Aaron Shapiro and 
Hanna Wallach, “The Problem with Bias: From "
247,nesta,"Ethical, Social and Political Challenges of AI in Health","Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",ethical-social-and-political-challenges-of-ai-in-health.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"y  patient-HCP  dynamic.  Dr 
Brent Mittelstadt (Research Fellow at the Oxford"
248,nesta,"Ethical, Social and Political Challenges of AI in Health","Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",ethical-social-and-political-challenges-of-ai-in-health.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"0.html
102. Interview with Dr Brent Mittelstadt, 1st February 2018
ETHICAL, SO"
249,nesta,"Ethical, Social and Political Challenges of AI in Health","Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",ethical-social-and-political-challenges-of-ai-in-health.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"uary 2018
166. Interview with Brent Mittelstadt, 1st February 2018
167. Lazer,"
250,nesta,"Ethical, Social and Political Challenges of AI in Health","Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",ethical-social-and-political-challenges-of-ai-in-health.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"rsity School 
of Medicine
 Dr Brent Mittelstadt, Research Fellow and British A"
251,nesta,Leading the way into the era of artificial intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",leading-the-way-into-the-era-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ased on them compiled by: 
•  Samuel Kaski, Academy Professor at Aalto Un"
252,nesta,Leading the way into the era of artificial intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",leading-the-way-into-the-era-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ent)
Sonja Ängeslevä (Zynga) 
Samuel Kaski (Aalto University)
Antti Vasar"
253,nesta,Leading the way into the era of artificial intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",leading-the-way-into-the-era-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"scher, Leadership Akatemia
•  Samuel Kaski, Aalto University
•  Ilkka Kiv"
254,nesta,Leading the way into the era of artificial intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",leading-the-way-into-the-era-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"ieto
•  Topi Järvinen, PwC
•  Samuel Kaski, Aalto University
•  Outi Kesk"
255,nesta,Leading the way into the era of artificial intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",leading-the-way-into-the-era-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"  Antti Karjaluoto, DIMECC
•  Samuel Kaski, Aalto University 
•  Ilkka Ki"
256,nesta,National Strategy for AI - Discussion Document,"If Only We Had Better Counterfactual Explanations: Five Key Deficits to
  Rectify in the Evaluation of Counterfactual XAI Techniques",national-strategy-for-ai-discussion-document.txt,http://arxiv.org/abs/2103.01035v1,by_author,Barry Smyth,"f data generated in 2016. 
As Barry Smyth, Professor of Computer science"
257,nesta,National Strategy for AI - Discussion Document,"Good Counterfactuals and Where to Find Them: A Case-Based Technique for
  Generating Counterfactuals for Explainable AI (XAI)",national-strategy-for-ai-discussion-document.txt,http://arxiv.org/abs/2005.13997v1,by_author,Barry Smyth,"f data generated in 2016. 
As Barry Smyth, Professor of Computer science"
258,nesta,National Strategy for AI - Discussion Document,"A Few Good Counterfactuals: Generating Interpretable, Plausible and
  Diverse Counterfactual Explanations",national-strategy-for-ai-discussion-document.txt,http://arxiv.org/abs/2101.09056v1,by_author,Barry Smyth,"f data generated in 2016. 
As Barry Smyth, Professor of Computer science"
259,nesta,National Strategy for AI - Discussion Document,"Generating Plausible Counterfactual Explanations for Deep Transformers
  in Financial Text Classification",national-strategy-for-ai-discussion-document.txt,http://arxiv.org/abs/2010.12512v1,by_author,Barry Smyth,"f data generated in 2016. 
As Barry Smyth, Professor of Computer science"
260,nesta,AI and National Security,Proceedings of NIPS 2017 Symposium on Interpretable Machine Learning,ai-and-national-security.txt,http://arxiv.org/abs/1711.09889v3,by_author,Jason Yosinski,"gh-
in.html.
49  Nguyen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural "
261,nesta,AI and National Security,Proceedings of NIPS 2017 Symposium on Interpretable Machine Learning,ai-and-national-security.txt,http://arxiv.org/abs/1711.09889v3,by_author,Jason Yosinski,"reats.html.
117  Nguyen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural "
262,nesta,AI and National Security,Neural Additive Models: Interpretable Machine Learning with Neural Nets,ai-and-national-security.txt,http://arxiv.org/abs/2004.13912v1,by_author,Geoffrey E. Hinton,"ky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “ImageNet classification with"
263,nesta,AI and National Security,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-and-national-security.txt,http://arxiv.org/abs/2004.07213v2,by_author,Paul Scharre,"rts of military activity. 
As Paul Scharre has written, “Ultra-cheap 3D-p"
264,nesta,AI and National Security,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-and-national-security.txt,http://arxiv.org/abs/2004.07213v2,by_author,Paul Scharre,"ght also pose a serious risk. Paul Scharre 
has pointed out that autonomo"
265,nesta,AI and National Security,Understanding Neural Networks via Feature Visualization: A survey,ai-and-national-security.txt,http://arxiv.org/abs/1904.08939v1,by_author,Jason Yosinski,"gh-
in.html.
49  Nguyen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural "
266,nesta,AI and National Security,Understanding Neural Networks via Feature Visualization: A survey,ai-and-national-security.txt,http://arxiv.org/abs/1904.08939v1,by_author,Jason Yosinski,"reats.html.
117  Nguyen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural "
267,nesta,AI and National Security,Understanding Neural Networks via Feature Visualization: A survey,ai-and-national-security.txt,http://arxiv.org/abs/1904.08939v1,by_author,Jeff Clune,"yen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural networks are eas"
268,nesta,AI and National Security,Understanding Neural Networks via Feature Visualization: A survey,ai-and-national-security.txt,http://arxiv.org/abs/1904.08939v1,by_author,Jeff Clune,"yen, Anh, Jason Yosinski, and Jeff Clune. “Deep neural networks are eas"
269,nesta,2016-2019 Progress Report: Advancing Artificial Intelligence R&D,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",2016-2019-progress-report-advancing-artificial-intelligence-randd.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
270,nesta,2016-2019 Progress Report: Advancing Artificial Intelligence R&D,Interpretable Convolutional Filters with SincNet,2016-2019-progress-report-advancing-artificial-intelligence-randd.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
271,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Domain Knowledge Aided Explainable Artificial Intelligence for Intrusion
  Detection and Response",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/1911.09853v2,by_author,Mike Rogers,"thors of this report, Admiral Mike Rogers, the Director 
of the National"
272,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Miles Brundage,"f
Peter Eckersley
Bobby Filar
Miles Brundage
Ben Garfinkel
Hyrum Anderson
C"
273,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Miles Brundage,"
On February 19 and 20, 2017, Miles Brundage of the Future of 
Humanity Ins"
274,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Miles Brundage,"he Study of Existential Risk 
Miles Brundage, Future of Humanity Institute "
275,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Shahar Avin,"d Mitigation
February  2018
  Shahar Avin
Allan Dafoe
  Jack Clark
Paul "
276,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Shahar Avin,"
Humanity Institute (FHI) and Shahar Avin of the Centre for the 
Study o"
277,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Shahar Avin,"entre for Effective Altruism 
Shahar Avin, Centre for the Study of Exist"
278,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Haydn Belfield,"n Yampolskiy
Jacob Steinhardt
Haydn Belfield
Owain Evans
Dario Amodei
 
9  "
279,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Helen Toner,"foe
  Jack Clark
Paul Scharre
Helen Toner
Thomas Zeitzoff
Peter Eckersle"
280,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Helen Toner,"he Study of Existential Risk 
Helen Toner, Open Philanthropy Project 
An"
281,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Jade Leung,"iddharth Garg, 
Martina Kunz, Jade Leung, Katherine Fletcher, Jan Leike"
282,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Andrew Trask,", Smitha Milli, Itzik Kotler, Andrew Trask, Siddharth Garg, 
Martina Kunz"
283,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Andrew Trask,"r, Open Philanthropy Project 
Andrew Trask, University of Oxford 
Roman Y"
284,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Jack Clark,"8
  Shahar Avin
Allan Dafoe
  Jack Clark
Paul Scharre
Helen Toner
Thoma"
285,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Jack Clark,"inceton University Center  
 
Jack Clark, OpenAI 
Guy Collyer, Organiza"
286,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Peter Eckersley,"e
Helen Toner
Thomas Zeitzoff
Peter Eckersley
Bobby Filar
Miles Brundage
Ben"
287,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Peter Eckersley,"Future of Humanity Institute 
Peter Eckersley, Electronic Frontier Foundatio"
288,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Ben Laurie,"ind/Future of Life Institute 
Ben Laurie, DeepMind 
Jan Leike, DeepMind"
289,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Amanda Askell,"Future of Humanity Institute 
Amanda Askell, Centre for Effective Altruism"
290,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Seán Ó hÉigeartaigh,"har
Michael Page
Heather Roff
Seán Ó hÉigeartaigh
  Clare Lyle
 Joanna Bryson 
G"
291,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Seán Ó hÉigeartaigh,"Future of Humanity Institute 
Seán Ó hÉigeartaigh, Centre for the Study of Exist"
292,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Allan Dafoe,"
February  2018
  Shahar Avin
Allan Dafoe
  Jack Clark
Paul Scharre
Hele"
293,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Allan Dafoe,"cca Crootof, Yale Law School 
Allan Dafoe, Yale University 
Eric Drexler"
294,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Paul Scharre,"Avin
Allan Dafoe
  Jack Clark
Paul Scharre
Helen Toner
Thomas Zeitzoff
Pe"
295,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Paul Scharre,"d/Arizona State University 
 
Paul Scharre, Center for a New American Sec"
296,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Carrick Flynn,"
Ben Garfinkel
Hyrum Anderson
Carrick Flynn
Sebastian Farquhar
Michael Pag"
297,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2004.07213v2,by_author,Carrick Flynn,"Future of Humanity Institute 
Carrick Flynn, Future of Humanity Institute "
298,nesta,"The Malicious Use of AI: Forecasting, Prevention, and Mitigation","`Why didn't you allocate this task to them?' Negotiation-Aware Task
  Allocation and Contrastive Explanation Generation",the-malicious-use-of-ai-forecasting-prevention-and-mitigation.txt,http://arxiv.org/abs/2002.01640v3,by_author,Subbarao Kambhampati,"
Weitzdorfer, Emma Bates, and Subbarao Kambhampati. Any 
remaining errors are the"
299,nesta,Bots at the Gate - Human Rights and ADS,The invisible power of fairness. How machine learning shapes democracy,bots-at-the-gate-human-rights-and-ads.txt,http://arxiv.org/abs/1903.09493v1,by_author,Bruno Lepri,"d-sex-offenders/237340/>
168  Bruno Lepri et al. (2017), “Fair transpare"
300,nesta,Bots at the Gate - Human Rights and ADS,The invisible power of fairness. How machine learning shapes democracy,bots-at-the-gate-human-rights-and-ads.txt,http://arxiv.org/abs/1903.09493v1,by_author,Bruno Lepri,"E-017-33462>.
308 
Ibid.
309  Bruno Lepri et al. (2017), “Fair transpare"
301,nesta,Algorithmic Impact Assessment - A Practical Framework for Public Agency Accountability,"What does it mean to solve the problem of discrimination in hiring?
  Social, technical and legal perspectives from the UK on automated hiring
  systems",algorithmic-impact-assessment-a-practical-framework-for-public-agency-accountability.txt,http://arxiv.org/abs/1910.06144v2,by_author,Lilian Edwards,"ash. L. Rev. 85 (2007): 1249; Lilian Edwards and 
Michael Veale, “Slave to "
302,nesta,Algorithmic Impact Assessment - A Practical Framework for Public Agency Accountability,Manipulating and Measuring Model Interpretability,algorithmic-impact-assessment-a-practical-framework-for-public-agency-accountability.txt,http://arxiv.org/abs/1802.07810v4,by_author,Hanna Wallach," Crawford, Aaron Shapiro and 
Hanna Wallach, “The Problem with Bias: From "
303,nesta,Algorithms in decisionmaking,Interpretability via Model Extraction,algorithms-in-decisionmaking.txt,http://arxiv.org/abs/1706.09773v4,by_author,Osbert Bastani," their own explanations. 
See Osbert Bastani, Carolyn Kim and Hamsa Bastani"
304,nesta,Algorithms in decisionmaking,Interpretability via Model Extraction,algorithms-in-decisionmaking.txt,http://arxiv.org/abs/1706.09773v4,by_author,Carolyn Kim,"nations. 
See Osbert Bastani, Carolyn Kim and Hamsa Bastani, “Interpreta"
305,nesta,Algorithms in decisionmaking,Interpretability via Model Extraction,algorithms-in-decisionmaking.txt,http://arxiv.org/abs/1706.09773v4,by_author,Hamsa Bastani,"bert Bastani, Carolyn Kim and Hamsa Bastani, “Interpretability via Model E"
306,nesta,Algorithms in decisionmaking,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2004.07213v2,by_author,Adrian Weller," 
algorithmic systems”.138 Dr Adrian Weller of the Alan Turing Institute e"
307,nesta,Algorithms in decisionmaking,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2004.07213v2,by_author,Adrian Weller,"development community
43.  Dr Adrian Weller from the Alan Turing Institute"
308,nesta,Algorithms in decisionmaking,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2004.07213v2,by_author,Adrian Weller,"ill not be liable for”.162 Dr Adrian Weller of 
the Alan Turing Institute "
309,nesta,Algorithms in decisionmaking,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2004.07213v2,by_author,Adrian Weller,"al Academy of Engineering; Dr Adrian Weller, Turing Fellow, 
Alan Turing I"
310,nesta,Algorithms in decisionmaking,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"
Principles and codes
49.  Dr Sandra Wachter of the Oxford Internet Institu"
311,nesta,Algorithms in decisionmaking,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"jority of decisions.”
74.  Dr Sandra Wachter of the Oxford Internet Institu"
312,nesta,Algorithms in decisionmaking,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"n our current inquiry too, Dr Sandra Wachter of the Oxford 
Internet Instit"
313,nesta,Algorithms in decisionmaking,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"Advocacy Officer, Liberty; Dr Sandra Wachter, Lawyer 
and Researcher in Dat"
314,nesta,Algorithms in decisionmaking,"""How do I fool you?"": Manipulating User Trust via Misleading Black Box
  Explanations",algorithms-in-decisionmaking.txt,http://arxiv.org/abs/1911.06473v1,by_author,Osbert Bastani," their own explanations. 
See Osbert Bastani, Carolyn Kim and Hamsa Bastani"
315,nesta,AI at the Service of Citizens,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/2004.07213v2,by_author,Allan Dafoe," Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, Owain Evans, Fu"
316,nesta,AI at the Service of Citizens,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio," to artificial intelligence.
(Yoshua Bengio)
The introduction of Artificia"
317,nesta,AI at the Service of Citizens,"Essential requirements for establishing and operating data trusts:
  practical guidance based on a working meeting of fifteen Canadian
  organizations and initiatives",ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/2005.06604v1,by_author_abbreviation,A\. Smith,"y
BIBLIOGRAPHY 
J. Anderson - A. Smith, AI, Robotics, and the Future "
318,nesta,AI at the Service of Citizens,The invisible power of fairness. How machine learning shapes democracy,ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/1903.09493v1,by_author,Antonio Santangelo,"o di Torino and
in particular Antonio Santangelo for their collaboration in dra"
319,nesta,AI at the Service of Citizens,The invisible power of fairness. How machine learning shapes democracy,ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/1903.09493v1,by_author,Bruno Lepri,"a description of an image.
32 Bruno Lepri, Nuria Oliver, Emmanuel Letouz"
320,nesta,AI at the Service of Citizens,The invisible power of fairness. How machine learning shapes democracy,ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/1903.09493v1,by_author_abbreviation,B\. Lepri,"versity of Thessaly, 
2017
78
B. Lepri, N. Oliver, E. Letouzé, et al."
321,nesta,AI at the Service of Citizens,Interpretable Convolutional Filters with SincNet,ai-at-the-service-of-citizens.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio," to artificial intelligence.
(Yoshua Bengio)
The introduction of Artificia"
322,nesta,AI4People Ethical Framework for a Good AI Society,"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",ai4people-ethical-framework-for-a-good-ai-society.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
323,nesta,AI4People Ethical Framework for a Good AI Society,Interpretable Convolutional Filters with SincNet,ai4people-ethical-framework-for-a-good-ai-society.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"Toronto (and now Google) and 
Yoshua Bengio of McGill University, Montreal"
324,nesta,A Practical Guide to Managing Risk in Machine Learning Models,FairLens: Auditing Black-box Clinical Decision Support Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2011.04049v1,by_author,Dino Pedreschi,"Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Giannotti, “A Surve"
325,nesta,A Practical Guide to Managing Risk in Machine Learning Models,"Proposed Guidelines for the Responsible Use of Explainable Machine
  Learning",a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1906.03533v3,by_author,Patrick Hall,"important model metadata.
13  Patrick Hall, Wen Phan, and SriSatish Ambat"
326,nesta,A Practical Guide to Managing Risk in Machine Learning Models,The Doctor Just Won't Accept That!,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1711.08037v2,by_author,Zachary C. Lipton,"explainability in ML is vast, Zachary C. Lipton provides a thorough overview i"
327,nesta,A Practical Guide to Managing Risk in Machine Learning Models,The Mythos of Model Interpretability,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1606.03490v3,by_arxiv_id,1606.03490,"able at https://arxiv.org/abs/1606.03490. Other 
reviews that address "
328,nesta,A Practical Guide to Managing Risk in Machine Learning Models,The Mythos of Model Interpretability,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1606.03490v3,by_author,Zachary C. Lipton,"explainability in ML is vast, Zachary C. Lipton provides a thorough overview i"
329,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1806.09936v1,by_author,Dino Pedreschi,"Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Giannotti, “A Surve"
330,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1806.09936v1,by_author,Fosca Giannotti,"o Turini, Dino Pedreschi, and Fosca Giannotti, “A Survey Of Methods For 
Exp"
331,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1806.09936v1,by_author,Riccardo Guidotti," survey 
of such methods, see Riccardo Guidotti, Anna Monreale, Franco Turini,"
332,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1806.09936v1,by_author,Anna Monreale,"thods, see Riccardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi"
333,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Open the Black Box Data-Driven Explanation of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1806.09936v1,by_author,Franco Turini,"ardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Gia"
334,nesta,A Practical Guide to Managing Risk in Machine Learning Models,GLocalX -- From Local to Global Explanations of Black Box AI Models,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2101.07685v2,by_author,Riccardo Guidotti," survey 
of such methods, see Riccardo Guidotti, Anna Monreale, Franco Turini,"
335,nesta,A Practical Guide to Managing Risk in Machine Learning Models,GLocalX -- From Local to Global Explanations of Black Box AI Models,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2101.07685v2,by_author,Anna Monreale,"thods, see Riccardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi"
336,nesta,A Practical Guide to Managing Risk in Machine Learning Models,GLocalX -- From Local to Global Explanations of Black Box AI Models,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2101.07685v2,by_author,Franco Turini,"ardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Gia"
337,nesta,A Practical Guide to Managing Risk in Machine Learning Models,GLocalX -- From Local to Global Explanations of Black Box AI Models,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2101.07685v2,by_author,Dino Pedreschi,"Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Giannotti, “A Surve"
338,nesta,A Practical Guide to Managing Risk in Machine Learning Models,GLocalX -- From Local to Global Explanations of Black Box AI Models,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/2101.07685v2,by_author,Fosca Giannotti,"o Turini, Dino Pedreschi, and Fosca Giannotti, “A Survey Of Methods For 
Exp"
339,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Local Rule-Based Explanations of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1805.10820v1,by_author,Riccardo Guidotti," survey 
of such methods, see Riccardo Guidotti, Anna Monreale, Franco Turini,"
340,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Local Rule-Based Explanations of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1805.10820v1,by_author,Anna Monreale,"thods, see Riccardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi"
341,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Local Rule-Based Explanations of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1805.10820v1,by_author,Dino Pedreschi,"Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Giannotti, “A Surve"
342,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Local Rule-Based Explanations of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1805.10820v1,by_author,Franco Turini,"ardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi, and Fosca Gia"
343,nesta,A Practical Guide to Managing Risk in Machine Learning Models,Local Rule-Based Explanations of Black Box Decision Systems,a-practical-guide-to-managing-risk-in-machine-learning-models.txt,http://arxiv.org/abs/1805.10820v1,by_author,Fosca Giannotti,"o Turini, Dino Pedreschi, and Fosca Giannotti, “A Survey Of Methods For 
Exp"
344,nesta,Governing AI - Upholding Human Rights and Dignity,Model Cards for Model Reporting,governing-ai-upholding-human-rights-and-dignity.txt,http://arxiv.org/abs/1810.03993v2,by_author,Timnit Gebru,"See, e.g., Joy Buolamwini and Timnit Gebru “Gender Shades: Intersectional"
345,nesta,Governing AI - Upholding Human Rights and Dignity,"""The Human Body is a Black Box"": Supporting Clinical Decision-Making
  with Deep Learning",governing-ai-upholding-human-rights-and-dignity.txt,http://arxiv.org/abs/1911.08089v2,by_author,Madeleine Elish,"with-it-4622ec1566d5.
26
 See Madeleine Elish and danah boyd, Situating Meth"
346,nesta,Regulation on Autonomous Driving,Model Cards for Model Reporting,regulation-on-autonomous-driving.txt,http://arxiv.org/abs/1810.03993v2,by_author,Timnit Gebru,"See, e.g., Joy Buolamwini and Timnit Gebru “Gender Shades: Intersectional"
347,nesta,Regulation on Autonomous Driving,"""The Human Body is a Black Box"": Supporting Clinical Decision-Making
  with Deep Learning",regulation-on-autonomous-driving.txt,http://arxiv.org/abs/1911.08089v2,by_author,Madeleine Elish,"with-it-4622ec1566d5.
26
 See Madeleine Elish and danah boyd, Situating Meth"
348,nesta,Unfairness by algorithm,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",unfairness-by-algorithm.txt,http://arxiv.org/abs/2005.05906v1,by_author,Sandra Wachter,"ica.org/series/machine-bias
• Sandra Wachter, Brent Mittelstadt, & Luciano "
349,nesta,Unfairness by algorithm,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",unfairness-by-algorithm.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"achine-bias
• Sandra Wachter, Brent Mittelstadt, & Luciano Floridi, Why a righ"
350,nesta,Privacy 2030 - A New Vision for Europe,TED: Teaching AI to Explain its Decisions,privacy-2030-a-new-vision-for-europe.txt,http://arxiv.org/abs/1811.04896v2,by_author,Murray Campbell,"pg. 20) Evan Provan 
(pg. 21) Murray Campbell 
(pg. 22) Markus Spiske 
(pg. "
351,nesta,Artificial Intelligence: a strategic vision for Luxembourg,Model Cards for Model Reporting,artificial-intelligence-a-strategic-vision-for-luxembourg.txt,http://arxiv.org/abs/1810.03993v2,by_arxiv_id,1810.03993,"ine at https://arxiv.org/
abs/1810.03993
For more see “Datasheets for "
352,nesta,Perspectives on Issues in AI Governance,Model Cards for Model Reporting,perspectives-on-issues-in-ai-governance.txt,http://arxiv.org/abs/1810.03993v2,by_arxiv_id,1810.03993,"ine at https://arxiv.org/
abs/1810.03993
For more see “Datasheets for "
353,nesta,Finland's Age of Artificial Intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",finlands-age-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"loper, Unity Technologies Oy 
Samuel Kaski, Academy Professor, Aalto Univ"
354,nesta,Finland's Age of Artificial Intelligence,"A Decision-Theoretic Approach for Model Interpretability in Bayesian
  Framework",finlands-age-of-artificial-intelligence.txt,http://arxiv.org/abs/1910.09358v2,by_author,Samuel Kaski,"Anita Lehikoinen 
Minna Aila 
Samuel Kaski 
Ilkka Kivimäki 
Merja Fischer"
355,nesta,Mapping Regulatory Proposals For Artificial Intelligence In Europe,"What does it mean to solve the problem of discrimination in hiring?
  Social, technical and legal perspectives from the UK on automated hiring
  systems",mapping-regulatory-proposals-for-artificial-intelligence-in-europe.txt,http://arxiv.org/abs/1910.06144v2,by_author_abbreviation,L\. Edwards," remedy you are looking for”, L. Edwards; and M. Veale, 2017, ​availabl"
356,nesta,Mapping Regulatory Proposals For Artificial Intelligence In Europe,"Why Fairness Cannot Be Automated: Bridging the Gap Between EU
  Non-Discrimination Law and AI",mapping-regulatory-proposals-for-artificial-intelligence-in-europe.txt,http://arxiv.org/abs/2005.05906v1,by_author,Brent Mittelstadt,"ion 
Regulation”, S. Watcher; Brent Mittelstadt; and Luciano Floridi, Internat"
357,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","An Experimentation Platform for Explainable Coalition Situational
  Understanding",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2010.14388v2,by_author_abbreviation,H\. Taylor,"tegration with AI.
7  Russell H. Taylor, “A Perspective on Medical Rob"
358,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"s that are investing in AI.
- Yoshua Bengio, Director, Montreal Institute "
359,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"d some words of 
caution from Yoshua Bengio, Director of the 
Montréal Ins"
360,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"er perspective was offered by Yoshua Bengio. 
As discussed above, Dr. Beng"
361,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"m. 
Element AI, co-founded by Yoshua Bengio, is part 
research lab and par"
362,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable
  Claims",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2004.07213v2,by_author,Yoshua Bengio,"itute for Learning Algorithms Yoshua Bengio, Director, Professor, Universi"
363,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","`Why didn't you allocate this task to them?' Negotiation-Aware Task
  Allocation and Contrastive Explanation Generation",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2002.01640v3,by_author,Subbarao Kambhampati," research in Canada. In fact 
Subbarao Kambhampati of the Association for the 
Ad"
364,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems","`Why didn't you allocate this task to them?' Negotiation-Aware Task
  Allocation and Contrastive Explanation Generation",integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/2002.01640v3,by_author,Subbarao Kambhampati,"botics (by 
video conference)
Subbarao Kambhampati, Professor, Arizona State 
Uni"
365,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Interpretable Convolutional Filters with SincNet,integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"s that are investing in AI.
- Yoshua Bengio, Director, Montreal Institute "
366,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Interpretable Convolutional Filters with SincNet,integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"d some words of 
caution from Yoshua Bengio, Director of the 
Montréal Ins"
367,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Interpretable Convolutional Filters with SincNet,integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"er perspective was offered by Yoshua Bengio. 
As discussed above, Dr. Beng"
368,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Interpretable Convolutional Filters with SincNet,integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"m. 
Element AI, co-founded by Yoshua Bengio, is part 
research lab and par"
369,nesta,"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Interpretable Convolutional Filters with SincNet,integrating-robotics-artificial-intelligence-and-3d-printing-technologies-into-canadas-healthcare-systems.txt,http://arxiv.org/abs/1811.09725v2,by_author,Yoshua Bengio,"itute for Learning Algorithms Yoshua Bengio, Director, Professor, Universi"
